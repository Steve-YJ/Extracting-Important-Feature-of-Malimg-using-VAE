{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03. Training MNIST_AAE_Add_loss_module.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyODXtE5zCDFa36awn2dEkd0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steve-YJ/Extracting-Important-Feature-of-Malimg-using-VAE/blob/master/03_Training_MNIST_AAE_Add_loss_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82A3hF-rzYfW",
        "colab_type": "text"
      },
      "source": [
        "# 03. Training MNIST_AAE\n",
        "\n",
        "1st. Run AAE Architecture on MNIST dataset<br>\n",
        "2nd. Add Loss Plot<br> \n",
        "3rd. be familiar with Deep Learning Process<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFUH7VEp5Bz3",
        "colab_type": "text"
      },
      "source": [
        "## Reference\n",
        "* god....!: https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/aae/aae.py\n",
        "\n",
        "### What I want to do\n",
        "from 20.07.15.wed<br>\n",
        "<br>\n",
        "\n",
        "* run AAE -> Done\n",
        "* practicing train -> Do more\n",
        "* practice & make my own work flow -> Make Template<br>\n",
        "    * continue: https://github.com/Steve-YJ/Colab_Exercise/blob/master/Again_Training_Exp05_Just_20Epochs.ipynb\n",
        "\n",
        "---\n",
        "### Log\n",
        "1. 20.07.15. Train 200 Epochs <- Original\n",
        "2. 20.07.16. Change Parameters & Train 200 Epochs => Good\n",
        "3. 20.07.16. Add module's \n",
        "    * Loss Graph\n",
        "        * Generator, Discriminator and ELBO Loss\n",
        "        \n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Reference<br>\n",
        "* Add\n",
        "    * Loss plot: Generator, Discriminator ...\n",
        "    * save plot every 10 Epochs\n",
        "    * plot latent vector Every Epoch\n",
        "        * save it every Epoch\n",
        "    * save model's state_dict per 10Epoch\n",
        "    * save latent vector per 10Epoch\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW-vEZgD0DvL",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "Start it<br><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fS38MY-58P9",
        "colab_type": "text"
      },
      "source": [
        "## 00. Mount Drive\n",
        "\n",
        "* If you use colab, first mount driver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NJaYzi-85Dn",
        "colab_type": "text"
      },
      "source": [
        "First, always check if your GPU is possible or not\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKjLf6sh4fkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "46ea56f4-6896-4e0e-a1c9-c6ac6e6bef1f"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jul 17 05:51:10 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kss7fKHM9LFj",
        "colab_type": "text"
      },
      "source": [
        "set 'autoreload'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t13_t5qH6DPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIGr7YlF9TZi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGPG-pJo6DSE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ec0f7314-22bf-469c-dfe1-9dfaec740317"
      },
      "source": [
        "# mount drive(Drive Mount)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A-1bsK69jsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49ebd610-aff9-49a9-fbf9-4590285b4c6e"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgOqQ4rm9jk5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "4f0ba23a-124d-401b-a9d2-d9430f75acca"
      },
      "source": [
        "# %cd drive/My\\ Drive/Post_InfoSec_Exp\n",
        "\n",
        "% cd '/content/drive/My Drive/Post_InfoSec_Exp_200715'\n",
        "! ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Post_InfoSec_Exp_200715\n",
            "'01. MNIST_AAE.ipynb의 사본'\t\t\t\t  data\t\t images\n",
            "'02. Training MNIST_AAE_Parameter Tunning.ipynb의 사본'   Exp02_images\n",
            "'03. Training MNIST_AAE_Add_loss_module.ipynb'\t\t  Exp03_images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo9M83Ix6D3g",
        "colab_type": "text"
      },
      "source": [
        "## 01. Library Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3BsDGHI6DUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision.utils import save_image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# 데이터 전처리는 주로 torchvision에서 하는데?\n",
        "# e.g torchivision.transforms, torchivision.save_image, torchivision.datasets\n",
        "\n",
        "# 직접적으로 train과 관련된 부분은 torch를 활용한다\n",
        "# torch.utils.data DataLoader, torch.autograd Variable, torch, torch.nn, torch.nn.functional"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOkr6zX6-K8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os library를 사용해 directory를 만드는 방법을 배워보자\n",
        "\n",
        "os.makedirs(\"Exp03_images\", exist_ok=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUURX5ro-Zsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "968cfaa6-0ac3-42b4-e905-54a24bb8c987"
      },
      "source": [
        "! ls  # Exp03_images directory가 생성된 것을 확인할 수 있다"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'01. MNIST_AAE.ipynb의 사본'\t\t\t\t  data\t\t images\n",
            "'02. Training MNIST_AAE_Parameter Tunning.ipynb의 사본'   Exp02_images\n",
            "'03. Training MNIST_AAE_Add_loss_module.ipynb'\t\t  Exp03_images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlTLvJ0u6GT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image shape를 정하고 간다\n",
        "# 1channel 32 width 32 height\n",
        "\n",
        "img_shape = (1, 32, 32)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Phe1OoZ1cqx",
        "colab_type": "text"
      },
      "source": [
        "Q. 모델의 파라미터를 어디에서 정해주면 좋을까?<br>\n",
        "\n",
        "A1. Library Import 단계에서?<br>\n",
        "A2. Training을 시작하기 전?(<- 후자가 좀 더 낫지 않을까?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaUKfNkO6Hfm",
        "colab_type": "text"
      },
      "source": [
        "## 02. Data Preprocessing\n",
        "* Load dataset\n",
        "* preprocess it\n",
        "    * transforms\n",
        "    * make custom dataset\n",
        "    * train_test split\n",
        "    * make train loader, test loader\n",
        "\n",
        "* work Flow\n",
        "    * transforms module 사용해서 image data compose\n",
        "        * size 조정 및 normalize, tensor 변환\n",
        "        * Image Folder를 이용해 dataload\n",
        "        * dataset split: train dataset, test dataset\n",
        "        * DataLoader로 batch단위 dataset 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WP2xo2a1yuY",
        "colab_type": "text"
      },
      "source": [
        "### 2-1. Configure data loader\n",
        "* 본 Tutorial에서는 Data Loader에 대해서만 신경써주면 될 것 같다\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "Parameter settings<br>\n",
        "* for preprocessing\n",
        "    * transforms.Resize: 32\n",
        "    * transforms.Normalize: 0.5(mean), 0.5(std)\n",
        "* for Data Loader\n",
        "    * batch_size: 64\n",
        "    * shuffle: True(shuffle it)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81yyEjRl6GWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configure data loader\n",
        "\n",
        "os.makedirs(\"./data/mnist\", exist_ok=True)  # make directory: ./data/mnist\n",
        "\n",
        "# Define DataLoader: Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset. \n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"./data/mnist\",  # root\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform = transforms.Compose(\n",
        "            [transforms.Resize(32),  # Resizing\n",
        "             transforms.ToTensor(),  # convert numpy to tensor\n",
        "             transforms.Normalize([0.5], [0.5])]  # transforms.Normalize(): Normalize a tensor image with mean and standard deviation.\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOzcPwFi6R5b",
        "colab_type": "text"
      },
      "source": [
        "# 03. Define Adversarial Variational AutoEncoder Class\n",
        "\n",
        "* Encoder Class\n",
        "* Decoder Class\n",
        "* Discriminator Class\n",
        "* Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHqN9lQ-CkxD",
        "colab_type": "text"
      },
      "source": [
        "### reparameterization module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5BhTQekCnhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reparameterization(mu, logvar):\n",
        "    std = torch.exp(logvar / 2)\n",
        "    sampled_z = Variable(Tensor(np.random.normal(0, 1, (mu.size(0), 10))))  # np.random.normal(): Draw random samples from a normal (Gaussian) distribution.\n",
        "                                                                            # mean:0, std: 1\n",
        "                                                                            # (batch_size, 10)\n",
        "    z = sampled_z * std + mu  # latent vector z\n",
        "    return z"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v9NKI-4_rqd",
        "colab_type": "text"
      },
      "source": [
        "### 3-1. Encoder Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3uDND6p6Vf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):  # initialization\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(  # nn.Sequential: A sequential container. Modules will be added to it in the order they are passed in the constructor. Alternatively, an ordered dict of modules can also be passed in.\n",
        "            nn.Linear(int(np.prod(img_shape)), 512),  # Linear Transform\n",
        "            nn.LeakyReLU(0.2, inplace=True),  # Activation Function\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )  \n",
        "        \n",
        "        self.mu = nn.Linear(512, 10)      # 10: latent dim\n",
        "        self.logvar = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.shape[0], -1)  # 1 x (32*32)\n",
        "        x = self.model(img_flat)  # extract_vector: (batch_size, 10)\n",
        "        mu = self.mu(x)\n",
        "        logvar = self.logvar(x)\n",
        "        z = reparameterization(mu, logvar)\n",
        "        return z\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB6wx4RvGZcX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8144d66c-1329-4401-dfb3-deea8f7beeab"
      },
      "source": [
        "np.prod(img_shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tbleCgU_qhk",
        "colab_type": "text"
      },
      "source": [
        "### 3-2. Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-kcpVe6BLNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(10, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, int(np.prod(img_shape))),  # (batch_size, 1024)\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img_flat = self.model(z)\n",
        "        img = img_flat.view(img_flat.shape[0], *img_shape)\n",
        "        return img"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XByElreCCU5",
        "colab_type": "text"
      },
      "source": [
        "### 3-3. Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxS4PlrvCCB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(10, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        validity = self.model(z)\n",
        "        return validity"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16KAJde9XWcV",
        "colab_type": "text"
      },
      "source": [
        "### Define Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXszRozK6V8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use binary cross-entropy loss\n",
        "\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "pixelwise_loss = torch.nn.L1Loss()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inxN0iHvXQ02",
        "colab_type": "text"
      },
      "source": [
        "### Initialize Generator & Discriminator\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmPLPvZ0XiO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize generator and discriminator\n",
        "encoder = Encoder()\n",
        "decoder = Decoder()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    encoder.cuda()\n",
        "    decoder.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "    pixelwise_loss.cuda()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2veA6ejHVfY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "594b2cde-196e-4760-a268-41387c01abb8"
      },
      "source": [
        "discriminator.parameters()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f2fadb6b3b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWYBdu_SDWA7",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHDEU370UNRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_G = torch.optim.Adam(\n",
        "    itertools.chain(encoder.parameters(), decoder.parameters()), lr=0.0002, betas=(0.5, 0.999)\n",
        ")\n",
        "\n",
        "# reduce optimizer_D's lr 0.0002 to 0.0002/50\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002/50, betas=(0.5, 0.999))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLBGg5ucU_Do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_image(n_row, batches_done):\n",
        "    \"\"\"Saves a grid of generated digits\"\"\"\n",
        "    # Sample noise\n",
        "    z = Variable(Tensor(np.random.normal(0, 1, (n_row ** 2, 10))))\n",
        "    gen_imgs = decoder(z)\n",
        "    save_image(gen_imgs.data, \"Exp03_images/%d.png\" % batches_done, nrow=n_row, normalize=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqbb-ZkS7d9x",
        "colab_type": "text"
      },
      "source": [
        "## 04. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_quS-4M50mHh",
        "colab_type": "text"
      },
      "source": [
        "### Set parameters\n",
        "\n",
        "* lr: learning rate\n",
        "* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4Yk-d6Z6V_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4874139f-42dd-4b0a-f534-a11ec5d53945"
      },
      "source": [
        "for epoch in range(200):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        encoded_imgs = encoder(real_imgs)\n",
        "        decoded_imgs = decoder(encoded_imgs)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = 0.001 * adversarial_loss(discriminator(encoded_imgs), valid) + 0.999 * pixelwise_loss(\n",
        "            decoded_imgs, real_imgs\n",
        "        )\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Sample noise as discriminator ground truth\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], 10))))\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(z), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(encoded_imgs.detach()), fake)\n",
        "        d_loss = 0.5 * (real_loss + fake_loss)\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, 200, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "        )\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % 400 == 0:\n",
        "            sample_image(n_row=10, batches_done=batches_done)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "[Epoch 23/200] [Batch 638/938] [D loss: 0.631937] [G loss: 0.067940]\n",
            "[Epoch 23/200] [Batch 639/938] [D loss: 0.645175] [G loss: 0.073549]\n",
            "[Epoch 23/200] [Batch 640/938] [D loss: 0.660817] [G loss: 0.078790]\n",
            "[Epoch 23/200] [Batch 641/938] [D loss: 0.648555] [G loss: 0.083500]\n",
            "[Epoch 23/200] [Batch 642/938] [D loss: 0.666250] [G loss: 0.078430]\n",
            "[Epoch 23/200] [Batch 643/938] [D loss: 0.661747] [G loss: 0.074199]\n",
            "[Epoch 23/200] [Batch 644/938] [D loss: 0.640669] [G loss: 0.077831]\n",
            "[Epoch 23/200] [Batch 645/938] [D loss: 0.625773] [G loss: 0.079463]\n",
            "[Epoch 23/200] [Batch 646/938] [D loss: 0.669482] [G loss: 0.074068]\n",
            "[Epoch 23/200] [Batch 647/938] [D loss: 0.696463] [G loss: 0.063480]\n",
            "[Epoch 23/200] [Batch 648/938] [D loss: 0.639407] [G loss: 0.075385]\n",
            "[Epoch 23/200] [Batch 649/938] [D loss: 0.626762] [G loss: 0.075299]\n",
            "[Epoch 23/200] [Batch 650/938] [D loss: 0.627017] [G loss: 0.071621]\n",
            "[Epoch 23/200] [Batch 651/938] [D loss: 0.625611] [G loss: 0.078012]\n",
            "[Epoch 23/200] [Batch 652/938] [D loss: 0.645992] [G loss: 0.079303]\n",
            "[Epoch 23/200] [Batch 653/938] [D loss: 0.662737] [G loss: 0.077564]\n",
            "[Epoch 23/200] [Batch 654/938] [D loss: 0.677176] [G loss: 0.071792]\n",
            "[Epoch 23/200] [Batch 655/938] [D loss: 0.676552] [G loss: 0.084797]\n",
            "[Epoch 23/200] [Batch 656/938] [D loss: 0.626172] [G loss: 0.071173]\n",
            "[Epoch 23/200] [Batch 657/938] [D loss: 0.616756] [G loss: 0.075145]\n",
            "[Epoch 23/200] [Batch 658/938] [D loss: 0.670441] [G loss: 0.070207]\n",
            "[Epoch 23/200] [Batch 659/938] [D loss: 0.634131] [G loss: 0.067825]\n",
            "[Epoch 23/200] [Batch 660/938] [D loss: 0.696055] [G loss: 0.072802]\n",
            "[Epoch 23/200] [Batch 661/938] [D loss: 0.650240] [G loss: 0.082574]\n",
            "[Epoch 23/200] [Batch 662/938] [D loss: 0.612819] [G loss: 0.080810]\n",
            "[Epoch 23/200] [Batch 663/938] [D loss: 0.598490] [G loss: 0.071028]\n",
            "[Epoch 23/200] [Batch 664/938] [D loss: 0.628386] [G loss: 0.065649]\n",
            "[Epoch 23/200] [Batch 665/938] [D loss: 0.611381] [G loss: 0.074516]\n",
            "[Epoch 23/200] [Batch 666/938] [D loss: 0.657940] [G loss: 0.076021]\n",
            "[Epoch 23/200] [Batch 667/938] [D loss: 0.663280] [G loss: 0.068755]\n",
            "[Epoch 23/200] [Batch 668/938] [D loss: 0.658250] [G loss: 0.065938]\n",
            "[Epoch 23/200] [Batch 669/938] [D loss: 0.671607] [G loss: 0.071992]\n",
            "[Epoch 23/200] [Batch 670/938] [D loss: 0.618742] [G loss: 0.078869]\n",
            "[Epoch 23/200] [Batch 671/938] [D loss: 0.663242] [G loss: 0.071807]\n",
            "[Epoch 23/200] [Batch 672/938] [D loss: 0.644280] [G loss: 0.067004]\n",
            "[Epoch 23/200] [Batch 673/938] [D loss: 0.636705] [G loss: 0.076727]\n",
            "[Epoch 23/200] [Batch 674/938] [D loss: 0.655370] [G loss: 0.076750]\n",
            "[Epoch 23/200] [Batch 675/938] [D loss: 0.619967] [G loss: 0.074413]\n",
            "[Epoch 23/200] [Batch 676/938] [D loss: 0.608578] [G loss: 0.073196]\n",
            "[Epoch 23/200] [Batch 677/938] [D loss: 0.667370] [G loss: 0.073165]\n",
            "[Epoch 23/200] [Batch 678/938] [D loss: 0.636674] [G loss: 0.083497]\n",
            "[Epoch 23/200] [Batch 679/938] [D loss: 0.621996] [G loss: 0.080309]\n",
            "[Epoch 23/200] [Batch 680/938] [D loss: 0.648461] [G loss: 0.073918]\n",
            "[Epoch 23/200] [Batch 681/938] [D loss: 0.666315] [G loss: 0.074791]\n",
            "[Epoch 23/200] [Batch 682/938] [D loss: 0.639181] [G loss: 0.069518]\n",
            "[Epoch 23/200] [Batch 683/938] [D loss: 0.627175] [G loss: 0.077775]\n",
            "[Epoch 23/200] [Batch 684/938] [D loss: 0.625391] [G loss: 0.067962]\n",
            "[Epoch 23/200] [Batch 685/938] [D loss: 0.655426] [G loss: 0.071083]\n",
            "[Epoch 23/200] [Batch 686/938] [D loss: 0.631117] [G loss: 0.077223]\n",
            "[Epoch 23/200] [Batch 687/938] [D loss: 0.625422] [G loss: 0.067901]\n",
            "[Epoch 23/200] [Batch 688/938] [D loss: 0.659770] [G loss: 0.079572]\n",
            "[Epoch 23/200] [Batch 689/938] [D loss: 0.664589] [G loss: 0.073123]\n",
            "[Epoch 23/200] [Batch 690/938] [D loss: 0.657017] [G loss: 0.075040]\n",
            "[Epoch 23/200] [Batch 691/938] [D loss: 0.660779] [G loss: 0.074522]\n",
            "[Epoch 23/200] [Batch 692/938] [D loss: 0.677407] [G loss: 0.069270]\n",
            "[Epoch 23/200] [Batch 693/938] [D loss: 0.649806] [G loss: 0.073198]\n",
            "[Epoch 23/200] [Batch 694/938] [D loss: 0.644723] [G loss: 0.079734]\n",
            "[Epoch 23/200] [Batch 695/938] [D loss: 0.624869] [G loss: 0.065728]\n",
            "[Epoch 23/200] [Batch 696/938] [D loss: 0.647505] [G loss: 0.080930]\n",
            "[Epoch 23/200] [Batch 697/938] [D loss: 0.657781] [G loss: 0.071167]\n",
            "[Epoch 23/200] [Batch 698/938] [D loss: 0.628136] [G loss: 0.071838]\n",
            "[Epoch 23/200] [Batch 699/938] [D loss: 0.659714] [G loss: 0.083023]\n",
            "[Epoch 23/200] [Batch 700/938] [D loss: 0.647084] [G loss: 0.074178]\n",
            "[Epoch 23/200] [Batch 701/938] [D loss: 0.597794] [G loss: 0.068368]\n",
            "[Epoch 23/200] [Batch 702/938] [D loss: 0.633343] [G loss: 0.079119]\n",
            "[Epoch 23/200] [Batch 703/938] [D loss: 0.635686] [G loss: 0.082041]\n",
            "[Epoch 23/200] [Batch 704/938] [D loss: 0.633995] [G loss: 0.072423]\n",
            "[Epoch 23/200] [Batch 705/938] [D loss: 0.641050] [G loss: 0.070917]\n",
            "[Epoch 23/200] [Batch 706/938] [D loss: 0.668984] [G loss: 0.066768]\n",
            "[Epoch 23/200] [Batch 707/938] [D loss: 0.611510] [G loss: 0.078554]\n",
            "[Epoch 23/200] [Batch 708/938] [D loss: 0.677181] [G loss: 0.066209]\n",
            "[Epoch 23/200] [Batch 709/938] [D loss: 0.655657] [G loss: 0.072613]\n",
            "[Epoch 23/200] [Batch 710/938] [D loss: 0.620624] [G loss: 0.072504]\n",
            "[Epoch 23/200] [Batch 711/938] [D loss: 0.640990] [G loss: 0.070626]\n",
            "[Epoch 23/200] [Batch 712/938] [D loss: 0.634332] [G loss: 0.078400]\n",
            "[Epoch 23/200] [Batch 713/938] [D loss: 0.664946] [G loss: 0.071734]\n",
            "[Epoch 23/200] [Batch 714/938] [D loss: 0.632885] [G loss: 0.070874]\n",
            "[Epoch 23/200] [Batch 715/938] [D loss: 0.643590] [G loss: 0.073003]\n",
            "[Epoch 23/200] [Batch 716/938] [D loss: 0.653186] [G loss: 0.075160]\n",
            "[Epoch 23/200] [Batch 717/938] [D loss: 0.633105] [G loss: 0.068805]\n",
            "[Epoch 23/200] [Batch 718/938] [D loss: 0.667416] [G loss: 0.079458]\n",
            "[Epoch 23/200] [Batch 719/938] [D loss: 0.619111] [G loss: 0.067632]\n",
            "[Epoch 23/200] [Batch 720/938] [D loss: 0.620625] [G loss: 0.078959]\n",
            "[Epoch 23/200] [Batch 721/938] [D loss: 0.663739] [G loss: 0.077868]\n",
            "[Epoch 23/200] [Batch 722/938] [D loss: 0.676322] [G loss: 0.075570]\n",
            "[Epoch 23/200] [Batch 723/938] [D loss: 0.631253] [G loss: 0.068274]\n",
            "[Epoch 23/200] [Batch 724/938] [D loss: 0.635128] [G loss: 0.074146]\n",
            "[Epoch 23/200] [Batch 725/938] [D loss: 0.654595] [G loss: 0.070466]\n",
            "[Epoch 23/200] [Batch 726/938] [D loss: 0.642608] [G loss: 0.074496]\n",
            "[Epoch 23/200] [Batch 727/938] [D loss: 0.641793] [G loss: 0.079715]\n",
            "[Epoch 23/200] [Batch 728/938] [D loss: 0.652722] [G loss: 0.069525]\n",
            "[Epoch 23/200] [Batch 729/938] [D loss: 0.624858] [G loss: 0.067639]\n",
            "[Epoch 23/200] [Batch 730/938] [D loss: 0.639039] [G loss: 0.075849]\n",
            "[Epoch 23/200] [Batch 731/938] [D loss: 0.632292] [G loss: 0.072703]\n",
            "[Epoch 23/200] [Batch 732/938] [D loss: 0.644506] [G loss: 0.074976]\n",
            "[Epoch 23/200] [Batch 733/938] [D loss: 0.639463] [G loss: 0.075250]\n",
            "[Epoch 23/200] [Batch 734/938] [D loss: 0.671119] [G loss: 0.074163]\n",
            "[Epoch 23/200] [Batch 735/938] [D loss: 0.628476] [G loss: 0.078211]\n",
            "[Epoch 23/200] [Batch 736/938] [D loss: 0.659061] [G loss: 0.073390]\n",
            "[Epoch 23/200] [Batch 737/938] [D loss: 0.653087] [G loss: 0.074752]\n",
            "[Epoch 23/200] [Batch 738/938] [D loss: 0.663467] [G loss: 0.078823]\n",
            "[Epoch 23/200] [Batch 739/938] [D loss: 0.637151] [G loss: 0.080027]\n",
            "[Epoch 23/200] [Batch 740/938] [D loss: 0.632138] [G loss: 0.074280]\n",
            "[Epoch 23/200] [Batch 741/938] [D loss: 0.610447] [G loss: 0.070901]\n",
            "[Epoch 23/200] [Batch 742/938] [D loss: 0.608027] [G loss: 0.075645]\n",
            "[Epoch 23/200] [Batch 743/938] [D loss: 0.613696] [G loss: 0.077342]\n",
            "[Epoch 23/200] [Batch 744/938] [D loss: 0.622094] [G loss: 0.070813]\n",
            "[Epoch 23/200] [Batch 745/938] [D loss: 0.623566] [G loss: 0.081359]\n",
            "[Epoch 23/200] [Batch 746/938] [D loss: 0.644299] [G loss: 0.070564]\n",
            "[Epoch 23/200] [Batch 747/938] [D loss: 0.644911] [G loss: 0.070395]\n",
            "[Epoch 23/200] [Batch 748/938] [D loss: 0.608524] [G loss: 0.075908]\n",
            "[Epoch 23/200] [Batch 749/938] [D loss: 0.647320] [G loss: 0.072636]\n",
            "[Epoch 23/200] [Batch 750/938] [D loss: 0.628065] [G loss: 0.075350]\n",
            "[Epoch 23/200] [Batch 751/938] [D loss: 0.671958] [G loss: 0.075068]\n",
            "[Epoch 23/200] [Batch 752/938] [D loss: 0.632858] [G loss: 0.067879]\n",
            "[Epoch 23/200] [Batch 753/938] [D loss: 0.658134] [G loss: 0.071268]\n",
            "[Epoch 23/200] [Batch 754/938] [D loss: 0.627956] [G loss: 0.074362]\n",
            "[Epoch 23/200] [Batch 755/938] [D loss: 0.661579] [G loss: 0.070826]\n",
            "[Epoch 23/200] [Batch 756/938] [D loss: 0.660348] [G loss: 0.072651]\n",
            "[Epoch 23/200] [Batch 757/938] [D loss: 0.631744] [G loss: 0.073764]\n",
            "[Epoch 23/200] [Batch 758/938] [D loss: 0.651746] [G loss: 0.075294]\n",
            "[Epoch 23/200] [Batch 759/938] [D loss: 0.633554] [G loss: 0.077046]\n",
            "[Epoch 23/200] [Batch 760/938] [D loss: 0.688764] [G loss: 0.075569]\n",
            "[Epoch 23/200] [Batch 761/938] [D loss: 0.662164] [G loss: 0.078724]\n",
            "[Epoch 23/200] [Batch 762/938] [D loss: 0.595387] [G loss: 0.080649]\n",
            "[Epoch 23/200] [Batch 763/938] [D loss: 0.624404] [G loss: 0.076575]\n",
            "[Epoch 23/200] [Batch 764/938] [D loss: 0.598824] [G loss: 0.069279]\n",
            "[Epoch 23/200] [Batch 765/938] [D loss: 0.681465] [G loss: 0.078130]\n",
            "[Epoch 23/200] [Batch 766/938] [D loss: 0.623409] [G loss: 0.072921]\n",
            "[Epoch 23/200] [Batch 767/938] [D loss: 0.646253] [G loss: 0.073111]\n",
            "[Epoch 23/200] [Batch 768/938] [D loss: 0.625736] [G loss: 0.079452]\n",
            "[Epoch 23/200] [Batch 769/938] [D loss: 0.654998] [G loss: 0.069329]\n",
            "[Epoch 23/200] [Batch 770/938] [D loss: 0.672164] [G loss: 0.076074]\n",
            "[Epoch 23/200] [Batch 771/938] [D loss: 0.662127] [G loss: 0.067836]\n",
            "[Epoch 23/200] [Batch 772/938] [D loss: 0.650051] [G loss: 0.073283]\n",
            "[Epoch 23/200] [Batch 773/938] [D loss: 0.623938] [G loss: 0.077058]\n",
            "[Epoch 23/200] [Batch 774/938] [D loss: 0.624215] [G loss: 0.071440]\n",
            "[Epoch 23/200] [Batch 775/938] [D loss: 0.651296] [G loss: 0.075584]\n",
            "[Epoch 23/200] [Batch 776/938] [D loss: 0.631140] [G loss: 0.077843]\n",
            "[Epoch 23/200] [Batch 777/938] [D loss: 0.651546] [G loss: 0.078763]\n",
            "[Epoch 23/200] [Batch 778/938] [D loss: 0.637467] [G loss: 0.077286]\n",
            "[Epoch 23/200] [Batch 779/938] [D loss: 0.627341] [G loss: 0.072511]\n",
            "[Epoch 23/200] [Batch 780/938] [D loss: 0.606659] [G loss: 0.078948]\n",
            "[Epoch 23/200] [Batch 781/938] [D loss: 0.661486] [G loss: 0.078244]\n",
            "[Epoch 23/200] [Batch 782/938] [D loss: 0.606635] [G loss: 0.072275]\n",
            "[Epoch 23/200] [Batch 783/938] [D loss: 0.657363] [G loss: 0.081100]\n",
            "[Epoch 23/200] [Batch 784/938] [D loss: 0.640497] [G loss: 0.071861]\n",
            "[Epoch 23/200] [Batch 785/938] [D loss: 0.652014] [G loss: 0.072175]\n",
            "[Epoch 23/200] [Batch 786/938] [D loss: 0.639809] [G loss: 0.075620]\n",
            "[Epoch 23/200] [Batch 787/938] [D loss: 0.685934] [G loss: 0.072113]\n",
            "[Epoch 23/200] [Batch 788/938] [D loss: 0.662881] [G loss: 0.072573]\n",
            "[Epoch 23/200] [Batch 789/938] [D loss: 0.654347] [G loss: 0.074640]\n",
            "[Epoch 23/200] [Batch 790/938] [D loss: 0.630497] [G loss: 0.077127]\n",
            "[Epoch 23/200] [Batch 791/938] [D loss: 0.655365] [G loss: 0.071120]\n",
            "[Epoch 23/200] [Batch 792/938] [D loss: 0.616011] [G loss: 0.070366]\n",
            "[Epoch 23/200] [Batch 793/938] [D loss: 0.674675] [G loss: 0.065722]\n",
            "[Epoch 23/200] [Batch 794/938] [D loss: 0.601659] [G loss: 0.080635]\n",
            "[Epoch 23/200] [Batch 795/938] [D loss: 0.621343] [G loss: 0.073488]\n",
            "[Epoch 23/200] [Batch 796/938] [D loss: 0.664339] [G loss: 0.073361]\n",
            "[Epoch 23/200] [Batch 797/938] [D loss: 0.643398] [G loss: 0.079226]\n",
            "[Epoch 23/200] [Batch 798/938] [D loss: 0.611504] [G loss: 0.075073]\n",
            "[Epoch 23/200] [Batch 799/938] [D loss: 0.637518] [G loss: 0.071835]\n",
            "[Epoch 23/200] [Batch 800/938] [D loss: 0.676289] [G loss: 0.069068]\n",
            "[Epoch 23/200] [Batch 801/938] [D loss: 0.660038] [G loss: 0.068810]\n",
            "[Epoch 23/200] [Batch 802/938] [D loss: 0.622613] [G loss: 0.075691]\n",
            "[Epoch 23/200] [Batch 803/938] [D loss: 0.644188] [G loss: 0.073857]\n",
            "[Epoch 23/200] [Batch 804/938] [D loss: 0.655472] [G loss: 0.077404]\n",
            "[Epoch 23/200] [Batch 805/938] [D loss: 0.706302] [G loss: 0.066629]\n",
            "[Epoch 23/200] [Batch 806/938] [D loss: 0.627959] [G loss: 0.078607]\n",
            "[Epoch 23/200] [Batch 807/938] [D loss: 0.629515] [G loss: 0.071207]\n",
            "[Epoch 23/200] [Batch 808/938] [D loss: 0.610703] [G loss: 0.076448]\n",
            "[Epoch 23/200] [Batch 809/938] [D loss: 0.651923] [G loss: 0.071709]\n",
            "[Epoch 23/200] [Batch 810/938] [D loss: 0.640417] [G loss: 0.070828]\n",
            "[Epoch 23/200] [Batch 811/938] [D loss: 0.619535] [G loss: 0.073354]\n",
            "[Epoch 23/200] [Batch 812/938] [D loss: 0.623032] [G loss: 0.067441]\n",
            "[Epoch 23/200] [Batch 813/938] [D loss: 0.612346] [G loss: 0.075878]\n",
            "[Epoch 23/200] [Batch 814/938] [D loss: 0.622141] [G loss: 0.073156]\n",
            "[Epoch 23/200] [Batch 815/938] [D loss: 0.669964] [G loss: 0.069780]\n",
            "[Epoch 23/200] [Batch 816/938] [D loss: 0.619136] [G loss: 0.078209]\n",
            "[Epoch 23/200] [Batch 817/938] [D loss: 0.634420] [G loss: 0.081586]\n",
            "[Epoch 23/200] [Batch 818/938] [D loss: 0.647642] [G loss: 0.082095]\n",
            "[Epoch 23/200] [Batch 819/938] [D loss: 0.617682] [G loss: 0.069450]\n",
            "[Epoch 23/200] [Batch 820/938] [D loss: 0.617510] [G loss: 0.084221]\n",
            "[Epoch 23/200] [Batch 821/938] [D loss: 0.626719] [G loss: 0.071943]\n",
            "[Epoch 23/200] [Batch 822/938] [D loss: 0.612491] [G loss: 0.076059]\n",
            "[Epoch 23/200] [Batch 823/938] [D loss: 0.621890] [G loss: 0.079912]\n",
            "[Epoch 23/200] [Batch 824/938] [D loss: 0.658348] [G loss: 0.068035]\n",
            "[Epoch 23/200] [Batch 825/938] [D loss: 0.609536] [G loss: 0.068726]\n",
            "[Epoch 23/200] [Batch 826/938] [D loss: 0.617468] [G loss: 0.078905]\n",
            "[Epoch 23/200] [Batch 827/938] [D loss: 0.617880] [G loss: 0.066369]\n",
            "[Epoch 23/200] [Batch 828/938] [D loss: 0.640882] [G loss: 0.076699]\n",
            "[Epoch 23/200] [Batch 829/938] [D loss: 0.603355] [G loss: 0.072527]\n",
            "[Epoch 23/200] [Batch 830/938] [D loss: 0.644749] [G loss: 0.083413]\n",
            "[Epoch 23/200] [Batch 831/938] [D loss: 0.654220] [G loss: 0.074856]\n",
            "[Epoch 23/200] [Batch 832/938] [D loss: 0.638396] [G loss: 0.082012]\n",
            "[Epoch 23/200] [Batch 833/938] [D loss: 0.631918] [G loss: 0.077185]\n",
            "[Epoch 23/200] [Batch 834/938] [D loss: 0.602451] [G loss: 0.075824]\n",
            "[Epoch 23/200] [Batch 835/938] [D loss: 0.663728] [G loss: 0.065812]\n",
            "[Epoch 23/200] [Batch 836/938] [D loss: 0.640796] [G loss: 0.072212]\n",
            "[Epoch 23/200] [Batch 837/938] [D loss: 0.598073] [G loss: 0.076918]\n",
            "[Epoch 23/200] [Batch 838/938] [D loss: 0.645135] [G loss: 0.070671]\n",
            "[Epoch 23/200] [Batch 839/938] [D loss: 0.671823] [G loss: 0.066462]\n",
            "[Epoch 23/200] [Batch 840/938] [D loss: 0.633033] [G loss: 0.073347]\n",
            "[Epoch 23/200] [Batch 841/938] [D loss: 0.662039] [G loss: 0.073700]\n",
            "[Epoch 23/200] [Batch 842/938] [D loss: 0.599772] [G loss: 0.076236]\n",
            "[Epoch 23/200] [Batch 843/938] [D loss: 0.661389] [G loss: 0.072988]\n",
            "[Epoch 23/200] [Batch 844/938] [D loss: 0.673065] [G loss: 0.075400]\n",
            "[Epoch 23/200] [Batch 845/938] [D loss: 0.609410] [G loss: 0.077161]\n",
            "[Epoch 23/200] [Batch 846/938] [D loss: 0.647795] [G loss: 0.079498]\n",
            "[Epoch 23/200] [Batch 847/938] [D loss: 0.670346] [G loss: 0.077976]\n",
            "[Epoch 23/200] [Batch 848/938] [D loss: 0.647941] [G loss: 0.076582]\n",
            "[Epoch 23/200] [Batch 849/938] [D loss: 0.651987] [G loss: 0.071262]\n",
            "[Epoch 23/200] [Batch 850/938] [D loss: 0.642281] [G loss: 0.069880]\n",
            "[Epoch 23/200] [Batch 851/938] [D loss: 0.632942] [G loss: 0.080391]\n",
            "[Epoch 23/200] [Batch 852/938] [D loss: 0.622930] [G loss: 0.074836]\n",
            "[Epoch 23/200] [Batch 853/938] [D loss: 0.640507] [G loss: 0.076088]\n",
            "[Epoch 23/200] [Batch 854/938] [D loss: 0.629084] [G loss: 0.068290]\n",
            "[Epoch 23/200] [Batch 855/938] [D loss: 0.635838] [G loss: 0.070399]\n",
            "[Epoch 23/200] [Batch 856/938] [D loss: 0.631439] [G loss: 0.068725]\n",
            "[Epoch 23/200] [Batch 857/938] [D loss: 0.631222] [G loss: 0.069113]\n",
            "[Epoch 23/200] [Batch 858/938] [D loss: 0.642597] [G loss: 0.075870]\n",
            "[Epoch 23/200] [Batch 859/938] [D loss: 0.637972] [G loss: 0.074633]\n",
            "[Epoch 23/200] [Batch 860/938] [D loss: 0.637926] [G loss: 0.079312]\n",
            "[Epoch 23/200] [Batch 861/938] [D loss: 0.654066] [G loss: 0.070123]\n",
            "[Epoch 23/200] [Batch 862/938] [D loss: 0.652670] [G loss: 0.067195]\n",
            "[Epoch 23/200] [Batch 863/938] [D loss: 0.638882] [G loss: 0.073492]\n",
            "[Epoch 23/200] [Batch 864/938] [D loss: 0.617668] [G loss: 0.067864]\n",
            "[Epoch 23/200] [Batch 865/938] [D loss: 0.626073] [G loss: 0.070091]\n",
            "[Epoch 23/200] [Batch 866/938] [D loss: 0.609565] [G loss: 0.076355]\n",
            "[Epoch 23/200] [Batch 867/938] [D loss: 0.635228] [G loss: 0.073533]\n",
            "[Epoch 23/200] [Batch 868/938] [D loss: 0.630163] [G loss: 0.073851]\n",
            "[Epoch 23/200] [Batch 869/938] [D loss: 0.605417] [G loss: 0.073365]\n",
            "[Epoch 23/200] [Batch 870/938] [D loss: 0.637061] [G loss: 0.072953]\n",
            "[Epoch 23/200] [Batch 871/938] [D loss: 0.633514] [G loss: 0.077043]\n",
            "[Epoch 23/200] [Batch 872/938] [D loss: 0.653669] [G loss: 0.069756]\n",
            "[Epoch 23/200] [Batch 873/938] [D loss: 0.625480] [G loss: 0.074176]\n",
            "[Epoch 23/200] [Batch 874/938] [D loss: 0.655746] [G loss: 0.067390]\n",
            "[Epoch 23/200] [Batch 875/938] [D loss: 0.672607] [G loss: 0.072553]\n",
            "[Epoch 23/200] [Batch 876/938] [D loss: 0.610644] [G loss: 0.078179]\n",
            "[Epoch 23/200] [Batch 877/938] [D loss: 0.631442] [G loss: 0.070285]\n",
            "[Epoch 23/200] [Batch 878/938] [D loss: 0.629930] [G loss: 0.073034]\n",
            "[Epoch 23/200] [Batch 879/938] [D loss: 0.665030] [G loss: 0.074070]\n",
            "[Epoch 23/200] [Batch 880/938] [D loss: 0.625085] [G loss: 0.069268]\n",
            "[Epoch 23/200] [Batch 881/938] [D loss: 0.617360] [G loss: 0.067780]\n",
            "[Epoch 23/200] [Batch 882/938] [D loss: 0.681177] [G loss: 0.086423]\n",
            "[Epoch 23/200] [Batch 883/938] [D loss: 0.623679] [G loss: 0.075623]\n",
            "[Epoch 23/200] [Batch 884/938] [D loss: 0.658483] [G loss: 0.071931]\n",
            "[Epoch 23/200] [Batch 885/938] [D loss: 0.638103] [G loss: 0.074905]\n",
            "[Epoch 23/200] [Batch 886/938] [D loss: 0.643298] [G loss: 0.068797]\n",
            "[Epoch 23/200] [Batch 887/938] [D loss: 0.650905] [G loss: 0.067691]\n",
            "[Epoch 23/200] [Batch 888/938] [D loss: 0.609405] [G loss: 0.071588]\n",
            "[Epoch 23/200] [Batch 889/938] [D loss: 0.630101] [G loss: 0.080130]\n",
            "[Epoch 23/200] [Batch 890/938] [D loss: 0.651995] [G loss: 0.073282]\n",
            "[Epoch 23/200] [Batch 891/938] [D loss: 0.639433] [G loss: 0.069642]\n",
            "[Epoch 23/200] [Batch 892/938] [D loss: 0.676791] [G loss: 0.067966]\n",
            "[Epoch 23/200] [Batch 893/938] [D loss: 0.630080] [G loss: 0.069400]\n",
            "[Epoch 23/200] [Batch 894/938] [D loss: 0.634385] [G loss: 0.068421]\n",
            "[Epoch 23/200] [Batch 895/938] [D loss: 0.665749] [G loss: 0.076123]\n",
            "[Epoch 23/200] [Batch 896/938] [D loss: 0.662296] [G loss: 0.076959]\n",
            "[Epoch 23/200] [Batch 897/938] [D loss: 0.661116] [G loss: 0.080351]\n",
            "[Epoch 23/200] [Batch 898/938] [D loss: 0.613807] [G loss: 0.071411]\n",
            "[Epoch 23/200] [Batch 899/938] [D loss: 0.665706] [G loss: 0.075818]\n",
            "[Epoch 23/200] [Batch 900/938] [D loss: 0.627492] [G loss: 0.072412]\n",
            "[Epoch 23/200] [Batch 901/938] [D loss: 0.634648] [G loss: 0.077127]\n",
            "[Epoch 23/200] [Batch 902/938] [D loss: 0.627245] [G loss: 0.069200]\n",
            "[Epoch 23/200] [Batch 903/938] [D loss: 0.621562] [G loss: 0.074591]\n",
            "[Epoch 23/200] [Batch 904/938] [D loss: 0.612617] [G loss: 0.072381]\n",
            "[Epoch 23/200] [Batch 905/938] [D loss: 0.614591] [G loss: 0.078504]\n",
            "[Epoch 23/200] [Batch 906/938] [D loss: 0.614106] [G loss: 0.072058]\n",
            "[Epoch 23/200] [Batch 907/938] [D loss: 0.600496] [G loss: 0.079702]\n",
            "[Epoch 23/200] [Batch 908/938] [D loss: 0.653079] [G loss: 0.077630]\n",
            "[Epoch 23/200] [Batch 909/938] [D loss: 0.671564] [G loss: 0.073812]\n",
            "[Epoch 23/200] [Batch 910/938] [D loss: 0.662144] [G loss: 0.070418]\n",
            "[Epoch 23/200] [Batch 911/938] [D loss: 0.624994] [G loss: 0.074426]\n",
            "[Epoch 23/200] [Batch 912/938] [D loss: 0.628555] [G loss: 0.074460]\n",
            "[Epoch 23/200] [Batch 913/938] [D loss: 0.623144] [G loss: 0.068565]\n",
            "[Epoch 23/200] [Batch 914/938] [D loss: 0.637836] [G loss: 0.075747]\n",
            "[Epoch 23/200] [Batch 915/938] [D loss: 0.590742] [G loss: 0.075671]\n",
            "[Epoch 23/200] [Batch 916/938] [D loss: 0.605065] [G loss: 0.075950]\n",
            "[Epoch 23/200] [Batch 917/938] [D loss: 0.596673] [G loss: 0.071684]\n",
            "[Epoch 23/200] [Batch 918/938] [D loss: 0.664760] [G loss: 0.070942]\n",
            "[Epoch 23/200] [Batch 919/938] [D loss: 0.662312] [G loss: 0.075818]\n",
            "[Epoch 23/200] [Batch 920/938] [D loss: 0.657713] [G loss: 0.079117]\n",
            "[Epoch 23/200] [Batch 921/938] [D loss: 0.653690] [G loss: 0.068382]\n",
            "[Epoch 23/200] [Batch 922/938] [D loss: 0.642068] [G loss: 0.073401]\n",
            "[Epoch 23/200] [Batch 923/938] [D loss: 0.662829] [G loss: 0.077367]\n",
            "[Epoch 23/200] [Batch 924/938] [D loss: 0.641150] [G loss: 0.068100]\n",
            "[Epoch 23/200] [Batch 925/938] [D loss: 0.621086] [G loss: 0.073784]\n",
            "[Epoch 23/200] [Batch 926/938] [D loss: 0.624191] [G loss: 0.069756]\n",
            "[Epoch 23/200] [Batch 927/938] [D loss: 0.614580] [G loss: 0.065332]\n",
            "[Epoch 23/200] [Batch 928/938] [D loss: 0.713141] [G loss: 0.075505]\n",
            "[Epoch 23/200] [Batch 929/938] [D loss: 0.638523] [G loss: 0.075971]\n",
            "[Epoch 23/200] [Batch 930/938] [D loss: 0.649096] [G loss: 0.074731]\n",
            "[Epoch 23/200] [Batch 931/938] [D loss: 0.648458] [G loss: 0.077781]\n",
            "[Epoch 23/200] [Batch 932/938] [D loss: 0.679657] [G loss: 0.073461]\n",
            "[Epoch 23/200] [Batch 933/938] [D loss: 0.661052] [G loss: 0.074280]\n",
            "[Epoch 23/200] [Batch 934/938] [D loss: 0.632041] [G loss: 0.079508]\n",
            "[Epoch 23/200] [Batch 935/938] [D loss: 0.654052] [G loss: 0.078158]\n",
            "[Epoch 23/200] [Batch 936/938] [D loss: 0.653418] [G loss: 0.074331]\n",
            "[Epoch 23/200] [Batch 937/938] [D loss: 0.625590] [G loss: 0.076211]\n",
            "[Epoch 24/200] [Batch 0/938] [D loss: 0.654747] [G loss: 0.077783]\n",
            "[Epoch 24/200] [Batch 1/938] [D loss: 0.641426] [G loss: 0.075366]\n",
            "[Epoch 24/200] [Batch 2/938] [D loss: 0.659951] [G loss: 0.072463]\n",
            "[Epoch 24/200] [Batch 3/938] [D loss: 0.617413] [G loss: 0.075391]\n",
            "[Epoch 24/200] [Batch 4/938] [D loss: 0.655636] [G loss: 0.074764]\n",
            "[Epoch 24/200] [Batch 5/938] [D loss: 0.666905] [G loss: 0.070994]\n",
            "[Epoch 24/200] [Batch 6/938] [D loss: 0.657984] [G loss: 0.079840]\n",
            "[Epoch 24/200] [Batch 7/938] [D loss: 0.633700] [G loss: 0.067430]\n",
            "[Epoch 24/200] [Batch 8/938] [D loss: 0.593804] [G loss: 0.074700]\n",
            "[Epoch 24/200] [Batch 9/938] [D loss: 0.632612] [G loss: 0.079282]\n",
            "[Epoch 24/200] [Batch 10/938] [D loss: 0.609836] [G loss: 0.079418]\n",
            "[Epoch 24/200] [Batch 11/938] [D loss: 0.644465] [G loss: 0.075633]\n",
            "[Epoch 24/200] [Batch 12/938] [D loss: 0.683303] [G loss: 0.074998]\n",
            "[Epoch 24/200] [Batch 13/938] [D loss: 0.646958] [G loss: 0.067294]\n",
            "[Epoch 24/200] [Batch 14/938] [D loss: 0.659165] [G loss: 0.071559]\n",
            "[Epoch 24/200] [Batch 15/938] [D loss: 0.676501] [G loss: 0.073585]\n",
            "[Epoch 24/200] [Batch 16/938] [D loss: 0.626906] [G loss: 0.074193]\n",
            "[Epoch 24/200] [Batch 17/938] [D loss: 0.632769] [G loss: 0.069569]\n",
            "[Epoch 24/200] [Batch 18/938] [D loss: 0.610109] [G loss: 0.064544]\n",
            "[Epoch 24/200] [Batch 19/938] [D loss: 0.676866] [G loss: 0.072194]\n",
            "[Epoch 24/200] [Batch 20/938] [D loss: 0.612548] [G loss: 0.074727]\n",
            "[Epoch 24/200] [Batch 21/938] [D loss: 0.697098] [G loss: 0.072832]\n",
            "[Epoch 24/200] [Batch 22/938] [D loss: 0.683557] [G loss: 0.072176]\n",
            "[Epoch 24/200] [Batch 23/938] [D loss: 0.627494] [G loss: 0.077041]\n",
            "[Epoch 24/200] [Batch 24/938] [D loss: 0.639577] [G loss: 0.068260]\n",
            "[Epoch 24/200] [Batch 25/938] [D loss: 0.645781] [G loss: 0.069870]\n",
            "[Epoch 24/200] [Batch 26/938] [D loss: 0.608685] [G loss: 0.073873]\n",
            "[Epoch 24/200] [Batch 27/938] [D loss: 0.635535] [G loss: 0.073914]\n",
            "[Epoch 24/200] [Batch 28/938] [D loss: 0.613917] [G loss: 0.072520]\n",
            "[Epoch 24/200] [Batch 29/938] [D loss: 0.621563] [G loss: 0.069748]\n",
            "[Epoch 24/200] [Batch 30/938] [D loss: 0.652920] [G loss: 0.069265]\n",
            "[Epoch 24/200] [Batch 31/938] [D loss: 0.672725] [G loss: 0.079111]\n",
            "[Epoch 24/200] [Batch 32/938] [D loss: 0.629071] [G loss: 0.074180]\n",
            "[Epoch 24/200] [Batch 33/938] [D loss: 0.649608] [G loss: 0.064738]\n",
            "[Epoch 24/200] [Batch 34/938] [D loss: 0.659858] [G loss: 0.071021]\n",
            "[Epoch 24/200] [Batch 35/938] [D loss: 0.614744] [G loss: 0.075710]\n",
            "[Epoch 24/200] [Batch 36/938] [D loss: 0.629301] [G loss: 0.073710]\n",
            "[Epoch 24/200] [Batch 37/938] [D loss: 0.627316] [G loss: 0.067322]\n",
            "[Epoch 24/200] [Batch 38/938] [D loss: 0.648820] [G loss: 0.076709]\n",
            "[Epoch 24/200] [Batch 39/938] [D loss: 0.640352] [G loss: 0.077029]\n",
            "[Epoch 24/200] [Batch 40/938] [D loss: 0.624337] [G loss: 0.077408]\n",
            "[Epoch 24/200] [Batch 41/938] [D loss: 0.636918] [G loss: 0.074898]\n",
            "[Epoch 24/200] [Batch 42/938] [D loss: 0.605801] [G loss: 0.073553]\n",
            "[Epoch 24/200] [Batch 43/938] [D loss: 0.635427] [G loss: 0.080149]\n",
            "[Epoch 24/200] [Batch 44/938] [D loss: 0.632817] [G loss: 0.077952]\n",
            "[Epoch 24/200] [Batch 45/938] [D loss: 0.612876] [G loss: 0.069582]\n",
            "[Epoch 24/200] [Batch 46/938] [D loss: 0.642891] [G loss: 0.071709]\n",
            "[Epoch 24/200] [Batch 47/938] [D loss: 0.639420] [G loss: 0.069629]\n",
            "[Epoch 24/200] [Batch 48/938] [D loss: 0.632607] [G loss: 0.069120]\n",
            "[Epoch 24/200] [Batch 49/938] [D loss: 0.633079] [G loss: 0.072085]\n",
            "[Epoch 24/200] [Batch 50/938] [D loss: 0.650019] [G loss: 0.072404]\n",
            "[Epoch 24/200] [Batch 51/938] [D loss: 0.660702] [G loss: 0.078976]\n",
            "[Epoch 24/200] [Batch 52/938] [D loss: 0.634897] [G loss: 0.076650]\n",
            "[Epoch 24/200] [Batch 53/938] [D loss: 0.645561] [G loss: 0.075496]\n",
            "[Epoch 24/200] [Batch 54/938] [D loss: 0.623193] [G loss: 0.073248]\n",
            "[Epoch 24/200] [Batch 55/938] [D loss: 0.642869] [G loss: 0.075515]\n",
            "[Epoch 24/200] [Batch 56/938] [D loss: 0.651506] [G loss: 0.071539]\n",
            "[Epoch 24/200] [Batch 57/938] [D loss: 0.659351] [G loss: 0.075377]\n",
            "[Epoch 24/200] [Batch 58/938] [D loss: 0.599242] [G loss: 0.071344]\n",
            "[Epoch 24/200] [Batch 59/938] [D loss: 0.657718] [G loss: 0.071108]\n",
            "[Epoch 24/200] [Batch 60/938] [D loss: 0.662453] [G loss: 0.073512]\n",
            "[Epoch 24/200] [Batch 61/938] [D loss: 0.637950] [G loss: 0.072327]\n",
            "[Epoch 24/200] [Batch 62/938] [D loss: 0.626184] [G loss: 0.069974]\n",
            "[Epoch 24/200] [Batch 63/938] [D loss: 0.622373] [G loss: 0.077524]\n",
            "[Epoch 24/200] [Batch 64/938] [D loss: 0.679458] [G loss: 0.080235]\n",
            "[Epoch 24/200] [Batch 65/938] [D loss: 0.622283] [G loss: 0.077548]\n",
            "[Epoch 24/200] [Batch 66/938] [D loss: 0.658483] [G loss: 0.077695]\n",
            "[Epoch 24/200] [Batch 67/938] [D loss: 0.629854] [G loss: 0.075643]\n",
            "[Epoch 24/200] [Batch 68/938] [D loss: 0.668143] [G loss: 0.079915]\n",
            "[Epoch 24/200] [Batch 69/938] [D loss: 0.656512] [G loss: 0.076853]\n",
            "[Epoch 24/200] [Batch 70/938] [D loss: 0.643572] [G loss: 0.074460]\n",
            "[Epoch 24/200] [Batch 71/938] [D loss: 0.617138] [G loss: 0.071573]\n",
            "[Epoch 24/200] [Batch 72/938] [D loss: 0.638750] [G loss: 0.077637]\n",
            "[Epoch 24/200] [Batch 73/938] [D loss: 0.645164] [G loss: 0.071062]\n",
            "[Epoch 24/200] [Batch 74/938] [D loss: 0.615540] [G loss: 0.073994]\n",
            "[Epoch 24/200] [Batch 75/938] [D loss: 0.653174] [G loss: 0.074959]\n",
            "[Epoch 24/200] [Batch 76/938] [D loss: 0.633621] [G loss: 0.060436]\n",
            "[Epoch 24/200] [Batch 77/938] [D loss: 0.639626] [G loss: 0.069315]\n",
            "[Epoch 24/200] [Batch 78/938] [D loss: 0.656495] [G loss: 0.078682]\n",
            "[Epoch 24/200] [Batch 79/938] [D loss: 0.593627] [G loss: 0.072995]\n",
            "[Epoch 24/200] [Batch 80/938] [D loss: 0.676010] [G loss: 0.070911]\n",
            "[Epoch 24/200] [Batch 81/938] [D loss: 0.648225] [G loss: 0.077702]\n",
            "[Epoch 24/200] [Batch 82/938] [D loss: 0.638318] [G loss: 0.072023]\n",
            "[Epoch 24/200] [Batch 83/938] [D loss: 0.661305] [G loss: 0.069375]\n",
            "[Epoch 24/200] [Batch 84/938] [D loss: 0.649887] [G loss: 0.078520]\n",
            "[Epoch 24/200] [Batch 85/938] [D loss: 0.616772] [G loss: 0.074978]\n",
            "[Epoch 24/200] [Batch 86/938] [D loss: 0.652045] [G loss: 0.070285]\n",
            "[Epoch 24/200] [Batch 87/938] [D loss: 0.642315] [G loss: 0.065494]\n",
            "[Epoch 24/200] [Batch 88/938] [D loss: 0.660235] [G loss: 0.072639]\n",
            "[Epoch 24/200] [Batch 89/938] [D loss: 0.623710] [G loss: 0.086479]\n",
            "[Epoch 24/200] [Batch 90/938] [D loss: 0.631378] [G loss: 0.086097]\n",
            "[Epoch 24/200] [Batch 91/938] [D loss: 0.654907] [G loss: 0.071284]\n",
            "[Epoch 24/200] [Batch 92/938] [D loss: 0.679053] [G loss: 0.072950]\n",
            "[Epoch 24/200] [Batch 93/938] [D loss: 0.667088] [G loss: 0.074773]\n",
            "[Epoch 24/200] [Batch 94/938] [D loss: 0.640526] [G loss: 0.073038]\n",
            "[Epoch 24/200] [Batch 95/938] [D loss: 0.641990] [G loss: 0.075595]\n",
            "[Epoch 24/200] [Batch 96/938] [D loss: 0.659302] [G loss: 0.076915]\n",
            "[Epoch 24/200] [Batch 97/938] [D loss: 0.652388] [G loss: 0.070611]\n",
            "[Epoch 24/200] [Batch 98/938] [D loss: 0.629965] [G loss: 0.070738]\n",
            "[Epoch 24/200] [Batch 99/938] [D loss: 0.652923] [G loss: 0.070115]\n",
            "[Epoch 24/200] [Batch 100/938] [D loss: 0.644516] [G loss: 0.074734]\n",
            "[Epoch 24/200] [Batch 101/938] [D loss: 0.656295] [G loss: 0.072249]\n",
            "[Epoch 24/200] [Batch 102/938] [D loss: 0.640495] [G loss: 0.070313]\n",
            "[Epoch 24/200] [Batch 103/938] [D loss: 0.664562] [G loss: 0.078287]\n",
            "[Epoch 24/200] [Batch 104/938] [D loss: 0.639193] [G loss: 0.066466]\n",
            "[Epoch 24/200] [Batch 105/938] [D loss: 0.682725] [G loss: 0.070610]\n",
            "[Epoch 24/200] [Batch 106/938] [D loss: 0.653219] [G loss: 0.073756]\n",
            "[Epoch 24/200] [Batch 107/938] [D loss: 0.637754] [G loss: 0.068144]\n",
            "[Epoch 24/200] [Batch 108/938] [D loss: 0.641468] [G loss: 0.077106]\n",
            "[Epoch 24/200] [Batch 109/938] [D loss: 0.619189] [G loss: 0.069576]\n",
            "[Epoch 24/200] [Batch 110/938] [D loss: 0.619028] [G loss: 0.072930]\n",
            "[Epoch 24/200] [Batch 111/938] [D loss: 0.658915] [G loss: 0.067164]\n",
            "[Epoch 24/200] [Batch 112/938] [D loss: 0.637432] [G loss: 0.070415]\n",
            "[Epoch 24/200] [Batch 113/938] [D loss: 0.662503] [G loss: 0.069869]\n",
            "[Epoch 24/200] [Batch 114/938] [D loss: 0.591691] [G loss: 0.071267]\n",
            "[Epoch 24/200] [Batch 115/938] [D loss: 0.626018] [G loss: 0.076022]\n",
            "[Epoch 24/200] [Batch 116/938] [D loss: 0.667059] [G loss: 0.074480]\n",
            "[Epoch 24/200] [Batch 117/938] [D loss: 0.629888] [G loss: 0.068547]\n",
            "[Epoch 24/200] [Batch 118/938] [D loss: 0.635156] [G loss: 0.073351]\n",
            "[Epoch 24/200] [Batch 119/938] [D loss: 0.599344] [G loss: 0.075152]\n",
            "[Epoch 24/200] [Batch 120/938] [D loss: 0.611712] [G loss: 0.071986]\n",
            "[Epoch 24/200] [Batch 121/938] [D loss: 0.654497] [G loss: 0.067464]\n",
            "[Epoch 24/200] [Batch 122/938] [D loss: 0.654668] [G loss: 0.073573]\n",
            "[Epoch 24/200] [Batch 123/938] [D loss: 0.644801] [G loss: 0.071502]\n",
            "[Epoch 24/200] [Batch 124/938] [D loss: 0.648090] [G loss: 0.064630]\n",
            "[Epoch 24/200] [Batch 125/938] [D loss: 0.636120] [G loss: 0.071797]\n",
            "[Epoch 24/200] [Batch 126/938] [D loss: 0.640687] [G loss: 0.072812]\n",
            "[Epoch 24/200] [Batch 127/938] [D loss: 0.622213] [G loss: 0.073570]\n",
            "[Epoch 24/200] [Batch 128/938] [D loss: 0.651520] [G loss: 0.069453]\n",
            "[Epoch 24/200] [Batch 129/938] [D loss: 0.672663] [G loss: 0.070821]\n",
            "[Epoch 24/200] [Batch 130/938] [D loss: 0.612111] [G loss: 0.074292]\n",
            "[Epoch 24/200] [Batch 131/938] [D loss: 0.635962] [G loss: 0.073011]\n",
            "[Epoch 24/200] [Batch 132/938] [D loss: 0.605221] [G loss: 0.076409]\n",
            "[Epoch 24/200] [Batch 133/938] [D loss: 0.641503] [G loss: 0.076531]\n",
            "[Epoch 24/200] [Batch 134/938] [D loss: 0.619462] [G loss: 0.076786]\n",
            "[Epoch 24/200] [Batch 135/938] [D loss: 0.633294] [G loss: 0.074002]\n",
            "[Epoch 24/200] [Batch 136/938] [D loss: 0.619094] [G loss: 0.071972]\n",
            "[Epoch 24/200] [Batch 137/938] [D loss: 0.639670] [G loss: 0.078950]\n",
            "[Epoch 24/200] [Batch 138/938] [D loss: 0.649849] [G loss: 0.074771]\n",
            "[Epoch 24/200] [Batch 139/938] [D loss: 0.658214] [G loss: 0.077733]\n",
            "[Epoch 24/200] [Batch 140/938] [D loss: 0.639553] [G loss: 0.068207]\n",
            "[Epoch 24/200] [Batch 141/938] [D loss: 0.631923] [G loss: 0.073535]\n",
            "[Epoch 24/200] [Batch 142/938] [D loss: 0.663181] [G loss: 0.076713]\n",
            "[Epoch 24/200] [Batch 143/938] [D loss: 0.665984] [G loss: 0.078537]\n",
            "[Epoch 24/200] [Batch 144/938] [D loss: 0.643890] [G loss: 0.073543]\n",
            "[Epoch 24/200] [Batch 145/938] [D loss: 0.657490] [G loss: 0.070306]\n",
            "[Epoch 24/200] [Batch 146/938] [D loss: 0.642517] [G loss: 0.073552]\n",
            "[Epoch 24/200] [Batch 147/938] [D loss: 0.641694] [G loss: 0.069914]\n",
            "[Epoch 24/200] [Batch 148/938] [D loss: 0.686142] [G loss: 0.069376]\n",
            "[Epoch 24/200] [Batch 149/938] [D loss: 0.619373] [G loss: 0.075896]\n",
            "[Epoch 24/200] [Batch 150/938] [D loss: 0.679614] [G loss: 0.065502]\n",
            "[Epoch 24/200] [Batch 151/938] [D loss: 0.645001] [G loss: 0.063686]\n",
            "[Epoch 24/200] [Batch 152/938] [D loss: 0.652227] [G loss: 0.074259]\n",
            "[Epoch 24/200] [Batch 153/938] [D loss: 0.632262] [G loss: 0.081470]\n",
            "[Epoch 24/200] [Batch 154/938] [D loss: 0.633207] [G loss: 0.082039]\n",
            "[Epoch 24/200] [Batch 155/938] [D loss: 0.652845] [G loss: 0.071056]\n",
            "[Epoch 24/200] [Batch 156/938] [D loss: 0.633892] [G loss: 0.074226]\n",
            "[Epoch 24/200] [Batch 157/938] [D loss: 0.652946] [G loss: 0.073514]\n",
            "[Epoch 24/200] [Batch 158/938] [D loss: 0.618674] [G loss: 0.078348]\n",
            "[Epoch 24/200] [Batch 159/938] [D loss: 0.635513] [G loss: 0.072586]\n",
            "[Epoch 24/200] [Batch 160/938] [D loss: 0.641419] [G loss: 0.078569]\n",
            "[Epoch 24/200] [Batch 161/938] [D loss: 0.644293] [G loss: 0.077375]\n",
            "[Epoch 24/200] [Batch 162/938] [D loss: 0.661616] [G loss: 0.073555]\n",
            "[Epoch 24/200] [Batch 163/938] [D loss: 0.670578] [G loss: 0.074849]\n",
            "[Epoch 24/200] [Batch 164/938] [D loss: 0.659297] [G loss: 0.072120]\n",
            "[Epoch 24/200] [Batch 165/938] [D loss: 0.648694] [G loss: 0.076892]\n",
            "[Epoch 24/200] [Batch 166/938] [D loss: 0.650529] [G loss: 0.084377]\n",
            "[Epoch 24/200] [Batch 167/938] [D loss: 0.626023] [G loss: 0.069864]\n",
            "[Epoch 24/200] [Batch 168/938] [D loss: 0.637459] [G loss: 0.080181]\n",
            "[Epoch 24/200] [Batch 169/938] [D loss: 0.651011] [G loss: 0.074131]\n",
            "[Epoch 24/200] [Batch 170/938] [D loss: 0.652791] [G loss: 0.068601]\n",
            "[Epoch 24/200] [Batch 171/938] [D loss: 0.629112] [G loss: 0.079286]\n",
            "[Epoch 24/200] [Batch 172/938] [D loss: 0.641490] [G loss: 0.076708]\n",
            "[Epoch 24/200] [Batch 173/938] [D loss: 0.682898] [G loss: 0.075100]\n",
            "[Epoch 24/200] [Batch 174/938] [D loss: 0.651420] [G loss: 0.066519]\n",
            "[Epoch 24/200] [Batch 175/938] [D loss: 0.642951] [G loss: 0.074458]\n",
            "[Epoch 24/200] [Batch 176/938] [D loss: 0.634842] [G loss: 0.072003]\n",
            "[Epoch 24/200] [Batch 177/938] [D loss: 0.664281] [G loss: 0.068752]\n",
            "[Epoch 24/200] [Batch 178/938] [D loss: 0.626646] [G loss: 0.076726]\n",
            "[Epoch 24/200] [Batch 179/938] [D loss: 0.632092] [G loss: 0.071637]\n",
            "[Epoch 24/200] [Batch 180/938] [D loss: 0.637694] [G loss: 0.071269]\n",
            "[Epoch 24/200] [Batch 181/938] [D loss: 0.644111] [G loss: 0.076242]\n",
            "[Epoch 24/200] [Batch 182/938] [D loss: 0.641694] [G loss: 0.068126]\n",
            "[Epoch 24/200] [Batch 183/938] [D loss: 0.635323] [G loss: 0.070613]\n",
            "[Epoch 24/200] [Batch 184/938] [D loss: 0.608827] [G loss: 0.075054]\n",
            "[Epoch 24/200] [Batch 185/938] [D loss: 0.626402] [G loss: 0.072793]\n",
            "[Epoch 24/200] [Batch 186/938] [D loss: 0.618902] [G loss: 0.069058]\n",
            "[Epoch 24/200] [Batch 187/938] [D loss: 0.649451] [G loss: 0.071269]\n",
            "[Epoch 24/200] [Batch 188/938] [D loss: 0.649859] [G loss: 0.079990]\n",
            "[Epoch 24/200] [Batch 189/938] [D loss: 0.613258] [G loss: 0.075373]\n",
            "[Epoch 24/200] [Batch 190/938] [D loss: 0.620790] [G loss: 0.073523]\n",
            "[Epoch 24/200] [Batch 191/938] [D loss: 0.638383] [G loss: 0.071326]\n",
            "[Epoch 24/200] [Batch 192/938] [D loss: 0.623526] [G loss: 0.073893]\n",
            "[Epoch 24/200] [Batch 193/938] [D loss: 0.628679] [G loss: 0.073609]\n",
            "[Epoch 24/200] [Batch 194/938] [D loss: 0.624265] [G loss: 0.066455]\n",
            "[Epoch 24/200] [Batch 195/938] [D loss: 0.682021] [G loss: 0.074403]\n",
            "[Epoch 24/200] [Batch 196/938] [D loss: 0.649482] [G loss: 0.071180]\n",
            "[Epoch 24/200] [Batch 197/938] [D loss: 0.653527] [G loss: 0.066061]\n",
            "[Epoch 24/200] [Batch 198/938] [D loss: 0.598924] [G loss: 0.068395]\n",
            "[Epoch 24/200] [Batch 199/938] [D loss: 0.619307] [G loss: 0.063760]\n",
            "[Epoch 24/200] [Batch 200/938] [D loss: 0.655571] [G loss: 0.071202]\n",
            "[Epoch 24/200] [Batch 201/938] [D loss: 0.611048] [G loss: 0.072636]\n",
            "[Epoch 24/200] [Batch 202/938] [D loss: 0.653670] [G loss: 0.064843]\n",
            "[Epoch 24/200] [Batch 203/938] [D loss: 0.659012] [G loss: 0.072401]\n",
            "[Epoch 24/200] [Batch 204/938] [D loss: 0.644549] [G loss: 0.071003]\n",
            "[Epoch 24/200] [Batch 205/938] [D loss: 0.601600] [G loss: 0.069501]\n",
            "[Epoch 24/200] [Batch 206/938] [D loss: 0.659489] [G loss: 0.067994]\n",
            "[Epoch 24/200] [Batch 207/938] [D loss: 0.601494] [G loss: 0.073610]\n",
            "[Epoch 24/200] [Batch 208/938] [D loss: 0.634355] [G loss: 0.070095]\n",
            "[Epoch 24/200] [Batch 209/938] [D loss: 0.651403] [G loss: 0.069122]\n",
            "[Epoch 24/200] [Batch 210/938] [D loss: 0.662349] [G loss: 0.070982]\n",
            "[Epoch 24/200] [Batch 211/938] [D loss: 0.648757] [G loss: 0.068868]\n",
            "[Epoch 24/200] [Batch 212/938] [D loss: 0.608450] [G loss: 0.072682]\n",
            "[Epoch 24/200] [Batch 213/938] [D loss: 0.636950] [G loss: 0.069755]\n",
            "[Epoch 24/200] [Batch 214/938] [D loss: 0.663385] [G loss: 0.072762]\n",
            "[Epoch 24/200] [Batch 215/938] [D loss: 0.593918] [G loss: 0.072516]\n",
            "[Epoch 24/200] [Batch 216/938] [D loss: 0.658191] [G loss: 0.074671]\n",
            "[Epoch 24/200] [Batch 217/938] [D loss: 0.642314] [G loss: 0.074023]\n",
            "[Epoch 24/200] [Batch 218/938] [D loss: 0.629146] [G loss: 0.075051]\n",
            "[Epoch 24/200] [Batch 219/938] [D loss: 0.628626] [G loss: 0.082306]\n",
            "[Epoch 24/200] [Batch 220/938] [D loss: 0.611387] [G loss: 0.067681]\n",
            "[Epoch 24/200] [Batch 221/938] [D loss: 0.621259] [G loss: 0.070331]\n",
            "[Epoch 24/200] [Batch 222/938] [D loss: 0.605236] [G loss: 0.078895]\n",
            "[Epoch 24/200] [Batch 223/938] [D loss: 0.612123] [G loss: 0.070275]\n",
            "[Epoch 24/200] [Batch 224/938] [D loss: 0.634208] [G loss: 0.073484]\n",
            "[Epoch 24/200] [Batch 225/938] [D loss: 0.659882] [G loss: 0.072737]\n",
            "[Epoch 24/200] [Batch 226/938] [D loss: 0.637854] [G loss: 0.071100]\n",
            "[Epoch 24/200] [Batch 227/938] [D loss: 0.627850] [G loss: 0.077714]\n",
            "[Epoch 24/200] [Batch 228/938] [D loss: 0.619417] [G loss: 0.073816]\n",
            "[Epoch 24/200] [Batch 229/938] [D loss: 0.694104] [G loss: 0.069195]\n",
            "[Epoch 24/200] [Batch 230/938] [D loss: 0.638688] [G loss: 0.073166]\n",
            "[Epoch 24/200] [Batch 231/938] [D loss: 0.653802] [G loss: 0.079018]\n",
            "[Epoch 24/200] [Batch 232/938] [D loss: 0.636969] [G loss: 0.075418]\n",
            "[Epoch 24/200] [Batch 233/938] [D loss: 0.633776] [G loss: 0.074910]\n",
            "[Epoch 24/200] [Batch 234/938] [D loss: 0.658697] [G loss: 0.076301]\n",
            "[Epoch 24/200] [Batch 235/938] [D loss: 0.603325] [G loss: 0.068973]\n",
            "[Epoch 24/200] [Batch 236/938] [D loss: 0.654713] [G loss: 0.072990]\n",
            "[Epoch 24/200] [Batch 237/938] [D loss: 0.594706] [G loss: 0.070716]\n",
            "[Epoch 24/200] [Batch 238/938] [D loss: 0.647745] [G loss: 0.069722]\n",
            "[Epoch 24/200] [Batch 239/938] [D loss: 0.607084] [G loss: 0.083174]\n",
            "[Epoch 24/200] [Batch 240/938] [D loss: 0.639896] [G loss: 0.071938]\n",
            "[Epoch 24/200] [Batch 241/938] [D loss: 0.665124] [G loss: 0.076540]\n",
            "[Epoch 24/200] [Batch 242/938] [D loss: 0.620620] [G loss: 0.067471]\n",
            "[Epoch 24/200] [Batch 243/938] [D loss: 0.637169] [G loss: 0.074591]\n",
            "[Epoch 24/200] [Batch 244/938] [D loss: 0.622507] [G loss: 0.079762]\n",
            "[Epoch 24/200] [Batch 245/938] [D loss: 0.615351] [G loss: 0.072202]\n",
            "[Epoch 24/200] [Batch 246/938] [D loss: 0.646072] [G loss: 0.073011]\n",
            "[Epoch 24/200] [Batch 247/938] [D loss: 0.598463] [G loss: 0.072437]\n",
            "[Epoch 24/200] [Batch 248/938] [D loss: 0.651126] [G loss: 0.071988]\n",
            "[Epoch 24/200] [Batch 249/938] [D loss: 0.622542] [G loss: 0.065330]\n",
            "[Epoch 24/200] [Batch 250/938] [D loss: 0.642908] [G loss: 0.068514]\n",
            "[Epoch 24/200] [Batch 251/938] [D loss: 0.632073] [G loss: 0.075492]\n",
            "[Epoch 24/200] [Batch 252/938] [D loss: 0.642478] [G loss: 0.074942]\n",
            "[Epoch 24/200] [Batch 253/938] [D loss: 0.636004] [G loss: 0.072513]\n",
            "[Epoch 24/200] [Batch 254/938] [D loss: 0.636699] [G loss: 0.073299]\n",
            "[Epoch 24/200] [Batch 255/938] [D loss: 0.616247] [G loss: 0.077046]\n",
            "[Epoch 24/200] [Batch 256/938] [D loss: 0.614115] [G loss: 0.069171]\n",
            "[Epoch 24/200] [Batch 257/938] [D loss: 0.633615] [G loss: 0.073550]\n",
            "[Epoch 24/200] [Batch 258/938] [D loss: 0.595950] [G loss: 0.076877]\n",
            "[Epoch 24/200] [Batch 259/938] [D loss: 0.642803] [G loss: 0.071575]\n",
            "[Epoch 24/200] [Batch 260/938] [D loss: 0.639786] [G loss: 0.072348]\n",
            "[Epoch 24/200] [Batch 261/938] [D loss: 0.641338] [G loss: 0.075333]\n",
            "[Epoch 24/200] [Batch 262/938] [D loss: 0.671262] [G loss: 0.076704]\n",
            "[Epoch 24/200] [Batch 263/938] [D loss: 0.677291] [G loss: 0.066271]\n",
            "[Epoch 24/200] [Batch 264/938] [D loss: 0.607030] [G loss: 0.074199]\n",
            "[Epoch 24/200] [Batch 265/938] [D loss: 0.690190] [G loss: 0.076560]\n",
            "[Epoch 24/200] [Batch 266/938] [D loss: 0.626243] [G loss: 0.071372]\n",
            "[Epoch 24/200] [Batch 267/938] [D loss: 0.626685] [G loss: 0.076208]\n",
            "[Epoch 24/200] [Batch 268/938] [D loss: 0.668981] [G loss: 0.072728]\n",
            "[Epoch 24/200] [Batch 269/938] [D loss: 0.626619] [G loss: 0.074579]\n",
            "[Epoch 24/200] [Batch 270/938] [D loss: 0.662781] [G loss: 0.065476]\n",
            "[Epoch 24/200] [Batch 271/938] [D loss: 0.642632] [G loss: 0.074583]\n",
            "[Epoch 24/200] [Batch 272/938] [D loss: 0.596910] [G loss: 0.075483]\n",
            "[Epoch 24/200] [Batch 273/938] [D loss: 0.629735] [G loss: 0.073690]\n",
            "[Epoch 24/200] [Batch 274/938] [D loss: 0.678975] [G loss: 0.070578]\n",
            "[Epoch 24/200] [Batch 275/938] [D loss: 0.637278] [G loss: 0.069514]\n",
            "[Epoch 24/200] [Batch 276/938] [D loss: 0.649062] [G loss: 0.071137]\n",
            "[Epoch 24/200] [Batch 277/938] [D loss: 0.650272] [G loss: 0.075471]\n",
            "[Epoch 24/200] [Batch 278/938] [D loss: 0.645006] [G loss: 0.078541]\n",
            "[Epoch 24/200] [Batch 279/938] [D loss: 0.651606] [G loss: 0.071671]\n",
            "[Epoch 24/200] [Batch 280/938] [D loss: 0.661870] [G loss: 0.076381]\n",
            "[Epoch 24/200] [Batch 281/938] [D loss: 0.687474] [G loss: 0.075600]\n",
            "[Epoch 24/200] [Batch 282/938] [D loss: 0.694525] [G loss: 0.073985]\n",
            "[Epoch 24/200] [Batch 283/938] [D loss: 0.589673] [G loss: 0.076868]\n",
            "[Epoch 24/200] [Batch 284/938] [D loss: 0.657449] [G loss: 0.072056]\n",
            "[Epoch 24/200] [Batch 285/938] [D loss: 0.613171] [G loss: 0.078045]\n",
            "[Epoch 24/200] [Batch 286/938] [D loss: 0.681325] [G loss: 0.069409]\n",
            "[Epoch 24/200] [Batch 287/938] [D loss: 0.642952] [G loss: 0.073982]\n",
            "[Epoch 24/200] [Batch 288/938] [D loss: 0.655671] [G loss: 0.074155]\n",
            "[Epoch 24/200] [Batch 289/938] [D loss: 0.620226] [G loss: 0.073174]\n",
            "[Epoch 24/200] [Batch 290/938] [D loss: 0.635337] [G loss: 0.076598]\n",
            "[Epoch 24/200] [Batch 291/938] [D loss: 0.630992] [G loss: 0.084486]\n",
            "[Epoch 24/200] [Batch 292/938] [D loss: 0.608846] [G loss: 0.076759]\n",
            "[Epoch 24/200] [Batch 293/938] [D loss: 0.660379] [G loss: 0.072332]\n",
            "[Epoch 24/200] [Batch 294/938] [D loss: 0.641861] [G loss: 0.086111]\n",
            "[Epoch 24/200] [Batch 295/938] [D loss: 0.629402] [G loss: 0.077793]\n",
            "[Epoch 24/200] [Batch 296/938] [D loss: 0.602141] [G loss: 0.070527]\n",
            "[Epoch 24/200] [Batch 297/938] [D loss: 0.650111] [G loss: 0.070686]\n",
            "[Epoch 24/200] [Batch 298/938] [D loss: 0.655723] [G loss: 0.069651]\n",
            "[Epoch 24/200] [Batch 299/938] [D loss: 0.625692] [G loss: 0.076609]\n",
            "[Epoch 24/200] [Batch 300/938] [D loss: 0.612478] [G loss: 0.071220]\n",
            "[Epoch 24/200] [Batch 301/938] [D loss: 0.619227] [G loss: 0.069284]\n",
            "[Epoch 24/200] [Batch 302/938] [D loss: 0.633348] [G loss: 0.077974]\n",
            "[Epoch 24/200] [Batch 303/938] [D loss: 0.658956] [G loss: 0.070128]\n",
            "[Epoch 24/200] [Batch 304/938] [D loss: 0.649175] [G loss: 0.077330]\n",
            "[Epoch 24/200] [Batch 305/938] [D loss: 0.594493] [G loss: 0.074993]\n",
            "[Epoch 24/200] [Batch 306/938] [D loss: 0.635348] [G loss: 0.073399]\n",
            "[Epoch 24/200] [Batch 307/938] [D loss: 0.654346] [G loss: 0.070357]\n",
            "[Epoch 24/200] [Batch 308/938] [D loss: 0.625181] [G loss: 0.075286]\n",
            "[Epoch 24/200] [Batch 309/938] [D loss: 0.650066] [G loss: 0.075779]\n",
            "[Epoch 24/200] [Batch 310/938] [D loss: 0.615091] [G loss: 0.074906]\n",
            "[Epoch 24/200] [Batch 311/938] [D loss: 0.655715] [G loss: 0.070371]\n",
            "[Epoch 24/200] [Batch 312/938] [D loss: 0.648538] [G loss: 0.073609]\n",
            "[Epoch 24/200] [Batch 313/938] [D loss: 0.639868] [G loss: 0.067840]\n",
            "[Epoch 24/200] [Batch 314/938] [D loss: 0.619377] [G loss: 0.077404]\n",
            "[Epoch 24/200] [Batch 315/938] [D loss: 0.634720] [G loss: 0.084180]\n",
            "[Epoch 24/200] [Batch 316/938] [D loss: 0.631272] [G loss: 0.077443]\n",
            "[Epoch 24/200] [Batch 317/938] [D loss: 0.635519] [G loss: 0.073797]\n",
            "[Epoch 24/200] [Batch 318/938] [D loss: 0.631803] [G loss: 0.069623]\n",
            "[Epoch 24/200] [Batch 319/938] [D loss: 0.632685] [G loss: 0.074009]\n",
            "[Epoch 24/200] [Batch 320/938] [D loss: 0.616289] [G loss: 0.071429]\n",
            "[Epoch 24/200] [Batch 321/938] [D loss: 0.655684] [G loss: 0.065929]\n",
            "[Epoch 24/200] [Batch 322/938] [D loss: 0.651696] [G loss: 0.073745]\n",
            "[Epoch 24/200] [Batch 323/938] [D loss: 0.626939] [G loss: 0.081406]\n",
            "[Epoch 24/200] [Batch 324/938] [D loss: 0.657796] [G loss: 0.077321]\n",
            "[Epoch 24/200] [Batch 325/938] [D loss: 0.646309] [G loss: 0.068793]\n",
            "[Epoch 24/200] [Batch 326/938] [D loss: 0.637246] [G loss: 0.068242]\n",
            "[Epoch 24/200] [Batch 327/938] [D loss: 0.636557] [G loss: 0.066587]\n",
            "[Epoch 24/200] [Batch 328/938] [D loss: 0.648590] [G loss: 0.075782]\n",
            "[Epoch 24/200] [Batch 329/938] [D loss: 0.608996] [G loss: 0.068044]\n",
            "[Epoch 24/200] [Batch 330/938] [D loss: 0.626862] [G loss: 0.076165]\n",
            "[Epoch 24/200] [Batch 331/938] [D loss: 0.623349] [G loss: 0.076643]\n",
            "[Epoch 24/200] [Batch 332/938] [D loss: 0.619243] [G loss: 0.069867]\n",
            "[Epoch 24/200] [Batch 333/938] [D loss: 0.642732] [G loss: 0.066978]\n",
            "[Epoch 24/200] [Batch 334/938] [D loss: 0.598155] [G loss: 0.076261]\n",
            "[Epoch 24/200] [Batch 335/938] [D loss: 0.612062] [G loss: 0.069954]\n",
            "[Epoch 24/200] [Batch 336/938] [D loss: 0.632461] [G loss: 0.072920]\n",
            "[Epoch 24/200] [Batch 337/938] [D loss: 0.630218] [G loss: 0.072187]\n",
            "[Epoch 24/200] [Batch 338/938] [D loss: 0.655929] [G loss: 0.078428]\n",
            "[Epoch 24/200] [Batch 339/938] [D loss: 0.652813] [G loss: 0.069180]\n",
            "[Epoch 24/200] [Batch 340/938] [D loss: 0.635691] [G loss: 0.068989]\n",
            "[Epoch 24/200] [Batch 341/938] [D loss: 0.643310] [G loss: 0.068395]\n",
            "[Epoch 24/200] [Batch 342/938] [D loss: 0.608226] [G loss: 0.081166]\n",
            "[Epoch 24/200] [Batch 343/938] [D loss: 0.626991] [G loss: 0.071892]\n",
            "[Epoch 24/200] [Batch 344/938] [D loss: 0.605106] [G loss: 0.071479]\n",
            "[Epoch 24/200] [Batch 345/938] [D loss: 0.629436] [G loss: 0.069736]\n",
            "[Epoch 24/200] [Batch 346/938] [D loss: 0.624327] [G loss: 0.076561]\n",
            "[Epoch 24/200] [Batch 347/938] [D loss: 0.636210] [G loss: 0.078780]\n",
            "[Epoch 24/200] [Batch 348/938] [D loss: 0.634100] [G loss: 0.071175]\n",
            "[Epoch 24/200] [Batch 349/938] [D loss: 0.624335] [G loss: 0.075849]\n",
            "[Epoch 24/200] [Batch 350/938] [D loss: 0.633324] [G loss: 0.072166]\n",
            "[Epoch 24/200] [Batch 351/938] [D loss: 0.630973] [G loss: 0.076793]\n",
            "[Epoch 24/200] [Batch 352/938] [D loss: 0.690082] [G loss: 0.074102]\n",
            "[Epoch 24/200] [Batch 353/938] [D loss: 0.640370] [G loss: 0.074465]\n",
            "[Epoch 24/200] [Batch 354/938] [D loss: 0.673532] [G loss: 0.070857]\n",
            "[Epoch 24/200] [Batch 355/938] [D loss: 0.624260] [G loss: 0.071108]\n",
            "[Epoch 24/200] [Batch 356/938] [D loss: 0.653109] [G loss: 0.073879]\n",
            "[Epoch 24/200] [Batch 357/938] [D loss: 0.637615] [G loss: 0.069763]\n",
            "[Epoch 24/200] [Batch 358/938] [D loss: 0.607360] [G loss: 0.071113]\n",
            "[Epoch 24/200] [Batch 359/938] [D loss: 0.621620] [G loss: 0.074990]\n",
            "[Epoch 24/200] [Batch 360/938] [D loss: 0.658480] [G loss: 0.071027]\n",
            "[Epoch 24/200] [Batch 361/938] [D loss: 0.640496] [G loss: 0.071299]\n",
            "[Epoch 24/200] [Batch 362/938] [D loss: 0.629948] [G loss: 0.067685]\n",
            "[Epoch 24/200] [Batch 363/938] [D loss: 0.685872] [G loss: 0.082927]\n",
            "[Epoch 24/200] [Batch 364/938] [D loss: 0.658444] [G loss: 0.079008]\n",
            "[Epoch 24/200] [Batch 365/938] [D loss: 0.703567] [G loss: 0.071092]\n",
            "[Epoch 24/200] [Batch 366/938] [D loss: 0.672201] [G loss: 0.070801]\n",
            "[Epoch 24/200] [Batch 367/938] [D loss: 0.648267] [G loss: 0.071005]\n",
            "[Epoch 24/200] [Batch 368/938] [D loss: 0.632325] [G loss: 0.075063]\n",
            "[Epoch 24/200] [Batch 369/938] [D loss: 0.673300] [G loss: 0.074108]\n",
            "[Epoch 24/200] [Batch 370/938] [D loss: 0.635924] [G loss: 0.077345]\n",
            "[Epoch 24/200] [Batch 371/938] [D loss: 0.623441] [G loss: 0.074667]\n",
            "[Epoch 24/200] [Batch 372/938] [D loss: 0.609604] [G loss: 0.077637]\n",
            "[Epoch 24/200] [Batch 373/938] [D loss: 0.610035] [G loss: 0.078408]\n",
            "[Epoch 24/200] [Batch 374/938] [D loss: 0.668882] [G loss: 0.076409]\n",
            "[Epoch 24/200] [Batch 375/938] [D loss: 0.669465] [G loss: 0.076526]\n",
            "[Epoch 24/200] [Batch 376/938] [D loss: 0.611150] [G loss: 0.070548]\n",
            "[Epoch 24/200] [Batch 377/938] [D loss: 0.645390] [G loss: 0.066904]\n",
            "[Epoch 24/200] [Batch 378/938] [D loss: 0.651208] [G loss: 0.074617]\n",
            "[Epoch 24/200] [Batch 379/938] [D loss: 0.645121] [G loss: 0.070330]\n",
            "[Epoch 24/200] [Batch 380/938] [D loss: 0.650686] [G loss: 0.073525]\n",
            "[Epoch 24/200] [Batch 381/938] [D loss: 0.601092] [G loss: 0.078632]\n",
            "[Epoch 24/200] [Batch 382/938] [D loss: 0.623848] [G loss: 0.071210]\n",
            "[Epoch 24/200] [Batch 383/938] [D loss: 0.662098] [G loss: 0.066493]\n",
            "[Epoch 24/200] [Batch 384/938] [D loss: 0.670722] [G loss: 0.064503]\n",
            "[Epoch 24/200] [Batch 385/938] [D loss: 0.608447] [G loss: 0.078659]\n",
            "[Epoch 24/200] [Batch 386/938] [D loss: 0.595630] [G loss: 0.076319]\n",
            "[Epoch 24/200] [Batch 387/938] [D loss: 0.678248] [G loss: 0.071054]\n",
            "[Epoch 24/200] [Batch 388/938] [D loss: 0.669975] [G loss: 0.076544]\n",
            "[Epoch 24/200] [Batch 389/938] [D loss: 0.636088] [G loss: 0.069329]\n",
            "[Epoch 24/200] [Batch 390/938] [D loss: 0.621127] [G loss: 0.071764]\n",
            "[Epoch 24/200] [Batch 391/938] [D loss: 0.610083] [G loss: 0.069220]\n",
            "[Epoch 24/200] [Batch 392/938] [D loss: 0.632406] [G loss: 0.068524]\n",
            "[Epoch 24/200] [Batch 393/938] [D loss: 0.625155] [G loss: 0.070966]\n",
            "[Epoch 24/200] [Batch 394/938] [D loss: 0.620179] [G loss: 0.066143]\n",
            "[Epoch 24/200] [Batch 395/938] [D loss: 0.663032] [G loss: 0.073129]\n",
            "[Epoch 24/200] [Batch 396/938] [D loss: 0.629990] [G loss: 0.082628]\n",
            "[Epoch 24/200] [Batch 397/938] [D loss: 0.600163] [G loss: 0.071938]\n",
            "[Epoch 24/200] [Batch 398/938] [D loss: 0.623999] [G loss: 0.076646]\n",
            "[Epoch 24/200] [Batch 399/938] [D loss: 0.615262] [G loss: 0.071910]\n",
            "[Epoch 24/200] [Batch 400/938] [D loss: 0.587859] [G loss: 0.075687]\n",
            "[Epoch 24/200] [Batch 401/938] [D loss: 0.634778] [G loss: 0.078911]\n",
            "[Epoch 24/200] [Batch 402/938] [D loss: 0.638657] [G loss: 0.069429]\n",
            "[Epoch 24/200] [Batch 403/938] [D loss: 0.609912] [G loss: 0.076653]\n",
            "[Epoch 24/200] [Batch 404/938] [D loss: 0.634842] [G loss: 0.083042]\n",
            "[Epoch 24/200] [Batch 405/938] [D loss: 0.592064] [G loss: 0.073136]\n",
            "[Epoch 24/200] [Batch 406/938] [D loss: 0.668297] [G loss: 0.074029]\n",
            "[Epoch 24/200] [Batch 407/938] [D loss: 0.691552] [G loss: 0.069060]\n",
            "[Epoch 24/200] [Batch 408/938] [D loss: 0.653093] [G loss: 0.075315]\n",
            "[Epoch 24/200] [Batch 409/938] [D loss: 0.618981] [G loss: 0.076031]\n",
            "[Epoch 24/200] [Batch 410/938] [D loss: 0.656655] [G loss: 0.065585]\n",
            "[Epoch 24/200] [Batch 411/938] [D loss: 0.621131] [G loss: 0.076629]\n",
            "[Epoch 24/200] [Batch 412/938] [D loss: 0.631472] [G loss: 0.078512]\n",
            "[Epoch 24/200] [Batch 413/938] [D loss: 0.636133] [G loss: 0.078587]\n",
            "[Epoch 24/200] [Batch 414/938] [D loss: 0.628674] [G loss: 0.071425]\n",
            "[Epoch 24/200] [Batch 415/938] [D loss: 0.672088] [G loss: 0.067850]\n",
            "[Epoch 24/200] [Batch 416/938] [D loss: 0.589924] [G loss: 0.073835]\n",
            "[Epoch 24/200] [Batch 417/938] [D loss: 0.661394] [G loss: 0.070100]\n",
            "[Epoch 24/200] [Batch 418/938] [D loss: 0.608812] [G loss: 0.072776]\n",
            "[Epoch 24/200] [Batch 419/938] [D loss: 0.620332] [G loss: 0.074226]\n",
            "[Epoch 24/200] [Batch 420/938] [D loss: 0.630802] [G loss: 0.073657]\n",
            "[Epoch 24/200] [Batch 421/938] [D loss: 0.637782] [G loss: 0.075344]\n",
            "[Epoch 24/200] [Batch 422/938] [D loss: 0.630088] [G loss: 0.075764]\n",
            "[Epoch 24/200] [Batch 423/938] [D loss: 0.646687] [G loss: 0.079584]\n",
            "[Epoch 24/200] [Batch 424/938] [D loss: 0.644154] [G loss: 0.082238]\n",
            "[Epoch 24/200] [Batch 425/938] [D loss: 0.628010] [G loss: 0.070896]\n",
            "[Epoch 24/200] [Batch 426/938] [D loss: 0.641892] [G loss: 0.065337]\n",
            "[Epoch 24/200] [Batch 427/938] [D loss: 0.662033] [G loss: 0.066774]\n",
            "[Epoch 24/200] [Batch 428/938] [D loss: 0.658129] [G loss: 0.071079]\n",
            "[Epoch 24/200] [Batch 429/938] [D loss: 0.665289] [G loss: 0.070877]\n",
            "[Epoch 24/200] [Batch 430/938] [D loss: 0.633800] [G loss: 0.076652]\n",
            "[Epoch 24/200] [Batch 431/938] [D loss: 0.628998] [G loss: 0.073974]\n",
            "[Epoch 24/200] [Batch 432/938] [D loss: 0.612526] [G loss: 0.070341]\n",
            "[Epoch 24/200] [Batch 433/938] [D loss: 0.653722] [G loss: 0.071674]\n",
            "[Epoch 24/200] [Batch 434/938] [D loss: 0.618885] [G loss: 0.072768]\n",
            "[Epoch 24/200] [Batch 435/938] [D loss: 0.642450] [G loss: 0.073078]\n",
            "[Epoch 24/200] [Batch 436/938] [D loss: 0.669957] [G loss: 0.067005]\n",
            "[Epoch 24/200] [Batch 437/938] [D loss: 0.636538] [G loss: 0.064087]\n",
            "[Epoch 24/200] [Batch 438/938] [D loss: 0.614304] [G loss: 0.074112]\n",
            "[Epoch 24/200] [Batch 439/938] [D loss: 0.622036] [G loss: 0.078633]\n",
            "[Epoch 24/200] [Batch 440/938] [D loss: 0.619956] [G loss: 0.070379]\n",
            "[Epoch 24/200] [Batch 441/938] [D loss: 0.636455] [G loss: 0.066321]\n",
            "[Epoch 24/200] [Batch 442/938] [D loss: 0.627761] [G loss: 0.073769]\n",
            "[Epoch 24/200] [Batch 443/938] [D loss: 0.615618] [G loss: 0.065383]\n",
            "[Epoch 24/200] [Batch 444/938] [D loss: 0.628354] [G loss: 0.066235]\n",
            "[Epoch 24/200] [Batch 445/938] [D loss: 0.607300] [G loss: 0.073915]\n",
            "[Epoch 24/200] [Batch 446/938] [D loss: 0.633113] [G loss: 0.063781]\n",
            "[Epoch 24/200] [Batch 447/938] [D loss: 0.640150] [G loss: 0.074392]\n",
            "[Epoch 24/200] [Batch 448/938] [D loss: 0.652854] [G loss: 0.067876]\n",
            "[Epoch 24/200] [Batch 449/938] [D loss: 0.625940] [G loss: 0.067580]\n",
            "[Epoch 24/200] [Batch 450/938] [D loss: 0.597031] [G loss: 0.071648]\n",
            "[Epoch 24/200] [Batch 451/938] [D loss: 0.620620] [G loss: 0.070242]\n",
            "[Epoch 24/200] [Batch 452/938] [D loss: 0.620638] [G loss: 0.070734]\n",
            "[Epoch 24/200] [Batch 453/938] [D loss: 0.602010] [G loss: 0.073082]\n",
            "[Epoch 24/200] [Batch 454/938] [D loss: 0.635896] [G loss: 0.068707]\n",
            "[Epoch 24/200] [Batch 455/938] [D loss: 0.632440] [G loss: 0.075934]\n",
            "[Epoch 24/200] [Batch 456/938] [D loss: 0.643108] [G loss: 0.071273]\n",
            "[Epoch 24/200] [Batch 457/938] [D loss: 0.646080] [G loss: 0.075128]\n",
            "[Epoch 24/200] [Batch 458/938] [D loss: 0.634433] [G loss: 0.075785]\n",
            "[Epoch 24/200] [Batch 459/938] [D loss: 0.661297] [G loss: 0.075715]\n",
            "[Epoch 24/200] [Batch 460/938] [D loss: 0.646792] [G loss: 0.069588]\n",
            "[Epoch 24/200] [Batch 461/938] [D loss: 0.700112] [G loss: 0.075763]\n",
            "[Epoch 24/200] [Batch 462/938] [D loss: 0.611671] [G loss: 0.079770]\n",
            "[Epoch 24/200] [Batch 463/938] [D loss: 0.620839] [G loss: 0.076247]\n",
            "[Epoch 24/200] [Batch 464/938] [D loss: 0.652459] [G loss: 0.070639]\n",
            "[Epoch 24/200] [Batch 465/938] [D loss: 0.640242] [G loss: 0.070177]\n",
            "[Epoch 24/200] [Batch 466/938] [D loss: 0.652281] [G loss: 0.072665]\n",
            "[Epoch 24/200] [Batch 467/938] [D loss: 0.643035] [G loss: 0.067303]\n",
            "[Epoch 24/200] [Batch 468/938] [D loss: 0.656162] [G loss: 0.076009]\n",
            "[Epoch 24/200] [Batch 469/938] [D loss: 0.650044] [G loss: 0.072543]\n",
            "[Epoch 24/200] [Batch 470/938] [D loss: 0.599091] [G loss: 0.080723]\n",
            "[Epoch 24/200] [Batch 471/938] [D loss: 0.638521] [G loss: 0.077722]\n",
            "[Epoch 24/200] [Batch 472/938] [D loss: 0.602817] [G loss: 0.074587]\n",
            "[Epoch 24/200] [Batch 473/938] [D loss: 0.639945] [G loss: 0.070980]\n",
            "[Epoch 24/200] [Batch 474/938] [D loss: 0.666986] [G loss: 0.078550]\n",
            "[Epoch 24/200] [Batch 475/938] [D loss: 0.645217] [G loss: 0.079698]\n",
            "[Epoch 24/200] [Batch 476/938] [D loss: 0.622875] [G loss: 0.080659]\n",
            "[Epoch 24/200] [Batch 477/938] [D loss: 0.650897] [G loss: 0.077065]\n",
            "[Epoch 24/200] [Batch 478/938] [D loss: 0.617201] [G loss: 0.073753]\n",
            "[Epoch 24/200] [Batch 479/938] [D loss: 0.612056] [G loss: 0.076869]\n",
            "[Epoch 24/200] [Batch 480/938] [D loss: 0.664412] [G loss: 0.073153]\n",
            "[Epoch 24/200] [Batch 481/938] [D loss: 0.643230] [G loss: 0.064494]\n",
            "[Epoch 24/200] [Batch 482/938] [D loss: 0.665909] [G loss: 0.071204]\n",
            "[Epoch 24/200] [Batch 483/938] [D loss: 0.639338] [G loss: 0.076236]\n",
            "[Epoch 24/200] [Batch 484/938] [D loss: 0.662198] [G loss: 0.072991]\n",
            "[Epoch 24/200] [Batch 485/938] [D loss: 0.615144] [G loss: 0.074512]\n",
            "[Epoch 24/200] [Batch 486/938] [D loss: 0.617500] [G loss: 0.075343]\n",
            "[Epoch 24/200] [Batch 487/938] [D loss: 0.605654] [G loss: 0.078100]\n",
            "[Epoch 24/200] [Batch 488/938] [D loss: 0.597654] [G loss: 0.083766]\n",
            "[Epoch 24/200] [Batch 489/938] [D loss: 0.607529] [G loss: 0.072181]\n",
            "[Epoch 24/200] [Batch 490/938] [D loss: 0.617606] [G loss: 0.080771]\n",
            "[Epoch 24/200] [Batch 491/938] [D loss: 0.640920] [G loss: 0.073027]\n",
            "[Epoch 24/200] [Batch 492/938] [D loss: 0.632700] [G loss: 0.075870]\n",
            "[Epoch 24/200] [Batch 493/938] [D loss: 0.589042] [G loss: 0.073096]\n",
            "[Epoch 24/200] [Batch 494/938] [D loss: 0.647269] [G loss: 0.068171]\n",
            "[Epoch 24/200] [Batch 495/938] [D loss: 0.675640] [G loss: 0.078432]\n",
            "[Epoch 24/200] [Batch 496/938] [D loss: 0.640964] [G loss: 0.074125]\n",
            "[Epoch 24/200] [Batch 497/938] [D loss: 0.638421] [G loss: 0.073704]\n",
            "[Epoch 24/200] [Batch 498/938] [D loss: 0.626219] [G loss: 0.066278]\n",
            "[Epoch 24/200] [Batch 499/938] [D loss: 0.688483] [G loss: 0.073278]\n",
            "[Epoch 24/200] [Batch 500/938] [D loss: 0.643923] [G loss: 0.075035]\n",
            "[Epoch 24/200] [Batch 501/938] [D loss: 0.607585] [G loss: 0.071480]\n",
            "[Epoch 24/200] [Batch 502/938] [D loss: 0.587184] [G loss: 0.067427]\n",
            "[Epoch 24/200] [Batch 503/938] [D loss: 0.605995] [G loss: 0.073573]\n",
            "[Epoch 24/200] [Batch 504/938] [D loss: 0.638267] [G loss: 0.075372]\n",
            "[Epoch 24/200] [Batch 505/938] [D loss: 0.624566] [G loss: 0.075847]\n",
            "[Epoch 24/200] [Batch 506/938] [D loss: 0.661044] [G loss: 0.071840]\n",
            "[Epoch 24/200] [Batch 507/938] [D loss: 0.641801] [G loss: 0.063992]\n",
            "[Epoch 24/200] [Batch 508/938] [D loss: 0.657898] [G loss: 0.069916]\n",
            "[Epoch 24/200] [Batch 509/938] [D loss: 0.608332] [G loss: 0.069222]\n",
            "[Epoch 24/200] [Batch 510/938] [D loss: 0.645663] [G loss: 0.072489]\n",
            "[Epoch 24/200] [Batch 511/938] [D loss: 0.620534] [G loss: 0.073530]\n",
            "[Epoch 24/200] [Batch 512/938] [D loss: 0.585596] [G loss: 0.068055]\n",
            "[Epoch 24/200] [Batch 513/938] [D loss: 0.642420] [G loss: 0.081185]\n",
            "[Epoch 24/200] [Batch 514/938] [D loss: 0.677041] [G loss: 0.073750]\n",
            "[Epoch 24/200] [Batch 515/938] [D loss: 0.652010] [G loss: 0.080643]\n",
            "[Epoch 24/200] [Batch 516/938] [D loss: 0.628387] [G loss: 0.071855]\n",
            "[Epoch 24/200] [Batch 517/938] [D loss: 0.650516] [G loss: 0.080487]\n",
            "[Epoch 24/200] [Batch 518/938] [D loss: 0.638376] [G loss: 0.075136]\n",
            "[Epoch 24/200] [Batch 519/938] [D loss: 0.651830] [G loss: 0.071426]\n",
            "[Epoch 24/200] [Batch 520/938] [D loss: 0.638242] [G loss: 0.068829]\n",
            "[Epoch 24/200] [Batch 521/938] [D loss: 0.636785] [G loss: 0.068670]\n",
            "[Epoch 24/200] [Batch 522/938] [D loss: 0.628765] [G loss: 0.077414]\n",
            "[Epoch 24/200] [Batch 523/938] [D loss: 0.635160] [G loss: 0.066089]\n",
            "[Epoch 24/200] [Batch 524/938] [D loss: 0.625538] [G loss: 0.067956]\n",
            "[Epoch 24/200] [Batch 525/938] [D loss: 0.644935] [G loss: 0.073662]\n",
            "[Epoch 24/200] [Batch 526/938] [D loss: 0.644230] [G loss: 0.068467]\n",
            "[Epoch 24/200] [Batch 527/938] [D loss: 0.648663] [G loss: 0.069376]\n",
            "[Epoch 24/200] [Batch 528/938] [D loss: 0.647370] [G loss: 0.073078]\n",
            "[Epoch 24/200] [Batch 529/938] [D loss: 0.627331] [G loss: 0.074828]\n",
            "[Epoch 24/200] [Batch 530/938] [D loss: 0.676544] [G loss: 0.075456]\n",
            "[Epoch 24/200] [Batch 531/938] [D loss: 0.631446] [G loss: 0.074319]\n",
            "[Epoch 24/200] [Batch 532/938] [D loss: 0.634905] [G loss: 0.077013]\n",
            "[Epoch 24/200] [Batch 533/938] [D loss: 0.639341] [G loss: 0.071483]\n",
            "[Epoch 24/200] [Batch 534/938] [D loss: 0.663111] [G loss: 0.066343]\n",
            "[Epoch 24/200] [Batch 535/938] [D loss: 0.630672] [G loss: 0.077463]\n",
            "[Epoch 24/200] [Batch 536/938] [D loss: 0.682256] [G loss: 0.074856]\n",
            "[Epoch 24/200] [Batch 537/938] [D loss: 0.637364] [G loss: 0.072306]\n",
            "[Epoch 24/200] [Batch 538/938] [D loss: 0.618389] [G loss: 0.081489]\n",
            "[Epoch 24/200] [Batch 539/938] [D loss: 0.633715] [G loss: 0.076437]\n",
            "[Epoch 24/200] [Batch 540/938] [D loss: 0.617494] [G loss: 0.077177]\n",
            "[Epoch 24/200] [Batch 541/938] [D loss: 0.611233] [G loss: 0.076749]\n",
            "[Epoch 24/200] [Batch 542/938] [D loss: 0.629368] [G loss: 0.074467]\n",
            "[Epoch 24/200] [Batch 543/938] [D loss: 0.652478] [G loss: 0.074649]\n",
            "[Epoch 24/200] [Batch 544/938] [D loss: 0.600572] [G loss: 0.076655]\n",
            "[Epoch 24/200] [Batch 545/938] [D loss: 0.665302] [G loss: 0.071802]\n",
            "[Epoch 24/200] [Batch 546/938] [D loss: 0.616174] [G loss: 0.071040]\n",
            "[Epoch 24/200] [Batch 547/938] [D loss: 0.631272] [G loss: 0.078687]\n",
            "[Epoch 24/200] [Batch 548/938] [D loss: 0.682676] [G loss: 0.072333]\n",
            "[Epoch 24/200] [Batch 549/938] [D loss: 0.592732] [G loss: 0.079091]\n",
            "[Epoch 24/200] [Batch 550/938] [D loss: 0.645534] [G loss: 0.064387]\n",
            "[Epoch 24/200] [Batch 551/938] [D loss: 0.610199] [G loss: 0.072256]\n",
            "[Epoch 24/200] [Batch 552/938] [D loss: 0.620682] [G loss: 0.075032]\n",
            "[Epoch 24/200] [Batch 553/938] [D loss: 0.619367] [G loss: 0.075391]\n",
            "[Epoch 24/200] [Batch 554/938] [D loss: 0.609178] [G loss: 0.074407]\n",
            "[Epoch 24/200] [Batch 555/938] [D loss: 0.638077] [G loss: 0.078185]\n",
            "[Epoch 24/200] [Batch 556/938] [D loss: 0.640353] [G loss: 0.072764]\n",
            "[Epoch 24/200] [Batch 557/938] [D loss: 0.627776] [G loss: 0.073251]\n",
            "[Epoch 24/200] [Batch 558/938] [D loss: 0.624022] [G loss: 0.070563]\n",
            "[Epoch 24/200] [Batch 559/938] [D loss: 0.644538] [G loss: 0.067621]\n",
            "[Epoch 24/200] [Batch 560/938] [D loss: 0.654356] [G loss: 0.070230]\n",
            "[Epoch 24/200] [Batch 561/938] [D loss: 0.611389] [G loss: 0.075280]\n",
            "[Epoch 24/200] [Batch 562/938] [D loss: 0.629750] [G loss: 0.067687]\n",
            "[Epoch 24/200] [Batch 563/938] [D loss: 0.626667] [G loss: 0.069420]\n",
            "[Epoch 24/200] [Batch 564/938] [D loss: 0.625315] [G loss: 0.072374]\n",
            "[Epoch 24/200] [Batch 565/938] [D loss: 0.617919] [G loss: 0.072587]\n",
            "[Epoch 24/200] [Batch 566/938] [D loss: 0.600363] [G loss: 0.069775]\n",
            "[Epoch 24/200] [Batch 567/938] [D loss: 0.675827] [G loss: 0.072094]\n",
            "[Epoch 24/200] [Batch 568/938] [D loss: 0.615553] [G loss: 0.073044]\n",
            "[Epoch 24/200] [Batch 569/938] [D loss: 0.605952] [G loss: 0.071303]\n",
            "[Epoch 24/200] [Batch 570/938] [D loss: 0.681352] [G loss: 0.072690]\n",
            "[Epoch 24/200] [Batch 571/938] [D loss: 0.614566] [G loss: 0.074775]\n",
            "[Epoch 24/200] [Batch 572/938] [D loss: 0.641739] [G loss: 0.073851]\n",
            "[Epoch 24/200] [Batch 573/938] [D loss: 0.650528] [G loss: 0.075926]\n",
            "[Epoch 24/200] [Batch 574/938] [D loss: 0.626371] [G loss: 0.074885]\n",
            "[Epoch 24/200] [Batch 575/938] [D loss: 0.674710] [G loss: 0.067733]\n",
            "[Epoch 24/200] [Batch 576/938] [D loss: 0.679838] [G loss: 0.073145]\n",
            "[Epoch 24/200] [Batch 577/938] [D loss: 0.629478] [G loss: 0.072150]\n",
            "[Epoch 24/200] [Batch 578/938] [D loss: 0.628057] [G loss: 0.077299]\n",
            "[Epoch 24/200] [Batch 579/938] [D loss: 0.654514] [G loss: 0.071252]\n",
            "[Epoch 24/200] [Batch 580/938] [D loss: 0.616024] [G loss: 0.071439]\n",
            "[Epoch 24/200] [Batch 581/938] [D loss: 0.598466] [G loss: 0.070381]\n",
            "[Epoch 24/200] [Batch 582/938] [D loss: 0.661283] [G loss: 0.074642]\n",
            "[Epoch 24/200] [Batch 583/938] [D loss: 0.652348] [G loss: 0.075602]\n",
            "[Epoch 24/200] [Batch 584/938] [D loss: 0.640848] [G loss: 0.068133]\n",
            "[Epoch 24/200] [Batch 585/938] [D loss: 0.638857] [G loss: 0.077812]\n",
            "[Epoch 24/200] [Batch 586/938] [D loss: 0.661172] [G loss: 0.071213]\n",
            "[Epoch 24/200] [Batch 587/938] [D loss: 0.688136] [G loss: 0.072010]\n",
            "[Epoch 24/200] [Batch 588/938] [D loss: 0.647647] [G loss: 0.077109]\n",
            "[Epoch 24/200] [Batch 589/938] [D loss: 0.633906] [G loss: 0.066104]\n",
            "[Epoch 24/200] [Batch 590/938] [D loss: 0.634257] [G loss: 0.078945]\n",
            "[Epoch 24/200] [Batch 591/938] [D loss: 0.616082] [G loss: 0.070759]\n",
            "[Epoch 24/200] [Batch 592/938] [D loss: 0.641247] [G loss: 0.077557]\n",
            "[Epoch 24/200] [Batch 593/938] [D loss: 0.642212] [G loss: 0.076211]\n",
            "[Epoch 24/200] [Batch 594/938] [D loss: 0.625646] [G loss: 0.078332]\n",
            "[Epoch 24/200] [Batch 595/938] [D loss: 0.622918] [G loss: 0.067363]\n",
            "[Epoch 24/200] [Batch 596/938] [D loss: 0.636784] [G loss: 0.068732]\n",
            "[Epoch 24/200] [Batch 597/938] [D loss: 0.627197] [G loss: 0.070794]\n",
            "[Epoch 24/200] [Batch 598/938] [D loss: 0.633676] [G loss: 0.073998]\n",
            "[Epoch 24/200] [Batch 599/938] [D loss: 0.636098] [G loss: 0.072226]\n",
            "[Epoch 24/200] [Batch 600/938] [D loss: 0.608446] [G loss: 0.070702]\n",
            "[Epoch 24/200] [Batch 601/938] [D loss: 0.648555] [G loss: 0.073719]\n",
            "[Epoch 24/200] [Batch 602/938] [D loss: 0.627713] [G loss: 0.076237]\n",
            "[Epoch 24/200] [Batch 603/938] [D loss: 0.631566] [G loss: 0.079075]\n",
            "[Epoch 24/200] [Batch 604/938] [D loss: 0.631898] [G loss: 0.073629]\n",
            "[Epoch 24/200] [Batch 605/938] [D loss: 0.650657] [G loss: 0.069860]\n",
            "[Epoch 24/200] [Batch 606/938] [D loss: 0.654380] [G loss: 0.070474]\n",
            "[Epoch 24/200] [Batch 607/938] [D loss: 0.638184] [G loss: 0.080295]\n",
            "[Epoch 24/200] [Batch 608/938] [D loss: 0.597389] [G loss: 0.071867]\n",
            "[Epoch 24/200] [Batch 609/938] [D loss: 0.621415] [G loss: 0.066359]\n",
            "[Epoch 24/200] [Batch 610/938] [D loss: 0.671090] [G loss: 0.074207]\n",
            "[Epoch 24/200] [Batch 611/938] [D loss: 0.649089] [G loss: 0.068161]\n",
            "[Epoch 24/200] [Batch 612/938] [D loss: 0.628696] [G loss: 0.070522]\n",
            "[Epoch 24/200] [Batch 613/938] [D loss: 0.647196] [G loss: 0.073163]\n",
            "[Epoch 24/200] [Batch 614/938] [D loss: 0.644540] [G loss: 0.069904]\n",
            "[Epoch 24/200] [Batch 615/938] [D loss: 0.629017] [G loss: 0.074569]\n",
            "[Epoch 24/200] [Batch 616/938] [D loss: 0.617555] [G loss: 0.072500]\n",
            "[Epoch 24/200] [Batch 617/938] [D loss: 0.631124] [G loss: 0.070959]\n",
            "[Epoch 24/200] [Batch 618/938] [D loss: 0.654179] [G loss: 0.075488]\n",
            "[Epoch 24/200] [Batch 619/938] [D loss: 0.641406] [G loss: 0.072129]\n",
            "[Epoch 24/200] [Batch 620/938] [D loss: 0.622458] [G loss: 0.076837]\n",
            "[Epoch 24/200] [Batch 621/938] [D loss: 0.628563] [G loss: 0.072201]\n",
            "[Epoch 24/200] [Batch 622/938] [D loss: 0.663710] [G loss: 0.074759]\n",
            "[Epoch 24/200] [Batch 623/938] [D loss: 0.666914] [G loss: 0.071916]\n",
            "[Epoch 24/200] [Batch 624/938] [D loss: 0.669300] [G loss: 0.067895]\n",
            "[Epoch 24/200] [Batch 625/938] [D loss: 0.614182] [G loss: 0.063098]\n",
            "[Epoch 24/200] [Batch 626/938] [D loss: 0.629911] [G loss: 0.067393]\n",
            "[Epoch 24/200] [Batch 627/938] [D loss: 0.637405] [G loss: 0.071103]\n",
            "[Epoch 24/200] [Batch 628/938] [D loss: 0.615287] [G loss: 0.071407]\n",
            "[Epoch 24/200] [Batch 629/938] [D loss: 0.638802] [G loss: 0.067107]\n",
            "[Epoch 24/200] [Batch 630/938] [D loss: 0.609688] [G loss: 0.076300]\n",
            "[Epoch 24/200] [Batch 631/938] [D loss: 0.623041] [G loss: 0.071792]\n",
            "[Epoch 24/200] [Batch 632/938] [D loss: 0.625900] [G loss: 0.078145]\n",
            "[Epoch 24/200] [Batch 633/938] [D loss: 0.671779] [G loss: 0.072445]\n",
            "[Epoch 24/200] [Batch 634/938] [D loss: 0.626998] [G loss: 0.066434]\n",
            "[Epoch 24/200] [Batch 635/938] [D loss: 0.620821] [G loss: 0.066924]\n",
            "[Epoch 24/200] [Batch 636/938] [D loss: 0.625458] [G loss: 0.073556]\n",
            "[Epoch 24/200] [Batch 637/938] [D loss: 0.655947] [G loss: 0.071711]\n",
            "[Epoch 24/200] [Batch 638/938] [D loss: 0.620116] [G loss: 0.074960]\n",
            "[Epoch 24/200] [Batch 639/938] [D loss: 0.615475] [G loss: 0.067168]\n",
            "[Epoch 24/200] [Batch 640/938] [D loss: 0.660917] [G loss: 0.072035]\n",
            "[Epoch 24/200] [Batch 641/938] [D loss: 0.641264] [G loss: 0.069076]\n",
            "[Epoch 24/200] [Batch 642/938] [D loss: 0.627312] [G loss: 0.068422]\n",
            "[Epoch 24/200] [Batch 643/938] [D loss: 0.653018] [G loss: 0.078988]\n",
            "[Epoch 24/200] [Batch 644/938] [D loss: 0.635731] [G loss: 0.072498]\n",
            "[Epoch 24/200] [Batch 645/938] [D loss: 0.644293] [G loss: 0.069097]\n",
            "[Epoch 24/200] [Batch 646/938] [D loss: 0.636775] [G loss: 0.069370]\n",
            "[Epoch 24/200] [Batch 647/938] [D loss: 0.617878] [G loss: 0.064441]\n",
            "[Epoch 24/200] [Batch 648/938] [D loss: 0.671325] [G loss: 0.071259]\n",
            "[Epoch 24/200] [Batch 649/938] [D loss: 0.604491] [G loss: 0.069122]\n",
            "[Epoch 24/200] [Batch 650/938] [D loss: 0.637712] [G loss: 0.068139]\n",
            "[Epoch 24/200] [Batch 651/938] [D loss: 0.618969] [G loss: 0.078043]\n",
            "[Epoch 24/200] [Batch 652/938] [D loss: 0.663116] [G loss: 0.082834]\n",
            "[Epoch 24/200] [Batch 653/938] [D loss: 0.644930] [G loss: 0.073229]\n",
            "[Epoch 24/200] [Batch 654/938] [D loss: 0.653644] [G loss: 0.071528]\n",
            "[Epoch 24/200] [Batch 655/938] [D loss: 0.647930] [G loss: 0.076440]\n",
            "[Epoch 24/200] [Batch 656/938] [D loss: 0.626486] [G loss: 0.072060]\n",
            "[Epoch 24/200] [Batch 657/938] [D loss: 0.665804] [G loss: 0.069594]\n",
            "[Epoch 24/200] [Batch 658/938] [D loss: 0.660005] [G loss: 0.069783]\n",
            "[Epoch 24/200] [Batch 659/938] [D loss: 0.627523] [G loss: 0.075408]\n",
            "[Epoch 24/200] [Batch 660/938] [D loss: 0.620337] [G loss: 0.076173]\n",
            "[Epoch 24/200] [Batch 661/938] [D loss: 0.623974] [G loss: 0.069457]\n",
            "[Epoch 24/200] [Batch 662/938] [D loss: 0.659361] [G loss: 0.077732]\n",
            "[Epoch 24/200] [Batch 663/938] [D loss: 0.644501] [G loss: 0.073364]\n",
            "[Epoch 24/200] [Batch 664/938] [D loss: 0.637196] [G loss: 0.078853]\n",
            "[Epoch 24/200] [Batch 665/938] [D loss: 0.662455] [G loss: 0.073435]\n",
            "[Epoch 24/200] [Batch 666/938] [D loss: 0.650922] [G loss: 0.072630]\n",
            "[Epoch 24/200] [Batch 667/938] [D loss: 0.658712] [G loss: 0.068904]\n",
            "[Epoch 24/200] [Batch 668/938] [D loss: 0.686706] [G loss: 0.073737]\n",
            "[Epoch 24/200] [Batch 669/938] [D loss: 0.669467] [G loss: 0.077182]\n",
            "[Epoch 24/200] [Batch 670/938] [D loss: 0.594465] [G loss: 0.069309]\n",
            "[Epoch 24/200] [Batch 671/938] [D loss: 0.610303] [G loss: 0.076917]\n",
            "[Epoch 24/200] [Batch 672/938] [D loss: 0.640046] [G loss: 0.075737]\n",
            "[Epoch 24/200] [Batch 673/938] [D loss: 0.661643] [G loss: 0.073490]\n",
            "[Epoch 24/200] [Batch 674/938] [D loss: 0.634772] [G loss: 0.073785]\n",
            "[Epoch 24/200] [Batch 675/938] [D loss: 0.596518] [G loss: 0.068249]\n",
            "[Epoch 24/200] [Batch 676/938] [D loss: 0.607189] [G loss: 0.074587]\n",
            "[Epoch 24/200] [Batch 677/938] [D loss: 0.661341] [G loss: 0.074008]\n",
            "[Epoch 24/200] [Batch 678/938] [D loss: 0.674317] [G loss: 0.071175]\n",
            "[Epoch 24/200] [Batch 679/938] [D loss: 0.609978] [G loss: 0.070750]\n",
            "[Epoch 24/200] [Batch 680/938] [D loss: 0.633935] [G loss: 0.068938]\n",
            "[Epoch 24/200] [Batch 681/938] [D loss: 0.630625] [G loss: 0.080709]\n",
            "[Epoch 24/200] [Batch 682/938] [D loss: 0.685961] [G loss: 0.070377]\n",
            "[Epoch 24/200] [Batch 683/938] [D loss: 0.664581] [G loss: 0.073253]\n",
            "[Epoch 24/200] [Batch 684/938] [D loss: 0.657422] [G loss: 0.072851]\n",
            "[Epoch 24/200] [Batch 685/938] [D loss: 0.647946] [G loss: 0.071305]\n",
            "[Epoch 24/200] [Batch 686/938] [D loss: 0.605828] [G loss: 0.072213]\n",
            "[Epoch 24/200] [Batch 687/938] [D loss: 0.613095] [G loss: 0.069095]\n",
            "[Epoch 24/200] [Batch 688/938] [D loss: 0.659667] [G loss: 0.072705]\n",
            "[Epoch 24/200] [Batch 689/938] [D loss: 0.657611] [G loss: 0.074539]\n",
            "[Epoch 24/200] [Batch 690/938] [D loss: 0.663749] [G loss: 0.069054]\n",
            "[Epoch 24/200] [Batch 691/938] [D loss: 0.641300] [G loss: 0.082254]\n",
            "[Epoch 24/200] [Batch 692/938] [D loss: 0.620273] [G loss: 0.072391]\n",
            "[Epoch 24/200] [Batch 693/938] [D loss: 0.667120] [G loss: 0.073447]\n",
            "[Epoch 24/200] [Batch 694/938] [D loss: 0.671534] [G loss: 0.074845]\n",
            "[Epoch 24/200] [Batch 695/938] [D loss: 0.634404] [G loss: 0.073405]\n",
            "[Epoch 24/200] [Batch 696/938] [D loss: 0.642215] [G loss: 0.071917]\n",
            "[Epoch 24/200] [Batch 697/938] [D loss: 0.656579] [G loss: 0.072107]\n",
            "[Epoch 24/200] [Batch 698/938] [D loss: 0.637264] [G loss: 0.069577]\n",
            "[Epoch 24/200] [Batch 699/938] [D loss: 0.665642] [G loss: 0.066472]\n",
            "[Epoch 24/200] [Batch 700/938] [D loss: 0.635253] [G loss: 0.071745]\n",
            "[Epoch 24/200] [Batch 701/938] [D loss: 0.648677] [G loss: 0.068780]\n",
            "[Epoch 24/200] [Batch 702/938] [D loss: 0.629544] [G loss: 0.072146]\n",
            "[Epoch 24/200] [Batch 703/938] [D loss: 0.603367] [G loss: 0.068297]\n",
            "[Epoch 24/200] [Batch 704/938] [D loss: 0.641199] [G loss: 0.070522]\n",
            "[Epoch 24/200] [Batch 705/938] [D loss: 0.649334] [G loss: 0.082615]\n",
            "[Epoch 24/200] [Batch 706/938] [D loss: 0.658331] [G loss: 0.071816]\n",
            "[Epoch 24/200] [Batch 707/938] [D loss: 0.621210] [G loss: 0.077273]\n",
            "[Epoch 24/200] [Batch 708/938] [D loss: 0.649829] [G loss: 0.075349]\n",
            "[Epoch 24/200] [Batch 709/938] [D loss: 0.593251] [G loss: 0.069402]\n",
            "[Epoch 24/200] [Batch 710/938] [D loss: 0.627485] [G loss: 0.077483]\n",
            "[Epoch 24/200] [Batch 711/938] [D loss: 0.645737] [G loss: 0.070482]\n",
            "[Epoch 24/200] [Batch 712/938] [D loss: 0.672425] [G loss: 0.070733]\n",
            "[Epoch 24/200] [Batch 713/938] [D loss: 0.637806] [G loss: 0.071058]\n",
            "[Epoch 24/200] [Batch 714/938] [D loss: 0.662994] [G loss: 0.080979]\n",
            "[Epoch 24/200] [Batch 715/938] [D loss: 0.624644] [G loss: 0.076474]\n",
            "[Epoch 24/200] [Batch 716/938] [D loss: 0.639901] [G loss: 0.075995]\n",
            "[Epoch 24/200] [Batch 717/938] [D loss: 0.650213] [G loss: 0.080909]\n",
            "[Epoch 24/200] [Batch 718/938] [D loss: 0.666849] [G loss: 0.067047]\n",
            "[Epoch 24/200] [Batch 719/938] [D loss: 0.638619] [G loss: 0.078406]\n",
            "[Epoch 24/200] [Batch 720/938] [D loss: 0.641025] [G loss: 0.074137]\n",
            "[Epoch 24/200] [Batch 721/938] [D loss: 0.711219] [G loss: 0.078553]\n",
            "[Epoch 24/200] [Batch 722/938] [D loss: 0.678357] [G loss: 0.074661]\n",
            "[Epoch 24/200] [Batch 723/938] [D loss: 0.649984] [G loss: 0.076955]\n",
            "[Epoch 24/200] [Batch 724/938] [D loss: 0.656731] [G loss: 0.080063]\n",
            "[Epoch 24/200] [Batch 725/938] [D loss: 0.625687] [G loss: 0.075542]\n",
            "[Epoch 24/200] [Batch 726/938] [D loss: 0.632213] [G loss: 0.080835]\n",
            "[Epoch 24/200] [Batch 727/938] [D loss: 0.660770] [G loss: 0.072443]\n",
            "[Epoch 24/200] [Batch 728/938] [D loss: 0.654753] [G loss: 0.074123]\n",
            "[Epoch 24/200] [Batch 729/938] [D loss: 0.656409] [G loss: 0.067311]\n",
            "[Epoch 24/200] [Batch 730/938] [D loss: 0.676459] [G loss: 0.071466]\n",
            "[Epoch 24/200] [Batch 731/938] [D loss: 0.647950] [G loss: 0.078469]\n",
            "[Epoch 24/200] [Batch 732/938] [D loss: 0.653592] [G loss: 0.079677]\n",
            "[Epoch 24/200] [Batch 733/938] [D loss: 0.651334] [G loss: 0.074238]\n",
            "[Epoch 24/200] [Batch 734/938] [D loss: 0.638197] [G loss: 0.077572]\n",
            "[Epoch 24/200] [Batch 735/938] [D loss: 0.616130] [G loss: 0.075364]\n",
            "[Epoch 24/200] [Batch 736/938] [D loss: 0.644767] [G loss: 0.073683]\n",
            "[Epoch 24/200] [Batch 737/938] [D loss: 0.672450] [G loss: 0.080007]\n",
            "[Epoch 24/200] [Batch 738/938] [D loss: 0.607312] [G loss: 0.075686]\n",
            "[Epoch 24/200] [Batch 739/938] [D loss: 0.646002] [G loss: 0.075761]\n",
            "[Epoch 24/200] [Batch 740/938] [D loss: 0.622122] [G loss: 0.072593]\n",
            "[Epoch 24/200] [Batch 741/938] [D loss: 0.655692] [G loss: 0.069947]\n",
            "[Epoch 24/200] [Batch 742/938] [D loss: 0.648780] [G loss: 0.074628]\n",
            "[Epoch 24/200] [Batch 743/938] [D loss: 0.649613] [G loss: 0.080889]\n",
            "[Epoch 24/200] [Batch 744/938] [D loss: 0.635804] [G loss: 0.066588]\n",
            "[Epoch 24/200] [Batch 745/938] [D loss: 0.655190] [G loss: 0.068537]\n",
            "[Epoch 24/200] [Batch 746/938] [D loss: 0.621019] [G loss: 0.073572]\n",
            "[Epoch 24/200] [Batch 747/938] [D loss: 0.650602] [G loss: 0.078849]\n",
            "[Epoch 24/200] [Batch 748/938] [D loss: 0.623690] [G loss: 0.071683]\n",
            "[Epoch 24/200] [Batch 749/938] [D loss: 0.641429] [G loss: 0.070165]\n",
            "[Epoch 24/200] [Batch 750/938] [D loss: 0.617255] [G loss: 0.071049]\n",
            "[Epoch 24/200] [Batch 751/938] [D loss: 0.650023] [G loss: 0.073418]\n",
            "[Epoch 24/200] [Batch 752/938] [D loss: 0.679326] [G loss: 0.068824]\n",
            "[Epoch 24/200] [Batch 753/938] [D loss: 0.665473] [G loss: 0.074386]\n",
            "[Epoch 24/200] [Batch 754/938] [D loss: 0.630159] [G loss: 0.071343]\n",
            "[Epoch 24/200] [Batch 755/938] [D loss: 0.624892] [G loss: 0.070167]\n",
            "[Epoch 24/200] [Batch 756/938] [D loss: 0.624133] [G loss: 0.068803]\n",
            "[Epoch 24/200] [Batch 757/938] [D loss: 0.633484] [G loss: 0.074709]\n",
            "[Epoch 24/200] [Batch 758/938] [D loss: 0.653979] [G loss: 0.075186]\n",
            "[Epoch 24/200] [Batch 759/938] [D loss: 0.595615] [G loss: 0.072672]\n",
            "[Epoch 24/200] [Batch 760/938] [D loss: 0.682052] [G loss: 0.068153]\n",
            "[Epoch 24/200] [Batch 761/938] [D loss: 0.606380] [G loss: 0.078071]\n",
            "[Epoch 24/200] [Batch 762/938] [D loss: 0.617991] [G loss: 0.072625]\n",
            "[Epoch 24/200] [Batch 763/938] [D loss: 0.642595] [G loss: 0.072423]\n",
            "[Epoch 24/200] [Batch 764/938] [D loss: 0.672360] [G loss: 0.066143]\n",
            "[Epoch 24/200] [Batch 765/938] [D loss: 0.642793] [G loss: 0.069263]\n",
            "[Epoch 24/200] [Batch 766/938] [D loss: 0.631680] [G loss: 0.076708]\n",
            "[Epoch 24/200] [Batch 767/938] [D loss: 0.635613] [G loss: 0.072857]\n",
            "[Epoch 24/200] [Batch 768/938] [D loss: 0.626152] [G loss: 0.079485]\n",
            "[Epoch 24/200] [Batch 769/938] [D loss: 0.633179] [G loss: 0.073663]\n",
            "[Epoch 24/200] [Batch 770/938] [D loss: 0.618495] [G loss: 0.075333]\n",
            "[Epoch 24/200] [Batch 771/938] [D loss: 0.663961] [G loss: 0.079898]\n",
            "[Epoch 24/200] [Batch 772/938] [D loss: 0.633934] [G loss: 0.065432]\n",
            "[Epoch 24/200] [Batch 773/938] [D loss: 0.603374] [G loss: 0.075719]\n",
            "[Epoch 24/200] [Batch 774/938] [D loss: 0.649982] [G loss: 0.068903]\n",
            "[Epoch 24/200] [Batch 775/938] [D loss: 0.624265] [G loss: 0.072210]\n",
            "[Epoch 24/200] [Batch 776/938] [D loss: 0.617020] [G loss: 0.069712]\n",
            "[Epoch 24/200] [Batch 777/938] [D loss: 0.629948] [G loss: 0.080207]\n",
            "[Epoch 24/200] [Batch 778/938] [D loss: 0.616956] [G loss: 0.076240]\n",
            "[Epoch 24/200] [Batch 779/938] [D loss: 0.632857] [G loss: 0.073373]\n",
            "[Epoch 24/200] [Batch 780/938] [D loss: 0.659167] [G loss: 0.076180]\n",
            "[Epoch 24/200] [Batch 781/938] [D loss: 0.620828] [G loss: 0.079279]\n",
            "[Epoch 24/200] [Batch 782/938] [D loss: 0.677816] [G loss: 0.075966]\n",
            "[Epoch 24/200] [Batch 783/938] [D loss: 0.653943] [G loss: 0.080154]\n",
            "[Epoch 24/200] [Batch 784/938] [D loss: 0.656363] [G loss: 0.071311]\n",
            "[Epoch 24/200] [Batch 785/938] [D loss: 0.591588] [G loss: 0.077784]\n",
            "[Epoch 24/200] [Batch 786/938] [D loss: 0.647686] [G loss: 0.071253]\n",
            "[Epoch 24/200] [Batch 787/938] [D loss: 0.622870] [G loss: 0.084860]\n",
            "[Epoch 24/200] [Batch 788/938] [D loss: 0.685237] [G loss: 0.069816]\n",
            "[Epoch 24/200] [Batch 789/938] [D loss: 0.636893] [G loss: 0.069565]\n",
            "[Epoch 24/200] [Batch 790/938] [D loss: 0.645900] [G loss: 0.078289]\n",
            "[Epoch 24/200] [Batch 791/938] [D loss: 0.619139] [G loss: 0.074714]\n",
            "[Epoch 24/200] [Batch 792/938] [D loss: 0.667862] [G loss: 0.070383]\n",
            "[Epoch 24/200] [Batch 793/938] [D loss: 0.609712] [G loss: 0.075083]\n",
            "[Epoch 24/200] [Batch 794/938] [D loss: 0.640815] [G loss: 0.072611]\n",
            "[Epoch 24/200] [Batch 795/938] [D loss: 0.641914] [G loss: 0.076566]\n",
            "[Epoch 24/200] [Batch 796/938] [D loss: 0.616737] [G loss: 0.078909]\n",
            "[Epoch 24/200] [Batch 797/938] [D loss: 0.610375] [G loss: 0.069920]\n",
            "[Epoch 24/200] [Batch 798/938] [D loss: 0.654639] [G loss: 0.070766]\n",
            "[Epoch 24/200] [Batch 799/938] [D loss: 0.622808] [G loss: 0.074041]\n",
            "[Epoch 24/200] [Batch 800/938] [D loss: 0.665752] [G loss: 0.071762]\n",
            "[Epoch 24/200] [Batch 801/938] [D loss: 0.644978] [G loss: 0.077286]\n",
            "[Epoch 24/200] [Batch 802/938] [D loss: 0.665110] [G loss: 0.063913]\n",
            "[Epoch 24/200] [Batch 803/938] [D loss: 0.651968] [G loss: 0.068476]\n",
            "[Epoch 24/200] [Batch 804/938] [D loss: 0.632546] [G loss: 0.081131]\n",
            "[Epoch 24/200] [Batch 805/938] [D loss: 0.606277] [G loss: 0.081140]\n",
            "[Epoch 24/200] [Batch 806/938] [D loss: 0.652144] [G loss: 0.072084]\n",
            "[Epoch 24/200] [Batch 807/938] [D loss: 0.603004] [G loss: 0.073048]\n",
            "[Epoch 24/200] [Batch 808/938] [D loss: 0.649072] [G loss: 0.072102]\n",
            "[Epoch 24/200] [Batch 809/938] [D loss: 0.636636] [G loss: 0.071169]\n",
            "[Epoch 24/200] [Batch 810/938] [D loss: 0.659784] [G loss: 0.067456]\n",
            "[Epoch 24/200] [Batch 811/938] [D loss: 0.651498] [G loss: 0.068351]\n",
            "[Epoch 24/200] [Batch 812/938] [D loss: 0.637084] [G loss: 0.081484]\n",
            "[Epoch 24/200] [Batch 813/938] [D loss: 0.637817] [G loss: 0.073400]\n",
            "[Epoch 24/200] [Batch 814/938] [D loss: 0.624577] [G loss: 0.073164]\n",
            "[Epoch 24/200] [Batch 815/938] [D loss: 0.607839] [G loss: 0.073343]\n",
            "[Epoch 24/200] [Batch 816/938] [D loss: 0.634678] [G loss: 0.073949]\n",
            "[Epoch 24/200] [Batch 817/938] [D loss: 0.645508] [G loss: 0.069113]\n",
            "[Epoch 24/200] [Batch 818/938] [D loss: 0.618675] [G loss: 0.076270]\n",
            "[Epoch 24/200] [Batch 819/938] [D loss: 0.658333] [G loss: 0.074786]\n",
            "[Epoch 24/200] [Batch 820/938] [D loss: 0.654427] [G loss: 0.073531]\n",
            "[Epoch 24/200] [Batch 821/938] [D loss: 0.649005] [G loss: 0.074039]\n",
            "[Epoch 24/200] [Batch 822/938] [D loss: 0.629760] [G loss: 0.075686]\n",
            "[Epoch 24/200] [Batch 823/938] [D loss: 0.638026] [G loss: 0.073582]\n",
            "[Epoch 24/200] [Batch 824/938] [D loss: 0.629340] [G loss: 0.072155]\n",
            "[Epoch 24/200] [Batch 825/938] [D loss: 0.610067] [G loss: 0.070256]\n",
            "[Epoch 24/200] [Batch 826/938] [D loss: 0.640160] [G loss: 0.079230]\n",
            "[Epoch 24/200] [Batch 827/938] [D loss: 0.630864] [G loss: 0.072719]\n",
            "[Epoch 24/200] [Batch 828/938] [D loss: 0.694028] [G loss: 0.069581]\n",
            "[Epoch 24/200] [Batch 829/938] [D loss: 0.633121] [G loss: 0.073934]\n",
            "[Epoch 24/200] [Batch 830/938] [D loss: 0.641724] [G loss: 0.073633]\n",
            "[Epoch 24/200] [Batch 831/938] [D loss: 0.662851] [G loss: 0.073633]\n",
            "[Epoch 24/200] [Batch 832/938] [D loss: 0.637143] [G loss: 0.065074]\n",
            "[Epoch 24/200] [Batch 833/938] [D loss: 0.622281] [G loss: 0.074790]\n",
            "[Epoch 24/200] [Batch 834/938] [D loss: 0.625558] [G loss: 0.077868]\n",
            "[Epoch 24/200] [Batch 835/938] [D loss: 0.608078] [G loss: 0.071878]\n",
            "[Epoch 24/200] [Batch 836/938] [D loss: 0.652860] [G loss: 0.072798]\n",
            "[Epoch 24/200] [Batch 837/938] [D loss: 0.670603] [G loss: 0.069580]\n",
            "[Epoch 24/200] [Batch 838/938] [D loss: 0.638344] [G loss: 0.070676]\n",
            "[Epoch 24/200] [Batch 839/938] [D loss: 0.630993] [G loss: 0.081768]\n",
            "[Epoch 24/200] [Batch 840/938] [D loss: 0.664521] [G loss: 0.073743]\n",
            "[Epoch 24/200] [Batch 841/938] [D loss: 0.631966] [G loss: 0.079582]\n",
            "[Epoch 24/200] [Batch 842/938] [D loss: 0.662847] [G loss: 0.072274]\n",
            "[Epoch 24/200] [Batch 843/938] [D loss: 0.628104] [G loss: 0.075346]\n",
            "[Epoch 24/200] [Batch 844/938] [D loss: 0.623783] [G loss: 0.075023]\n",
            "[Epoch 24/200] [Batch 845/938] [D loss: 0.658635] [G loss: 0.071074]\n",
            "[Epoch 24/200] [Batch 846/938] [D loss: 0.623200] [G loss: 0.079562]\n",
            "[Epoch 24/200] [Batch 847/938] [D loss: 0.673591] [G loss: 0.075817]\n",
            "[Epoch 24/200] [Batch 848/938] [D loss: 0.690848] [G loss: 0.070614]\n",
            "[Epoch 24/200] [Batch 849/938] [D loss: 0.650745] [G loss: 0.074756]\n",
            "[Epoch 24/200] [Batch 850/938] [D loss: 0.679166] [G loss: 0.067633]\n",
            "[Epoch 24/200] [Batch 851/938] [D loss: 0.592992] [G loss: 0.063928]\n",
            "[Epoch 24/200] [Batch 852/938] [D loss: 0.601827] [G loss: 0.072378]\n",
            "[Epoch 24/200] [Batch 853/938] [D loss: 0.640939] [G loss: 0.080002]\n",
            "[Epoch 24/200] [Batch 854/938] [D loss: 0.653681] [G loss: 0.075080]\n",
            "[Epoch 24/200] [Batch 855/938] [D loss: 0.625416] [G loss: 0.071067]\n",
            "[Epoch 24/200] [Batch 856/938] [D loss: 0.674076] [G loss: 0.067876]\n",
            "[Epoch 24/200] [Batch 857/938] [D loss: 0.600920] [G loss: 0.079407]\n",
            "[Epoch 24/200] [Batch 858/938] [D loss: 0.639062] [G loss: 0.069000]\n",
            "[Epoch 24/200] [Batch 859/938] [D loss: 0.661295] [G loss: 0.070982]\n",
            "[Epoch 24/200] [Batch 860/938] [D loss: 0.643798] [G loss: 0.072973]\n",
            "[Epoch 24/200] [Batch 861/938] [D loss: 0.615308] [G loss: 0.078442]\n",
            "[Epoch 24/200] [Batch 862/938] [D loss: 0.644510] [G loss: 0.074988]\n",
            "[Epoch 24/200] [Batch 863/938] [D loss: 0.637032] [G loss: 0.075678]\n",
            "[Epoch 24/200] [Batch 864/938] [D loss: 0.643205] [G loss: 0.067045]\n",
            "[Epoch 24/200] [Batch 865/938] [D loss: 0.642736] [G loss: 0.072827]\n",
            "[Epoch 24/200] [Batch 866/938] [D loss: 0.638811] [G loss: 0.076398]\n",
            "[Epoch 24/200] [Batch 867/938] [D loss: 0.659918] [G loss: 0.070488]\n",
            "[Epoch 24/200] [Batch 868/938] [D loss: 0.658567] [G loss: 0.070338]\n",
            "[Epoch 24/200] [Batch 869/938] [D loss: 0.635221] [G loss: 0.076153]\n",
            "[Epoch 24/200] [Batch 870/938] [D loss: 0.644162] [G loss: 0.075549]\n",
            "[Epoch 24/200] [Batch 871/938] [D loss: 0.619837] [G loss: 0.070963]\n",
            "[Epoch 24/200] [Batch 872/938] [D loss: 0.632698] [G loss: 0.079584]\n",
            "[Epoch 24/200] [Batch 873/938] [D loss: 0.642822] [G loss: 0.075098]\n",
            "[Epoch 24/200] [Batch 874/938] [D loss: 0.656316] [G loss: 0.076612]\n",
            "[Epoch 24/200] [Batch 875/938] [D loss: 0.647442] [G loss: 0.078680]\n",
            "[Epoch 24/200] [Batch 876/938] [D loss: 0.654646] [G loss: 0.075856]\n",
            "[Epoch 24/200] [Batch 877/938] [D loss: 0.636869] [G loss: 0.074473]\n",
            "[Epoch 24/200] [Batch 878/938] [D loss: 0.669495] [G loss: 0.069983]\n",
            "[Epoch 24/200] [Batch 879/938] [D loss: 0.624543] [G loss: 0.070824]\n",
            "[Epoch 24/200] [Batch 880/938] [D loss: 0.640778] [G loss: 0.067484]\n",
            "[Epoch 24/200] [Batch 881/938] [D loss: 0.644762] [G loss: 0.074575]\n",
            "[Epoch 24/200] [Batch 882/938] [D loss: 0.675659] [G loss: 0.087458]\n",
            "[Epoch 24/200] [Batch 883/938] [D loss: 0.600735] [G loss: 0.073919]\n",
            "[Epoch 24/200] [Batch 884/938] [D loss: 0.639884] [G loss: 0.073179]\n",
            "[Epoch 24/200] [Batch 885/938] [D loss: 0.646977] [G loss: 0.067374]\n",
            "[Epoch 24/200] [Batch 886/938] [D loss: 0.636925] [G loss: 0.068735]\n",
            "[Epoch 24/200] [Batch 887/938] [D loss: 0.615629] [G loss: 0.073610]\n",
            "[Epoch 24/200] [Batch 888/938] [D loss: 0.651881] [G loss: 0.078033]\n",
            "[Epoch 24/200] [Batch 889/938] [D loss: 0.615653] [G loss: 0.078377]\n",
            "[Epoch 24/200] [Batch 890/938] [D loss: 0.655600] [G loss: 0.070667]\n",
            "[Epoch 24/200] [Batch 891/938] [D loss: 0.661120] [G loss: 0.073423]\n",
            "[Epoch 24/200] [Batch 892/938] [D loss: 0.595190] [G loss: 0.077547]\n",
            "[Epoch 24/200] [Batch 893/938] [D loss: 0.605234] [G loss: 0.071586]\n",
            "[Epoch 24/200] [Batch 894/938] [D loss: 0.645435] [G loss: 0.076409]\n",
            "[Epoch 24/200] [Batch 895/938] [D loss: 0.668975] [G loss: 0.068512]\n",
            "[Epoch 24/200] [Batch 896/938] [D loss: 0.620301] [G loss: 0.070288]\n",
            "[Epoch 24/200] [Batch 897/938] [D loss: 0.666052] [G loss: 0.081665]\n",
            "[Epoch 24/200] [Batch 898/938] [D loss: 0.676708] [G loss: 0.077029]\n",
            "[Epoch 24/200] [Batch 899/938] [D loss: 0.631423] [G loss: 0.076426]\n",
            "[Epoch 24/200] [Batch 900/938] [D loss: 0.632249] [G loss: 0.075918]\n",
            "[Epoch 24/200] [Batch 901/938] [D loss: 0.676966] [G loss: 0.073037]\n",
            "[Epoch 24/200] [Batch 902/938] [D loss: 0.631837] [G loss: 0.076128]\n",
            "[Epoch 24/200] [Batch 903/938] [D loss: 0.620656] [G loss: 0.073541]\n",
            "[Epoch 24/200] [Batch 904/938] [D loss: 0.633279] [G loss: 0.069471]\n",
            "[Epoch 24/200] [Batch 905/938] [D loss: 0.629761] [G loss: 0.073973]\n",
            "[Epoch 24/200] [Batch 906/938] [D loss: 0.642436] [G loss: 0.075854]\n",
            "[Epoch 24/200] [Batch 907/938] [D loss: 0.631871] [G loss: 0.077042]\n",
            "[Epoch 24/200] [Batch 908/938] [D loss: 0.662649] [G loss: 0.072936]\n",
            "[Epoch 24/200] [Batch 909/938] [D loss: 0.621850] [G loss: 0.078991]\n",
            "[Epoch 24/200] [Batch 910/938] [D loss: 0.626075] [G loss: 0.071302]\n",
            "[Epoch 24/200] [Batch 911/938] [D loss: 0.645785] [G loss: 0.075065]\n",
            "[Epoch 24/200] [Batch 912/938] [D loss: 0.656194] [G loss: 0.072539]\n",
            "[Epoch 24/200] [Batch 913/938] [D loss: 0.650136] [G loss: 0.075011]\n",
            "[Epoch 24/200] [Batch 914/938] [D loss: 0.651179] [G loss: 0.074872]\n",
            "[Epoch 24/200] [Batch 915/938] [D loss: 0.655425] [G loss: 0.072807]\n",
            "[Epoch 24/200] [Batch 916/938] [D loss: 0.604550] [G loss: 0.078820]\n",
            "[Epoch 24/200] [Batch 917/938] [D loss: 0.616174] [G loss: 0.070151]\n",
            "[Epoch 24/200] [Batch 918/938] [D loss: 0.623495] [G loss: 0.074185]\n",
            "[Epoch 24/200] [Batch 919/938] [D loss: 0.684167] [G loss: 0.072045]\n",
            "[Epoch 24/200] [Batch 920/938] [D loss: 0.651094] [G loss: 0.067443]\n",
            "[Epoch 24/200] [Batch 921/938] [D loss: 0.638009] [G loss: 0.074424]\n",
            "[Epoch 24/200] [Batch 922/938] [D loss: 0.655240] [G loss: 0.072592]\n",
            "[Epoch 24/200] [Batch 923/938] [D loss: 0.646078] [G loss: 0.082714]\n",
            "[Epoch 24/200] [Batch 924/938] [D loss: 0.623890] [G loss: 0.075151]\n",
            "[Epoch 24/200] [Batch 925/938] [D loss: 0.641373] [G loss: 0.074280]\n",
            "[Epoch 24/200] [Batch 926/938] [D loss: 0.647326] [G loss: 0.074938]\n",
            "[Epoch 24/200] [Batch 927/938] [D loss: 0.636649] [G loss: 0.070027]\n",
            "[Epoch 24/200] [Batch 928/938] [D loss: 0.653322] [G loss: 0.068497]\n",
            "[Epoch 24/200] [Batch 929/938] [D loss: 0.622858] [G loss: 0.071084]\n",
            "[Epoch 24/200] [Batch 930/938] [D loss: 0.660717] [G loss: 0.075067]\n",
            "[Epoch 24/200] [Batch 931/938] [D loss: 0.628710] [G loss: 0.074073]\n",
            "[Epoch 24/200] [Batch 932/938] [D loss: 0.624853] [G loss: 0.073742]\n",
            "[Epoch 24/200] [Batch 933/938] [D loss: 0.634057] [G loss: 0.070135]\n",
            "[Epoch 24/200] [Batch 934/938] [D loss: 0.620948] [G loss: 0.071101]\n",
            "[Epoch 24/200] [Batch 935/938] [D loss: 0.629308] [G loss: 0.074721]\n",
            "[Epoch 24/200] [Batch 936/938] [D loss: 0.637698] [G loss: 0.072151]\n",
            "[Epoch 24/200] [Batch 937/938] [D loss: 0.643880] [G loss: 0.074887]\n",
            "[Epoch 25/200] [Batch 0/938] [D loss: 0.662349] [G loss: 0.070422]\n",
            "[Epoch 25/200] [Batch 1/938] [D loss: 0.666969] [G loss: 0.075267]\n",
            "[Epoch 25/200] [Batch 2/938] [D loss: 0.611334] [G loss: 0.066515]\n",
            "[Epoch 25/200] [Batch 3/938] [D loss: 0.634445] [G loss: 0.071899]\n",
            "[Epoch 25/200] [Batch 4/938] [D loss: 0.608597] [G loss: 0.074484]\n",
            "[Epoch 25/200] [Batch 5/938] [D loss: 0.638881] [G loss: 0.081214]\n",
            "[Epoch 25/200] [Batch 6/938] [D loss: 0.634576] [G loss: 0.083752]\n",
            "[Epoch 25/200] [Batch 7/938] [D loss: 0.654463] [G loss: 0.070968]\n",
            "[Epoch 25/200] [Batch 8/938] [D loss: 0.671590] [G loss: 0.072261]\n",
            "[Epoch 25/200] [Batch 9/938] [D loss: 0.653609] [G loss: 0.066472]\n",
            "[Epoch 25/200] [Batch 10/938] [D loss: 0.659430] [G loss: 0.067785]\n",
            "[Epoch 25/200] [Batch 11/938] [D loss: 0.628516] [G loss: 0.074411]\n",
            "[Epoch 25/200] [Batch 12/938] [D loss: 0.603645] [G loss: 0.071251]\n",
            "[Epoch 25/200] [Batch 13/938] [D loss: 0.619374] [G loss: 0.075622]\n",
            "[Epoch 25/200] [Batch 14/938] [D loss: 0.648408] [G loss: 0.073674]\n",
            "[Epoch 25/200] [Batch 15/938] [D loss: 0.630266] [G loss: 0.070292]\n",
            "[Epoch 25/200] [Batch 16/938] [D loss: 0.643542] [G loss: 0.068653]\n",
            "[Epoch 25/200] [Batch 17/938] [D loss: 0.628090] [G loss: 0.070279]\n",
            "[Epoch 25/200] [Batch 18/938] [D loss: 0.619963] [G loss: 0.077748]\n",
            "[Epoch 25/200] [Batch 19/938] [D loss: 0.638335] [G loss: 0.078740]\n",
            "[Epoch 25/200] [Batch 20/938] [D loss: 0.604612] [G loss: 0.074957]\n",
            "[Epoch 25/200] [Batch 21/938] [D loss: 0.611055] [G loss: 0.074791]\n",
            "[Epoch 25/200] [Batch 22/938] [D loss: 0.580318] [G loss: 0.072034]\n",
            "[Epoch 25/200] [Batch 23/938] [D loss: 0.631815] [G loss: 0.070317]\n",
            "[Epoch 25/200] [Batch 24/938] [D loss: 0.624643] [G loss: 0.072149]\n",
            "[Epoch 25/200] [Batch 25/938] [D loss: 0.621351] [G loss: 0.076893]\n",
            "[Epoch 25/200] [Batch 26/938] [D loss: 0.627060] [G loss: 0.073125]\n",
            "[Epoch 25/200] [Batch 27/938] [D loss: 0.666610] [G loss: 0.073175]\n",
            "[Epoch 25/200] [Batch 28/938] [D loss: 0.655900] [G loss: 0.076645]\n",
            "[Epoch 25/200] [Batch 29/938] [D loss: 0.663362] [G loss: 0.075924]\n",
            "[Epoch 25/200] [Batch 30/938] [D loss: 0.672537] [G loss: 0.067378]\n",
            "[Epoch 25/200] [Batch 31/938] [D loss: 0.638845] [G loss: 0.070272]\n",
            "[Epoch 25/200] [Batch 32/938] [D loss: 0.691828] [G loss: 0.075180]\n",
            "[Epoch 25/200] [Batch 33/938] [D loss: 0.629022] [G loss: 0.068981]\n",
            "[Epoch 25/200] [Batch 34/938] [D loss: 0.624135] [G loss: 0.073532]\n",
            "[Epoch 25/200] [Batch 35/938] [D loss: 0.665718] [G loss: 0.067273]\n",
            "[Epoch 25/200] [Batch 36/938] [D loss: 0.661754] [G loss: 0.076860]\n",
            "[Epoch 25/200] [Batch 37/938] [D loss: 0.640411] [G loss: 0.073928]\n",
            "[Epoch 25/200] [Batch 38/938] [D loss: 0.663288] [G loss: 0.073764]\n",
            "[Epoch 25/200] [Batch 39/938] [D loss: 0.630236] [G loss: 0.064973]\n",
            "[Epoch 25/200] [Batch 40/938] [D loss: 0.612697] [G loss: 0.066678]\n",
            "[Epoch 25/200] [Batch 41/938] [D loss: 0.612410] [G loss: 0.075477]\n",
            "[Epoch 25/200] [Batch 42/938] [D loss: 0.615595] [G loss: 0.064864]\n",
            "[Epoch 25/200] [Batch 43/938] [D loss: 0.615467] [G loss: 0.072585]\n",
            "[Epoch 25/200] [Batch 44/938] [D loss: 0.602692] [G loss: 0.068109]\n",
            "[Epoch 25/200] [Batch 45/938] [D loss: 0.628269] [G loss: 0.074785]\n",
            "[Epoch 25/200] [Batch 46/938] [D loss: 0.623253] [G loss: 0.072559]\n",
            "[Epoch 25/200] [Batch 47/938] [D loss: 0.615252] [G loss: 0.066886]\n",
            "[Epoch 25/200] [Batch 48/938] [D loss: 0.660498] [G loss: 0.072125]\n",
            "[Epoch 25/200] [Batch 49/938] [D loss: 0.624353] [G loss: 0.078565]\n",
            "[Epoch 25/200] [Batch 50/938] [D loss: 0.649768] [G loss: 0.071006]\n",
            "[Epoch 25/200] [Batch 51/938] [D loss: 0.632429] [G loss: 0.072257]\n",
            "[Epoch 25/200] [Batch 52/938] [D loss: 0.630375] [G loss: 0.071648]\n",
            "[Epoch 25/200] [Batch 53/938] [D loss: 0.620487] [G loss: 0.069655]\n",
            "[Epoch 25/200] [Batch 54/938] [D loss: 0.620838] [G loss: 0.079166]\n",
            "[Epoch 25/200] [Batch 55/938] [D loss: 0.628177] [G loss: 0.069492]\n",
            "[Epoch 25/200] [Batch 56/938] [D loss: 0.673153] [G loss: 0.065621]\n",
            "[Epoch 25/200] [Batch 57/938] [D loss: 0.616145] [G loss: 0.079762]\n",
            "[Epoch 25/200] [Batch 58/938] [D loss: 0.646433] [G loss: 0.070319]\n",
            "[Epoch 25/200] [Batch 59/938] [D loss: 0.686640] [G loss: 0.074907]\n",
            "[Epoch 25/200] [Batch 60/938] [D loss: 0.658024] [G loss: 0.069999]\n",
            "[Epoch 25/200] [Batch 61/938] [D loss: 0.655772] [G loss: 0.073860]\n",
            "[Epoch 25/200] [Batch 62/938] [D loss: 0.625386] [G loss: 0.078543]\n",
            "[Epoch 25/200] [Batch 63/938] [D loss: 0.645618] [G loss: 0.068944]\n",
            "[Epoch 25/200] [Batch 64/938] [D loss: 0.644595] [G loss: 0.074037]\n",
            "[Epoch 25/200] [Batch 65/938] [D loss: 0.635319] [G loss: 0.073675]\n",
            "[Epoch 25/200] [Batch 66/938] [D loss: 0.633286] [G loss: 0.073938]\n",
            "[Epoch 25/200] [Batch 67/938] [D loss: 0.693134] [G loss: 0.074690]\n",
            "[Epoch 25/200] [Batch 68/938] [D loss: 0.616283] [G loss: 0.072381]\n",
            "[Epoch 25/200] [Batch 69/938] [D loss: 0.637081] [G loss: 0.083989]\n",
            "[Epoch 25/200] [Batch 70/938] [D loss: 0.650428] [G loss: 0.077775]\n",
            "[Epoch 25/200] [Batch 71/938] [D loss: 0.624817] [G loss: 0.070056]\n",
            "[Epoch 25/200] [Batch 72/938] [D loss: 0.643413] [G loss: 0.072445]\n",
            "[Epoch 25/200] [Batch 73/938] [D loss: 0.599715] [G loss: 0.076828]\n",
            "[Epoch 25/200] [Batch 74/938] [D loss: 0.667583] [G loss: 0.076326]\n",
            "[Epoch 25/200] [Batch 75/938] [D loss: 0.656148] [G loss: 0.076843]\n",
            "[Epoch 25/200] [Batch 76/938] [D loss: 0.618526] [G loss: 0.079846]\n",
            "[Epoch 25/200] [Batch 77/938] [D loss: 0.625509] [G loss: 0.071635]\n",
            "[Epoch 25/200] [Batch 78/938] [D loss: 0.614175] [G loss: 0.076870]\n",
            "[Epoch 25/200] [Batch 79/938] [D loss: 0.611305] [G loss: 0.070491]\n",
            "[Epoch 25/200] [Batch 80/938] [D loss: 0.676112] [G loss: 0.071111]\n",
            "[Epoch 25/200] [Batch 81/938] [D loss: 0.645712] [G loss: 0.074664]\n",
            "[Epoch 25/200] [Batch 82/938] [D loss: 0.650064] [G loss: 0.065397]\n",
            "[Epoch 25/200] [Batch 83/938] [D loss: 0.660764] [G loss: 0.071541]\n",
            "[Epoch 25/200] [Batch 84/938] [D loss: 0.652745] [G loss: 0.079744]\n",
            "[Epoch 25/200] [Batch 85/938] [D loss: 0.639128] [G loss: 0.079410]\n",
            "[Epoch 25/200] [Batch 86/938] [D loss: 0.658522] [G loss: 0.069435]\n",
            "[Epoch 25/200] [Batch 87/938] [D loss: 0.622221] [G loss: 0.066278]\n",
            "[Epoch 25/200] [Batch 88/938] [D loss: 0.612823] [G loss: 0.068717]\n",
            "[Epoch 25/200] [Batch 89/938] [D loss: 0.653610] [G loss: 0.080352]\n",
            "[Epoch 25/200] [Batch 90/938] [D loss: 0.582845] [G loss: 0.073828]\n",
            "[Epoch 25/200] [Batch 91/938] [D loss: 0.644532] [G loss: 0.075612]\n",
            "[Epoch 25/200] [Batch 92/938] [D loss: 0.634355] [G loss: 0.069375]\n",
            "[Epoch 25/200] [Batch 93/938] [D loss: 0.639479] [G loss: 0.070535]\n",
            "[Epoch 25/200] [Batch 94/938] [D loss: 0.668345] [G loss: 0.072789]\n",
            "[Epoch 25/200] [Batch 95/938] [D loss: 0.637213] [G loss: 0.078635]\n",
            "[Epoch 25/200] [Batch 96/938] [D loss: 0.647939] [G loss: 0.068566]\n",
            "[Epoch 25/200] [Batch 97/938] [D loss: 0.617487] [G loss: 0.075024]\n",
            "[Epoch 25/200] [Batch 98/938] [D loss: 0.670624] [G loss: 0.075804]\n",
            "[Epoch 25/200] [Batch 99/938] [D loss: 0.654253] [G loss: 0.067050]\n",
            "[Epoch 25/200] [Batch 100/938] [D loss: 0.638171] [G loss: 0.071081]\n",
            "[Epoch 25/200] [Batch 101/938] [D loss: 0.602194] [G loss: 0.066835]\n",
            "[Epoch 25/200] [Batch 102/938] [D loss: 0.623745] [G loss: 0.074662]\n",
            "[Epoch 25/200] [Batch 103/938] [D loss: 0.653570] [G loss: 0.074348]\n",
            "[Epoch 25/200] [Batch 104/938] [D loss: 0.657449] [G loss: 0.076344]\n",
            "[Epoch 25/200] [Batch 105/938] [D loss: 0.639011] [G loss: 0.069661]\n",
            "[Epoch 25/200] [Batch 106/938] [D loss: 0.642516] [G loss: 0.075001]\n",
            "[Epoch 25/200] [Batch 107/938] [D loss: 0.653091] [G loss: 0.074460]\n",
            "[Epoch 25/200] [Batch 108/938] [D loss: 0.639911] [G loss: 0.072657]\n",
            "[Epoch 25/200] [Batch 109/938] [D loss: 0.582624] [G loss: 0.072198]\n",
            "[Epoch 25/200] [Batch 110/938] [D loss: 0.604111] [G loss: 0.075326]\n",
            "[Epoch 25/200] [Batch 111/938] [D loss: 0.661157] [G loss: 0.068758]\n",
            "[Epoch 25/200] [Batch 112/938] [D loss: 0.636467] [G loss: 0.072760]\n",
            "[Epoch 25/200] [Batch 113/938] [D loss: 0.665066] [G loss: 0.071680]\n",
            "[Epoch 25/200] [Batch 114/938] [D loss: 0.637621] [G loss: 0.067606]\n",
            "[Epoch 25/200] [Batch 115/938] [D loss: 0.666860] [G loss: 0.074511]\n",
            "[Epoch 25/200] [Batch 116/938] [D loss: 0.639932] [G loss: 0.079117]\n",
            "[Epoch 25/200] [Batch 117/938] [D loss: 0.630701] [G loss: 0.076985]\n",
            "[Epoch 25/200] [Batch 118/938] [D loss: 0.667537] [G loss: 0.070109]\n",
            "[Epoch 25/200] [Batch 119/938] [D loss: 0.627348] [G loss: 0.074227]\n",
            "[Epoch 25/200] [Batch 120/938] [D loss: 0.649233] [G loss: 0.075088]\n",
            "[Epoch 25/200] [Batch 121/938] [D loss: 0.660480] [G loss: 0.067776]\n",
            "[Epoch 25/200] [Batch 122/938] [D loss: 0.648576] [G loss: 0.069694]\n",
            "[Epoch 25/200] [Batch 123/938] [D loss: 0.639714] [G loss: 0.065075]\n",
            "[Epoch 25/200] [Batch 124/938] [D loss: 0.626084] [G loss: 0.069572]\n",
            "[Epoch 25/200] [Batch 125/938] [D loss: 0.628845] [G loss: 0.073525]\n",
            "[Epoch 25/200] [Batch 126/938] [D loss: 0.658228] [G loss: 0.068535]\n",
            "[Epoch 25/200] [Batch 127/938] [D loss: 0.679926] [G loss: 0.078196]\n",
            "[Epoch 25/200] [Batch 128/938] [D loss: 0.633925] [G loss: 0.073504]\n",
            "[Epoch 25/200] [Batch 129/938] [D loss: 0.656221] [G loss: 0.071366]\n",
            "[Epoch 25/200] [Batch 130/938] [D loss: 0.609248] [G loss: 0.073640]\n",
            "[Epoch 25/200] [Batch 131/938] [D loss: 0.656163] [G loss: 0.067801]\n",
            "[Epoch 25/200] [Batch 132/938] [D loss: 0.640671] [G loss: 0.076144]\n",
            "[Epoch 25/200] [Batch 133/938] [D loss: 0.639874] [G loss: 0.066661]\n",
            "[Epoch 25/200] [Batch 134/938] [D loss: 0.612021] [G loss: 0.072522]\n",
            "[Epoch 25/200] [Batch 135/938] [D loss: 0.600376] [G loss: 0.074179]\n",
            "[Epoch 25/200] [Batch 136/938] [D loss: 0.638085] [G loss: 0.065661]\n",
            "[Epoch 25/200] [Batch 137/938] [D loss: 0.641037] [G loss: 0.070434]\n",
            "[Epoch 25/200] [Batch 138/938] [D loss: 0.603194] [G loss: 0.069043]\n",
            "[Epoch 25/200] [Batch 139/938] [D loss: 0.648097] [G loss: 0.074156]\n",
            "[Epoch 25/200] [Batch 140/938] [D loss: 0.610705] [G loss: 0.073849]\n",
            "[Epoch 25/200] [Batch 141/938] [D loss: 0.608226] [G loss: 0.068153]\n",
            "[Epoch 25/200] [Batch 142/938] [D loss: 0.628681] [G loss: 0.070693]\n",
            "[Epoch 25/200] [Batch 143/938] [D loss: 0.647039] [G loss: 0.078694]\n",
            "[Epoch 25/200] [Batch 144/938] [D loss: 0.600248] [G loss: 0.076358]\n",
            "[Epoch 25/200] [Batch 145/938] [D loss: 0.615003] [G loss: 0.079603]\n",
            "[Epoch 25/200] [Batch 146/938] [D loss: 0.634521] [G loss: 0.069762]\n",
            "[Epoch 25/200] [Batch 147/938] [D loss: 0.642954] [G loss: 0.070206]\n",
            "[Epoch 25/200] [Batch 148/938] [D loss: 0.654444] [G loss: 0.077249]\n",
            "[Epoch 25/200] [Batch 149/938] [D loss: 0.627906] [G loss: 0.072572]\n",
            "[Epoch 25/200] [Batch 150/938] [D loss: 0.625172] [G loss: 0.068845]\n",
            "[Epoch 25/200] [Batch 151/938] [D loss: 0.606500] [G loss: 0.074922]\n",
            "[Epoch 25/200] [Batch 152/938] [D loss: 0.630980] [G loss: 0.071871]\n",
            "[Epoch 25/200] [Batch 153/938] [D loss: 0.640635] [G loss: 0.067781]\n",
            "[Epoch 25/200] [Batch 154/938] [D loss: 0.633785] [G loss: 0.080105]\n",
            "[Epoch 25/200] [Batch 155/938] [D loss: 0.640931] [G loss: 0.071735]\n",
            "[Epoch 25/200] [Batch 156/938] [D loss: 0.652694] [G loss: 0.075580]\n",
            "[Epoch 25/200] [Batch 157/938] [D loss: 0.648861] [G loss: 0.067717]\n",
            "[Epoch 25/200] [Batch 158/938] [D loss: 0.660023] [G loss: 0.074284]\n",
            "[Epoch 25/200] [Batch 159/938] [D loss: 0.611256] [G loss: 0.073718]\n",
            "[Epoch 25/200] [Batch 160/938] [D loss: 0.643543] [G loss: 0.078299]\n",
            "[Epoch 25/200] [Batch 161/938] [D loss: 0.702473] [G loss: 0.068582]\n",
            "[Epoch 25/200] [Batch 162/938] [D loss: 0.648190] [G loss: 0.073934]\n",
            "[Epoch 25/200] [Batch 163/938] [D loss: 0.648951] [G loss: 0.073092]\n",
            "[Epoch 25/200] [Batch 164/938] [D loss: 0.644232] [G loss: 0.070947]\n",
            "[Epoch 25/200] [Batch 165/938] [D loss: 0.638582] [G loss: 0.079121]\n",
            "[Epoch 25/200] [Batch 166/938] [D loss: 0.641479] [G loss: 0.072152]\n",
            "[Epoch 25/200] [Batch 167/938] [D loss: 0.633531] [G loss: 0.065208]\n",
            "[Epoch 25/200] [Batch 168/938] [D loss: 0.634921] [G loss: 0.073107]\n",
            "[Epoch 25/200] [Batch 169/938] [D loss: 0.642008] [G loss: 0.082600]\n",
            "[Epoch 25/200] [Batch 170/938] [D loss: 0.631373] [G loss: 0.074729]\n",
            "[Epoch 25/200] [Batch 171/938] [D loss: 0.597236] [G loss: 0.067769]\n",
            "[Epoch 25/200] [Batch 172/938] [D loss: 0.603458] [G loss: 0.073903]\n",
            "[Epoch 25/200] [Batch 173/938] [D loss: 0.652016] [G loss: 0.073292]\n",
            "[Epoch 25/200] [Batch 174/938] [D loss: 0.618180] [G loss: 0.068386]\n",
            "[Epoch 25/200] [Batch 175/938] [D loss: 0.583507] [G loss: 0.076509]\n",
            "[Epoch 25/200] [Batch 176/938] [D loss: 0.632357] [G loss: 0.070877]\n",
            "[Epoch 25/200] [Batch 177/938] [D loss: 0.639075] [G loss: 0.075725]\n",
            "[Epoch 25/200] [Batch 178/938] [D loss: 0.637353] [G loss: 0.076576]\n",
            "[Epoch 25/200] [Batch 179/938] [D loss: 0.625316] [G loss: 0.074091]\n",
            "[Epoch 25/200] [Batch 180/938] [D loss: 0.633792] [G loss: 0.078395]\n",
            "[Epoch 25/200] [Batch 181/938] [D loss: 0.607147] [G loss: 0.076121]\n",
            "[Epoch 25/200] [Batch 182/938] [D loss: 0.667207] [G loss: 0.067985]\n",
            "[Epoch 25/200] [Batch 183/938] [D loss: 0.619114] [G loss: 0.074093]\n",
            "[Epoch 25/200] [Batch 184/938] [D loss: 0.629662] [G loss: 0.070292]\n",
            "[Epoch 25/200] [Batch 185/938] [D loss: 0.642248] [G loss: 0.074906]\n",
            "[Epoch 25/200] [Batch 186/938] [D loss: 0.603234] [G loss: 0.070553]\n",
            "[Epoch 25/200] [Batch 187/938] [D loss: 0.638355] [G loss: 0.068123]\n",
            "[Epoch 25/200] [Batch 188/938] [D loss: 0.636046] [G loss: 0.072655]\n",
            "[Epoch 25/200] [Batch 189/938] [D loss: 0.651067] [G loss: 0.082887]\n",
            "[Epoch 25/200] [Batch 190/938] [D loss: 0.618719] [G loss: 0.066623]\n",
            "[Epoch 25/200] [Batch 191/938] [D loss: 0.601319] [G loss: 0.071347]\n",
            "[Epoch 25/200] [Batch 192/938] [D loss: 0.643481] [G loss: 0.076373]\n",
            "[Epoch 25/200] [Batch 193/938] [D loss: 0.616343] [G loss: 0.074241]\n",
            "[Epoch 25/200] [Batch 194/938] [D loss: 0.601029] [G loss: 0.068628]\n",
            "[Epoch 25/200] [Batch 195/938] [D loss: 0.667708] [G loss: 0.071326]\n",
            "[Epoch 25/200] [Batch 196/938] [D loss: 0.659241] [G loss: 0.071077]\n",
            "[Epoch 25/200] [Batch 197/938] [D loss: 0.651701] [G loss: 0.070897]\n",
            "[Epoch 25/200] [Batch 198/938] [D loss: 0.622848] [G loss: 0.077718]\n",
            "[Epoch 25/200] [Batch 199/938] [D loss: 0.612906] [G loss: 0.080676]\n",
            "[Epoch 25/200] [Batch 200/938] [D loss: 0.631506] [G loss: 0.074435]\n",
            "[Epoch 25/200] [Batch 201/938] [D loss: 0.636315] [G loss: 0.072387]\n",
            "[Epoch 25/200] [Batch 202/938] [D loss: 0.615689] [G loss: 0.075763]\n",
            "[Epoch 25/200] [Batch 203/938] [D loss: 0.632853] [G loss: 0.070268]\n",
            "[Epoch 25/200] [Batch 204/938] [D loss: 0.614351] [G loss: 0.080441]\n",
            "[Epoch 25/200] [Batch 205/938] [D loss: 0.651546] [G loss: 0.072171]\n",
            "[Epoch 25/200] [Batch 206/938] [D loss: 0.641204] [G loss: 0.067667]\n",
            "[Epoch 25/200] [Batch 207/938] [D loss: 0.633860] [G loss: 0.071782]\n",
            "[Epoch 25/200] [Batch 208/938] [D loss: 0.635355] [G loss: 0.072722]\n",
            "[Epoch 25/200] [Batch 209/938] [D loss: 0.632575] [G loss: 0.069536]\n",
            "[Epoch 25/200] [Batch 210/938] [D loss: 0.631133] [G loss: 0.074474]\n",
            "[Epoch 25/200] [Batch 211/938] [D loss: 0.625816] [G loss: 0.071625]\n",
            "[Epoch 25/200] [Batch 212/938] [D loss: 0.626834] [G loss: 0.074590]\n",
            "[Epoch 25/200] [Batch 213/938] [D loss: 0.633973] [G loss: 0.068136]\n",
            "[Epoch 25/200] [Batch 214/938] [D loss: 0.694195] [G loss: 0.081407]\n",
            "[Epoch 25/200] [Batch 215/938] [D loss: 0.646415] [G loss: 0.070023]\n",
            "[Epoch 25/200] [Batch 216/938] [D loss: 0.631772] [G loss: 0.074101]\n",
            "[Epoch 25/200] [Batch 217/938] [D loss: 0.655826] [G loss: 0.069149]\n",
            "[Epoch 25/200] [Batch 218/938] [D loss: 0.607464] [G loss: 0.068439]\n",
            "[Epoch 25/200] [Batch 219/938] [D loss: 0.660090] [G loss: 0.074154]\n",
            "[Epoch 25/200] [Batch 220/938] [D loss: 0.634693] [G loss: 0.070429]\n",
            "[Epoch 25/200] [Batch 221/938] [D loss: 0.654879] [G loss: 0.072038]\n",
            "[Epoch 25/200] [Batch 222/938] [D loss: 0.624808] [G loss: 0.072586]\n",
            "[Epoch 25/200] [Batch 223/938] [D loss: 0.646686] [G loss: 0.069181]\n",
            "[Epoch 25/200] [Batch 224/938] [D loss: 0.632803] [G loss: 0.068176]\n",
            "[Epoch 25/200] [Batch 225/938] [D loss: 0.628766] [G loss: 0.085696]\n",
            "[Epoch 25/200] [Batch 226/938] [D loss: 0.629726] [G loss: 0.071552]\n",
            "[Epoch 25/200] [Batch 227/938] [D loss: 0.605771] [G loss: 0.069439]\n",
            "[Epoch 25/200] [Batch 228/938] [D loss: 0.588361] [G loss: 0.074274]\n",
            "[Epoch 25/200] [Batch 229/938] [D loss: 0.624903] [G loss: 0.069148]\n",
            "[Epoch 25/200] [Batch 230/938] [D loss: 0.613608] [G loss: 0.072792]\n",
            "[Epoch 25/200] [Batch 231/938] [D loss: 0.637076] [G loss: 0.077705]\n",
            "[Epoch 25/200] [Batch 232/938] [D loss: 0.632151] [G loss: 0.070720]\n",
            "[Epoch 25/200] [Batch 233/938] [D loss: 0.622859] [G loss: 0.073363]\n",
            "[Epoch 25/200] [Batch 234/938] [D loss: 0.615124] [G loss: 0.072540]\n",
            "[Epoch 25/200] [Batch 235/938] [D loss: 0.639981] [G loss: 0.072787]\n",
            "[Epoch 25/200] [Batch 236/938] [D loss: 0.606474] [G loss: 0.070223]\n",
            "[Epoch 25/200] [Batch 237/938] [D loss: 0.650990] [G loss: 0.072487]\n",
            "[Epoch 25/200] [Batch 238/938] [D loss: 0.655478] [G loss: 0.073317]\n",
            "[Epoch 25/200] [Batch 239/938] [D loss: 0.640089] [G loss: 0.078704]\n",
            "[Epoch 25/200] [Batch 240/938] [D loss: 0.670808] [G loss: 0.066780]\n",
            "[Epoch 25/200] [Batch 241/938] [D loss: 0.634820] [G loss: 0.071009]\n",
            "[Epoch 25/200] [Batch 242/938] [D loss: 0.623641] [G loss: 0.068243]\n",
            "[Epoch 25/200] [Batch 243/938] [D loss: 0.618311] [G loss: 0.072145]\n",
            "[Epoch 25/200] [Batch 244/938] [D loss: 0.630072] [G loss: 0.069874]\n",
            "[Epoch 25/200] [Batch 245/938] [D loss: 0.690679] [G loss: 0.066450]\n",
            "[Epoch 25/200] [Batch 246/938] [D loss: 0.670493] [G loss: 0.071846]\n",
            "[Epoch 25/200] [Batch 247/938] [D loss: 0.619477] [G loss: 0.068065]\n",
            "[Epoch 25/200] [Batch 248/938] [D loss: 0.586864] [G loss: 0.072420]\n",
            "[Epoch 25/200] [Batch 249/938] [D loss: 0.672316] [G loss: 0.064966]\n",
            "[Epoch 25/200] [Batch 250/938] [D loss: 0.659120] [G loss: 0.068832]\n",
            "[Epoch 25/200] [Batch 251/938] [D loss: 0.627890] [G loss: 0.073891]\n",
            "[Epoch 25/200] [Batch 252/938] [D loss: 0.615591] [G loss: 0.073327]\n",
            "[Epoch 25/200] [Batch 253/938] [D loss: 0.622292] [G loss: 0.068130]\n",
            "[Epoch 25/200] [Batch 254/938] [D loss: 0.657524] [G loss: 0.071613]\n",
            "[Epoch 25/200] [Batch 255/938] [D loss: 0.651139] [G loss: 0.071431]\n",
            "[Epoch 25/200] [Batch 256/938] [D loss: 0.622561] [G loss: 0.076658]\n",
            "[Epoch 25/200] [Batch 257/938] [D loss: 0.643131] [G loss: 0.077467]\n",
            "[Epoch 25/200] [Batch 258/938] [D loss: 0.630990] [G loss: 0.064061]\n",
            "[Epoch 25/200] [Batch 259/938] [D loss: 0.609772] [G loss: 0.070770]\n",
            "[Epoch 25/200] [Batch 260/938] [D loss: 0.630722] [G loss: 0.067883]\n",
            "[Epoch 25/200] [Batch 261/938] [D loss: 0.647730] [G loss: 0.066490]\n",
            "[Epoch 25/200] [Batch 262/938] [D loss: 0.659687] [G loss: 0.074324]\n",
            "[Epoch 25/200] [Batch 263/938] [D loss: 0.597886] [G loss: 0.073918]\n",
            "[Epoch 25/200] [Batch 264/938] [D loss: 0.639026] [G loss: 0.072881]\n",
            "[Epoch 25/200] [Batch 265/938] [D loss: 0.626071] [G loss: 0.070567]\n",
            "[Epoch 25/200] [Batch 266/938] [D loss: 0.648496] [G loss: 0.070332]\n",
            "[Epoch 25/200] [Batch 267/938] [D loss: 0.620884] [G loss: 0.079379]\n",
            "[Epoch 25/200] [Batch 268/938] [D loss: 0.657450] [G loss: 0.077833]\n",
            "[Epoch 25/200] [Batch 269/938] [D loss: 0.645251] [G loss: 0.074739]\n",
            "[Epoch 25/200] [Batch 270/938] [D loss: 0.682190] [G loss: 0.079577]\n",
            "[Epoch 25/200] [Batch 271/938] [D loss: 0.637154] [G loss: 0.073806]\n",
            "[Epoch 25/200] [Batch 272/938] [D loss: 0.613143] [G loss: 0.075644]\n",
            "[Epoch 25/200] [Batch 273/938] [D loss: 0.659592] [G loss: 0.072171]\n",
            "[Epoch 25/200] [Batch 274/938] [D loss: 0.624563] [G loss: 0.074536]\n",
            "[Epoch 25/200] [Batch 275/938] [D loss: 0.601883] [G loss: 0.072735]\n",
            "[Epoch 25/200] [Batch 276/938] [D loss: 0.638155] [G loss: 0.078886]\n",
            "[Epoch 25/200] [Batch 277/938] [D loss: 0.669467] [G loss: 0.069195]\n",
            "[Epoch 25/200] [Batch 278/938] [D loss: 0.650706] [G loss: 0.074982]\n",
            "[Epoch 25/200] [Batch 279/938] [D loss: 0.680639] [G loss: 0.078459]\n",
            "[Epoch 25/200] [Batch 280/938] [D loss: 0.644981] [G loss: 0.068030]\n",
            "[Epoch 25/200] [Batch 281/938] [D loss: 0.613278] [G loss: 0.072406]\n",
            "[Epoch 25/200] [Batch 282/938] [D loss: 0.661711] [G loss: 0.070979]\n",
            "[Epoch 25/200] [Batch 283/938] [D loss: 0.608821] [G loss: 0.073050]\n",
            "[Epoch 25/200] [Batch 284/938] [D loss: 0.675496] [G loss: 0.081412]\n",
            "[Epoch 25/200] [Batch 285/938] [D loss: 0.660569] [G loss: 0.076548]\n",
            "[Epoch 25/200] [Batch 286/938] [D loss: 0.655624] [G loss: 0.074889]\n",
            "[Epoch 25/200] [Batch 287/938] [D loss: 0.610387] [G loss: 0.069084]\n",
            "[Epoch 25/200] [Batch 288/938] [D loss: 0.658592] [G loss: 0.066394]\n",
            "[Epoch 25/200] [Batch 289/938] [D loss: 0.651014] [G loss: 0.075669]\n",
            "[Epoch 25/200] [Batch 290/938] [D loss: 0.645146] [G loss: 0.077530]\n",
            "[Epoch 25/200] [Batch 291/938] [D loss: 0.606215] [G loss: 0.072349]\n",
            "[Epoch 25/200] [Batch 292/938] [D loss: 0.634771] [G loss: 0.070318]\n",
            "[Epoch 25/200] [Batch 293/938] [D loss: 0.618092] [G loss: 0.073668]\n",
            "[Epoch 25/200] [Batch 294/938] [D loss: 0.695127] [G loss: 0.074380]\n",
            "[Epoch 25/200] [Batch 295/938] [D loss: 0.612906] [G loss: 0.069037]\n",
            "[Epoch 25/200] [Batch 296/938] [D loss: 0.635308] [G loss: 0.068489]\n",
            "[Epoch 25/200] [Batch 297/938] [D loss: 0.642834] [G loss: 0.073350]\n",
            "[Epoch 25/200] [Batch 298/938] [D loss: 0.609662] [G loss: 0.075671]\n",
            "[Epoch 25/200] [Batch 299/938] [D loss: 0.686566] [G loss: 0.069520]\n",
            "[Epoch 25/200] [Batch 300/938] [D loss: 0.654429] [G loss: 0.072371]\n",
            "[Epoch 25/200] [Batch 301/938] [D loss: 0.642870] [G loss: 0.074090]\n",
            "[Epoch 25/200] [Batch 302/938] [D loss: 0.619996] [G loss: 0.076426]\n",
            "[Epoch 25/200] [Batch 303/938] [D loss: 0.645052] [G loss: 0.074440]\n",
            "[Epoch 25/200] [Batch 304/938] [D loss: 0.609854] [G loss: 0.070237]\n",
            "[Epoch 25/200] [Batch 305/938] [D loss: 0.609867] [G loss: 0.079534]\n",
            "[Epoch 25/200] [Batch 306/938] [D loss: 0.666796] [G loss: 0.067814]\n",
            "[Epoch 25/200] [Batch 307/938] [D loss: 0.640665] [G loss: 0.075064]\n",
            "[Epoch 25/200] [Batch 308/938] [D loss: 0.631644] [G loss: 0.067224]\n",
            "[Epoch 25/200] [Batch 309/938] [D loss: 0.644050] [G loss: 0.075363]\n",
            "[Epoch 25/200] [Batch 310/938] [D loss: 0.613848] [G loss: 0.074006]\n",
            "[Epoch 25/200] [Batch 311/938] [D loss: 0.624942] [G loss: 0.074437]\n",
            "[Epoch 25/200] [Batch 312/938] [D loss: 0.667071] [G loss: 0.071888]\n",
            "[Epoch 25/200] [Batch 313/938] [D loss: 0.578643] [G loss: 0.073232]\n",
            "[Epoch 25/200] [Batch 314/938] [D loss: 0.633030] [G loss: 0.069405]\n",
            "[Epoch 25/200] [Batch 315/938] [D loss: 0.664052] [G loss: 0.076813]\n",
            "[Epoch 25/200] [Batch 316/938] [D loss: 0.654021] [G loss: 0.073984]\n",
            "[Epoch 25/200] [Batch 317/938] [D loss: 0.660349] [G loss: 0.074132]\n",
            "[Epoch 25/200] [Batch 318/938] [D loss: 0.671263] [G loss: 0.082136]\n",
            "[Epoch 25/200] [Batch 319/938] [D loss: 0.621521] [G loss: 0.073736]\n",
            "[Epoch 25/200] [Batch 320/938] [D loss: 0.644816] [G loss: 0.066108]\n",
            "[Epoch 25/200] [Batch 321/938] [D loss: 0.609613] [G loss: 0.079153]\n",
            "[Epoch 25/200] [Batch 322/938] [D loss: 0.612255] [G loss: 0.078872]\n",
            "[Epoch 25/200] [Batch 323/938] [D loss: 0.672950] [G loss: 0.066510]\n",
            "[Epoch 25/200] [Batch 324/938] [D loss: 0.620552] [G loss: 0.076213]\n",
            "[Epoch 25/200] [Batch 325/938] [D loss: 0.687341] [G loss: 0.072652]\n",
            "[Epoch 25/200] [Batch 326/938] [D loss: 0.592895] [G loss: 0.072648]\n",
            "[Epoch 25/200] [Batch 327/938] [D loss: 0.637639] [G loss: 0.079120]\n",
            "[Epoch 25/200] [Batch 328/938] [D loss: 0.644160] [G loss: 0.075070]\n",
            "[Epoch 25/200] [Batch 329/938] [D loss: 0.687499] [G loss: 0.077573]\n",
            "[Epoch 25/200] [Batch 330/938] [D loss: 0.659053] [G loss: 0.076478]\n",
            "[Epoch 25/200] [Batch 331/938] [D loss: 0.664648] [G loss: 0.069977]\n",
            "[Epoch 25/200] [Batch 332/938] [D loss: 0.629417] [G loss: 0.072983]\n",
            "[Epoch 25/200] [Batch 333/938] [D loss: 0.644148] [G loss: 0.069214]\n",
            "[Epoch 25/200] [Batch 334/938] [D loss: 0.648138] [G loss: 0.067539]\n",
            "[Epoch 25/200] [Batch 335/938] [D loss: 0.606709] [G loss: 0.068804]\n",
            "[Epoch 25/200] [Batch 336/938] [D loss: 0.636662] [G loss: 0.075683]\n",
            "[Epoch 25/200] [Batch 337/938] [D loss: 0.633470] [G loss: 0.070327]\n",
            "[Epoch 25/200] [Batch 338/938] [D loss: 0.663197] [G loss: 0.065176]\n",
            "[Epoch 25/200] [Batch 339/938] [D loss: 0.614436] [G loss: 0.085769]\n",
            "[Epoch 25/200] [Batch 340/938] [D loss: 0.673596] [G loss: 0.074984]\n",
            "[Epoch 25/200] [Batch 341/938] [D loss: 0.612589] [G loss: 0.077069]\n",
            "[Epoch 25/200] [Batch 342/938] [D loss: 0.651911] [G loss: 0.067344]\n",
            "[Epoch 25/200] [Batch 343/938] [D loss: 0.626589] [G loss: 0.080851]\n",
            "[Epoch 25/200] [Batch 344/938] [D loss: 0.638187] [G loss: 0.078325]\n",
            "[Epoch 25/200] [Batch 345/938] [D loss: 0.656809] [G loss: 0.067305]\n",
            "[Epoch 25/200] [Batch 346/938] [D loss: 0.653059] [G loss: 0.070314]\n",
            "[Epoch 25/200] [Batch 347/938] [D loss: 0.604795] [G loss: 0.074529]\n",
            "[Epoch 25/200] [Batch 348/938] [D loss: 0.610339] [G loss: 0.071276]\n",
            "[Epoch 25/200] [Batch 349/938] [D loss: 0.625351] [G loss: 0.071798]\n",
            "[Epoch 25/200] [Batch 350/938] [D loss: 0.606891] [G loss: 0.075482]\n",
            "[Epoch 25/200] [Batch 351/938] [D loss: 0.630497] [G loss: 0.068831]\n",
            "[Epoch 25/200] [Batch 352/938] [D loss: 0.585088] [G loss: 0.076122]\n",
            "[Epoch 25/200] [Batch 353/938] [D loss: 0.637427] [G loss: 0.077193]\n",
            "[Epoch 25/200] [Batch 354/938] [D loss: 0.651353] [G loss: 0.075659]\n",
            "[Epoch 25/200] [Batch 355/938] [D loss: 0.631109] [G loss: 0.078192]\n",
            "[Epoch 25/200] [Batch 356/938] [D loss: 0.646584] [G loss: 0.073015]\n",
            "[Epoch 25/200] [Batch 357/938] [D loss: 0.633054] [G loss: 0.081055]\n",
            "[Epoch 25/200] [Batch 358/938] [D loss: 0.668000] [G loss: 0.068691]\n",
            "[Epoch 25/200] [Batch 359/938] [D loss: 0.619732] [G loss: 0.074135]\n",
            "[Epoch 25/200] [Batch 360/938] [D loss: 0.639398] [G loss: 0.075024]\n",
            "[Epoch 25/200] [Batch 361/938] [D loss: 0.656213] [G loss: 0.065134]\n",
            "[Epoch 25/200] [Batch 362/938] [D loss: 0.631439] [G loss: 0.080719]\n",
            "[Epoch 25/200] [Batch 363/938] [D loss: 0.658277] [G loss: 0.083347]\n",
            "[Epoch 25/200] [Batch 364/938] [D loss: 0.627825] [G loss: 0.073568]\n",
            "[Epoch 25/200] [Batch 365/938] [D loss: 0.653588] [G loss: 0.067461]\n",
            "[Epoch 25/200] [Batch 366/938] [D loss: 0.600101] [G loss: 0.070860]\n",
            "[Epoch 25/200] [Batch 367/938] [D loss: 0.647269] [G loss: 0.072082]\n",
            "[Epoch 25/200] [Batch 368/938] [D loss: 0.603582] [G loss: 0.074738]\n",
            "[Epoch 25/200] [Batch 369/938] [D loss: 0.611486] [G loss: 0.078774]\n",
            "[Epoch 25/200] [Batch 370/938] [D loss: 0.636042] [G loss: 0.080499]\n",
            "[Epoch 25/200] [Batch 371/938] [D loss: 0.647798] [G loss: 0.073544]\n",
            "[Epoch 25/200] [Batch 372/938] [D loss: 0.628096] [G loss: 0.072587]\n",
            "[Epoch 25/200] [Batch 373/938] [D loss: 0.646572] [G loss: 0.079613]\n",
            "[Epoch 25/200] [Batch 374/938] [D loss: 0.607971] [G loss: 0.071416]\n",
            "[Epoch 25/200] [Batch 375/938] [D loss: 0.632188] [G loss: 0.073190]\n",
            "[Epoch 25/200] [Batch 376/938] [D loss: 0.643398] [G loss: 0.071813]\n",
            "[Epoch 25/200] [Batch 377/938] [D loss: 0.641098] [G loss: 0.072095]\n",
            "[Epoch 25/200] [Batch 378/938] [D loss: 0.619581] [G loss: 0.080569]\n",
            "[Epoch 25/200] [Batch 379/938] [D loss: 0.616036] [G loss: 0.075049]\n",
            "[Epoch 25/200] [Batch 380/938] [D loss: 0.659656] [G loss: 0.073678]\n",
            "[Epoch 25/200] [Batch 381/938] [D loss: 0.635081] [G loss: 0.074822]\n",
            "[Epoch 25/200] [Batch 382/938] [D loss: 0.622200] [G loss: 0.071750]\n",
            "[Epoch 25/200] [Batch 383/938] [D loss: 0.658796] [G loss: 0.074285]\n",
            "[Epoch 25/200] [Batch 384/938] [D loss: 0.655810] [G loss: 0.065756]\n",
            "[Epoch 25/200] [Batch 385/938] [D loss: 0.657059] [G loss: 0.067843]\n",
            "[Epoch 25/200] [Batch 386/938] [D loss: 0.650189] [G loss: 0.072948]\n",
            "[Epoch 25/200] [Batch 387/938] [D loss: 0.635076] [G loss: 0.070920]\n",
            "[Epoch 25/200] [Batch 388/938] [D loss: 0.646121] [G loss: 0.074139]\n",
            "[Epoch 25/200] [Batch 389/938] [D loss: 0.686417] [G loss: 0.070469]\n",
            "[Epoch 25/200] [Batch 390/938] [D loss: 0.655463] [G loss: 0.068669]\n",
            "[Epoch 25/200] [Batch 391/938] [D loss: 0.653514] [G loss: 0.078672]\n",
            "[Epoch 25/200] [Batch 392/938] [D loss: 0.620059] [G loss: 0.067580]\n",
            "[Epoch 25/200] [Batch 393/938] [D loss: 0.599882] [G loss: 0.076187]\n",
            "[Epoch 25/200] [Batch 394/938] [D loss: 0.653029] [G loss: 0.076506]\n",
            "[Epoch 25/200] [Batch 395/938] [D loss: 0.671026] [G loss: 0.080329]\n",
            "[Epoch 25/200] [Batch 396/938] [D loss: 0.635924] [G loss: 0.077454]\n",
            "[Epoch 25/200] [Batch 397/938] [D loss: 0.658599] [G loss: 0.076716]\n",
            "[Epoch 25/200] [Batch 398/938] [D loss: 0.644987] [G loss: 0.075022]\n",
            "[Epoch 25/200] [Batch 399/938] [D loss: 0.643282] [G loss: 0.069651]\n",
            "[Epoch 25/200] [Batch 400/938] [D loss: 0.636183] [G loss: 0.068444]\n",
            "[Epoch 25/200] [Batch 401/938] [D loss: 0.691679] [G loss: 0.068293]\n",
            "[Epoch 25/200] [Batch 402/938] [D loss: 0.630223] [G loss: 0.071680]\n",
            "[Epoch 25/200] [Batch 403/938] [D loss: 0.661274] [G loss: 0.073684]\n",
            "[Epoch 25/200] [Batch 404/938] [D loss: 0.636171] [G loss: 0.069710]\n",
            "[Epoch 25/200] [Batch 405/938] [D loss: 0.631996] [G loss: 0.074139]\n",
            "[Epoch 25/200] [Batch 406/938] [D loss: 0.643743] [G loss: 0.073443]\n",
            "[Epoch 25/200] [Batch 407/938] [D loss: 0.642719] [G loss: 0.074859]\n",
            "[Epoch 25/200] [Batch 408/938] [D loss: 0.640336] [G loss: 0.071713]\n",
            "[Epoch 25/200] [Batch 409/938] [D loss: 0.651842] [G loss: 0.074564]\n",
            "[Epoch 25/200] [Batch 410/938] [D loss: 0.645515] [G loss: 0.073034]\n",
            "[Epoch 25/200] [Batch 411/938] [D loss: 0.674756] [G loss: 0.070567]\n",
            "[Epoch 25/200] [Batch 412/938] [D loss: 0.641924] [G loss: 0.070934]\n",
            "[Epoch 25/200] [Batch 413/938] [D loss: 0.642205] [G loss: 0.083663]\n",
            "[Epoch 25/200] [Batch 414/938] [D loss: 0.669708] [G loss: 0.073245]\n",
            "[Epoch 25/200] [Batch 415/938] [D loss: 0.676088] [G loss: 0.070354]\n",
            "[Epoch 25/200] [Batch 416/938] [D loss: 0.649241] [G loss: 0.067479]\n",
            "[Epoch 25/200] [Batch 417/938] [D loss: 0.644211] [G loss: 0.069417]\n",
            "[Epoch 25/200] [Batch 418/938] [D loss: 0.632473] [G loss: 0.070000]\n",
            "[Epoch 25/200] [Batch 419/938] [D loss: 0.651773] [G loss: 0.072809]\n",
            "[Epoch 25/200] [Batch 420/938] [D loss: 0.607849] [G loss: 0.067013]\n",
            "[Epoch 25/200] [Batch 421/938] [D loss: 0.606738] [G loss: 0.074008]\n",
            "[Epoch 25/200] [Batch 422/938] [D loss: 0.632038] [G loss: 0.073498]\n",
            "[Epoch 25/200] [Batch 423/938] [D loss: 0.608268] [G loss: 0.066045]\n",
            "[Epoch 25/200] [Batch 424/938] [D loss: 0.653809] [G loss: 0.074553]\n",
            "[Epoch 25/200] [Batch 425/938] [D loss: 0.659733] [G loss: 0.066905]\n",
            "[Epoch 25/200] [Batch 426/938] [D loss: 0.602493] [G loss: 0.071777]\n",
            "[Epoch 25/200] [Batch 427/938] [D loss: 0.627058] [G loss: 0.080104]\n",
            "[Epoch 25/200] [Batch 428/938] [D loss: 0.719542] [G loss: 0.080424]\n",
            "[Epoch 25/200] [Batch 429/938] [D loss: 0.612394] [G loss: 0.074304]\n",
            "[Epoch 25/200] [Batch 430/938] [D loss: 0.642663] [G loss: 0.071350]\n",
            "[Epoch 25/200] [Batch 431/938] [D loss: 0.646017] [G loss: 0.085726]\n",
            "[Epoch 25/200] [Batch 432/938] [D loss: 0.633146] [G loss: 0.071976]\n",
            "[Epoch 25/200] [Batch 433/938] [D loss: 0.626687] [G loss: 0.077819]\n",
            "[Epoch 25/200] [Batch 434/938] [D loss: 0.654752] [G loss: 0.077211]\n",
            "[Epoch 25/200] [Batch 435/938] [D loss: 0.603467] [G loss: 0.065455]\n",
            "[Epoch 25/200] [Batch 436/938] [D loss: 0.628459] [G loss: 0.072793]\n",
            "[Epoch 25/200] [Batch 437/938] [D loss: 0.623872] [G loss: 0.074605]\n",
            "[Epoch 25/200] [Batch 438/938] [D loss: 0.636679] [G loss: 0.072064]\n",
            "[Epoch 25/200] [Batch 439/938] [D loss: 0.610847] [G loss: 0.067893]\n",
            "[Epoch 25/200] [Batch 440/938] [D loss: 0.608287] [G loss: 0.071574]\n",
            "[Epoch 25/200] [Batch 441/938] [D loss: 0.649802] [G loss: 0.071838]\n",
            "[Epoch 25/200] [Batch 442/938] [D loss: 0.613106] [G loss: 0.071840]\n",
            "[Epoch 25/200] [Batch 443/938] [D loss: 0.667617] [G loss: 0.076230]\n",
            "[Epoch 25/200] [Batch 444/938] [D loss: 0.601535] [G loss: 0.072108]\n",
            "[Epoch 25/200] [Batch 445/938] [D loss: 0.623900] [G loss: 0.070590]\n",
            "[Epoch 25/200] [Batch 446/938] [D loss: 0.629433] [G loss: 0.078785]\n",
            "[Epoch 25/200] [Batch 447/938] [D loss: 0.650530] [G loss: 0.069516]\n",
            "[Epoch 25/200] [Batch 448/938] [D loss: 0.607559] [G loss: 0.071305]\n",
            "[Epoch 25/200] [Batch 449/938] [D loss: 0.635341] [G loss: 0.070627]\n",
            "[Epoch 25/200] [Batch 450/938] [D loss: 0.662311] [G loss: 0.073092]\n",
            "[Epoch 25/200] [Batch 451/938] [D loss: 0.656065] [G loss: 0.074936]\n",
            "[Epoch 25/200] [Batch 452/938] [D loss: 0.672480] [G loss: 0.074078]\n",
            "[Epoch 25/200] [Batch 453/938] [D loss: 0.656730] [G loss: 0.066693]\n",
            "[Epoch 25/200] [Batch 454/938] [D loss: 0.654928] [G loss: 0.071675]\n",
            "[Epoch 25/200] [Batch 455/938] [D loss: 0.664176] [G loss: 0.080112]\n",
            "[Epoch 25/200] [Batch 456/938] [D loss: 0.646734] [G loss: 0.068721]\n",
            "[Epoch 25/200] [Batch 457/938] [D loss: 0.645369] [G loss: 0.071737]\n",
            "[Epoch 25/200] [Batch 458/938] [D loss: 0.625373] [G loss: 0.070745]\n",
            "[Epoch 25/200] [Batch 459/938] [D loss: 0.626478] [G loss: 0.066525]\n",
            "[Epoch 25/200] [Batch 460/938] [D loss: 0.639310] [G loss: 0.070245]\n",
            "[Epoch 25/200] [Batch 461/938] [D loss: 0.665246] [G loss: 0.071540]\n",
            "[Epoch 25/200] [Batch 462/938] [D loss: 0.641181] [G loss: 0.075469]\n",
            "[Epoch 25/200] [Batch 463/938] [D loss: 0.630244] [G loss: 0.072599]\n",
            "[Epoch 25/200] [Batch 464/938] [D loss: 0.626266] [G loss: 0.075111]\n",
            "[Epoch 25/200] [Batch 465/938] [D loss: 0.641857] [G loss: 0.071427]\n",
            "[Epoch 25/200] [Batch 466/938] [D loss: 0.663122] [G loss: 0.077056]\n",
            "[Epoch 25/200] [Batch 467/938] [D loss: 0.582649] [G loss: 0.072605]\n",
            "[Epoch 25/200] [Batch 468/938] [D loss: 0.643349] [G loss: 0.071347]\n",
            "[Epoch 25/200] [Batch 469/938] [D loss: 0.632850] [G loss: 0.071191]\n",
            "[Epoch 25/200] [Batch 470/938] [D loss: 0.655699] [G loss: 0.079098]\n",
            "[Epoch 25/200] [Batch 471/938] [D loss: 0.572994] [G loss: 0.069160]\n",
            "[Epoch 25/200] [Batch 472/938] [D loss: 0.642546] [G loss: 0.072885]\n",
            "[Epoch 25/200] [Batch 473/938] [D loss: 0.619590] [G loss: 0.079333]\n",
            "[Epoch 25/200] [Batch 474/938] [D loss: 0.607730] [G loss: 0.070614]\n",
            "[Epoch 25/200] [Batch 475/938] [D loss: 0.679669] [G loss: 0.066209]\n",
            "[Epoch 25/200] [Batch 476/938] [D loss: 0.592673] [G loss: 0.071694]\n",
            "[Epoch 25/200] [Batch 477/938] [D loss: 0.631745] [G loss: 0.067733]\n",
            "[Epoch 25/200] [Batch 478/938] [D loss: 0.621324] [G loss: 0.071694]\n",
            "[Epoch 25/200] [Batch 479/938] [D loss: 0.627386] [G loss: 0.070078]\n",
            "[Epoch 25/200] [Batch 480/938] [D loss: 0.602320] [G loss: 0.069030]\n",
            "[Epoch 25/200] [Batch 481/938] [D loss: 0.686181] [G loss: 0.074709]\n",
            "[Epoch 25/200] [Batch 482/938] [D loss: 0.664693] [G loss: 0.070378]\n",
            "[Epoch 25/200] [Batch 483/938] [D loss: 0.607016] [G loss: 0.070496]\n",
            "[Epoch 25/200] [Batch 484/938] [D loss: 0.632733] [G loss: 0.066970]\n",
            "[Epoch 25/200] [Batch 485/938] [D loss: 0.655532] [G loss: 0.076846]\n",
            "[Epoch 25/200] [Batch 486/938] [D loss: 0.654655] [G loss: 0.065828]\n",
            "[Epoch 25/200] [Batch 487/938] [D loss: 0.640834] [G loss: 0.065859]\n",
            "[Epoch 25/200] [Batch 488/938] [D loss: 0.609884] [G loss: 0.074034]\n",
            "[Epoch 25/200] [Batch 489/938] [D loss: 0.657733] [G loss: 0.076392]\n",
            "[Epoch 25/200] [Batch 490/938] [D loss: 0.631266] [G loss: 0.080344]\n",
            "[Epoch 25/200] [Batch 491/938] [D loss: 0.652005] [G loss: 0.073257]\n",
            "[Epoch 25/200] [Batch 492/938] [D loss: 0.635706] [G loss: 0.073457]\n",
            "[Epoch 25/200] [Batch 493/938] [D loss: 0.702426] [G loss: 0.080174]\n",
            "[Epoch 25/200] [Batch 494/938] [D loss: 0.634004] [G loss: 0.073276]\n",
            "[Epoch 25/200] [Batch 495/938] [D loss: 0.608886] [G loss: 0.076920]\n",
            "[Epoch 25/200] [Batch 496/938] [D loss: 0.631413] [G loss: 0.077080]\n",
            "[Epoch 25/200] [Batch 497/938] [D loss: 0.672775] [G loss: 0.073677]\n",
            "[Epoch 25/200] [Batch 498/938] [D loss: 0.624362] [G loss: 0.071550]\n",
            "[Epoch 25/200] [Batch 499/938] [D loss: 0.617179] [G loss: 0.074832]\n",
            "[Epoch 25/200] [Batch 500/938] [D loss: 0.616615] [G loss: 0.082773]\n",
            "[Epoch 25/200] [Batch 501/938] [D loss: 0.600378] [G loss: 0.077880]\n",
            "[Epoch 25/200] [Batch 502/938] [D loss: 0.641820] [G loss: 0.075211]\n",
            "[Epoch 25/200] [Batch 503/938] [D loss: 0.647302] [G loss: 0.076480]\n",
            "[Epoch 25/200] [Batch 504/938] [D loss: 0.609211] [G loss: 0.071024]\n",
            "[Epoch 25/200] [Batch 505/938] [D loss: 0.647012] [G loss: 0.082082]\n",
            "[Epoch 25/200] [Batch 506/938] [D loss: 0.670420] [G loss: 0.071926]\n",
            "[Epoch 25/200] [Batch 507/938] [D loss: 0.614236] [G loss: 0.070043]\n",
            "[Epoch 25/200] [Batch 508/938] [D loss: 0.646266] [G loss: 0.079031]\n",
            "[Epoch 25/200] [Batch 509/938] [D loss: 0.649390] [G loss: 0.072138]\n",
            "[Epoch 25/200] [Batch 510/938] [D loss: 0.659663] [G loss: 0.071195]\n",
            "[Epoch 25/200] [Batch 511/938] [D loss: 0.643695] [G loss: 0.065823]\n",
            "[Epoch 25/200] [Batch 512/938] [D loss: 0.632299] [G loss: 0.077071]\n",
            "[Epoch 25/200] [Batch 513/938] [D loss: 0.611989] [G loss: 0.070700]\n",
            "[Epoch 25/200] [Batch 514/938] [D loss: 0.653325] [G loss: 0.078770]\n",
            "[Epoch 25/200] [Batch 515/938] [D loss: 0.679936] [G loss: 0.073441]\n",
            "[Epoch 25/200] [Batch 516/938] [D loss: 0.623310] [G loss: 0.075155]\n",
            "[Epoch 25/200] [Batch 517/938] [D loss: 0.633041] [G loss: 0.075224]\n",
            "[Epoch 25/200] [Batch 518/938] [D loss: 0.627250] [G loss: 0.066328]\n",
            "[Epoch 25/200] [Batch 519/938] [D loss: 0.627680] [G loss: 0.069678]\n",
            "[Epoch 25/200] [Batch 520/938] [D loss: 0.651942] [G loss: 0.067836]\n",
            "[Epoch 25/200] [Batch 521/938] [D loss: 0.672377] [G loss: 0.081906]\n",
            "[Epoch 25/200] [Batch 522/938] [D loss: 0.632473] [G loss: 0.073494]\n",
            "[Epoch 25/200] [Batch 523/938] [D loss: 0.637511] [G loss: 0.072961]\n",
            "[Epoch 25/200] [Batch 524/938] [D loss: 0.641949] [G loss: 0.074174]\n",
            "[Epoch 25/200] [Batch 525/938] [D loss: 0.638999] [G loss: 0.073703]\n",
            "[Epoch 25/200] [Batch 526/938] [D loss: 0.611043] [G loss: 0.079613]\n",
            "[Epoch 25/200] [Batch 527/938] [D loss: 0.616001] [G loss: 0.073379]\n",
            "[Epoch 25/200] [Batch 528/938] [D loss: 0.635252] [G loss: 0.071667]\n",
            "[Epoch 25/200] [Batch 529/938] [D loss: 0.629342] [G loss: 0.075587]\n",
            "[Epoch 25/200] [Batch 530/938] [D loss: 0.659253] [G loss: 0.080667]\n",
            "[Epoch 25/200] [Batch 531/938] [D loss: 0.647438] [G loss: 0.077859]\n",
            "[Epoch 25/200] [Batch 532/938] [D loss: 0.623563] [G loss: 0.069626]\n",
            "[Epoch 25/200] [Batch 533/938] [D loss: 0.640946] [G loss: 0.075498]\n",
            "[Epoch 25/200] [Batch 534/938] [D loss: 0.624933] [G loss: 0.071466]\n",
            "[Epoch 25/200] [Batch 535/938] [D loss: 0.668296] [G loss: 0.078495]\n",
            "[Epoch 25/200] [Batch 536/938] [D loss: 0.681507] [G loss: 0.070808]\n",
            "[Epoch 25/200] [Batch 537/938] [D loss: 0.673881] [G loss: 0.072534]\n",
            "[Epoch 25/200] [Batch 538/938] [D loss: 0.609490] [G loss: 0.074333]\n",
            "[Epoch 25/200] [Batch 539/938] [D loss: 0.629525] [G loss: 0.068139]\n",
            "[Epoch 25/200] [Batch 540/938] [D loss: 0.628427] [G loss: 0.077186]\n",
            "[Epoch 25/200] [Batch 541/938] [D loss: 0.622250] [G loss: 0.073323]\n",
            "[Epoch 25/200] [Batch 542/938] [D loss: 0.661205] [G loss: 0.071287]\n",
            "[Epoch 25/200] [Batch 543/938] [D loss: 0.650290] [G loss: 0.073912]\n",
            "[Epoch 25/200] [Batch 544/938] [D loss: 0.616012] [G loss: 0.075599]\n",
            "[Epoch 25/200] [Batch 545/938] [D loss: 0.621148] [G loss: 0.075376]\n",
            "[Epoch 25/200] [Batch 546/938] [D loss: 0.611580] [G loss: 0.067080]\n",
            "[Epoch 25/200] [Batch 547/938] [D loss: 0.651095] [G loss: 0.076465]\n",
            "[Epoch 25/200] [Batch 548/938] [D loss: 0.653359] [G loss: 0.069766]\n",
            "[Epoch 25/200] [Batch 549/938] [D loss: 0.608620] [G loss: 0.075843]\n",
            "[Epoch 25/200] [Batch 550/938] [D loss: 0.629391] [G loss: 0.074164]\n",
            "[Epoch 25/200] [Batch 551/938] [D loss: 0.643429] [G loss: 0.071739]\n",
            "[Epoch 25/200] [Batch 552/938] [D loss: 0.650979] [G loss: 0.073052]\n",
            "[Epoch 25/200] [Batch 553/938] [D loss: 0.634186] [G loss: 0.071969]\n",
            "[Epoch 25/200] [Batch 554/938] [D loss: 0.660501] [G loss: 0.079683]\n",
            "[Epoch 25/200] [Batch 555/938] [D loss: 0.628061] [G loss: 0.073277]\n",
            "[Epoch 25/200] [Batch 556/938] [D loss: 0.606193] [G loss: 0.077007]\n",
            "[Epoch 25/200] [Batch 557/938] [D loss: 0.625084] [G loss: 0.078779]\n",
            "[Epoch 25/200] [Batch 558/938] [D loss: 0.602308] [G loss: 0.080734]\n",
            "[Epoch 25/200] [Batch 559/938] [D loss: 0.642056] [G loss: 0.071092]\n",
            "[Epoch 25/200] [Batch 560/938] [D loss: 0.679445] [G loss: 0.073916]\n",
            "[Epoch 25/200] [Batch 561/938] [D loss: 0.623550] [G loss: 0.077478]\n",
            "[Epoch 25/200] [Batch 562/938] [D loss: 0.620988] [G loss: 0.073698]\n",
            "[Epoch 25/200] [Batch 563/938] [D loss: 0.626987] [G loss: 0.071193]\n",
            "[Epoch 25/200] [Batch 564/938] [D loss: 0.626693] [G loss: 0.069320]\n",
            "[Epoch 25/200] [Batch 565/938] [D loss: 0.639828] [G loss: 0.075328]\n",
            "[Epoch 25/200] [Batch 566/938] [D loss: 0.638135] [G loss: 0.069236]\n",
            "[Epoch 25/200] [Batch 567/938] [D loss: 0.595712] [G loss: 0.073059]\n",
            "[Epoch 25/200] [Batch 568/938] [D loss: 0.605931] [G loss: 0.072621]\n",
            "[Epoch 25/200] [Batch 569/938] [D loss: 0.633551] [G loss: 0.070782]\n",
            "[Epoch 25/200] [Batch 570/938] [D loss: 0.612333] [G loss: 0.079015]\n",
            "[Epoch 25/200] [Batch 571/938] [D loss: 0.647990] [G loss: 0.076924]\n",
            "[Epoch 25/200] [Batch 572/938] [D loss: 0.685704] [G loss: 0.065909]\n",
            "[Epoch 25/200] [Batch 573/938] [D loss: 0.635318] [G loss: 0.068946]\n",
            "[Epoch 25/200] [Batch 574/938] [D loss: 0.629655] [G loss: 0.075535]\n",
            "[Epoch 25/200] [Batch 575/938] [D loss: 0.640597] [G loss: 0.073200]\n",
            "[Epoch 25/200] [Batch 576/938] [D loss: 0.621442] [G loss: 0.073187]\n",
            "[Epoch 25/200] [Batch 577/938] [D loss: 0.632050] [G loss: 0.079888]\n",
            "[Epoch 25/200] [Batch 578/938] [D loss: 0.662234] [G loss: 0.074248]\n",
            "[Epoch 25/200] [Batch 579/938] [D loss: 0.609709] [G loss: 0.068168]\n",
            "[Epoch 25/200] [Batch 580/938] [D loss: 0.620824] [G loss: 0.068298]\n",
            "[Epoch 25/200] [Batch 581/938] [D loss: 0.658814] [G loss: 0.068164]\n",
            "[Epoch 25/200] [Batch 582/938] [D loss: 0.645976] [G loss: 0.080529]\n",
            "[Epoch 25/200] [Batch 583/938] [D loss: 0.629073] [G loss: 0.069510]\n",
            "[Epoch 25/200] [Batch 584/938] [D loss: 0.655193] [G loss: 0.066236]\n",
            "[Epoch 25/200] [Batch 585/938] [D loss: 0.645444] [G loss: 0.075697]\n",
            "[Epoch 25/200] [Batch 586/938] [D loss: 0.641464] [G loss: 0.075515]\n",
            "[Epoch 25/200] [Batch 587/938] [D loss: 0.651697] [G loss: 0.077518]\n",
            "[Epoch 25/200] [Batch 588/938] [D loss: 0.645514] [G loss: 0.079247]\n",
            "[Epoch 25/200] [Batch 589/938] [D loss: 0.642610] [G loss: 0.076446]\n",
            "[Epoch 25/200] [Batch 590/938] [D loss: 0.683930] [G loss: 0.084342]\n",
            "[Epoch 25/200] [Batch 591/938] [D loss: 0.621842] [G loss: 0.071002]\n",
            "[Epoch 25/200] [Batch 592/938] [D loss: 0.653911] [G loss: 0.071076]\n",
            "[Epoch 25/200] [Batch 593/938] [D loss: 0.649291] [G loss: 0.070840]\n",
            "[Epoch 25/200] [Batch 594/938] [D loss: 0.640835] [G loss: 0.066668]\n",
            "[Epoch 25/200] [Batch 595/938] [D loss: 0.703843] [G loss: 0.072249]\n",
            "[Epoch 25/200] [Batch 596/938] [D loss: 0.626235] [G loss: 0.065329]\n",
            "[Epoch 25/200] [Batch 597/938] [D loss: 0.669590] [G loss: 0.076273]\n",
            "[Epoch 25/200] [Batch 598/938] [D loss: 0.698124] [G loss: 0.074862]\n",
            "[Epoch 25/200] [Batch 599/938] [D loss: 0.630834] [G loss: 0.071146]\n",
            "[Epoch 25/200] [Batch 600/938] [D loss: 0.621555] [G loss: 0.074881]\n",
            "[Epoch 25/200] [Batch 601/938] [D loss: 0.625619] [G loss: 0.069699]\n",
            "[Epoch 25/200] [Batch 602/938] [D loss: 0.671012] [G loss: 0.067857]\n",
            "[Epoch 25/200] [Batch 603/938] [D loss: 0.643687] [G loss: 0.073003]\n",
            "[Epoch 25/200] [Batch 604/938] [D loss: 0.659362] [G loss: 0.066281]\n",
            "[Epoch 25/200] [Batch 605/938] [D loss: 0.633011] [G loss: 0.071764]\n",
            "[Epoch 25/200] [Batch 606/938] [D loss: 0.654511] [G loss: 0.072101]\n",
            "[Epoch 25/200] [Batch 607/938] [D loss: 0.605800] [G loss: 0.069729]\n",
            "[Epoch 25/200] [Batch 608/938] [D loss: 0.664097] [G loss: 0.065372]\n",
            "[Epoch 25/200] [Batch 609/938] [D loss: 0.645863] [G loss: 0.072993]\n",
            "[Epoch 25/200] [Batch 610/938] [D loss: 0.664320] [G loss: 0.074300]\n",
            "[Epoch 25/200] [Batch 611/938] [D loss: 0.624166] [G loss: 0.069413]\n",
            "[Epoch 25/200] [Batch 612/938] [D loss: 0.661640] [G loss: 0.070953]\n",
            "[Epoch 25/200] [Batch 613/938] [D loss: 0.615775] [G loss: 0.070335]\n",
            "[Epoch 25/200] [Batch 614/938] [D loss: 0.698619] [G loss: 0.072652]\n",
            "[Epoch 25/200] [Batch 615/938] [D loss: 0.648165] [G loss: 0.075670]\n",
            "[Epoch 25/200] [Batch 616/938] [D loss: 0.656043] [G loss: 0.069172]\n",
            "[Epoch 25/200] [Batch 617/938] [D loss: 0.613411] [G loss: 0.071845]\n",
            "[Epoch 25/200] [Batch 618/938] [D loss: 0.641955] [G loss: 0.069996]\n",
            "[Epoch 25/200] [Batch 619/938] [D loss: 0.675742] [G loss: 0.075861]\n",
            "[Epoch 25/200] [Batch 620/938] [D loss: 0.668195] [G loss: 0.077571]\n",
            "[Epoch 25/200] [Batch 621/938] [D loss: 0.635142] [G loss: 0.077404]\n",
            "[Epoch 25/200] [Batch 622/938] [D loss: 0.652112] [G loss: 0.069507]\n",
            "[Epoch 25/200] [Batch 623/938] [D loss: 0.655083] [G loss: 0.066947]\n",
            "[Epoch 25/200] [Batch 624/938] [D loss: 0.649839] [G loss: 0.069486]\n",
            "[Epoch 25/200] [Batch 625/938] [D loss: 0.650214] [G loss: 0.071100]\n",
            "[Epoch 25/200] [Batch 626/938] [D loss: 0.628808] [G loss: 0.070568]\n",
            "[Epoch 25/200] [Batch 627/938] [D loss: 0.606757] [G loss: 0.070268]\n",
            "[Epoch 25/200] [Batch 628/938] [D loss: 0.652543] [G loss: 0.075280]\n",
            "[Epoch 25/200] [Batch 629/938] [D loss: 0.657874] [G loss: 0.071083]\n",
            "[Epoch 25/200] [Batch 630/938] [D loss: 0.615645] [G loss: 0.078873]\n",
            "[Epoch 25/200] [Batch 631/938] [D loss: 0.650018] [G loss: 0.069571]\n",
            "[Epoch 25/200] [Batch 632/938] [D loss: 0.642211] [G loss: 0.071107]\n",
            "[Epoch 25/200] [Batch 633/938] [D loss: 0.635468] [G loss: 0.077962]\n",
            "[Epoch 25/200] [Batch 634/938] [D loss: 0.643087] [G loss: 0.066450]\n",
            "[Epoch 25/200] [Batch 635/938] [D loss: 0.650434] [G loss: 0.070731]\n",
            "[Epoch 25/200] [Batch 636/938] [D loss: 0.623918] [G loss: 0.071856]\n",
            "[Epoch 25/200] [Batch 637/938] [D loss: 0.642008] [G loss: 0.078389]\n",
            "[Epoch 25/200] [Batch 638/938] [D loss: 0.619210] [G loss: 0.073378]\n",
            "[Epoch 25/200] [Batch 639/938] [D loss: 0.615916] [G loss: 0.078924]\n",
            "[Epoch 25/200] [Batch 640/938] [D loss: 0.648233] [G loss: 0.075476]\n",
            "[Epoch 25/200] [Batch 641/938] [D loss: 0.614808] [G loss: 0.077108]\n",
            "[Epoch 25/200] [Batch 642/938] [D loss: 0.650795] [G loss: 0.083606]\n",
            "[Epoch 25/200] [Batch 643/938] [D loss: 0.676068] [G loss: 0.084625]\n",
            "[Epoch 25/200] [Batch 644/938] [D loss: 0.627405] [G loss: 0.070979]\n",
            "[Epoch 25/200] [Batch 645/938] [D loss: 0.657431] [G loss: 0.075856]\n",
            "[Epoch 25/200] [Batch 646/938] [D loss: 0.669259] [G loss: 0.073835]\n",
            "[Epoch 25/200] [Batch 647/938] [D loss: 0.635703] [G loss: 0.070945]\n",
            "[Epoch 25/200] [Batch 648/938] [D loss: 0.647221] [G loss: 0.071957]\n",
            "[Epoch 25/200] [Batch 649/938] [D loss: 0.616382] [G loss: 0.067275]\n",
            "[Epoch 25/200] [Batch 650/938] [D loss: 0.632963] [G loss: 0.073725]\n",
            "[Epoch 25/200] [Batch 651/938] [D loss: 0.700172] [G loss: 0.073847]\n",
            "[Epoch 25/200] [Batch 652/938] [D loss: 0.617597] [G loss: 0.077839]\n",
            "[Epoch 25/200] [Batch 653/938] [D loss: 0.651047] [G loss: 0.075142]\n",
            "[Epoch 25/200] [Batch 654/938] [D loss: 0.604378] [G loss: 0.075489]\n",
            "[Epoch 25/200] [Batch 655/938] [D loss: 0.644909] [G loss: 0.067823]\n",
            "[Epoch 25/200] [Batch 656/938] [D loss: 0.678649] [G loss: 0.074419]\n",
            "[Epoch 25/200] [Batch 657/938] [D loss: 0.668534] [G loss: 0.083202]\n",
            "[Epoch 25/200] [Batch 658/938] [D loss: 0.606129] [G loss: 0.075351]\n",
            "[Epoch 25/200] [Batch 659/938] [D loss: 0.639340] [G loss: 0.072550]\n",
            "[Epoch 25/200] [Batch 660/938] [D loss: 0.595792] [G loss: 0.065849]\n",
            "[Epoch 25/200] [Batch 661/938] [D loss: 0.609577] [G loss: 0.068647]\n",
            "[Epoch 25/200] [Batch 662/938] [D loss: 0.634791] [G loss: 0.080656]\n",
            "[Epoch 25/200] [Batch 663/938] [D loss: 0.651836] [G loss: 0.074296]\n",
            "[Epoch 25/200] [Batch 664/938] [D loss: 0.668681] [G loss: 0.079828]\n",
            "[Epoch 25/200] [Batch 665/938] [D loss: 0.643015] [G loss: 0.076933]\n",
            "[Epoch 25/200] [Batch 666/938] [D loss: 0.625826] [G loss: 0.071219]\n",
            "[Epoch 25/200] [Batch 667/938] [D loss: 0.662929] [G loss: 0.070941]\n",
            "[Epoch 25/200] [Batch 668/938] [D loss: 0.624185] [G loss: 0.076538]\n",
            "[Epoch 25/200] [Batch 669/938] [D loss: 0.607167] [G loss: 0.074288]\n",
            "[Epoch 25/200] [Batch 670/938] [D loss: 0.679867] [G loss: 0.071268]\n",
            "[Epoch 25/200] [Batch 671/938] [D loss: 0.656762] [G loss: 0.068511]\n",
            "[Epoch 25/200] [Batch 672/938] [D loss: 0.597628] [G loss: 0.076261]\n",
            "[Epoch 25/200] [Batch 673/938] [D loss: 0.639454] [G loss: 0.069250]\n",
            "[Epoch 25/200] [Batch 674/938] [D loss: 0.643281] [G loss: 0.068055]\n",
            "[Epoch 25/200] [Batch 675/938] [D loss: 0.619664] [G loss: 0.080578]\n",
            "[Epoch 25/200] [Batch 676/938] [D loss: 0.635266] [G loss: 0.070814]\n",
            "[Epoch 25/200] [Batch 677/938] [D loss: 0.649780] [G loss: 0.063922]\n",
            "[Epoch 25/200] [Batch 678/938] [D loss: 0.612991] [G loss: 0.073973]\n",
            "[Epoch 25/200] [Batch 679/938] [D loss: 0.617387] [G loss: 0.067207]\n",
            "[Epoch 25/200] [Batch 680/938] [D loss: 0.609702] [G loss: 0.071233]\n",
            "[Epoch 25/200] [Batch 681/938] [D loss: 0.639401] [G loss: 0.077850]\n",
            "[Epoch 25/200] [Batch 682/938] [D loss: 0.627257] [G loss: 0.082059]\n",
            "[Epoch 25/200] [Batch 683/938] [D loss: 0.658105] [G loss: 0.077073]\n",
            "[Epoch 25/200] [Batch 684/938] [D loss: 0.642058] [G loss: 0.069654]\n",
            "[Epoch 25/200] [Batch 685/938] [D loss: 0.668762] [G loss: 0.074665]\n",
            "[Epoch 25/200] [Batch 686/938] [D loss: 0.650658] [G loss: 0.075977]\n",
            "[Epoch 25/200] [Batch 687/938] [D loss: 0.650092] [G loss: 0.074945]\n",
            "[Epoch 25/200] [Batch 688/938] [D loss: 0.631422] [G loss: 0.081192]\n",
            "[Epoch 25/200] [Batch 689/938] [D loss: 0.635146] [G loss: 0.070817]\n",
            "[Epoch 25/200] [Batch 690/938] [D loss: 0.668741] [G loss: 0.065287]\n",
            "[Epoch 25/200] [Batch 691/938] [D loss: 0.622971] [G loss: 0.071073]\n",
            "[Epoch 25/200] [Batch 692/938] [D loss: 0.627580] [G loss: 0.070447]\n",
            "[Epoch 25/200] [Batch 693/938] [D loss: 0.661293] [G loss: 0.071255]\n",
            "[Epoch 25/200] [Batch 694/938] [D loss: 0.655234] [G loss: 0.078554]\n",
            "[Epoch 25/200] [Batch 695/938] [D loss: 0.620073] [G loss: 0.066265]\n",
            "[Epoch 25/200] [Batch 696/938] [D loss: 0.603877] [G loss: 0.070146]\n",
            "[Epoch 25/200] [Batch 697/938] [D loss: 0.642193] [G loss: 0.073615]\n",
            "[Epoch 25/200] [Batch 698/938] [D loss: 0.660977] [G loss: 0.073812]\n",
            "[Epoch 25/200] [Batch 699/938] [D loss: 0.618287] [G loss: 0.074495]\n",
            "[Epoch 25/200] [Batch 700/938] [D loss: 0.628687] [G loss: 0.072200]\n",
            "[Epoch 25/200] [Batch 701/938] [D loss: 0.614749] [G loss: 0.076584]\n",
            "[Epoch 25/200] [Batch 702/938] [D loss: 0.631243] [G loss: 0.070550]\n",
            "[Epoch 25/200] [Batch 703/938] [D loss: 0.620564] [G loss: 0.069535]\n",
            "[Epoch 25/200] [Batch 704/938] [D loss: 0.662497] [G loss: 0.073607]\n",
            "[Epoch 25/200] [Batch 705/938] [D loss: 0.656534] [G loss: 0.076433]\n",
            "[Epoch 25/200] [Batch 706/938] [D loss: 0.656551] [G loss: 0.079280]\n",
            "[Epoch 25/200] [Batch 707/938] [D loss: 0.594870] [G loss: 0.071594]\n",
            "[Epoch 25/200] [Batch 708/938] [D loss: 0.623004] [G loss: 0.070556]\n",
            "[Epoch 25/200] [Batch 709/938] [D loss: 0.621574] [G loss: 0.075724]\n",
            "[Epoch 25/200] [Batch 710/938] [D loss: 0.673501] [G loss: 0.071777]\n",
            "[Epoch 25/200] [Batch 711/938] [D loss: 0.649301] [G loss: 0.067367]\n",
            "[Epoch 25/200] [Batch 712/938] [D loss: 0.669418] [G loss: 0.073788]\n",
            "[Epoch 25/200] [Batch 713/938] [D loss: 0.632457] [G loss: 0.074882]\n",
            "[Epoch 25/200] [Batch 714/938] [D loss: 0.626346] [G loss: 0.075863]\n",
            "[Epoch 25/200] [Batch 715/938] [D loss: 0.654843] [G loss: 0.069269]\n",
            "[Epoch 25/200] [Batch 716/938] [D loss: 0.674183] [G loss: 0.073695]\n",
            "[Epoch 25/200] [Batch 717/938] [D loss: 0.684002] [G loss: 0.068996]\n",
            "[Epoch 25/200] [Batch 718/938] [D loss: 0.621653] [G loss: 0.060654]\n",
            "[Epoch 25/200] [Batch 719/938] [D loss: 0.660203] [G loss: 0.080103]\n",
            "[Epoch 25/200] [Batch 720/938] [D loss: 0.650432] [G loss: 0.067301]\n",
            "[Epoch 25/200] [Batch 721/938] [D loss: 0.655204] [G loss: 0.070719]\n",
            "[Epoch 25/200] [Batch 722/938] [D loss: 0.632259] [G loss: 0.073745]\n",
            "[Epoch 25/200] [Batch 723/938] [D loss: 0.622460] [G loss: 0.069033]\n",
            "[Epoch 25/200] [Batch 724/938] [D loss: 0.638885] [G loss: 0.072565]\n",
            "[Epoch 25/200] [Batch 725/938] [D loss: 0.709459] [G loss: 0.075926]\n",
            "[Epoch 25/200] [Batch 726/938] [D loss: 0.647934] [G loss: 0.078332]\n",
            "[Epoch 25/200] [Batch 727/938] [D loss: 0.650207] [G loss: 0.074575]\n",
            "[Epoch 25/200] [Batch 728/938] [D loss: 0.654070] [G loss: 0.071202]\n",
            "[Epoch 25/200] [Batch 729/938] [D loss: 0.669972] [G loss: 0.077177]\n",
            "[Epoch 25/200] [Batch 730/938] [D loss: 0.638112] [G loss: 0.069848]\n",
            "[Epoch 25/200] [Batch 731/938] [D loss: 0.613571] [G loss: 0.072759]\n",
            "[Epoch 25/200] [Batch 732/938] [D loss: 0.655254] [G loss: 0.076321]\n",
            "[Epoch 25/200] [Batch 733/938] [D loss: 0.637472] [G loss: 0.073026]\n",
            "[Epoch 25/200] [Batch 734/938] [D loss: 0.628924] [G loss: 0.077971]\n",
            "[Epoch 25/200] [Batch 735/938] [D loss: 0.625216] [G loss: 0.072917]\n",
            "[Epoch 25/200] [Batch 736/938] [D loss: 0.595229] [G loss: 0.075633]\n",
            "[Epoch 25/200] [Batch 737/938] [D loss: 0.581171] [G loss: 0.077548]\n",
            "[Epoch 25/200] [Batch 738/938] [D loss: 0.652737] [G loss: 0.070913]\n",
            "[Epoch 25/200] [Batch 739/938] [D loss: 0.628040] [G loss: 0.073859]\n",
            "[Epoch 25/200] [Batch 740/938] [D loss: 0.632625] [G loss: 0.080183]\n",
            "[Epoch 25/200] [Batch 741/938] [D loss: 0.650234] [G loss: 0.077773]\n",
            "[Epoch 25/200] [Batch 742/938] [D loss: 0.617048] [G loss: 0.071632]\n",
            "[Epoch 25/200] [Batch 743/938] [D loss: 0.619796] [G loss: 0.075721]\n",
            "[Epoch 25/200] [Batch 744/938] [D loss: 0.624903] [G loss: 0.073241]\n",
            "[Epoch 25/200] [Batch 745/938] [D loss: 0.624874] [G loss: 0.075051]\n",
            "[Epoch 25/200] [Batch 746/938] [D loss: 0.650209] [G loss: 0.080437]\n",
            "[Epoch 25/200] [Batch 747/938] [D loss: 0.668076] [G loss: 0.076991]\n",
            "[Epoch 25/200] [Batch 748/938] [D loss: 0.661793] [G loss: 0.074839]\n",
            "[Epoch 25/200] [Batch 749/938] [D loss: 0.659039] [G loss: 0.071001]\n",
            "[Epoch 25/200] [Batch 750/938] [D loss: 0.668267] [G loss: 0.066039]\n",
            "[Epoch 25/200] [Batch 751/938] [D loss: 0.652477] [G loss: 0.077174]\n",
            "[Epoch 25/200] [Batch 752/938] [D loss: 0.643689] [G loss: 0.078000]\n",
            "[Epoch 25/200] [Batch 753/938] [D loss: 0.649699] [G loss: 0.073266]\n",
            "[Epoch 25/200] [Batch 754/938] [D loss: 0.616262] [G loss: 0.073979]\n",
            "[Epoch 25/200] [Batch 755/938] [D loss: 0.667139] [G loss: 0.077096]\n",
            "[Epoch 25/200] [Batch 756/938] [D loss: 0.622078] [G loss: 0.070794]\n",
            "[Epoch 25/200] [Batch 757/938] [D loss: 0.651999] [G loss: 0.068680]\n",
            "[Epoch 25/200] [Batch 758/938] [D loss: 0.653719] [G loss: 0.070867]\n",
            "[Epoch 25/200] [Batch 759/938] [D loss: 0.582887] [G loss: 0.079790]\n",
            "[Epoch 25/200] [Batch 760/938] [D loss: 0.622685] [G loss: 0.070245]\n",
            "[Epoch 25/200] [Batch 761/938] [D loss: 0.585685] [G loss: 0.080275]\n",
            "[Epoch 25/200] [Batch 762/938] [D loss: 0.640222] [G loss: 0.075004]\n",
            "[Epoch 25/200] [Batch 763/938] [D loss: 0.632989] [G loss: 0.069848]\n",
            "[Epoch 25/200] [Batch 764/938] [D loss: 0.592554] [G loss: 0.068307]\n",
            "[Epoch 25/200] [Batch 765/938] [D loss: 0.599265] [G loss: 0.073245]\n",
            "[Epoch 25/200] [Batch 766/938] [D loss: 0.634411] [G loss: 0.075916]\n",
            "[Epoch 25/200] [Batch 767/938] [D loss: 0.617307] [G loss: 0.070094]\n",
            "[Epoch 25/200] [Batch 768/938] [D loss: 0.661921] [G loss: 0.070776]\n",
            "[Epoch 25/200] [Batch 769/938] [D loss: 0.645882] [G loss: 0.070434]\n",
            "[Epoch 25/200] [Batch 770/938] [D loss: 0.647267] [G loss: 0.066808]\n",
            "[Epoch 25/200] [Batch 771/938] [D loss: 0.651409] [G loss: 0.071632]\n",
            "[Epoch 25/200] [Batch 772/938] [D loss: 0.635100] [G loss: 0.078022]\n",
            "[Epoch 25/200] [Batch 773/938] [D loss: 0.652386] [G loss: 0.071993]\n",
            "[Epoch 25/200] [Batch 774/938] [D loss: 0.666722] [G loss: 0.069022]\n",
            "[Epoch 25/200] [Batch 775/938] [D loss: 0.649323] [G loss: 0.070375]\n",
            "[Epoch 25/200] [Batch 776/938] [D loss: 0.628603] [G loss: 0.064500]\n",
            "[Epoch 25/200] [Batch 777/938] [D loss: 0.622900] [G loss: 0.081120]\n",
            "[Epoch 25/200] [Batch 778/938] [D loss: 0.617180] [G loss: 0.075532]\n",
            "[Epoch 25/200] [Batch 779/938] [D loss: 0.668054] [G loss: 0.068403]\n",
            "[Epoch 25/200] [Batch 780/938] [D loss: 0.646681] [G loss: 0.081423]\n",
            "[Epoch 25/200] [Batch 781/938] [D loss: 0.581369] [G loss: 0.076292]\n",
            "[Epoch 25/200] [Batch 782/938] [D loss: 0.622227] [G loss: 0.072735]\n",
            "[Epoch 25/200] [Batch 783/938] [D loss: 0.628209] [G loss: 0.073467]\n",
            "[Epoch 25/200] [Batch 784/938] [D loss: 0.631456] [G loss: 0.074076]\n",
            "[Epoch 25/200] [Batch 785/938] [D loss: 0.627337] [G loss: 0.069399]\n",
            "[Epoch 25/200] [Batch 786/938] [D loss: 0.644724] [G loss: 0.070506]\n",
            "[Epoch 25/200] [Batch 787/938] [D loss: 0.626516] [G loss: 0.072222]\n",
            "[Epoch 25/200] [Batch 788/938] [D loss: 0.632330] [G loss: 0.067321]\n",
            "[Epoch 25/200] [Batch 789/938] [D loss: 0.677306] [G loss: 0.074325]\n",
            "[Epoch 25/200] [Batch 790/938] [D loss: 0.623155] [G loss: 0.072247]\n",
            "[Epoch 25/200] [Batch 791/938] [D loss: 0.621855] [G loss: 0.074486]\n",
            "[Epoch 25/200] [Batch 792/938] [D loss: 0.628691] [G loss: 0.074571]\n",
            "[Epoch 25/200] [Batch 793/938] [D loss: 0.661500] [G loss: 0.066484]\n",
            "[Epoch 25/200] [Batch 794/938] [D loss: 0.680336] [G loss: 0.069798]\n",
            "[Epoch 25/200] [Batch 795/938] [D loss: 0.651810] [G loss: 0.072542]\n",
            "[Epoch 25/200] [Batch 796/938] [D loss: 0.645271] [G loss: 0.073971]\n",
            "[Epoch 25/200] [Batch 797/938] [D loss: 0.649509] [G loss: 0.072016]\n",
            "[Epoch 25/200] [Batch 798/938] [D loss: 0.624600] [G loss: 0.065786]\n",
            "[Epoch 25/200] [Batch 799/938] [D loss: 0.606942] [G loss: 0.071187]\n",
            "[Epoch 25/200] [Batch 800/938] [D loss: 0.620719] [G loss: 0.073952]\n",
            "[Epoch 25/200] [Batch 801/938] [D loss: 0.673364] [G loss: 0.074563]\n",
            "[Epoch 25/200] [Batch 802/938] [D loss: 0.639103] [G loss: 0.077686]\n",
            "[Epoch 25/200] [Batch 803/938] [D loss: 0.626367] [G loss: 0.072972]\n",
            "[Epoch 25/200] [Batch 804/938] [D loss: 0.594927] [G loss: 0.078331]\n",
            "[Epoch 25/200] [Batch 805/938] [D loss: 0.666652] [G loss: 0.075670]\n",
            "[Epoch 25/200] [Batch 806/938] [D loss: 0.634001] [G loss: 0.069560]\n",
            "[Epoch 25/200] [Batch 807/938] [D loss: 0.635662] [G loss: 0.075040]\n",
            "[Epoch 25/200] [Batch 808/938] [D loss: 0.652357] [G loss: 0.072470]\n",
            "[Epoch 25/200] [Batch 809/938] [D loss: 0.598044] [G loss: 0.071805]\n",
            "[Epoch 25/200] [Batch 810/938] [D loss: 0.608587] [G loss: 0.070768]\n",
            "[Epoch 25/200] [Batch 811/938] [D loss: 0.654862] [G loss: 0.070429]\n",
            "[Epoch 25/200] [Batch 812/938] [D loss: 0.625831] [G loss: 0.081511]\n",
            "[Epoch 25/200] [Batch 813/938] [D loss: 0.619427] [G loss: 0.069674]\n",
            "[Epoch 25/200] [Batch 814/938] [D loss: 0.640874] [G loss: 0.072584]\n",
            "[Epoch 25/200] [Batch 815/938] [D loss: 0.610350] [G loss: 0.070815]\n",
            "[Epoch 25/200] [Batch 816/938] [D loss: 0.622321] [G loss: 0.073305]\n",
            "[Epoch 25/200] [Batch 817/938] [D loss: 0.614379] [G loss: 0.075129]\n",
            "[Epoch 25/200] [Batch 818/938] [D loss: 0.654626] [G loss: 0.070906]\n",
            "[Epoch 25/200] [Batch 819/938] [D loss: 0.604692] [G loss: 0.067487]\n",
            "[Epoch 25/200] [Batch 820/938] [D loss: 0.642378] [G loss: 0.075633]\n",
            "[Epoch 25/200] [Batch 821/938] [D loss: 0.643164] [G loss: 0.068165]\n",
            "[Epoch 25/200] [Batch 822/938] [D loss: 0.627521] [G loss: 0.073232]\n",
            "[Epoch 25/200] [Batch 823/938] [D loss: 0.639975] [G loss: 0.067248]\n",
            "[Epoch 25/200] [Batch 824/938] [D loss: 0.603498] [G loss: 0.069483]\n",
            "[Epoch 25/200] [Batch 825/938] [D loss: 0.703423] [G loss: 0.073902]\n",
            "[Epoch 25/200] [Batch 826/938] [D loss: 0.652660] [G loss: 0.079226]\n",
            "[Epoch 25/200] [Batch 827/938] [D loss: 0.639807] [G loss: 0.081153]\n",
            "[Epoch 25/200] [Batch 828/938] [D loss: 0.630477] [G loss: 0.076644]\n",
            "[Epoch 25/200] [Batch 829/938] [D loss: 0.618265] [G loss: 0.074317]\n",
            "[Epoch 25/200] [Batch 830/938] [D loss: 0.609147] [G loss: 0.076492]\n",
            "[Epoch 25/200] [Batch 831/938] [D loss: 0.638132] [G loss: 0.078347]\n",
            "[Epoch 25/200] [Batch 832/938] [D loss: 0.630573] [G loss: 0.072141]\n",
            "[Epoch 25/200] [Batch 833/938] [D loss: 0.640159] [G loss: 0.069333]\n",
            "[Epoch 25/200] [Batch 834/938] [D loss: 0.652259] [G loss: 0.060855]\n",
            "[Epoch 25/200] [Batch 835/938] [D loss: 0.656905] [G loss: 0.074015]\n",
            "[Epoch 25/200] [Batch 836/938] [D loss: 0.608534] [G loss: 0.074437]\n",
            "[Epoch 25/200] [Batch 837/938] [D loss: 0.603179] [G loss: 0.075702]\n",
            "[Epoch 25/200] [Batch 838/938] [D loss: 0.684747] [G loss: 0.069081]\n",
            "[Epoch 25/200] [Batch 839/938] [D loss: 0.663588] [G loss: 0.068153]\n",
            "[Epoch 25/200] [Batch 840/938] [D loss: 0.642381] [G loss: 0.068601]\n",
            "[Epoch 25/200] [Batch 841/938] [D loss: 0.584519] [G loss: 0.071969]\n",
            "[Epoch 25/200] [Batch 842/938] [D loss: 0.610062] [G loss: 0.075804]\n",
            "[Epoch 25/200] [Batch 843/938] [D loss: 0.662389] [G loss: 0.074906]\n",
            "[Epoch 25/200] [Batch 844/938] [D loss: 0.598767] [G loss: 0.072792]\n",
            "[Epoch 25/200] [Batch 845/938] [D loss: 0.609601] [G loss: 0.070790]\n",
            "[Epoch 25/200] [Batch 846/938] [D loss: 0.658157] [G loss: 0.071360]\n",
            "[Epoch 25/200] [Batch 847/938] [D loss: 0.626322] [G loss: 0.072132]\n",
            "[Epoch 25/200] [Batch 848/938] [D loss: 0.604464] [G loss: 0.072654]\n",
            "[Epoch 25/200] [Batch 849/938] [D loss: 0.641911] [G loss: 0.069455]\n",
            "[Epoch 25/200] [Batch 850/938] [D loss: 0.624096] [G loss: 0.070723]\n",
            "[Epoch 25/200] [Batch 851/938] [D loss: 0.612565] [G loss: 0.073695]\n",
            "[Epoch 25/200] [Batch 852/938] [D loss: 0.627554] [G loss: 0.070711]\n",
            "[Epoch 25/200] [Batch 853/938] [D loss: 0.633489] [G loss: 0.063034]\n",
            "[Epoch 25/200] [Batch 854/938] [D loss: 0.647456] [G loss: 0.069064]\n",
            "[Epoch 25/200] [Batch 855/938] [D loss: 0.660005] [G loss: 0.075464]\n",
            "[Epoch 25/200] [Batch 856/938] [D loss: 0.659662] [G loss: 0.067477]\n",
            "[Epoch 25/200] [Batch 857/938] [D loss: 0.602727] [G loss: 0.084386]\n",
            "[Epoch 25/200] [Batch 858/938] [D loss: 0.653604] [G loss: 0.071761]\n",
            "[Epoch 25/200] [Batch 859/938] [D loss: 0.692440] [G loss: 0.078282]\n",
            "[Epoch 25/200] [Batch 860/938] [D loss: 0.621820] [G loss: 0.068684]\n",
            "[Epoch 25/200] [Batch 861/938] [D loss: 0.646779] [G loss: 0.077873]\n",
            "[Epoch 25/200] [Batch 862/938] [D loss: 0.636302] [G loss: 0.067716]\n",
            "[Epoch 25/200] [Batch 863/938] [D loss: 0.652818] [G loss: 0.067517]\n",
            "[Epoch 25/200] [Batch 864/938] [D loss: 0.584947] [G loss: 0.072786]\n",
            "[Epoch 25/200] [Batch 865/938] [D loss: 0.602556] [G loss: 0.071038]\n",
            "[Epoch 25/200] [Batch 866/938] [D loss: 0.645127] [G loss: 0.070279]\n",
            "[Epoch 25/200] [Batch 867/938] [D loss: 0.638520] [G loss: 0.071286]\n",
            "[Epoch 25/200] [Batch 868/938] [D loss: 0.652492] [G loss: 0.066664]\n",
            "[Epoch 25/200] [Batch 869/938] [D loss: 0.682190] [G loss: 0.073338]\n",
            "[Epoch 25/200] [Batch 870/938] [D loss: 0.623697] [G loss: 0.074069]\n",
            "[Epoch 25/200] [Batch 871/938] [D loss: 0.656217] [G loss: 0.067598]\n",
            "[Epoch 25/200] [Batch 872/938] [D loss: 0.627124] [G loss: 0.079909]\n",
            "[Epoch 25/200] [Batch 873/938] [D loss: 0.608399] [G loss: 0.072171]\n",
            "[Epoch 25/200] [Batch 874/938] [D loss: 0.628085] [G loss: 0.068118]\n",
            "[Epoch 25/200] [Batch 875/938] [D loss: 0.632185] [G loss: 0.079412]\n",
            "[Epoch 25/200] [Batch 876/938] [D loss: 0.622355] [G loss: 0.070292]\n",
            "[Epoch 25/200] [Batch 877/938] [D loss: 0.655611] [G loss: 0.071260]\n",
            "[Epoch 25/200] [Batch 878/938] [D loss: 0.630583] [G loss: 0.068307]\n",
            "[Epoch 25/200] [Batch 879/938] [D loss: 0.617196] [G loss: 0.074752]\n",
            "[Epoch 25/200] [Batch 880/938] [D loss: 0.663369] [G loss: 0.074583]\n",
            "[Epoch 25/200] [Batch 881/938] [D loss: 0.619843] [G loss: 0.073955]\n",
            "[Epoch 25/200] [Batch 882/938] [D loss: 0.639624] [G loss: 0.075741]\n",
            "[Epoch 25/200] [Batch 883/938] [D loss: 0.604929] [G loss: 0.074864]\n",
            "[Epoch 25/200] [Batch 884/938] [D loss: 0.635524] [G loss: 0.070530]\n",
            "[Epoch 25/200] [Batch 885/938] [D loss: 0.654001] [G loss: 0.066625]\n",
            "[Epoch 25/200] [Batch 886/938] [D loss: 0.622117] [G loss: 0.076447]\n",
            "[Epoch 25/200] [Batch 887/938] [D loss: 0.632180] [G loss: 0.076770]\n",
            "[Epoch 25/200] [Batch 888/938] [D loss: 0.650131] [G loss: 0.068907]\n",
            "[Epoch 25/200] [Batch 889/938] [D loss: 0.627682] [G loss: 0.078674]\n",
            "[Epoch 25/200] [Batch 890/938] [D loss: 0.643776] [G loss: 0.073226]\n",
            "[Epoch 25/200] [Batch 891/938] [D loss: 0.628536] [G loss: 0.074380]\n",
            "[Epoch 25/200] [Batch 892/938] [D loss: 0.608906] [G loss: 0.071206]\n",
            "[Epoch 25/200] [Batch 893/938] [D loss: 0.622665] [G loss: 0.067211]\n",
            "[Epoch 25/200] [Batch 894/938] [D loss: 0.647730] [G loss: 0.067990]\n",
            "[Epoch 25/200] [Batch 895/938] [D loss: 0.603630] [G loss: 0.078494]\n",
            "[Epoch 25/200] [Batch 896/938] [D loss: 0.608666] [G loss: 0.080990]\n",
            "[Epoch 25/200] [Batch 897/938] [D loss: 0.620770] [G loss: 0.071988]\n",
            "[Epoch 25/200] [Batch 898/938] [D loss: 0.630320] [G loss: 0.073058]\n",
            "[Epoch 25/200] [Batch 899/938] [D loss: 0.646765] [G loss: 0.062985]\n",
            "[Epoch 25/200] [Batch 900/938] [D loss: 0.614696] [G loss: 0.069031]\n",
            "[Epoch 25/200] [Batch 901/938] [D loss: 0.626063] [G loss: 0.088543]\n",
            "[Epoch 25/200] [Batch 902/938] [D loss: 0.626875] [G loss: 0.070656]\n",
            "[Epoch 25/200] [Batch 903/938] [D loss: 0.650189] [G loss: 0.071748]\n",
            "[Epoch 25/200] [Batch 904/938] [D loss: 0.610821] [G loss: 0.074190]\n",
            "[Epoch 25/200] [Batch 905/938] [D loss: 0.641393] [G loss: 0.071328]\n",
            "[Epoch 25/200] [Batch 906/938] [D loss: 0.663654] [G loss: 0.071261]\n",
            "[Epoch 25/200] [Batch 907/938] [D loss: 0.613859] [G loss: 0.071972]\n",
            "[Epoch 25/200] [Batch 908/938] [D loss: 0.634249] [G loss: 0.070977]\n",
            "[Epoch 25/200] [Batch 909/938] [D loss: 0.645095] [G loss: 0.070823]\n",
            "[Epoch 25/200] [Batch 910/938] [D loss: 0.671288] [G loss: 0.067932]\n",
            "[Epoch 25/200] [Batch 911/938] [D loss: 0.631403] [G loss: 0.074006]\n",
            "[Epoch 25/200] [Batch 912/938] [D loss: 0.642978] [G loss: 0.070459]\n",
            "[Epoch 25/200] [Batch 913/938] [D loss: 0.655199] [G loss: 0.080922]\n",
            "[Epoch 25/200] [Batch 914/938] [D loss: 0.612526] [G loss: 0.070664]\n",
            "[Epoch 25/200] [Batch 915/938] [D loss: 0.664149] [G loss: 0.070454]\n",
            "[Epoch 25/200] [Batch 916/938] [D loss: 0.629198] [G loss: 0.078244]\n",
            "[Epoch 25/200] [Batch 917/938] [D loss: 0.593820] [G loss: 0.076854]\n",
            "[Epoch 25/200] [Batch 918/938] [D loss: 0.638987] [G loss: 0.069042]\n",
            "[Epoch 25/200] [Batch 919/938] [D loss: 0.641180] [G loss: 0.073565]\n",
            "[Epoch 25/200] [Batch 920/938] [D loss: 0.643780] [G loss: 0.072471]\n",
            "[Epoch 25/200] [Batch 921/938] [D loss: 0.644487] [G loss: 0.073836]\n",
            "[Epoch 25/200] [Batch 922/938] [D loss: 0.670044] [G loss: 0.068077]\n",
            "[Epoch 25/200] [Batch 923/938] [D loss: 0.635125] [G loss: 0.075158]\n",
            "[Epoch 25/200] [Batch 924/938] [D loss: 0.689407] [G loss: 0.074279]\n",
            "[Epoch 25/200] [Batch 925/938] [D loss: 0.604236] [G loss: 0.072287]\n",
            "[Epoch 25/200] [Batch 926/938] [D loss: 0.635274] [G loss: 0.076309]\n",
            "[Epoch 25/200] [Batch 927/938] [D loss: 0.633945] [G loss: 0.074961]\n",
            "[Epoch 25/200] [Batch 928/938] [D loss: 0.627939] [G loss: 0.073966]\n",
            "[Epoch 25/200] [Batch 929/938] [D loss: 0.626561] [G loss: 0.073614]\n",
            "[Epoch 25/200] [Batch 930/938] [D loss: 0.639177] [G loss: 0.068916]\n",
            "[Epoch 25/200] [Batch 931/938] [D loss: 0.656367] [G loss: 0.072533]\n",
            "[Epoch 25/200] [Batch 932/938] [D loss: 0.638591] [G loss: 0.068588]\n",
            "[Epoch 25/200] [Batch 933/938] [D loss: 0.642620] [G loss: 0.071177]\n",
            "[Epoch 25/200] [Batch 934/938] [D loss: 0.641155] [G loss: 0.070062]\n",
            "[Epoch 25/200] [Batch 935/938] [D loss: 0.630097] [G loss: 0.077745]\n",
            "[Epoch 25/200] [Batch 936/938] [D loss: 0.618402] [G loss: 0.066298]\n",
            "[Epoch 25/200] [Batch 937/938] [D loss: 0.612060] [G loss: 0.080376]\n",
            "[Epoch 26/200] [Batch 0/938] [D loss: 0.595806] [G loss: 0.072531]\n",
            "[Epoch 26/200] [Batch 1/938] [D loss: 0.662802] [G loss: 0.080903]\n",
            "[Epoch 26/200] [Batch 2/938] [D loss: 0.625268] [G loss: 0.070837]\n",
            "[Epoch 26/200] [Batch 3/938] [D loss: 0.641213] [G loss: 0.073627]\n",
            "[Epoch 26/200] [Batch 4/938] [D loss: 0.626771] [G loss: 0.071630]\n",
            "[Epoch 26/200] [Batch 5/938] [D loss: 0.662540] [G loss: 0.071833]\n",
            "[Epoch 26/200] [Batch 6/938] [D loss: 0.650580] [G loss: 0.075888]\n",
            "[Epoch 26/200] [Batch 7/938] [D loss: 0.666678] [G loss: 0.066131]\n",
            "[Epoch 26/200] [Batch 8/938] [D loss: 0.623479] [G loss: 0.078104]\n",
            "[Epoch 26/200] [Batch 9/938] [D loss: 0.647507] [G loss: 0.064092]\n",
            "[Epoch 26/200] [Batch 10/938] [D loss: 0.649048] [G loss: 0.072182]\n",
            "[Epoch 26/200] [Batch 11/938] [D loss: 0.636308] [G loss: 0.064311]\n",
            "[Epoch 26/200] [Batch 12/938] [D loss: 0.652935] [G loss: 0.065895]\n",
            "[Epoch 26/200] [Batch 13/938] [D loss: 0.596002] [G loss: 0.072772]\n",
            "[Epoch 26/200] [Batch 14/938] [D loss: 0.587142] [G loss: 0.075639]\n",
            "[Epoch 26/200] [Batch 15/938] [D loss: 0.660606] [G loss: 0.080048]\n",
            "[Epoch 26/200] [Batch 16/938] [D loss: 0.624463] [G loss: 0.076754]\n",
            "[Epoch 26/200] [Batch 17/938] [D loss: 0.659353] [G loss: 0.067295]\n",
            "[Epoch 26/200] [Batch 18/938] [D loss: 0.661017] [G loss: 0.072529]\n",
            "[Epoch 26/200] [Batch 19/938] [D loss: 0.658662] [G loss: 0.072196]\n",
            "[Epoch 26/200] [Batch 20/938] [D loss: 0.650077] [G loss: 0.069051]\n",
            "[Epoch 26/200] [Batch 21/938] [D loss: 0.662519] [G loss: 0.072494]\n",
            "[Epoch 26/200] [Batch 22/938] [D loss: 0.647150] [G loss: 0.069982]\n",
            "[Epoch 26/200] [Batch 23/938] [D loss: 0.634314] [G loss: 0.068913]\n",
            "[Epoch 26/200] [Batch 24/938] [D loss: 0.629164] [G loss: 0.074740]\n",
            "[Epoch 26/200] [Batch 25/938] [D loss: 0.637612] [G loss: 0.070177]\n",
            "[Epoch 26/200] [Batch 26/938] [D loss: 0.649092] [G loss: 0.075003]\n",
            "[Epoch 26/200] [Batch 27/938] [D loss: 0.627036] [G loss: 0.077698]\n",
            "[Epoch 26/200] [Batch 28/938] [D loss: 0.671404] [G loss: 0.072754]\n",
            "[Epoch 26/200] [Batch 29/938] [D loss: 0.666375] [G loss: 0.069310]\n",
            "[Epoch 26/200] [Batch 30/938] [D loss: 0.655260] [G loss: 0.076212]\n",
            "[Epoch 26/200] [Batch 31/938] [D loss: 0.677038] [G loss: 0.071389]\n",
            "[Epoch 26/200] [Batch 32/938] [D loss: 0.645938] [G loss: 0.067818]\n",
            "[Epoch 26/200] [Batch 33/938] [D loss: 0.650586] [G loss: 0.064749]\n",
            "[Epoch 26/200] [Batch 34/938] [D loss: 0.609321] [G loss: 0.070374]\n",
            "[Epoch 26/200] [Batch 35/938] [D loss: 0.653374] [G loss: 0.075466]\n",
            "[Epoch 26/200] [Batch 36/938] [D loss: 0.630237] [G loss: 0.069573]\n",
            "[Epoch 26/200] [Batch 37/938] [D loss: 0.618111] [G loss: 0.073878]\n",
            "[Epoch 26/200] [Batch 38/938] [D loss: 0.647648] [G loss: 0.082551]\n",
            "[Epoch 26/200] [Batch 39/938] [D loss: 0.672027] [G loss: 0.071473]\n",
            "[Epoch 26/200] [Batch 40/938] [D loss: 0.648136] [G loss: 0.072180]\n",
            "[Epoch 26/200] [Batch 41/938] [D loss: 0.612295] [G loss: 0.074821]\n",
            "[Epoch 26/200] [Batch 42/938] [D loss: 0.625970] [G loss: 0.083760]\n",
            "[Epoch 26/200] [Batch 43/938] [D loss: 0.624297] [G loss: 0.066140]\n",
            "[Epoch 26/200] [Batch 44/938] [D loss: 0.657414] [G loss: 0.072941]\n",
            "[Epoch 26/200] [Batch 45/938] [D loss: 0.649800] [G loss: 0.072352]\n",
            "[Epoch 26/200] [Batch 46/938] [D loss: 0.624751] [G loss: 0.070906]\n",
            "[Epoch 26/200] [Batch 47/938] [D loss: 0.632978] [G loss: 0.071015]\n",
            "[Epoch 26/200] [Batch 48/938] [D loss: 0.642255] [G loss: 0.066421]\n",
            "[Epoch 26/200] [Batch 49/938] [D loss: 0.658510] [G loss: 0.067447]\n",
            "[Epoch 26/200] [Batch 50/938] [D loss: 0.650954] [G loss: 0.070850]\n",
            "[Epoch 26/200] [Batch 51/938] [D loss: 0.606857] [G loss: 0.082077]\n",
            "[Epoch 26/200] [Batch 52/938] [D loss: 0.615490] [G loss: 0.073861]\n",
            "[Epoch 26/200] [Batch 53/938] [D loss: 0.663894] [G loss: 0.074494]\n",
            "[Epoch 26/200] [Batch 54/938] [D loss: 0.688618] [G loss: 0.071382]\n",
            "[Epoch 26/200] [Batch 55/938] [D loss: 0.630171] [G loss: 0.071242]\n",
            "[Epoch 26/200] [Batch 56/938] [D loss: 0.650534] [G loss: 0.078157]\n",
            "[Epoch 26/200] [Batch 57/938] [D loss: 0.606877] [G loss: 0.069406]\n",
            "[Epoch 26/200] [Batch 58/938] [D loss: 0.665434] [G loss: 0.070840]\n",
            "[Epoch 26/200] [Batch 59/938] [D loss: 0.651951] [G loss: 0.075025]\n",
            "[Epoch 26/200] [Batch 60/938] [D loss: 0.659765] [G loss: 0.068644]\n",
            "[Epoch 26/200] [Batch 61/938] [D loss: 0.632500] [G loss: 0.078710]\n",
            "[Epoch 26/200] [Batch 62/938] [D loss: 0.663613] [G loss: 0.067872]\n",
            "[Epoch 26/200] [Batch 63/938] [D loss: 0.648018] [G loss: 0.071448]\n",
            "[Epoch 26/200] [Batch 64/938] [D loss: 0.638128] [G loss: 0.075400]\n",
            "[Epoch 26/200] [Batch 65/938] [D loss: 0.584969] [G loss: 0.073716]\n",
            "[Epoch 26/200] [Batch 66/938] [D loss: 0.619524] [G loss: 0.083462]\n",
            "[Epoch 26/200] [Batch 67/938] [D loss: 0.646392] [G loss: 0.070952]\n",
            "[Epoch 26/200] [Batch 68/938] [D loss: 0.625332] [G loss: 0.074330]\n",
            "[Epoch 26/200] [Batch 69/938] [D loss: 0.682592] [G loss: 0.067104]\n",
            "[Epoch 26/200] [Batch 70/938] [D loss: 0.668835] [G loss: 0.075617]\n",
            "[Epoch 26/200] [Batch 71/938] [D loss: 0.645397] [G loss: 0.080718]\n",
            "[Epoch 26/200] [Batch 72/938] [D loss: 0.655452] [G loss: 0.073578]\n",
            "[Epoch 26/200] [Batch 73/938] [D loss: 0.643124] [G loss: 0.071349]\n",
            "[Epoch 26/200] [Batch 74/938] [D loss: 0.638415] [G loss: 0.072656]\n",
            "[Epoch 26/200] [Batch 75/938] [D loss: 0.642291] [G loss: 0.075670]\n",
            "[Epoch 26/200] [Batch 76/938] [D loss: 0.605775] [G loss: 0.071462]\n",
            "[Epoch 26/200] [Batch 77/938] [D loss: 0.622683] [G loss: 0.072311]\n",
            "[Epoch 26/200] [Batch 78/938] [D loss: 0.599052] [G loss: 0.071585]\n",
            "[Epoch 26/200] [Batch 79/938] [D loss: 0.648527] [G loss: 0.073274]\n",
            "[Epoch 26/200] [Batch 80/938] [D loss: 0.635165] [G loss: 0.072983]\n",
            "[Epoch 26/200] [Batch 81/938] [D loss: 0.659949] [G loss: 0.072187]\n",
            "[Epoch 26/200] [Batch 82/938] [D loss: 0.641195] [G loss: 0.072284]\n",
            "[Epoch 26/200] [Batch 83/938] [D loss: 0.679964] [G loss: 0.072097]\n",
            "[Epoch 26/200] [Batch 84/938] [D loss: 0.655804] [G loss: 0.077544]\n",
            "[Epoch 26/200] [Batch 85/938] [D loss: 0.665115] [G loss: 0.079701]\n",
            "[Epoch 26/200] [Batch 86/938] [D loss: 0.639709] [G loss: 0.071363]\n",
            "[Epoch 26/200] [Batch 87/938] [D loss: 0.657460] [G loss: 0.072503]\n",
            "[Epoch 26/200] [Batch 88/938] [D loss: 0.652408] [G loss: 0.067494]\n",
            "[Epoch 26/200] [Batch 89/938] [D loss: 0.670104] [G loss: 0.073780]\n",
            "[Epoch 26/200] [Batch 90/938] [D loss: 0.656735] [G loss: 0.080505]\n",
            "[Epoch 26/200] [Batch 91/938] [D loss: 0.626870] [G loss: 0.076282]\n",
            "[Epoch 26/200] [Batch 92/938] [D loss: 0.643188] [G loss: 0.067387]\n",
            "[Epoch 26/200] [Batch 93/938] [D loss: 0.658192] [G loss: 0.075842]\n",
            "[Epoch 26/200] [Batch 94/938] [D loss: 0.644515] [G loss: 0.070372]\n",
            "[Epoch 26/200] [Batch 95/938] [D loss: 0.609262] [G loss: 0.076735]\n",
            "[Epoch 26/200] [Batch 96/938] [D loss: 0.622091] [G loss: 0.067327]\n",
            "[Epoch 26/200] [Batch 97/938] [D loss: 0.597876] [G loss: 0.075526]\n",
            "[Epoch 26/200] [Batch 98/938] [D loss: 0.642023] [G loss: 0.062520]\n",
            "[Epoch 26/200] [Batch 99/938] [D loss: 0.631338] [G loss: 0.073812]\n",
            "[Epoch 26/200] [Batch 100/938] [D loss: 0.635761] [G loss: 0.074609]\n",
            "[Epoch 26/200] [Batch 101/938] [D loss: 0.657692] [G loss: 0.069696]\n",
            "[Epoch 26/200] [Batch 102/938] [D loss: 0.641122] [G loss: 0.069868]\n",
            "[Epoch 26/200] [Batch 103/938] [D loss: 0.643202] [G loss: 0.072184]\n",
            "[Epoch 26/200] [Batch 104/938] [D loss: 0.642406] [G loss: 0.073811]\n",
            "[Epoch 26/200] [Batch 105/938] [D loss: 0.619877] [G loss: 0.072230]\n",
            "[Epoch 26/200] [Batch 106/938] [D loss: 0.616274] [G loss: 0.075256]\n",
            "[Epoch 26/200] [Batch 107/938] [D loss: 0.619850] [G loss: 0.078131]\n",
            "[Epoch 26/200] [Batch 108/938] [D loss: 0.638768] [G loss: 0.070997]\n",
            "[Epoch 26/200] [Batch 109/938] [D loss: 0.660812] [G loss: 0.072235]\n",
            "[Epoch 26/200] [Batch 110/938] [D loss: 0.628160] [G loss: 0.081319]\n",
            "[Epoch 26/200] [Batch 111/938] [D loss: 0.658328] [G loss: 0.075113]\n",
            "[Epoch 26/200] [Batch 112/938] [D loss: 0.619851] [G loss: 0.070751]\n",
            "[Epoch 26/200] [Batch 113/938] [D loss: 0.628793] [G loss: 0.068186]\n",
            "[Epoch 26/200] [Batch 114/938] [D loss: 0.640633] [G loss: 0.065163]\n",
            "[Epoch 26/200] [Batch 115/938] [D loss: 0.676708] [G loss: 0.079793]\n",
            "[Epoch 26/200] [Batch 116/938] [D loss: 0.651755] [G loss: 0.075780]\n",
            "[Epoch 26/200] [Batch 117/938] [D loss: 0.606870] [G loss: 0.061685]\n",
            "[Epoch 26/200] [Batch 118/938] [D loss: 0.609277] [G loss: 0.069711]\n",
            "[Epoch 26/200] [Batch 119/938] [D loss: 0.614926] [G loss: 0.070370]\n",
            "[Epoch 26/200] [Batch 120/938] [D loss: 0.660468] [G loss: 0.064758]\n",
            "[Epoch 26/200] [Batch 121/938] [D loss: 0.606761] [G loss: 0.072567]\n",
            "[Epoch 26/200] [Batch 122/938] [D loss: 0.657331] [G loss: 0.067049]\n",
            "[Epoch 26/200] [Batch 123/938] [D loss: 0.652022] [G loss: 0.068741]\n",
            "[Epoch 26/200] [Batch 124/938] [D loss: 0.635643] [G loss: 0.078891]\n",
            "[Epoch 26/200] [Batch 125/938] [D loss: 0.649904] [G loss: 0.073565]\n",
            "[Epoch 26/200] [Batch 126/938] [D loss: 0.658626] [G loss: 0.074487]\n",
            "[Epoch 26/200] [Batch 127/938] [D loss: 0.615554] [G loss: 0.071228]\n",
            "[Epoch 26/200] [Batch 128/938] [D loss: 0.631631] [G loss: 0.076622]\n",
            "[Epoch 26/200] [Batch 129/938] [D loss: 0.630865] [G loss: 0.069733]\n",
            "[Epoch 26/200] [Batch 130/938] [D loss: 0.649124] [G loss: 0.077914]\n",
            "[Epoch 26/200] [Batch 131/938] [D loss: 0.626930] [G loss: 0.066693]\n",
            "[Epoch 26/200] [Batch 132/938] [D loss: 0.623194] [G loss: 0.070083]\n",
            "[Epoch 26/200] [Batch 133/938] [D loss: 0.678554] [G loss: 0.086937]\n",
            "[Epoch 26/200] [Batch 134/938] [D loss: 0.648265] [G loss: 0.072888]\n",
            "[Epoch 26/200] [Batch 135/938] [D loss: 0.616164] [G loss: 0.075793]\n",
            "[Epoch 26/200] [Batch 136/938] [D loss: 0.663962] [G loss: 0.075504]\n",
            "[Epoch 26/200] [Batch 137/938] [D loss: 0.617521] [G loss: 0.072517]\n",
            "[Epoch 26/200] [Batch 138/938] [D loss: 0.638190] [G loss: 0.072963]\n",
            "[Epoch 26/200] [Batch 139/938] [D loss: 0.673520] [G loss: 0.072069]\n",
            "[Epoch 26/200] [Batch 140/938] [D loss: 0.637827] [G loss: 0.070752]\n",
            "[Epoch 26/200] [Batch 141/938] [D loss: 0.660916] [G loss: 0.075401]\n",
            "[Epoch 26/200] [Batch 142/938] [D loss: 0.632405] [G loss: 0.068990]\n",
            "[Epoch 26/200] [Batch 143/938] [D loss: 0.654785] [G loss: 0.067502]\n",
            "[Epoch 26/200] [Batch 144/938] [D loss: 0.624184] [G loss: 0.076361]\n",
            "[Epoch 26/200] [Batch 145/938] [D loss: 0.644383] [G loss: 0.070213]\n",
            "[Epoch 26/200] [Batch 146/938] [D loss: 0.605030] [G loss: 0.074480]\n",
            "[Epoch 26/200] [Batch 147/938] [D loss: 0.633866] [G loss: 0.071995]\n",
            "[Epoch 26/200] [Batch 148/938] [D loss: 0.632656] [G loss: 0.075504]\n",
            "[Epoch 26/200] [Batch 149/938] [D loss: 0.640378] [G loss: 0.074269]\n",
            "[Epoch 26/200] [Batch 150/938] [D loss: 0.626657] [G loss: 0.072289]\n",
            "[Epoch 26/200] [Batch 151/938] [D loss: 0.640721] [G loss: 0.062100]\n",
            "[Epoch 26/200] [Batch 152/938] [D loss: 0.591738] [G loss: 0.065365]\n",
            "[Epoch 26/200] [Batch 153/938] [D loss: 0.635944] [G loss: 0.067469]\n",
            "[Epoch 26/200] [Batch 154/938] [D loss: 0.614862] [G loss: 0.073891]\n",
            "[Epoch 26/200] [Batch 155/938] [D loss: 0.665463] [G loss: 0.072803]\n",
            "[Epoch 26/200] [Batch 156/938] [D loss: 0.630500] [G loss: 0.067496]\n",
            "[Epoch 26/200] [Batch 157/938] [D loss: 0.615548] [G loss: 0.072718]\n",
            "[Epoch 26/200] [Batch 158/938] [D loss: 0.595625] [G loss: 0.075515]\n",
            "[Epoch 26/200] [Batch 159/938] [D loss: 0.672236] [G loss: 0.076200]\n",
            "[Epoch 26/200] [Batch 160/938] [D loss: 0.660680] [G loss: 0.072261]\n",
            "[Epoch 26/200] [Batch 161/938] [D loss: 0.655885] [G loss: 0.072296]\n",
            "[Epoch 26/200] [Batch 162/938] [D loss: 0.618810] [G loss: 0.074822]\n",
            "[Epoch 26/200] [Batch 163/938] [D loss: 0.669272] [G loss: 0.080062]\n",
            "[Epoch 26/200] [Batch 164/938] [D loss: 0.655517] [G loss: 0.072323]\n",
            "[Epoch 26/200] [Batch 165/938] [D loss: 0.643271] [G loss: 0.076221]\n",
            "[Epoch 26/200] [Batch 166/938] [D loss: 0.662622] [G loss: 0.071935]\n",
            "[Epoch 26/200] [Batch 167/938] [D loss: 0.662400] [G loss: 0.070138]\n",
            "[Epoch 26/200] [Batch 168/938] [D loss: 0.627382] [G loss: 0.068254]\n",
            "[Epoch 26/200] [Batch 169/938] [D loss: 0.647279] [G loss: 0.065348]\n",
            "[Epoch 26/200] [Batch 170/938] [D loss: 0.636830] [G loss: 0.070638]\n",
            "[Epoch 26/200] [Batch 171/938] [D loss: 0.623856] [G loss: 0.073042]\n",
            "[Epoch 26/200] [Batch 172/938] [D loss: 0.638250] [G loss: 0.074547]\n",
            "[Epoch 26/200] [Batch 173/938] [D loss: 0.660628] [G loss: 0.079113]\n",
            "[Epoch 26/200] [Batch 174/938] [D loss: 0.647321] [G loss: 0.077583]\n",
            "[Epoch 26/200] [Batch 175/938] [D loss: 0.639978] [G loss: 0.068325]\n",
            "[Epoch 26/200] [Batch 176/938] [D loss: 0.621279] [G loss: 0.075872]\n",
            "[Epoch 26/200] [Batch 177/938] [D loss: 0.633808] [G loss: 0.073808]\n",
            "[Epoch 26/200] [Batch 178/938] [D loss: 0.611104] [G loss: 0.069061]\n",
            "[Epoch 26/200] [Batch 179/938] [D loss: 0.626048] [G loss: 0.067475]\n",
            "[Epoch 26/200] [Batch 180/938] [D loss: 0.606812] [G loss: 0.079666]\n",
            "[Epoch 26/200] [Batch 181/938] [D loss: 0.651840] [G loss: 0.071611]\n",
            "[Epoch 26/200] [Batch 182/938] [D loss: 0.635456] [G loss: 0.067725]\n",
            "[Epoch 26/200] [Batch 183/938] [D loss: 0.676779] [G loss: 0.072356]\n",
            "[Epoch 26/200] [Batch 184/938] [D loss: 0.644825] [G loss: 0.074624]\n",
            "[Epoch 26/200] [Batch 185/938] [D loss: 0.635275] [G loss: 0.064522]\n",
            "[Epoch 26/200] [Batch 186/938] [D loss: 0.636954] [G loss: 0.068505]\n",
            "[Epoch 26/200] [Batch 187/938] [D loss: 0.635612] [G loss: 0.078568]\n",
            "[Epoch 26/200] [Batch 188/938] [D loss: 0.629632] [G loss: 0.060631]\n",
            "[Epoch 26/200] [Batch 189/938] [D loss: 0.587220] [G loss: 0.069896]\n",
            "[Epoch 26/200] [Batch 190/938] [D loss: 0.595531] [G loss: 0.078488]\n",
            "[Epoch 26/200] [Batch 191/938] [D loss: 0.621436] [G loss: 0.070939]\n",
            "[Epoch 26/200] [Batch 192/938] [D loss: 0.657791] [G loss: 0.069618]\n",
            "[Epoch 26/200] [Batch 193/938] [D loss: 0.612496] [G loss: 0.068681]\n",
            "[Epoch 26/200] [Batch 194/938] [D loss: 0.639429] [G loss: 0.066932]\n",
            "[Epoch 26/200] [Batch 195/938] [D loss: 0.628553] [G loss: 0.076673]\n",
            "[Epoch 26/200] [Batch 196/938] [D loss: 0.629894] [G loss: 0.070187]\n",
            "[Epoch 26/200] [Batch 197/938] [D loss: 0.623391] [G loss: 0.073388]\n",
            "[Epoch 26/200] [Batch 198/938] [D loss: 0.626145] [G loss: 0.072290]\n",
            "[Epoch 26/200] [Batch 199/938] [D loss: 0.651747] [G loss: 0.068329]\n",
            "[Epoch 26/200] [Batch 200/938] [D loss: 0.640240] [G loss: 0.070449]\n",
            "[Epoch 26/200] [Batch 201/938] [D loss: 0.658287] [G loss: 0.072533]\n",
            "[Epoch 26/200] [Batch 202/938] [D loss: 0.642078] [G loss: 0.079549]\n",
            "[Epoch 26/200] [Batch 203/938] [D loss: 0.630748] [G loss: 0.076004]\n",
            "[Epoch 26/200] [Batch 204/938] [D loss: 0.619824] [G loss: 0.073647]\n",
            "[Epoch 26/200] [Batch 205/938] [D loss: 0.655879] [G loss: 0.071655]\n",
            "[Epoch 26/200] [Batch 206/938] [D loss: 0.671886] [G loss: 0.074968]\n",
            "[Epoch 26/200] [Batch 207/938] [D loss: 0.608774] [G loss: 0.072363]\n",
            "[Epoch 26/200] [Batch 208/938] [D loss: 0.654477] [G loss: 0.070509]\n",
            "[Epoch 26/200] [Batch 209/938] [D loss: 0.665873] [G loss: 0.074791]\n",
            "[Epoch 26/200] [Batch 210/938] [D loss: 0.631155] [G loss: 0.070822]\n",
            "[Epoch 26/200] [Batch 211/938] [D loss: 0.617457] [G loss: 0.069455]\n",
            "[Epoch 26/200] [Batch 212/938] [D loss: 0.621169] [G loss: 0.072179]\n",
            "[Epoch 26/200] [Batch 213/938] [D loss: 0.652413] [G loss: 0.071795]\n",
            "[Epoch 26/200] [Batch 214/938] [D loss: 0.643889] [G loss: 0.070811]\n",
            "[Epoch 26/200] [Batch 215/938] [D loss: 0.649778] [G loss: 0.074927]\n",
            "[Epoch 26/200] [Batch 216/938] [D loss: 0.620284] [G loss: 0.069818]\n",
            "[Epoch 26/200] [Batch 217/938] [D loss: 0.644406] [G loss: 0.069659]\n",
            "[Epoch 26/200] [Batch 218/938] [D loss: 0.611991] [G loss: 0.074431]\n",
            "[Epoch 26/200] [Batch 219/938] [D loss: 0.640996] [G loss: 0.073897]\n",
            "[Epoch 26/200] [Batch 220/938] [D loss: 0.641193] [G loss: 0.078282]\n",
            "[Epoch 26/200] [Batch 221/938] [D loss: 0.620346] [G loss: 0.071578]\n",
            "[Epoch 26/200] [Batch 222/938] [D loss: 0.607779] [G loss: 0.075497]\n",
            "[Epoch 26/200] [Batch 223/938] [D loss: 0.632330] [G loss: 0.074654]\n",
            "[Epoch 26/200] [Batch 224/938] [D loss: 0.616028] [G loss: 0.079249]\n",
            "[Epoch 26/200] [Batch 225/938] [D loss: 0.655465] [G loss: 0.073621]\n",
            "[Epoch 26/200] [Batch 226/938] [D loss: 0.647307] [G loss: 0.075800]\n",
            "[Epoch 26/200] [Batch 227/938] [D loss: 0.662505] [G loss: 0.073385]\n",
            "[Epoch 26/200] [Batch 228/938] [D loss: 0.629952] [G loss: 0.077730]\n",
            "[Epoch 26/200] [Batch 229/938] [D loss: 0.674959] [G loss: 0.075030]\n",
            "[Epoch 26/200] [Batch 230/938] [D loss: 0.582351] [G loss: 0.074192]\n",
            "[Epoch 26/200] [Batch 231/938] [D loss: 0.603637] [G loss: 0.072948]\n",
            "[Epoch 26/200] [Batch 232/938] [D loss: 0.675535] [G loss: 0.072872]\n",
            "[Epoch 26/200] [Batch 233/938] [D loss: 0.663536] [G loss: 0.072664]\n",
            "[Epoch 26/200] [Batch 234/938] [D loss: 0.638007] [G loss: 0.071905]\n",
            "[Epoch 26/200] [Batch 235/938] [D loss: 0.603930] [G loss: 0.076902]\n",
            "[Epoch 26/200] [Batch 236/938] [D loss: 0.611488] [G loss: 0.071982]\n",
            "[Epoch 26/200] [Batch 237/938] [D loss: 0.654005] [G loss: 0.073577]\n",
            "[Epoch 26/200] [Batch 238/938] [D loss: 0.677875] [G loss: 0.072706]\n",
            "[Epoch 26/200] [Batch 239/938] [D loss: 0.621285] [G loss: 0.068172]\n",
            "[Epoch 26/200] [Batch 240/938] [D loss: 0.594488] [G loss: 0.076588]\n",
            "[Epoch 26/200] [Batch 241/938] [D loss: 0.649872] [G loss: 0.071114]\n",
            "[Epoch 26/200] [Batch 242/938] [D loss: 0.630953] [G loss: 0.076272]\n",
            "[Epoch 26/200] [Batch 243/938] [D loss: 0.618966] [G loss: 0.082777]\n",
            "[Epoch 26/200] [Batch 244/938] [D loss: 0.622471] [G loss: 0.072711]\n",
            "[Epoch 26/200] [Batch 245/938] [D loss: 0.635035] [G loss: 0.071000]\n",
            "[Epoch 26/200] [Batch 246/938] [D loss: 0.629529] [G loss: 0.065864]\n",
            "[Epoch 26/200] [Batch 247/938] [D loss: 0.657137] [G loss: 0.070498]\n",
            "[Epoch 26/200] [Batch 248/938] [D loss: 0.643190] [G loss: 0.071069]\n",
            "[Epoch 26/200] [Batch 249/938] [D loss: 0.631330] [G loss: 0.078308]\n",
            "[Epoch 26/200] [Batch 250/938] [D loss: 0.635921] [G loss: 0.069631]\n",
            "[Epoch 26/200] [Batch 251/938] [D loss: 0.605070] [G loss: 0.077944]\n",
            "[Epoch 26/200] [Batch 252/938] [D loss: 0.644114] [G loss: 0.076360]\n",
            "[Epoch 26/200] [Batch 253/938] [D loss: 0.668211] [G loss: 0.074758]\n",
            "[Epoch 26/200] [Batch 254/938] [D loss: 0.625623] [G loss: 0.073367]\n",
            "[Epoch 26/200] [Batch 255/938] [D loss: 0.674325] [G loss: 0.066024]\n",
            "[Epoch 26/200] [Batch 256/938] [D loss: 0.605246] [G loss: 0.069983]\n",
            "[Epoch 26/200] [Batch 257/938] [D loss: 0.671299] [G loss: 0.076985]\n",
            "[Epoch 26/200] [Batch 258/938] [D loss: 0.654522] [G loss: 0.070535]\n",
            "[Epoch 26/200] [Batch 259/938] [D loss: 0.662711] [G loss: 0.075392]\n",
            "[Epoch 26/200] [Batch 260/938] [D loss: 0.638667] [G loss: 0.077568]\n",
            "[Epoch 26/200] [Batch 261/938] [D loss: 0.621475] [G loss: 0.069074]\n",
            "[Epoch 26/200] [Batch 262/938] [D loss: 0.669096] [G loss: 0.075253]\n",
            "[Epoch 26/200] [Batch 263/938] [D loss: 0.646227] [G loss: 0.063632]\n",
            "[Epoch 26/200] [Batch 264/938] [D loss: 0.643902] [G loss: 0.075327]\n",
            "[Epoch 26/200] [Batch 265/938] [D loss: 0.633046] [G loss: 0.069718]\n",
            "[Epoch 26/200] [Batch 266/938] [D loss: 0.652244] [G loss: 0.069997]\n",
            "[Epoch 26/200] [Batch 267/938] [D loss: 0.618618] [G loss: 0.077955]\n",
            "[Epoch 26/200] [Batch 268/938] [D loss: 0.628902] [G loss: 0.069943]\n",
            "[Epoch 26/200] [Batch 269/938] [D loss: 0.631738] [G loss: 0.071566]\n",
            "[Epoch 26/200] [Batch 270/938] [D loss: 0.632998] [G loss: 0.076788]\n",
            "[Epoch 26/200] [Batch 271/938] [D loss: 0.655472] [G loss: 0.072615]\n",
            "[Epoch 26/200] [Batch 272/938] [D loss: 0.667061] [G loss: 0.073615]\n",
            "[Epoch 26/200] [Batch 273/938] [D loss: 0.653815] [G loss: 0.080972]\n",
            "[Epoch 26/200] [Batch 274/938] [D loss: 0.664264] [G loss: 0.073820]\n",
            "[Epoch 26/200] [Batch 275/938] [D loss: 0.675978] [G loss: 0.067239]\n",
            "[Epoch 26/200] [Batch 276/938] [D loss: 0.601098] [G loss: 0.071438]\n",
            "[Epoch 26/200] [Batch 277/938] [D loss: 0.610392] [G loss: 0.072653]\n",
            "[Epoch 26/200] [Batch 278/938] [D loss: 0.628910] [G loss: 0.074633]\n",
            "[Epoch 26/200] [Batch 279/938] [D loss: 0.634914] [G loss: 0.072373]\n",
            "[Epoch 26/200] [Batch 280/938] [D loss: 0.655865] [G loss: 0.073648]\n",
            "[Epoch 26/200] [Batch 281/938] [D loss: 0.628714] [G loss: 0.065724]\n",
            "[Epoch 26/200] [Batch 282/938] [D loss: 0.655760] [G loss: 0.067241]\n",
            "[Epoch 26/200] [Batch 283/938] [D loss: 0.646128] [G loss: 0.075609]\n",
            "[Epoch 26/200] [Batch 284/938] [D loss: 0.644020] [G loss: 0.071023]\n",
            "[Epoch 26/200] [Batch 285/938] [D loss: 0.633812] [G loss: 0.073069]\n",
            "[Epoch 26/200] [Batch 286/938] [D loss: 0.659562] [G loss: 0.075920]\n",
            "[Epoch 26/200] [Batch 287/938] [D loss: 0.642061] [G loss: 0.072573]\n",
            "[Epoch 26/200] [Batch 288/938] [D loss: 0.644183] [G loss: 0.076665]\n",
            "[Epoch 26/200] [Batch 289/938] [D loss: 0.637493] [G loss: 0.071665]\n",
            "[Epoch 26/200] [Batch 290/938] [D loss: 0.621213] [G loss: 0.068268]\n",
            "[Epoch 26/200] [Batch 291/938] [D loss: 0.605221] [G loss: 0.075225]\n",
            "[Epoch 26/200] [Batch 292/938] [D loss: 0.655073] [G loss: 0.072625]\n",
            "[Epoch 26/200] [Batch 293/938] [D loss: 0.624683] [G loss: 0.070849]\n",
            "[Epoch 26/200] [Batch 294/938] [D loss: 0.628381] [G loss: 0.068418]\n",
            "[Epoch 26/200] [Batch 295/938] [D loss: 0.627450] [G loss: 0.069080]\n",
            "[Epoch 26/200] [Batch 296/938] [D loss: 0.617850] [G loss: 0.067712]\n",
            "[Epoch 26/200] [Batch 297/938] [D loss: 0.650206] [G loss: 0.069557]\n",
            "[Epoch 26/200] [Batch 298/938] [D loss: 0.625980] [G loss: 0.067989]\n",
            "[Epoch 26/200] [Batch 299/938] [D loss: 0.643514] [G loss: 0.072790]\n",
            "[Epoch 26/200] [Batch 300/938] [D loss: 0.584505] [G loss: 0.070226]\n",
            "[Epoch 26/200] [Batch 301/938] [D loss: 0.625277] [G loss: 0.067582]\n",
            "[Epoch 26/200] [Batch 302/938] [D loss: 0.641588] [G loss: 0.067537]\n",
            "[Epoch 26/200] [Batch 303/938] [D loss: 0.649073] [G loss: 0.067147]\n",
            "[Epoch 26/200] [Batch 304/938] [D loss: 0.612909] [G loss: 0.066839]\n",
            "[Epoch 26/200] [Batch 305/938] [D loss: 0.642113] [G loss: 0.065417]\n",
            "[Epoch 26/200] [Batch 306/938] [D loss: 0.660149] [G loss: 0.076433]\n",
            "[Epoch 26/200] [Batch 307/938] [D loss: 0.626329] [G loss: 0.069137]\n",
            "[Epoch 26/200] [Batch 308/938] [D loss: 0.617321] [G loss: 0.071222]\n",
            "[Epoch 26/200] [Batch 309/938] [D loss: 0.659236] [G loss: 0.067346]\n",
            "[Epoch 26/200] [Batch 310/938] [D loss: 0.603584] [G loss: 0.069219]\n",
            "[Epoch 26/200] [Batch 311/938] [D loss: 0.674836] [G loss: 0.068033]\n",
            "[Epoch 26/200] [Batch 312/938] [D loss: 0.649267] [G loss: 0.076224]\n",
            "[Epoch 26/200] [Batch 313/938] [D loss: 0.638502] [G loss: 0.080363]\n",
            "[Epoch 26/200] [Batch 314/938] [D loss: 0.624481] [G loss: 0.070031]\n",
            "[Epoch 26/200] [Batch 315/938] [D loss: 0.645976] [G loss: 0.070055]\n",
            "[Epoch 26/200] [Batch 316/938] [D loss: 0.642242] [G loss: 0.083981]\n",
            "[Epoch 26/200] [Batch 317/938] [D loss: 0.654904] [G loss: 0.080237]\n",
            "[Epoch 26/200] [Batch 318/938] [D loss: 0.610239] [G loss: 0.067085]\n",
            "[Epoch 26/200] [Batch 319/938] [D loss: 0.632974] [G loss: 0.067993]\n",
            "[Epoch 26/200] [Batch 320/938] [D loss: 0.624595] [G loss: 0.077665]\n",
            "[Epoch 26/200] [Batch 321/938] [D loss: 0.627134] [G loss: 0.070887]\n",
            "[Epoch 26/200] [Batch 322/938] [D loss: 0.609344] [G loss: 0.069163]\n",
            "[Epoch 26/200] [Batch 323/938] [D loss: 0.621042] [G loss: 0.065782]\n",
            "[Epoch 26/200] [Batch 324/938] [D loss: 0.633107] [G loss: 0.072275]\n",
            "[Epoch 26/200] [Batch 325/938] [D loss: 0.621235] [G loss: 0.075509]\n",
            "[Epoch 26/200] [Batch 326/938] [D loss: 0.641784] [G loss: 0.076666]\n",
            "[Epoch 26/200] [Batch 327/938] [D loss: 0.648776] [G loss: 0.071667]\n",
            "[Epoch 26/200] [Batch 328/938] [D loss: 0.668533] [G loss: 0.078123]\n",
            "[Epoch 26/200] [Batch 329/938] [D loss: 0.627231] [G loss: 0.072876]\n",
            "[Epoch 26/200] [Batch 330/938] [D loss: 0.608113] [G loss: 0.069747]\n",
            "[Epoch 26/200] [Batch 331/938] [D loss: 0.640305] [G loss: 0.070997]\n",
            "[Epoch 26/200] [Batch 332/938] [D loss: 0.615712] [G loss: 0.083874]\n",
            "[Epoch 26/200] [Batch 333/938] [D loss: 0.605034] [G loss: 0.073168]\n",
            "[Epoch 26/200] [Batch 334/938] [D loss: 0.667662] [G loss: 0.072389]\n",
            "[Epoch 26/200] [Batch 335/938] [D loss: 0.690585] [G loss: 0.070312]\n",
            "[Epoch 26/200] [Batch 336/938] [D loss: 0.610575] [G loss: 0.069669]\n",
            "[Epoch 26/200] [Batch 337/938] [D loss: 0.648858] [G loss: 0.068292]\n",
            "[Epoch 26/200] [Batch 338/938] [D loss: 0.646402] [G loss: 0.067622]\n",
            "[Epoch 26/200] [Batch 339/938] [D loss: 0.639758] [G loss: 0.071301]\n",
            "[Epoch 26/200] [Batch 340/938] [D loss: 0.622303] [G loss: 0.079859]\n",
            "[Epoch 26/200] [Batch 341/938] [D loss: 0.622049] [G loss: 0.068772]\n",
            "[Epoch 26/200] [Batch 342/938] [D loss: 0.646403] [G loss: 0.073552]\n",
            "[Epoch 26/200] [Batch 343/938] [D loss: 0.640624] [G loss: 0.076624]\n",
            "[Epoch 26/200] [Batch 344/938] [D loss: 0.644781] [G loss: 0.070355]\n",
            "[Epoch 26/200] [Batch 345/938] [D loss: 0.639371] [G loss: 0.076804]\n",
            "[Epoch 26/200] [Batch 346/938] [D loss: 0.619640] [G loss: 0.077435]\n",
            "[Epoch 26/200] [Batch 347/938] [D loss: 0.628414] [G loss: 0.071293]\n",
            "[Epoch 26/200] [Batch 348/938] [D loss: 0.644255] [G loss: 0.078116]\n",
            "[Epoch 26/200] [Batch 349/938] [D loss: 0.618835] [G loss: 0.070446]\n",
            "[Epoch 26/200] [Batch 350/938] [D loss: 0.593675] [G loss: 0.069107]\n",
            "[Epoch 26/200] [Batch 351/938] [D loss: 0.604350] [G loss: 0.068555]\n",
            "[Epoch 26/200] [Batch 352/938] [D loss: 0.652157] [G loss: 0.077001]\n",
            "[Epoch 26/200] [Batch 353/938] [D loss: 0.656759] [G loss: 0.074551]\n",
            "[Epoch 26/200] [Batch 354/938] [D loss: 0.602805] [G loss: 0.074516]\n",
            "[Epoch 26/200] [Batch 355/938] [D loss: 0.631200] [G loss: 0.071089]\n",
            "[Epoch 26/200] [Batch 356/938] [D loss: 0.633665] [G loss: 0.068583]\n",
            "[Epoch 26/200] [Batch 357/938] [D loss: 0.587060] [G loss: 0.080116]\n",
            "[Epoch 26/200] [Batch 358/938] [D loss: 0.624072] [G loss: 0.077358]\n",
            "[Epoch 26/200] [Batch 359/938] [D loss: 0.645899] [G loss: 0.083054]\n",
            "[Epoch 26/200] [Batch 360/938] [D loss: 0.623900] [G loss: 0.077864]\n",
            "[Epoch 26/200] [Batch 361/938] [D loss: 0.591361] [G loss: 0.078557]\n",
            "[Epoch 26/200] [Batch 362/938] [D loss: 0.635932] [G loss: 0.075103]\n",
            "[Epoch 26/200] [Batch 363/938] [D loss: 0.609586] [G loss: 0.077148]\n",
            "[Epoch 26/200] [Batch 364/938] [D loss: 0.650612] [G loss: 0.069463]\n",
            "[Epoch 26/200] [Batch 365/938] [D loss: 0.663882] [G loss: 0.071047]\n",
            "[Epoch 26/200] [Batch 366/938] [D loss: 0.639723] [G loss: 0.067336]\n",
            "[Epoch 26/200] [Batch 367/938] [D loss: 0.644695] [G loss: 0.077516]\n",
            "[Epoch 26/200] [Batch 368/938] [D loss: 0.619415] [G loss: 0.069985]\n",
            "[Epoch 26/200] [Batch 369/938] [D loss: 0.612439] [G loss: 0.073445]\n",
            "[Epoch 26/200] [Batch 370/938] [D loss: 0.644659] [G loss: 0.079322]\n",
            "[Epoch 26/200] [Batch 371/938] [D loss: 0.607701] [G loss: 0.074462]\n",
            "[Epoch 26/200] [Batch 372/938] [D loss: 0.629478] [G loss: 0.072164]\n",
            "[Epoch 26/200] [Batch 373/938] [D loss: 0.625986] [G loss: 0.073768]\n",
            "[Epoch 26/200] [Batch 374/938] [D loss: 0.646675] [G loss: 0.073286]\n",
            "[Epoch 26/200] [Batch 375/938] [D loss: 0.622040] [G loss: 0.068916]\n",
            "[Epoch 26/200] [Batch 376/938] [D loss: 0.652079] [G loss: 0.063561]\n",
            "[Epoch 26/200] [Batch 377/938] [D loss: 0.638445] [G loss: 0.073235]\n",
            "[Epoch 26/200] [Batch 378/938] [D loss: 0.631817] [G loss: 0.065913]\n",
            "[Epoch 26/200] [Batch 379/938] [D loss: 0.650074] [G loss: 0.069399]\n",
            "[Epoch 26/200] [Batch 380/938] [D loss: 0.687267] [G loss: 0.065448]\n",
            "[Epoch 26/200] [Batch 381/938] [D loss: 0.598306] [G loss: 0.080832]\n",
            "[Epoch 26/200] [Batch 382/938] [D loss: 0.628539] [G loss: 0.074192]\n",
            "[Epoch 26/200] [Batch 383/938] [D loss: 0.596947] [G loss: 0.071869]\n",
            "[Epoch 26/200] [Batch 384/938] [D loss: 0.623982] [G loss: 0.084378]\n",
            "[Epoch 26/200] [Batch 385/938] [D loss: 0.620273] [G loss: 0.071559]\n",
            "[Epoch 26/200] [Batch 386/938] [D loss: 0.643329] [G loss: 0.072767]\n",
            "[Epoch 26/200] [Batch 387/938] [D loss: 0.597664] [G loss: 0.067307]\n",
            "[Epoch 26/200] [Batch 388/938] [D loss: 0.576893] [G loss: 0.069688]\n",
            "[Epoch 26/200] [Batch 389/938] [D loss: 0.651533] [G loss: 0.072364]\n",
            "[Epoch 26/200] [Batch 390/938] [D loss: 0.646709] [G loss: 0.069119]\n",
            "[Epoch 26/200] [Batch 391/938] [D loss: 0.625061] [G loss: 0.069653]\n",
            "[Epoch 26/200] [Batch 392/938] [D loss: 0.640749] [G loss: 0.069402]\n",
            "[Epoch 26/200] [Batch 393/938] [D loss: 0.639024] [G loss: 0.069390]\n",
            "[Epoch 26/200] [Batch 394/938] [D loss: 0.632914] [G loss: 0.073487]\n",
            "[Epoch 26/200] [Batch 395/938] [D loss: 0.689818] [G loss: 0.074980]\n",
            "[Epoch 26/200] [Batch 396/938] [D loss: 0.631130] [G loss: 0.074548]\n",
            "[Epoch 26/200] [Batch 397/938] [D loss: 0.658255] [G loss: 0.077629]\n",
            "[Epoch 26/200] [Batch 398/938] [D loss: 0.608336] [G loss: 0.065835]\n",
            "[Epoch 26/200] [Batch 399/938] [D loss: 0.627650] [G loss: 0.069023]\n",
            "[Epoch 26/200] [Batch 400/938] [D loss: 0.616732] [G loss: 0.069458]\n",
            "[Epoch 26/200] [Batch 401/938] [D loss: 0.622916] [G loss: 0.075812]\n",
            "[Epoch 26/200] [Batch 402/938] [D loss: 0.643777] [G loss: 0.072447]\n",
            "[Epoch 26/200] [Batch 403/938] [D loss: 0.602172] [G loss: 0.071434]\n",
            "[Epoch 26/200] [Batch 404/938] [D loss: 0.664592] [G loss: 0.067349]\n",
            "[Epoch 26/200] [Batch 405/938] [D loss: 0.648328] [G loss: 0.077843]\n",
            "[Epoch 26/200] [Batch 406/938] [D loss: 0.610657] [G loss: 0.068413]\n",
            "[Epoch 26/200] [Batch 407/938] [D loss: 0.650912] [G loss: 0.076075]\n",
            "[Epoch 26/200] [Batch 408/938] [D loss: 0.654222] [G loss: 0.070095]\n",
            "[Epoch 26/200] [Batch 409/938] [D loss: 0.641250] [G loss: 0.071051]\n",
            "[Epoch 26/200] [Batch 410/938] [D loss: 0.628179] [G loss: 0.067852]\n",
            "[Epoch 26/200] [Batch 411/938] [D loss: 0.599657] [G loss: 0.078919]\n",
            "[Epoch 26/200] [Batch 412/938] [D loss: 0.634190] [G loss: 0.070262]\n",
            "[Epoch 26/200] [Batch 413/938] [D loss: 0.625147] [G loss: 0.070417]\n",
            "[Epoch 26/200] [Batch 414/938] [D loss: 0.637276] [G loss: 0.073420]\n",
            "[Epoch 26/200] [Batch 415/938] [D loss: 0.659158] [G loss: 0.075216]\n",
            "[Epoch 26/200] [Batch 416/938] [D loss: 0.623350] [G loss: 0.070791]\n",
            "[Epoch 26/200] [Batch 417/938] [D loss: 0.629550] [G loss: 0.078560]\n",
            "[Epoch 26/200] [Batch 418/938] [D loss: 0.633468] [G loss: 0.066018]\n",
            "[Epoch 26/200] [Batch 419/938] [D loss: 0.670402] [G loss: 0.075074]\n",
            "[Epoch 26/200] [Batch 420/938] [D loss: 0.640452] [G loss: 0.080434]\n",
            "[Epoch 26/200] [Batch 421/938] [D loss: 0.635327] [G loss: 0.074368]\n",
            "[Epoch 26/200] [Batch 422/938] [D loss: 0.661291] [G loss: 0.077266]\n",
            "[Epoch 26/200] [Batch 423/938] [D loss: 0.651333] [G loss: 0.073824]\n",
            "[Epoch 26/200] [Batch 424/938] [D loss: 0.634739] [G loss: 0.069562]\n",
            "[Epoch 26/200] [Batch 425/938] [D loss: 0.631757] [G loss: 0.071076]\n",
            "[Epoch 26/200] [Batch 426/938] [D loss: 0.633670] [G loss: 0.072973]\n",
            "[Epoch 26/200] [Batch 427/938] [D loss: 0.572200] [G loss: 0.076434]\n",
            "[Epoch 26/200] [Batch 428/938] [D loss: 0.653767] [G loss: 0.067037]\n",
            "[Epoch 26/200] [Batch 429/938] [D loss: 0.629555] [G loss: 0.077676]\n",
            "[Epoch 26/200] [Batch 430/938] [D loss: 0.604124] [G loss: 0.071123]\n",
            "[Epoch 26/200] [Batch 431/938] [D loss: 0.660890] [G loss: 0.074009]\n",
            "[Epoch 26/200] [Batch 432/938] [D loss: 0.646856] [G loss: 0.076260]\n",
            "[Epoch 26/200] [Batch 433/938] [D loss: 0.638200] [G loss: 0.068764]\n",
            "[Epoch 26/200] [Batch 434/938] [D loss: 0.696100] [G loss: 0.071351]\n",
            "[Epoch 26/200] [Batch 435/938] [D loss: 0.661318] [G loss: 0.078001]\n",
            "[Epoch 26/200] [Batch 436/938] [D loss: 0.650690] [G loss: 0.071323]\n",
            "[Epoch 26/200] [Batch 437/938] [D loss: 0.629318] [G loss: 0.079146]\n",
            "[Epoch 26/200] [Batch 438/938] [D loss: 0.636436] [G loss: 0.072470]\n",
            "[Epoch 26/200] [Batch 439/938] [D loss: 0.635098] [G loss: 0.078249]\n",
            "[Epoch 26/200] [Batch 440/938] [D loss: 0.657295] [G loss: 0.074792]\n",
            "[Epoch 26/200] [Batch 441/938] [D loss: 0.634467] [G loss: 0.071530]\n",
            "[Epoch 26/200] [Batch 442/938] [D loss: 0.617571] [G loss: 0.069519]\n",
            "[Epoch 26/200] [Batch 443/938] [D loss: 0.623093] [G loss: 0.077087]\n",
            "[Epoch 26/200] [Batch 444/938] [D loss: 0.603335] [G loss: 0.067524]\n",
            "[Epoch 26/200] [Batch 445/938] [D loss: 0.638436] [G loss: 0.069114]\n",
            "[Epoch 26/200] [Batch 446/938] [D loss: 0.616876] [G loss: 0.070344]\n",
            "[Epoch 26/200] [Batch 447/938] [D loss: 0.602819] [G loss: 0.076032]\n",
            "[Epoch 26/200] [Batch 448/938] [D loss: 0.617784] [G loss: 0.071951]\n",
            "[Epoch 26/200] [Batch 449/938] [D loss: 0.614124] [G loss: 0.072195]\n",
            "[Epoch 26/200] [Batch 450/938] [D loss: 0.615870] [G loss: 0.075281]\n",
            "[Epoch 26/200] [Batch 451/938] [D loss: 0.603918] [G loss: 0.076144]\n",
            "[Epoch 26/200] [Batch 452/938] [D loss: 0.690707] [G loss: 0.085413]\n",
            "[Epoch 26/200] [Batch 453/938] [D loss: 0.626596] [G loss: 0.076609]\n",
            "[Epoch 26/200] [Batch 454/938] [D loss: 0.608758] [G loss: 0.074879]\n",
            "[Epoch 26/200] [Batch 455/938] [D loss: 0.643294] [G loss: 0.072164]\n",
            "[Epoch 26/200] [Batch 456/938] [D loss: 0.634287] [G loss: 0.081265]\n",
            "[Epoch 26/200] [Batch 457/938] [D loss: 0.664380] [G loss: 0.070354]\n",
            "[Epoch 26/200] [Batch 458/938] [D loss: 0.641005] [G loss: 0.070590]\n",
            "[Epoch 26/200] [Batch 459/938] [D loss: 0.652517] [G loss: 0.068650]\n",
            "[Epoch 26/200] [Batch 460/938] [D loss: 0.631651] [G loss: 0.069087]\n",
            "[Epoch 26/200] [Batch 461/938] [D loss: 0.627791] [G loss: 0.069033]\n",
            "[Epoch 26/200] [Batch 462/938] [D loss: 0.668013] [G loss: 0.071710]\n",
            "[Epoch 26/200] [Batch 463/938] [D loss: 0.604053] [G loss: 0.068785]\n",
            "[Epoch 26/200] [Batch 464/938] [D loss: 0.615641] [G loss: 0.078987]\n",
            "[Epoch 26/200] [Batch 465/938] [D loss: 0.651114] [G loss: 0.068884]\n",
            "[Epoch 26/200] [Batch 466/938] [D loss: 0.669904] [G loss: 0.066639]\n",
            "[Epoch 26/200] [Batch 467/938] [D loss: 0.638382] [G loss: 0.071867]\n",
            "[Epoch 26/200] [Batch 468/938] [D loss: 0.622949] [G loss: 0.072945]\n",
            "[Epoch 26/200] [Batch 469/938] [D loss: 0.626422] [G loss: 0.068962]\n",
            "[Epoch 26/200] [Batch 470/938] [D loss: 0.605790] [G loss: 0.078949]\n",
            "[Epoch 26/200] [Batch 471/938] [D loss: 0.639299] [G loss: 0.073421]\n",
            "[Epoch 26/200] [Batch 472/938] [D loss: 0.614801] [G loss: 0.067311]\n",
            "[Epoch 26/200] [Batch 473/938] [D loss: 0.635710] [G loss: 0.070536]\n",
            "[Epoch 26/200] [Batch 474/938] [D loss: 0.623004] [G loss: 0.072157]\n",
            "[Epoch 26/200] [Batch 475/938] [D loss: 0.637938] [G loss: 0.079720]\n",
            "[Epoch 26/200] [Batch 476/938] [D loss: 0.627807] [G loss: 0.071155]\n",
            "[Epoch 26/200] [Batch 477/938] [D loss: 0.616956] [G loss: 0.068477]\n",
            "[Epoch 26/200] [Batch 478/938] [D loss: 0.672234] [G loss: 0.072212]\n",
            "[Epoch 26/200] [Batch 479/938] [D loss: 0.624579] [G loss: 0.071854]\n",
            "[Epoch 26/200] [Batch 480/938] [D loss: 0.649108] [G loss: 0.070045]\n",
            "[Epoch 26/200] [Batch 481/938] [D loss: 0.636492] [G loss: 0.074029]\n",
            "[Epoch 26/200] [Batch 482/938] [D loss: 0.591791] [G loss: 0.067644]\n",
            "[Epoch 26/200] [Batch 483/938] [D loss: 0.615519] [G loss: 0.071203]\n",
            "[Epoch 26/200] [Batch 484/938] [D loss: 0.615521] [G loss: 0.067008]\n",
            "[Epoch 26/200] [Batch 485/938] [D loss: 0.622782] [G loss: 0.071618]\n",
            "[Epoch 26/200] [Batch 486/938] [D loss: 0.622535] [G loss: 0.067480]\n",
            "[Epoch 26/200] [Batch 487/938] [D loss: 0.625402] [G loss: 0.077730]\n",
            "[Epoch 26/200] [Batch 488/938] [D loss: 0.619813] [G loss: 0.069716]\n",
            "[Epoch 26/200] [Batch 489/938] [D loss: 0.654811] [G loss: 0.073741]\n",
            "[Epoch 26/200] [Batch 490/938] [D loss: 0.651224] [G loss: 0.078540]\n",
            "[Epoch 26/200] [Batch 491/938] [D loss: 0.615574] [G loss: 0.066804]\n",
            "[Epoch 26/200] [Batch 492/938] [D loss: 0.645621] [G loss: 0.072681]\n",
            "[Epoch 26/200] [Batch 493/938] [D loss: 0.644817] [G loss: 0.076797]\n",
            "[Epoch 26/200] [Batch 494/938] [D loss: 0.622792] [G loss: 0.075197]\n",
            "[Epoch 26/200] [Batch 495/938] [D loss: 0.648148] [G loss: 0.080648]\n",
            "[Epoch 26/200] [Batch 496/938] [D loss: 0.610339] [G loss: 0.072496]\n",
            "[Epoch 26/200] [Batch 497/938] [D loss: 0.639490] [G loss: 0.081603]\n",
            "[Epoch 26/200] [Batch 498/938] [D loss: 0.642200] [G loss: 0.068535]\n",
            "[Epoch 26/200] [Batch 499/938] [D loss: 0.646848] [G loss: 0.078015]\n",
            "[Epoch 26/200] [Batch 500/938] [D loss: 0.603764] [G loss: 0.068343]\n",
            "[Epoch 26/200] [Batch 501/938] [D loss: 0.672716] [G loss: 0.075296]\n",
            "[Epoch 26/200] [Batch 502/938] [D loss: 0.643937] [G loss: 0.070588]\n",
            "[Epoch 26/200] [Batch 503/938] [D loss: 0.686817] [G loss: 0.078266]\n",
            "[Epoch 26/200] [Batch 504/938] [D loss: 0.647779] [G loss: 0.071660]\n",
            "[Epoch 26/200] [Batch 505/938] [D loss: 0.628351] [G loss: 0.069485]\n",
            "[Epoch 26/200] [Batch 506/938] [D loss: 0.650425] [G loss: 0.067538]\n",
            "[Epoch 26/200] [Batch 507/938] [D loss: 0.619604] [G loss: 0.080220]\n",
            "[Epoch 26/200] [Batch 508/938] [D loss: 0.621890] [G loss: 0.073027]\n",
            "[Epoch 26/200] [Batch 509/938] [D loss: 0.643167] [G loss: 0.073211]\n",
            "[Epoch 26/200] [Batch 510/938] [D loss: 0.658913] [G loss: 0.069061]\n",
            "[Epoch 26/200] [Batch 511/938] [D loss: 0.658418] [G loss: 0.070483]\n",
            "[Epoch 26/200] [Batch 512/938] [D loss: 0.612717] [G loss: 0.076891]\n",
            "[Epoch 26/200] [Batch 513/938] [D loss: 0.624630] [G loss: 0.071264]\n",
            "[Epoch 26/200] [Batch 514/938] [D loss: 0.628854] [G loss: 0.067621]\n",
            "[Epoch 26/200] [Batch 515/938] [D loss: 0.631203] [G loss: 0.068861]\n",
            "[Epoch 26/200] [Batch 516/938] [D loss: 0.674327] [G loss: 0.070233]\n",
            "[Epoch 26/200] [Batch 517/938] [D loss: 0.607732] [G loss: 0.072776]\n",
            "[Epoch 26/200] [Batch 518/938] [D loss: 0.660501] [G loss: 0.073546]\n",
            "[Epoch 26/200] [Batch 519/938] [D loss: 0.622516] [G loss: 0.083539]\n",
            "[Epoch 26/200] [Batch 520/938] [D loss: 0.662573] [G loss: 0.072094]\n",
            "[Epoch 26/200] [Batch 521/938] [D loss: 0.636387] [G loss: 0.074680]\n",
            "[Epoch 26/200] [Batch 522/938] [D loss: 0.618393] [G loss: 0.077558]\n",
            "[Epoch 26/200] [Batch 523/938] [D loss: 0.641384] [G loss: 0.069838]\n",
            "[Epoch 26/200] [Batch 524/938] [D loss: 0.686378] [G loss: 0.072678]\n",
            "[Epoch 26/200] [Batch 525/938] [D loss: 0.643521] [G loss: 0.079790]\n",
            "[Epoch 26/200] [Batch 526/938] [D loss: 0.616353] [G loss: 0.075716]\n",
            "[Epoch 26/200] [Batch 527/938] [D loss: 0.675937] [G loss: 0.066672]\n",
            "[Epoch 26/200] [Batch 528/938] [D loss: 0.626000] [G loss: 0.084272]\n",
            "[Epoch 26/200] [Batch 529/938] [D loss: 0.662140] [G loss: 0.079638]\n",
            "[Epoch 26/200] [Batch 530/938] [D loss: 0.671728] [G loss: 0.066347]\n",
            "[Epoch 26/200] [Batch 531/938] [D loss: 0.630459] [G loss: 0.077641]\n",
            "[Epoch 26/200] [Batch 532/938] [D loss: 0.648020] [G loss: 0.071889]\n",
            "[Epoch 26/200] [Batch 533/938] [D loss: 0.624455] [G loss: 0.073834]\n",
            "[Epoch 26/200] [Batch 534/938] [D loss: 0.628902] [G loss: 0.070865]\n",
            "[Epoch 26/200] [Batch 535/938] [D loss: 0.610761] [G loss: 0.069588]\n",
            "[Epoch 26/200] [Batch 536/938] [D loss: 0.638208] [G loss: 0.070760]\n",
            "[Epoch 26/200] [Batch 537/938] [D loss: 0.626107] [G loss: 0.081648]\n",
            "[Epoch 26/200] [Batch 538/938] [D loss: 0.617630] [G loss: 0.078673]\n",
            "[Epoch 26/200] [Batch 539/938] [D loss: 0.620327] [G loss: 0.069724]\n",
            "[Epoch 26/200] [Batch 540/938] [D loss: 0.605870] [G loss: 0.074285]\n",
            "[Epoch 26/200] [Batch 541/938] [D loss: 0.666106] [G loss: 0.075263]\n",
            "[Epoch 26/200] [Batch 542/938] [D loss: 0.650683] [G loss: 0.074487]\n",
            "[Epoch 26/200] [Batch 543/938] [D loss: 0.649318] [G loss: 0.079068]\n",
            "[Epoch 26/200] [Batch 544/938] [D loss: 0.642115] [G loss: 0.067525]\n",
            "[Epoch 26/200] [Batch 545/938] [D loss: 0.669031] [G loss: 0.072814]\n",
            "[Epoch 26/200] [Batch 546/938] [D loss: 0.632353] [G loss: 0.077643]\n",
            "[Epoch 26/200] [Batch 547/938] [D loss: 0.622948] [G loss: 0.071863]\n",
            "[Epoch 26/200] [Batch 548/938] [D loss: 0.616078] [G loss: 0.071254]\n",
            "[Epoch 26/200] [Batch 549/938] [D loss: 0.627862] [G loss: 0.071509]\n",
            "[Epoch 26/200] [Batch 550/938] [D loss: 0.607607] [G loss: 0.076100]\n",
            "[Epoch 26/200] [Batch 551/938] [D loss: 0.605115] [G loss: 0.074623]\n",
            "[Epoch 26/200] [Batch 552/938] [D loss: 0.688971] [G loss: 0.075531]\n",
            "[Epoch 26/200] [Batch 553/938] [D loss: 0.627486] [G loss: 0.071868]\n",
            "[Epoch 26/200] [Batch 554/938] [D loss: 0.664985] [G loss: 0.076653]\n",
            "[Epoch 26/200] [Batch 555/938] [D loss: 0.642010] [G loss: 0.073768]\n",
            "[Epoch 26/200] [Batch 556/938] [D loss: 0.635979] [G loss: 0.072323]\n",
            "[Epoch 26/200] [Batch 557/938] [D loss: 0.667321] [G loss: 0.074198]\n",
            "[Epoch 26/200] [Batch 558/938] [D loss: 0.629578] [G loss: 0.068815]\n",
            "[Epoch 26/200] [Batch 559/938] [D loss: 0.642323] [G loss: 0.076595]\n",
            "[Epoch 26/200] [Batch 560/938] [D loss: 0.630002] [G loss: 0.061495]\n",
            "[Epoch 26/200] [Batch 561/938] [D loss: 0.649501] [G loss: 0.077450]\n",
            "[Epoch 26/200] [Batch 562/938] [D loss: 0.620736] [G loss: 0.077470]\n",
            "[Epoch 26/200] [Batch 563/938] [D loss: 0.616935] [G loss: 0.073312]\n",
            "[Epoch 26/200] [Batch 564/938] [D loss: 0.659044] [G loss: 0.072893]\n",
            "[Epoch 26/200] [Batch 565/938] [D loss: 0.623454] [G loss: 0.075988]\n",
            "[Epoch 26/200] [Batch 566/938] [D loss: 0.647583] [G loss: 0.074318]\n",
            "[Epoch 26/200] [Batch 567/938] [D loss: 0.636065] [G loss: 0.067906]\n",
            "[Epoch 26/200] [Batch 568/938] [D loss: 0.683381] [G loss: 0.072334]\n",
            "[Epoch 26/200] [Batch 569/938] [D loss: 0.651940] [G loss: 0.076836]\n",
            "[Epoch 26/200] [Batch 570/938] [D loss: 0.601983] [G loss: 0.073444]\n",
            "[Epoch 26/200] [Batch 571/938] [D loss: 0.660794] [G loss: 0.071973]\n",
            "[Epoch 26/200] [Batch 572/938] [D loss: 0.638539] [G loss: 0.069690]\n",
            "[Epoch 26/200] [Batch 573/938] [D loss: 0.625178] [G loss: 0.066565]\n",
            "[Epoch 26/200] [Batch 574/938] [D loss: 0.619533] [G loss: 0.068416]\n",
            "[Epoch 26/200] [Batch 575/938] [D loss: 0.618543] [G loss: 0.068487]\n",
            "[Epoch 26/200] [Batch 576/938] [D loss: 0.653821] [G loss: 0.072364]\n",
            "[Epoch 26/200] [Batch 577/938] [D loss: 0.612597] [G loss: 0.073298]\n",
            "[Epoch 26/200] [Batch 578/938] [D loss: 0.670647] [G loss: 0.074791]\n",
            "[Epoch 26/200] [Batch 579/938] [D loss: 0.627504] [G loss: 0.079787]\n",
            "[Epoch 26/200] [Batch 580/938] [D loss: 0.651858] [G loss: 0.071891]\n",
            "[Epoch 26/200] [Batch 581/938] [D loss: 0.670110] [G loss: 0.074642]\n",
            "[Epoch 26/200] [Batch 582/938] [D loss: 0.622521] [G loss: 0.073319]\n",
            "[Epoch 26/200] [Batch 583/938] [D loss: 0.638159] [G loss: 0.067936]\n",
            "[Epoch 26/200] [Batch 584/938] [D loss: 0.627367] [G loss: 0.073142]\n",
            "[Epoch 26/200] [Batch 585/938] [D loss: 0.637739] [G loss: 0.076197]\n",
            "[Epoch 26/200] [Batch 586/938] [D loss: 0.661713] [G loss: 0.071940]\n",
            "[Epoch 26/200] [Batch 587/938] [D loss: 0.664159] [G loss: 0.067769]\n",
            "[Epoch 26/200] [Batch 588/938] [D loss: 0.629531] [G loss: 0.074214]\n",
            "[Epoch 26/200] [Batch 589/938] [D loss: 0.622917] [G loss: 0.070620]\n",
            "[Epoch 26/200] [Batch 590/938] [D loss: 0.607510] [G loss: 0.082088]\n",
            "[Epoch 26/200] [Batch 591/938] [D loss: 0.607071] [G loss: 0.069040]\n",
            "[Epoch 26/200] [Batch 592/938] [D loss: 0.649085] [G loss: 0.067704]\n",
            "[Epoch 26/200] [Batch 593/938] [D loss: 0.608351] [G loss: 0.077279]\n",
            "[Epoch 26/200] [Batch 594/938] [D loss: 0.606634] [G loss: 0.074684]\n",
            "[Epoch 26/200] [Batch 595/938] [D loss: 0.608838] [G loss: 0.062096]\n",
            "[Epoch 26/200] [Batch 596/938] [D loss: 0.620957] [G loss: 0.074189]\n",
            "[Epoch 26/200] [Batch 597/938] [D loss: 0.660017] [G loss: 0.070592]\n",
            "[Epoch 26/200] [Batch 598/938] [D loss: 0.629866] [G loss: 0.077391]\n",
            "[Epoch 26/200] [Batch 599/938] [D loss: 0.616947] [G loss: 0.068783]\n",
            "[Epoch 26/200] [Batch 600/938] [D loss: 0.623680] [G loss: 0.068717]\n",
            "[Epoch 26/200] [Batch 601/938] [D loss: 0.656573] [G loss: 0.071851]\n",
            "[Epoch 26/200] [Batch 602/938] [D loss: 0.641686] [G loss: 0.076118]\n",
            "[Epoch 26/200] [Batch 603/938] [D loss: 0.611311] [G loss: 0.069627]\n",
            "[Epoch 26/200] [Batch 604/938] [D loss: 0.592945] [G loss: 0.070795]\n",
            "[Epoch 26/200] [Batch 605/938] [D loss: 0.634771] [G loss: 0.068154]\n",
            "[Epoch 26/200] [Batch 606/938] [D loss: 0.663456] [G loss: 0.075875]\n",
            "[Epoch 26/200] [Batch 607/938] [D loss: 0.662822] [G loss: 0.078126]\n",
            "[Epoch 26/200] [Batch 608/938] [D loss: 0.651573] [G loss: 0.074719]\n",
            "[Epoch 26/200] [Batch 609/938] [D loss: 0.668225] [G loss: 0.070769]\n",
            "[Epoch 26/200] [Batch 610/938] [D loss: 0.623117] [G loss: 0.068319]\n",
            "[Epoch 26/200] [Batch 611/938] [D loss: 0.664350] [G loss: 0.070318]\n",
            "[Epoch 26/200] [Batch 612/938] [D loss: 0.613018] [G loss: 0.075450]\n",
            "[Epoch 26/200] [Batch 613/938] [D loss: 0.655795] [G loss: 0.081579]\n",
            "[Epoch 26/200] [Batch 614/938] [D loss: 0.622414] [G loss: 0.085227]\n",
            "[Epoch 26/200] [Batch 615/938] [D loss: 0.625908] [G loss: 0.076499]\n",
            "[Epoch 26/200] [Batch 616/938] [D loss: 0.634494] [G loss: 0.068880]\n",
            "[Epoch 26/200] [Batch 617/938] [D loss: 0.631065] [G loss: 0.073426]\n",
            "[Epoch 26/200] [Batch 618/938] [D loss: 0.630645] [G loss: 0.068129]\n",
            "[Epoch 26/200] [Batch 619/938] [D loss: 0.641746] [G loss: 0.071095]\n",
            "[Epoch 26/200] [Batch 620/938] [D loss: 0.651901] [G loss: 0.077639]\n",
            "[Epoch 26/200] [Batch 621/938] [D loss: 0.665727] [G loss: 0.075196]\n",
            "[Epoch 26/200] [Batch 622/938] [D loss: 0.678620] [G loss: 0.070868]\n",
            "[Epoch 26/200] [Batch 623/938] [D loss: 0.669494] [G loss: 0.072554]\n",
            "[Epoch 26/200] [Batch 624/938] [D loss: 0.649615] [G loss: 0.076439]\n",
            "[Epoch 26/200] [Batch 625/938] [D loss: 0.634816] [G loss: 0.072379]\n",
            "[Epoch 26/200] [Batch 626/938] [D loss: 0.652041] [G loss: 0.069740]\n",
            "[Epoch 26/200] [Batch 627/938] [D loss: 0.630770] [G loss: 0.077304]\n",
            "[Epoch 26/200] [Batch 628/938] [D loss: 0.658199] [G loss: 0.073172]\n",
            "[Epoch 26/200] [Batch 629/938] [D loss: 0.612523] [G loss: 0.071531]\n",
            "[Epoch 26/200] [Batch 630/938] [D loss: 0.642662] [G loss: 0.066017]\n",
            "[Epoch 26/200] [Batch 631/938] [D loss: 0.627190] [G loss: 0.073331]\n",
            "[Epoch 26/200] [Batch 632/938] [D loss: 0.609231] [G loss: 0.074824]\n",
            "[Epoch 26/200] [Batch 633/938] [D loss: 0.648673] [G loss: 0.075207]\n",
            "[Epoch 26/200] [Batch 634/938] [D loss: 0.654372] [G loss: 0.071943]\n",
            "[Epoch 26/200] [Batch 635/938] [D loss: 0.632370] [G loss: 0.069825]\n",
            "[Epoch 26/200] [Batch 636/938] [D loss: 0.638762] [G loss: 0.074697]\n",
            "[Epoch 26/200] [Batch 637/938] [D loss: 0.629785] [G loss: 0.068090]\n",
            "[Epoch 26/200] [Batch 638/938] [D loss: 0.635009] [G loss: 0.070998]\n",
            "[Epoch 26/200] [Batch 639/938] [D loss: 0.644158] [G loss: 0.071583]\n",
            "[Epoch 26/200] [Batch 640/938] [D loss: 0.639542] [G loss: 0.070336]\n",
            "[Epoch 26/200] [Batch 641/938] [D loss: 0.623971] [G loss: 0.067105]\n",
            "[Epoch 26/200] [Batch 642/938] [D loss: 0.628719] [G loss: 0.076297]\n",
            "[Epoch 26/200] [Batch 643/938] [D loss: 0.628917] [G loss: 0.066439]\n",
            "[Epoch 26/200] [Batch 644/938] [D loss: 0.630291] [G loss: 0.071303]\n",
            "[Epoch 26/200] [Batch 645/938] [D loss: 0.620994] [G loss: 0.071065]\n",
            "[Epoch 26/200] [Batch 646/938] [D loss: 0.649536] [G loss: 0.070378]\n",
            "[Epoch 26/200] [Batch 647/938] [D loss: 0.697142] [G loss: 0.068023]\n",
            "[Epoch 26/200] [Batch 648/938] [D loss: 0.637613] [G loss: 0.064684]\n",
            "[Epoch 26/200] [Batch 649/938] [D loss: 0.635143] [G loss: 0.068593]\n",
            "[Epoch 26/200] [Batch 650/938] [D loss: 0.631633] [G loss: 0.076607]\n",
            "[Epoch 26/200] [Batch 651/938] [D loss: 0.656734] [G loss: 0.065766]\n",
            "[Epoch 26/200] [Batch 652/938] [D loss: 0.625864] [G loss: 0.079890]\n",
            "[Epoch 26/200] [Batch 653/938] [D loss: 0.620405] [G loss: 0.070316]\n",
            "[Epoch 26/200] [Batch 654/938] [D loss: 0.636814] [G loss: 0.072494]\n",
            "[Epoch 26/200] [Batch 655/938] [D loss: 0.600687] [G loss: 0.077321]\n",
            "[Epoch 26/200] [Batch 656/938] [D loss: 0.641019] [G loss: 0.068056]\n",
            "[Epoch 26/200] [Batch 657/938] [D loss: 0.673674] [G loss: 0.067374]\n",
            "[Epoch 26/200] [Batch 658/938] [D loss: 0.620203] [G loss: 0.067320]\n",
            "[Epoch 26/200] [Batch 659/938] [D loss: 0.651640] [G loss: 0.068888]\n",
            "[Epoch 26/200] [Batch 660/938] [D loss: 0.672321] [G loss: 0.080628]\n",
            "[Epoch 26/200] [Batch 661/938] [D loss: 0.614848] [G loss: 0.067832]\n",
            "[Epoch 26/200] [Batch 662/938] [D loss: 0.653156] [G loss: 0.068682]\n",
            "[Epoch 26/200] [Batch 663/938] [D loss: 0.691726] [G loss: 0.070225]\n",
            "[Epoch 26/200] [Batch 664/938] [D loss: 0.614119] [G loss: 0.069485]\n",
            "[Epoch 26/200] [Batch 665/938] [D loss: 0.668642] [G loss: 0.079969]\n",
            "[Epoch 26/200] [Batch 666/938] [D loss: 0.613753] [G loss: 0.066940]\n",
            "[Epoch 26/200] [Batch 667/938] [D loss: 0.625569] [G loss: 0.068324]\n",
            "[Epoch 26/200] [Batch 668/938] [D loss: 0.605680] [G loss: 0.076130]\n",
            "[Epoch 26/200] [Batch 669/938] [D loss: 0.659148] [G loss: 0.077399]\n",
            "[Epoch 26/200] [Batch 670/938] [D loss: 0.645144] [G loss: 0.072368]\n",
            "[Epoch 26/200] [Batch 671/938] [D loss: 0.644331] [G loss: 0.078213]\n",
            "[Epoch 26/200] [Batch 672/938] [D loss: 0.619833] [G loss: 0.072982]\n",
            "[Epoch 26/200] [Batch 673/938] [D loss: 0.682247] [G loss: 0.070880]\n",
            "[Epoch 26/200] [Batch 674/938] [D loss: 0.628653] [G loss: 0.081589]\n",
            "[Epoch 26/200] [Batch 675/938] [D loss: 0.617926] [G loss: 0.073185]\n",
            "[Epoch 26/200] [Batch 676/938] [D loss: 0.636095] [G loss: 0.080559]\n",
            "[Epoch 26/200] [Batch 677/938] [D loss: 0.606027] [G loss: 0.080618]\n",
            "[Epoch 26/200] [Batch 678/938] [D loss: 0.614849] [G loss: 0.084038]\n",
            "[Epoch 26/200] [Batch 679/938] [D loss: 0.618730] [G loss: 0.073334]\n",
            "[Epoch 26/200] [Batch 680/938] [D loss: 0.603701] [G loss: 0.075573]\n",
            "[Epoch 26/200] [Batch 681/938] [D loss: 0.632497] [G loss: 0.067401]\n",
            "[Epoch 26/200] [Batch 682/938] [D loss: 0.604945] [G loss: 0.075980]\n",
            "[Epoch 26/200] [Batch 683/938] [D loss: 0.667362] [G loss: 0.072646]\n",
            "[Epoch 26/200] [Batch 684/938] [D loss: 0.614991] [G loss: 0.070697]\n",
            "[Epoch 26/200] [Batch 685/938] [D loss: 0.641222] [G loss: 0.082478]\n",
            "[Epoch 26/200] [Batch 686/938] [D loss: 0.650990] [G loss: 0.066027]\n",
            "[Epoch 26/200] [Batch 687/938] [D loss: 0.654253] [G loss: 0.074505]\n",
            "[Epoch 26/200] [Batch 688/938] [D loss: 0.648720] [G loss: 0.072847]\n",
            "[Epoch 26/200] [Batch 689/938] [D loss: 0.642440] [G loss: 0.070387]\n",
            "[Epoch 26/200] [Batch 690/938] [D loss: 0.612001] [G loss: 0.077875]\n",
            "[Epoch 26/200] [Batch 691/938] [D loss: 0.627615] [G loss: 0.070856]\n",
            "[Epoch 26/200] [Batch 692/938] [D loss: 0.629062] [G loss: 0.068296]\n",
            "[Epoch 26/200] [Batch 693/938] [D loss: 0.617935] [G loss: 0.072379]\n",
            "[Epoch 26/200] [Batch 694/938] [D loss: 0.625834] [G loss: 0.069998]\n",
            "[Epoch 26/200] [Batch 695/938] [D loss: 0.607955] [G loss: 0.078934]\n",
            "[Epoch 26/200] [Batch 696/938] [D loss: 0.650642] [G loss: 0.071888]\n",
            "[Epoch 26/200] [Batch 697/938] [D loss: 0.634839] [G loss: 0.070725]\n",
            "[Epoch 26/200] [Batch 698/938] [D loss: 0.610140] [G loss: 0.068046]\n",
            "[Epoch 26/200] [Batch 699/938] [D loss: 0.650094] [G loss: 0.067035]\n",
            "[Epoch 26/200] [Batch 700/938] [D loss: 0.643357] [G loss: 0.070633]\n",
            "[Epoch 26/200] [Batch 701/938] [D loss: 0.630016] [G loss: 0.073861]\n",
            "[Epoch 26/200] [Batch 702/938] [D loss: 0.616238] [G loss: 0.064876]\n",
            "[Epoch 26/200] [Batch 703/938] [D loss: 0.631364] [G loss: 0.076178]\n",
            "[Epoch 26/200] [Batch 704/938] [D loss: 0.625556] [G loss: 0.071809]\n",
            "[Epoch 26/200] [Batch 705/938] [D loss: 0.657987] [G loss: 0.071641]\n",
            "[Epoch 26/200] [Batch 706/938] [D loss: 0.567328] [G loss: 0.077916]\n",
            "[Epoch 26/200] [Batch 707/938] [D loss: 0.672459] [G loss: 0.074398]\n",
            "[Epoch 26/200] [Batch 708/938] [D loss: 0.642488] [G loss: 0.071982]\n",
            "[Epoch 26/200] [Batch 709/938] [D loss: 0.630423] [G loss: 0.073084]\n",
            "[Epoch 26/200] [Batch 710/938] [D loss: 0.629435] [G loss: 0.083016]\n",
            "[Epoch 26/200] [Batch 711/938] [D loss: 0.675069] [G loss: 0.071063]\n",
            "[Epoch 26/200] [Batch 712/938] [D loss: 0.642550] [G loss: 0.074320]\n",
            "[Epoch 26/200] [Batch 713/938] [D loss: 0.590912] [G loss: 0.079940]\n",
            "[Epoch 26/200] [Batch 714/938] [D loss: 0.658647] [G loss: 0.076006]\n",
            "[Epoch 26/200] [Batch 715/938] [D loss: 0.658507] [G loss: 0.067283]\n",
            "[Epoch 26/200] [Batch 716/938] [D loss: 0.652900] [G loss: 0.070193]\n",
            "[Epoch 26/200] [Batch 717/938] [D loss: 0.650712] [G loss: 0.074698]\n",
            "[Epoch 26/200] [Batch 718/938] [D loss: 0.645286] [G loss: 0.067533]\n",
            "[Epoch 26/200] [Batch 719/938] [D loss: 0.635527] [G loss: 0.083587]\n",
            "[Epoch 26/200] [Batch 720/938] [D loss: 0.639614] [G loss: 0.065716]\n",
            "[Epoch 26/200] [Batch 721/938] [D loss: 0.612827] [G loss: 0.069462]\n",
            "[Epoch 26/200] [Batch 722/938] [D loss: 0.613154] [G loss: 0.069454]\n",
            "[Epoch 26/200] [Batch 723/938] [D loss: 0.624189] [G loss: 0.072739]\n",
            "[Epoch 26/200] [Batch 724/938] [D loss: 0.636258] [G loss: 0.078279]\n",
            "[Epoch 26/200] [Batch 725/938] [D loss: 0.631140] [G loss: 0.072249]\n",
            "[Epoch 26/200] [Batch 726/938] [D loss: 0.657815] [G loss: 0.072978]\n",
            "[Epoch 26/200] [Batch 727/938] [D loss: 0.620530] [G loss: 0.072938]\n",
            "[Epoch 26/200] [Batch 728/938] [D loss: 0.615987] [G loss: 0.069167]\n",
            "[Epoch 26/200] [Batch 729/938] [D loss: 0.672037] [G loss: 0.067393]\n",
            "[Epoch 26/200] [Batch 730/938] [D loss: 0.623834] [G loss: 0.074027]\n",
            "[Epoch 26/200] [Batch 731/938] [D loss: 0.647017] [G loss: 0.074471]\n",
            "[Epoch 26/200] [Batch 732/938] [D loss: 0.613865] [G loss: 0.074973]\n",
            "[Epoch 26/200] [Batch 733/938] [D loss: 0.643280] [G loss: 0.063740]\n",
            "[Epoch 26/200] [Batch 734/938] [D loss: 0.643879] [G loss: 0.072808]\n",
            "[Epoch 26/200] [Batch 735/938] [D loss: 0.611952] [G loss: 0.078532]\n",
            "[Epoch 26/200] [Batch 736/938] [D loss: 0.657504] [G loss: 0.074223]\n",
            "[Epoch 26/200] [Batch 737/938] [D loss: 0.658161] [G loss: 0.078366]\n",
            "[Epoch 26/200] [Batch 738/938] [D loss: 0.648971] [G loss: 0.073376]\n",
            "[Epoch 26/200] [Batch 739/938] [D loss: 0.622042] [G loss: 0.077950]\n",
            "[Epoch 26/200] [Batch 740/938] [D loss: 0.649139] [G loss: 0.071004]\n",
            "[Epoch 26/200] [Batch 741/938] [D loss: 0.630672] [G loss: 0.066507]\n",
            "[Epoch 26/200] [Batch 742/938] [D loss: 0.606160] [G loss: 0.073758]\n",
            "[Epoch 26/200] [Batch 743/938] [D loss: 0.626046] [G loss: 0.073671]\n",
            "[Epoch 26/200] [Batch 744/938] [D loss: 0.653912] [G loss: 0.071130]\n",
            "[Epoch 26/200] [Batch 745/938] [D loss: 0.647993] [G loss: 0.073853]\n",
            "[Epoch 26/200] [Batch 746/938] [D loss: 0.637755] [G loss: 0.078359]\n",
            "[Epoch 26/200] [Batch 747/938] [D loss: 0.647099] [G loss: 0.079163]\n",
            "[Epoch 26/200] [Batch 748/938] [D loss: 0.639603] [G loss: 0.068962]\n",
            "[Epoch 26/200] [Batch 749/938] [D loss: 0.631323] [G loss: 0.075626]\n",
            "[Epoch 26/200] [Batch 750/938] [D loss: 0.666310] [G loss: 0.070095]\n",
            "[Epoch 26/200] [Batch 751/938] [D loss: 0.662904] [G loss: 0.067413]\n",
            "[Epoch 26/200] [Batch 752/938] [D loss: 0.634808] [G loss: 0.074403]\n",
            "[Epoch 26/200] [Batch 753/938] [D loss: 0.662793] [G loss: 0.072215]\n",
            "[Epoch 26/200] [Batch 754/938] [D loss: 0.652675] [G loss: 0.070307]\n",
            "[Epoch 26/200] [Batch 755/938] [D loss: 0.635579] [G loss: 0.067004]\n",
            "[Epoch 26/200] [Batch 756/938] [D loss: 0.639446] [G loss: 0.075966]\n",
            "[Epoch 26/200] [Batch 757/938] [D loss: 0.604755] [G loss: 0.073367]\n",
            "[Epoch 26/200] [Batch 758/938] [D loss: 0.613320] [G loss: 0.070880]\n",
            "[Epoch 26/200] [Batch 759/938] [D loss: 0.624718] [G loss: 0.067253]\n",
            "[Epoch 26/200] [Batch 760/938] [D loss: 0.642176] [G loss: 0.077848]\n",
            "[Epoch 26/200] [Batch 761/938] [D loss: 0.637804] [G loss: 0.067808]\n",
            "[Epoch 26/200] [Batch 762/938] [D loss: 0.631646] [G loss: 0.080251]\n",
            "[Epoch 26/200] [Batch 763/938] [D loss: 0.666429] [G loss: 0.073628]\n",
            "[Epoch 26/200] [Batch 764/938] [D loss: 0.640740] [G loss: 0.069703]\n",
            "[Epoch 26/200] [Batch 765/938] [D loss: 0.647404] [G loss: 0.072142]\n",
            "[Epoch 26/200] [Batch 766/938] [D loss: 0.624595] [G loss: 0.074337]\n",
            "[Epoch 26/200] [Batch 767/938] [D loss: 0.601396] [G loss: 0.077808]\n",
            "[Epoch 26/200] [Batch 768/938] [D loss: 0.629228] [G loss: 0.074002]\n",
            "[Epoch 26/200] [Batch 769/938] [D loss: 0.682471] [G loss: 0.082192]\n",
            "[Epoch 26/200] [Batch 770/938] [D loss: 0.618974] [G loss: 0.066663]\n",
            "[Epoch 26/200] [Batch 771/938] [D loss: 0.608013] [G loss: 0.073075]\n",
            "[Epoch 26/200] [Batch 772/938] [D loss: 0.616992] [G loss: 0.071815]\n",
            "[Epoch 26/200] [Batch 773/938] [D loss: 0.614190] [G loss: 0.072153]\n",
            "[Epoch 26/200] [Batch 774/938] [D loss: 0.628903] [G loss: 0.067168]\n",
            "[Epoch 26/200] [Batch 775/938] [D loss: 0.641982] [G loss: 0.064339]\n",
            "[Epoch 26/200] [Batch 776/938] [D loss: 0.645899] [G loss: 0.072202]\n",
            "[Epoch 26/200] [Batch 777/938] [D loss: 0.623033] [G loss: 0.080040]\n",
            "[Epoch 26/200] [Batch 778/938] [D loss: 0.662096] [G loss: 0.072208]\n",
            "[Epoch 26/200] [Batch 779/938] [D loss: 0.627749] [G loss: 0.078833]\n",
            "[Epoch 26/200] [Batch 780/938] [D loss: 0.684138] [G loss: 0.072010]\n",
            "[Epoch 26/200] [Batch 781/938] [D loss: 0.638633] [G loss: 0.073330]\n",
            "[Epoch 26/200] [Batch 782/938] [D loss: 0.621359] [G loss: 0.072191]\n",
            "[Epoch 26/200] [Batch 783/938] [D loss: 0.591737] [G loss: 0.072785]\n",
            "[Epoch 26/200] [Batch 784/938] [D loss: 0.621779] [G loss: 0.071421]\n",
            "[Epoch 26/200] [Batch 785/938] [D loss: 0.643702] [G loss: 0.072685]\n",
            "[Epoch 26/200] [Batch 786/938] [D loss: 0.660000] [G loss: 0.073700]\n",
            "[Epoch 26/200] [Batch 787/938] [D loss: 0.654710] [G loss: 0.073337]\n",
            "[Epoch 26/200] [Batch 788/938] [D loss: 0.663558] [G loss: 0.072288]\n",
            "[Epoch 26/200] [Batch 789/938] [D loss: 0.641534] [G loss: 0.075881]\n",
            "[Epoch 26/200] [Batch 790/938] [D loss: 0.627214] [G loss: 0.070998]\n",
            "[Epoch 26/200] [Batch 791/938] [D loss: 0.624695] [G loss: 0.081036]\n",
            "[Epoch 26/200] [Batch 792/938] [D loss: 0.651136] [G loss: 0.070623]\n",
            "[Epoch 26/200] [Batch 793/938] [D loss: 0.626416] [G loss: 0.076475]\n",
            "[Epoch 26/200] [Batch 794/938] [D loss: 0.640804] [G loss: 0.071109]\n",
            "[Epoch 26/200] [Batch 795/938] [D loss: 0.616766] [G loss: 0.072853]\n",
            "[Epoch 26/200] [Batch 796/938] [D loss: 0.611697] [G loss: 0.075567]\n",
            "[Epoch 26/200] [Batch 797/938] [D loss: 0.620216] [G loss: 0.071392]\n",
            "[Epoch 26/200] [Batch 798/938] [D loss: 0.636804] [G loss: 0.074247]\n",
            "[Epoch 26/200] [Batch 799/938] [D loss: 0.623506] [G loss: 0.072847]\n",
            "[Epoch 26/200] [Batch 800/938] [D loss: 0.621187] [G loss: 0.071393]\n",
            "[Epoch 26/200] [Batch 801/938] [D loss: 0.594882] [G loss: 0.075653]\n",
            "[Epoch 26/200] [Batch 802/938] [D loss: 0.617904] [G loss: 0.081013]\n",
            "[Epoch 26/200] [Batch 803/938] [D loss: 0.643858] [G loss: 0.069225]\n",
            "[Epoch 26/200] [Batch 804/938] [D loss: 0.653257] [G loss: 0.066709]\n",
            "[Epoch 26/200] [Batch 805/938] [D loss: 0.643725] [G loss: 0.065980]\n",
            "[Epoch 26/200] [Batch 806/938] [D loss: 0.646621] [G loss: 0.074074]\n",
            "[Epoch 26/200] [Batch 807/938] [D loss: 0.672756] [G loss: 0.075964]\n",
            "[Epoch 26/200] [Batch 808/938] [D loss: 0.632961] [G loss: 0.069591]\n",
            "[Epoch 26/200] [Batch 809/938] [D loss: 0.631493] [G loss: 0.066803]\n",
            "[Epoch 26/200] [Batch 810/938] [D loss: 0.636336] [G loss: 0.080510]\n",
            "[Epoch 26/200] [Batch 811/938] [D loss: 0.617708] [G loss: 0.070985]\n",
            "[Epoch 26/200] [Batch 812/938] [D loss: 0.628440] [G loss: 0.069567]\n",
            "[Epoch 26/200] [Batch 813/938] [D loss: 0.694330] [G loss: 0.072405]\n",
            "[Epoch 26/200] [Batch 814/938] [D loss: 0.664884] [G loss: 0.075473]\n",
            "[Epoch 26/200] [Batch 815/938] [D loss: 0.633755] [G loss: 0.071643]\n",
            "[Epoch 26/200] [Batch 816/938] [D loss: 0.648344] [G loss: 0.075035]\n",
            "[Epoch 26/200] [Batch 817/938] [D loss: 0.636385] [G loss: 0.072382]\n",
            "[Epoch 26/200] [Batch 818/938] [D loss: 0.610334] [G loss: 0.073140]\n",
            "[Epoch 26/200] [Batch 819/938] [D loss: 0.625181] [G loss: 0.068045]\n",
            "[Epoch 26/200] [Batch 820/938] [D loss: 0.649069] [G loss: 0.081646]\n",
            "[Epoch 26/200] [Batch 821/938] [D loss: 0.643728] [G loss: 0.073903]\n",
            "[Epoch 26/200] [Batch 822/938] [D loss: 0.626915] [G loss: 0.063685]\n",
            "[Epoch 26/200] [Batch 823/938] [D loss: 0.625464] [G loss: 0.078203]\n",
            "[Epoch 26/200] [Batch 824/938] [D loss: 0.650716] [G loss: 0.078351]\n",
            "[Epoch 26/200] [Batch 825/938] [D loss: 0.622868] [G loss: 0.073694]\n",
            "[Epoch 26/200] [Batch 826/938] [D loss: 0.627618] [G loss: 0.078029]\n",
            "[Epoch 26/200] [Batch 827/938] [D loss: 0.613964] [G loss: 0.072577]\n",
            "[Epoch 26/200] [Batch 828/938] [D loss: 0.659908] [G loss: 0.072838]\n",
            "[Epoch 26/200] [Batch 829/938] [D loss: 0.654949] [G loss: 0.073285]\n",
            "[Epoch 26/200] [Batch 830/938] [D loss: 0.640811] [G loss: 0.069451]\n",
            "[Epoch 26/200] [Batch 831/938] [D loss: 0.621801] [G loss: 0.073734]\n",
            "[Epoch 26/200] [Batch 832/938] [D loss: 0.637752] [G loss: 0.077846]\n",
            "[Epoch 26/200] [Batch 833/938] [D loss: 0.620954] [G loss: 0.066310]\n",
            "[Epoch 26/200] [Batch 834/938] [D loss: 0.623740] [G loss: 0.065738]\n",
            "[Epoch 26/200] [Batch 835/938] [D loss: 0.642276] [G loss: 0.073698]\n",
            "[Epoch 26/200] [Batch 836/938] [D loss: 0.639462] [G loss: 0.070692]\n",
            "[Epoch 26/200] [Batch 837/938] [D loss: 0.599515] [G loss: 0.072061]\n",
            "[Epoch 26/200] [Batch 838/938] [D loss: 0.629108] [G loss: 0.070810]\n",
            "[Epoch 26/200] [Batch 839/938] [D loss: 0.629878] [G loss: 0.075990]\n",
            "[Epoch 26/200] [Batch 840/938] [D loss: 0.627835] [G loss: 0.079480]\n",
            "[Epoch 26/200] [Batch 841/938] [D loss: 0.669270] [G loss: 0.071040]\n",
            "[Epoch 26/200] [Batch 842/938] [D loss: 0.626019] [G loss: 0.072841]\n",
            "[Epoch 26/200] [Batch 843/938] [D loss: 0.604799] [G loss: 0.077449]\n",
            "[Epoch 26/200] [Batch 844/938] [D loss: 0.621146] [G loss: 0.075317]\n",
            "[Epoch 26/200] [Batch 845/938] [D loss: 0.622592] [G loss: 0.078370]\n",
            "[Epoch 26/200] [Batch 846/938] [D loss: 0.635883] [G loss: 0.072869]\n",
            "[Epoch 26/200] [Batch 847/938] [D loss: 0.663211] [G loss: 0.072444]\n",
            "[Epoch 26/200] [Batch 848/938] [D loss: 0.608112] [G loss: 0.072482]\n",
            "[Epoch 26/200] [Batch 849/938] [D loss: 0.632954] [G loss: 0.082983]\n",
            "[Epoch 26/200] [Batch 850/938] [D loss: 0.607457] [G loss: 0.077133]\n",
            "[Epoch 26/200] [Batch 851/938] [D loss: 0.598426] [G loss: 0.074173]\n",
            "[Epoch 26/200] [Batch 852/938] [D loss: 0.632205] [G loss: 0.069519]\n",
            "[Epoch 26/200] [Batch 853/938] [D loss: 0.630862] [G loss: 0.069146]\n",
            "[Epoch 26/200] [Batch 854/938] [D loss: 0.624216] [G loss: 0.074021]\n",
            "[Epoch 26/200] [Batch 855/938] [D loss: 0.613666] [G loss: 0.072382]\n",
            "[Epoch 26/200] [Batch 856/938] [D loss: 0.679106] [G loss: 0.074021]\n",
            "[Epoch 26/200] [Batch 857/938] [D loss: 0.611267] [G loss: 0.066620]\n",
            "[Epoch 26/200] [Batch 858/938] [D loss: 0.698211] [G loss: 0.075542]\n",
            "[Epoch 26/200] [Batch 859/938] [D loss: 0.627309] [G loss: 0.079044]\n",
            "[Epoch 26/200] [Batch 860/938] [D loss: 0.657165] [G loss: 0.071153]\n",
            "[Epoch 26/200] [Batch 861/938] [D loss: 0.668469] [G loss: 0.077985]\n",
            "[Epoch 26/200] [Batch 862/938] [D loss: 0.629122] [G loss: 0.071485]\n",
            "[Epoch 26/200] [Batch 863/938] [D loss: 0.659421] [G loss: 0.069835]\n",
            "[Epoch 26/200] [Batch 864/938] [D loss: 0.690205] [G loss: 0.068720]\n",
            "[Epoch 26/200] [Batch 865/938] [D loss: 0.634213] [G loss: 0.076800]\n",
            "[Epoch 26/200] [Batch 866/938] [D loss: 0.608236] [G loss: 0.074157]\n",
            "[Epoch 26/200] [Batch 867/938] [D loss: 0.611346] [G loss: 0.073678]\n",
            "[Epoch 26/200] [Batch 868/938] [D loss: 0.608668] [G loss: 0.072303]\n",
            "[Epoch 26/200] [Batch 869/938] [D loss: 0.639953] [G loss: 0.073694]\n",
            "[Epoch 26/200] [Batch 870/938] [D loss: 0.668102] [G loss: 0.073872]\n",
            "[Epoch 26/200] [Batch 871/938] [D loss: 0.630360] [G loss: 0.077088]\n",
            "[Epoch 26/200] [Batch 872/938] [D loss: 0.662669] [G loss: 0.069879]\n",
            "[Epoch 26/200] [Batch 873/938] [D loss: 0.669372] [G loss: 0.072712]\n",
            "[Epoch 26/200] [Batch 874/938] [D loss: 0.643141] [G loss: 0.076842]\n",
            "[Epoch 26/200] [Batch 875/938] [D loss: 0.623324] [G loss: 0.077142]\n",
            "[Epoch 26/200] [Batch 876/938] [D loss: 0.630066] [G loss: 0.074698]\n",
            "[Epoch 26/200] [Batch 877/938] [D loss: 0.637838] [G loss: 0.072127]\n",
            "[Epoch 26/200] [Batch 878/938] [D loss: 0.645756] [G loss: 0.070015]\n",
            "[Epoch 26/200] [Batch 879/938] [D loss: 0.621673] [G loss: 0.075174]\n",
            "[Epoch 26/200] [Batch 880/938] [D loss: 0.630345] [G loss: 0.079511]\n",
            "[Epoch 26/200] [Batch 881/938] [D loss: 0.642507] [G loss: 0.071952]\n",
            "[Epoch 26/200] [Batch 882/938] [D loss: 0.641710] [G loss: 0.070952]\n",
            "[Epoch 26/200] [Batch 883/938] [D loss: 0.686650] [G loss: 0.067501]\n",
            "[Epoch 26/200] [Batch 884/938] [D loss: 0.649479] [G loss: 0.073886]\n",
            "[Epoch 26/200] [Batch 885/938] [D loss: 0.630681] [G loss: 0.065534]\n",
            "[Epoch 26/200] [Batch 886/938] [D loss: 0.634133] [G loss: 0.071146]\n",
            "[Epoch 26/200] [Batch 887/938] [D loss: 0.679114] [G loss: 0.070050]\n",
            "[Epoch 26/200] [Batch 888/938] [D loss: 0.611619] [G loss: 0.070666]\n",
            "[Epoch 26/200] [Batch 889/938] [D loss: 0.653403] [G loss: 0.080826]\n",
            "[Epoch 26/200] [Batch 890/938] [D loss: 0.662069] [G loss: 0.075381]\n",
            "[Epoch 26/200] [Batch 891/938] [D loss: 0.641976] [G loss: 0.071286]\n",
            "[Epoch 26/200] [Batch 892/938] [D loss: 0.603030] [G loss: 0.069835]\n",
            "[Epoch 26/200] [Batch 893/938] [D loss: 0.658682] [G loss: 0.070405]\n",
            "[Epoch 26/200] [Batch 894/938] [D loss: 0.611858] [G loss: 0.073366]\n",
            "[Epoch 26/200] [Batch 895/938] [D loss: 0.672560] [G loss: 0.076642]\n",
            "[Epoch 26/200] [Batch 896/938] [D loss: 0.644473] [G loss: 0.068982]\n",
            "[Epoch 26/200] [Batch 897/938] [D loss: 0.656098] [G loss: 0.071093]\n",
            "[Epoch 26/200] [Batch 898/938] [D loss: 0.646134] [G loss: 0.072177]\n",
            "[Epoch 26/200] [Batch 899/938] [D loss: 0.620116] [G loss: 0.075240]\n",
            "[Epoch 26/200] [Batch 900/938] [D loss: 0.611090] [G loss: 0.072233]\n",
            "[Epoch 26/200] [Batch 901/938] [D loss: 0.632782] [G loss: 0.072415]\n",
            "[Epoch 26/200] [Batch 902/938] [D loss: 0.638088] [G loss: 0.074381]\n",
            "[Epoch 26/200] [Batch 903/938] [D loss: 0.627059] [G loss: 0.074034]\n",
            "[Epoch 26/200] [Batch 904/938] [D loss: 0.619885] [G loss: 0.073494]\n",
            "[Epoch 26/200] [Batch 905/938] [D loss: 0.657948] [G loss: 0.071918]\n",
            "[Epoch 26/200] [Batch 906/938] [D loss: 0.619451] [G loss: 0.074459]\n",
            "[Epoch 26/200] [Batch 907/938] [D loss: 0.636030] [G loss: 0.068786]\n",
            "[Epoch 26/200] [Batch 908/938] [D loss: 0.649222] [G loss: 0.067648]\n",
            "[Epoch 26/200] [Batch 909/938] [D loss: 0.632885] [G loss: 0.083182]\n",
            "[Epoch 26/200] [Batch 910/938] [D loss: 0.631711] [G loss: 0.077102]\n",
            "[Epoch 26/200] [Batch 911/938] [D loss: 0.663704] [G loss: 0.074277]\n",
            "[Epoch 26/200] [Batch 912/938] [D loss: 0.631828] [G loss: 0.076879]\n",
            "[Epoch 26/200] [Batch 913/938] [D loss: 0.641061] [G loss: 0.066299]\n",
            "[Epoch 26/200] [Batch 914/938] [D loss: 0.639260] [G loss: 0.073392]\n",
            "[Epoch 26/200] [Batch 915/938] [D loss: 0.676235] [G loss: 0.070334]\n",
            "[Epoch 26/200] [Batch 916/938] [D loss: 0.646459] [G loss: 0.072376]\n",
            "[Epoch 26/200] [Batch 917/938] [D loss: 0.621326] [G loss: 0.070065]\n",
            "[Epoch 26/200] [Batch 918/938] [D loss: 0.620870] [G loss: 0.068559]\n",
            "[Epoch 26/200] [Batch 919/938] [D loss: 0.626554] [G loss: 0.067950]\n",
            "[Epoch 26/200] [Batch 920/938] [D loss: 0.596898] [G loss: 0.067977]\n",
            "[Epoch 26/200] [Batch 921/938] [D loss: 0.656918] [G loss: 0.074633]\n",
            "[Epoch 26/200] [Batch 922/938] [D loss: 0.637957] [G loss: 0.076898]\n",
            "[Epoch 26/200] [Batch 923/938] [D loss: 0.665359] [G loss: 0.065793]\n",
            "[Epoch 26/200] [Batch 924/938] [D loss: 0.635199] [G loss: 0.075422]\n",
            "[Epoch 26/200] [Batch 925/938] [D loss: 0.626243] [G loss: 0.077173]\n",
            "[Epoch 26/200] [Batch 926/938] [D loss: 0.664450] [G loss: 0.066993]\n",
            "[Epoch 26/200] [Batch 927/938] [D loss: 0.656144] [G loss: 0.070051]\n",
            "[Epoch 26/200] [Batch 928/938] [D loss: 0.660643] [G loss: 0.073317]\n",
            "[Epoch 26/200] [Batch 929/938] [D loss: 0.672282] [G loss: 0.077051]\n",
            "[Epoch 26/200] [Batch 930/938] [D loss: 0.664780] [G loss: 0.064272]\n",
            "[Epoch 26/200] [Batch 931/938] [D loss: 0.636281] [G loss: 0.074753]\n",
            "[Epoch 26/200] [Batch 932/938] [D loss: 0.623900] [G loss: 0.068142]\n",
            "[Epoch 26/200] [Batch 933/938] [D loss: 0.622702] [G loss: 0.070503]\n",
            "[Epoch 26/200] [Batch 934/938] [D loss: 0.690377] [G loss: 0.071640]\n",
            "[Epoch 26/200] [Batch 935/938] [D loss: 0.644027] [G loss: 0.072020]\n",
            "[Epoch 26/200] [Batch 936/938] [D loss: 0.638268] [G loss: 0.071596]\n",
            "[Epoch 26/200] [Batch 937/938] [D loss: 0.602203] [G loss: 0.083026]\n",
            "[Epoch 27/200] [Batch 0/938] [D loss: 0.645436] [G loss: 0.073131]\n",
            "[Epoch 27/200] [Batch 1/938] [D loss: 0.636247] [G loss: 0.067190]\n",
            "[Epoch 27/200] [Batch 2/938] [D loss: 0.677827] [G loss: 0.069477]\n",
            "[Epoch 27/200] [Batch 3/938] [D loss: 0.604938] [G loss: 0.076276]\n",
            "[Epoch 27/200] [Batch 4/938] [D loss: 0.630829] [G loss: 0.071033]\n",
            "[Epoch 27/200] [Batch 5/938] [D loss: 0.636654] [G loss: 0.077182]\n",
            "[Epoch 27/200] [Batch 6/938] [D loss: 0.652075] [G loss: 0.067872]\n",
            "[Epoch 27/200] [Batch 7/938] [D loss: 0.657962] [G loss: 0.074290]\n",
            "[Epoch 27/200] [Batch 8/938] [D loss: 0.630476] [G loss: 0.075109]\n",
            "[Epoch 27/200] [Batch 9/938] [D loss: 0.644307] [G loss: 0.074905]\n",
            "[Epoch 27/200] [Batch 10/938] [D loss: 0.610161] [G loss: 0.069003]\n",
            "[Epoch 27/200] [Batch 11/938] [D loss: 0.630400] [G loss: 0.070851]\n",
            "[Epoch 27/200] [Batch 12/938] [D loss: 0.649025] [G loss: 0.078503]\n",
            "[Epoch 27/200] [Batch 13/938] [D loss: 0.607531] [G loss: 0.067952]\n",
            "[Epoch 27/200] [Batch 14/938] [D loss: 0.646957] [G loss: 0.064758]\n",
            "[Epoch 27/200] [Batch 15/938] [D loss: 0.662787] [G loss: 0.065347]\n",
            "[Epoch 27/200] [Batch 16/938] [D loss: 0.642891] [G loss: 0.073253]\n",
            "[Epoch 27/200] [Batch 17/938] [D loss: 0.629663] [G loss: 0.070553]\n",
            "[Epoch 27/200] [Batch 18/938] [D loss: 0.639097] [G loss: 0.073773]\n",
            "[Epoch 27/200] [Batch 19/938] [D loss: 0.576456] [G loss: 0.067710]\n",
            "[Epoch 27/200] [Batch 20/938] [D loss: 0.612497] [G loss: 0.070137]\n",
            "[Epoch 27/200] [Batch 21/938] [D loss: 0.588358] [G loss: 0.072738]\n",
            "[Epoch 27/200] [Batch 22/938] [D loss: 0.630742] [G loss: 0.069809]\n",
            "[Epoch 27/200] [Batch 23/938] [D loss: 0.607379] [G loss: 0.082040]\n",
            "[Epoch 27/200] [Batch 24/938] [D loss: 0.625793] [G loss: 0.073485]\n",
            "[Epoch 27/200] [Batch 25/938] [D loss: 0.619574] [G loss: 0.075603]\n",
            "[Epoch 27/200] [Batch 26/938] [D loss: 0.623195] [G loss: 0.064337]\n",
            "[Epoch 27/200] [Batch 27/938] [D loss: 0.636240] [G loss: 0.078748]\n",
            "[Epoch 27/200] [Batch 28/938] [D loss: 0.644542] [G loss: 0.067708]\n",
            "[Epoch 27/200] [Batch 29/938] [D loss: 0.638676] [G loss: 0.074135]\n",
            "[Epoch 27/200] [Batch 30/938] [D loss: 0.640994] [G loss: 0.073708]\n",
            "[Epoch 27/200] [Batch 31/938] [D loss: 0.598490] [G loss: 0.064572]\n",
            "[Epoch 27/200] [Batch 32/938] [D loss: 0.619558] [G loss: 0.075515]\n",
            "[Epoch 27/200] [Batch 33/938] [D loss: 0.625526] [G loss: 0.070855]\n",
            "[Epoch 27/200] [Batch 34/938] [D loss: 0.637675] [G loss: 0.073635]\n",
            "[Epoch 27/200] [Batch 35/938] [D loss: 0.626944] [G loss: 0.069903]\n",
            "[Epoch 27/200] [Batch 36/938] [D loss: 0.671047] [G loss: 0.067486]\n",
            "[Epoch 27/200] [Batch 37/938] [D loss: 0.657092] [G loss: 0.079053]\n",
            "[Epoch 27/200] [Batch 38/938] [D loss: 0.646368] [G loss: 0.073050]\n",
            "[Epoch 27/200] [Batch 39/938] [D loss: 0.631896] [G loss: 0.071804]\n",
            "[Epoch 27/200] [Batch 40/938] [D loss: 0.638764] [G loss: 0.067743]\n",
            "[Epoch 27/200] [Batch 41/938] [D loss: 0.698195] [G loss: 0.080470]\n",
            "[Epoch 27/200] [Batch 42/938] [D loss: 0.656973] [G loss: 0.064941]\n",
            "[Epoch 27/200] [Batch 43/938] [D loss: 0.636230] [G loss: 0.068642]\n",
            "[Epoch 27/200] [Batch 44/938] [D loss: 0.595350] [G loss: 0.076840]\n",
            "[Epoch 27/200] [Batch 45/938] [D loss: 0.673660] [G loss: 0.067132]\n",
            "[Epoch 27/200] [Batch 46/938] [D loss: 0.637138] [G loss: 0.067475]\n",
            "[Epoch 27/200] [Batch 47/938] [D loss: 0.666815] [G loss: 0.069401]\n",
            "[Epoch 27/200] [Batch 48/938] [D loss: 0.592684] [G loss: 0.076233]\n",
            "[Epoch 27/200] [Batch 49/938] [D loss: 0.601282] [G loss: 0.068554]\n",
            "[Epoch 27/200] [Batch 50/938] [D loss: 0.643324] [G loss: 0.070695]\n",
            "[Epoch 27/200] [Batch 51/938] [D loss: 0.645576] [G loss: 0.063246]\n",
            "[Epoch 27/200] [Batch 52/938] [D loss: 0.624345] [G loss: 0.068442]\n",
            "[Epoch 27/200] [Batch 53/938] [D loss: 0.650852] [G loss: 0.077812]\n",
            "[Epoch 27/200] [Batch 54/938] [D loss: 0.618765] [G loss: 0.066315]\n",
            "[Epoch 27/200] [Batch 55/938] [D loss: 0.614082] [G loss: 0.075353]\n",
            "[Epoch 27/200] [Batch 56/938] [D loss: 0.628599] [G loss: 0.067592]\n",
            "[Epoch 27/200] [Batch 57/938] [D loss: 0.623916] [G loss: 0.070755]\n",
            "[Epoch 27/200] [Batch 58/938] [D loss: 0.678440] [G loss: 0.070111]\n",
            "[Epoch 27/200] [Batch 59/938] [D loss: 0.657505] [G loss: 0.067107]\n",
            "[Epoch 27/200] [Batch 60/938] [D loss: 0.634363] [G loss: 0.083227]\n",
            "[Epoch 27/200] [Batch 61/938] [D loss: 0.621277] [G loss: 0.071203]\n",
            "[Epoch 27/200] [Batch 62/938] [D loss: 0.668895] [G loss: 0.073377]\n",
            "[Epoch 27/200] [Batch 63/938] [D loss: 0.622819] [G loss: 0.074283]\n",
            "[Epoch 27/200] [Batch 64/938] [D loss: 0.625898] [G loss: 0.071659]\n",
            "[Epoch 27/200] [Batch 65/938] [D loss: 0.633883] [G loss: 0.081084]\n",
            "[Epoch 27/200] [Batch 66/938] [D loss: 0.658903] [G loss: 0.064474]\n",
            "[Epoch 27/200] [Batch 67/938] [D loss: 0.645972] [G loss: 0.076727]\n",
            "[Epoch 27/200] [Batch 68/938] [D loss: 0.626683] [G loss: 0.072712]\n",
            "[Epoch 27/200] [Batch 69/938] [D loss: 0.665886] [G loss: 0.070928]\n",
            "[Epoch 27/200] [Batch 70/938] [D loss: 0.653431] [G loss: 0.072316]\n",
            "[Epoch 27/200] [Batch 71/938] [D loss: 0.646470] [G loss: 0.072610]\n",
            "[Epoch 27/200] [Batch 72/938] [D loss: 0.676832] [G loss: 0.065626]\n",
            "[Epoch 27/200] [Batch 73/938] [D loss: 0.675488] [G loss: 0.069978]\n",
            "[Epoch 27/200] [Batch 74/938] [D loss: 0.622631] [G loss: 0.078131]\n",
            "[Epoch 27/200] [Batch 75/938] [D loss: 0.668175] [G loss: 0.075265]\n",
            "[Epoch 27/200] [Batch 76/938] [D loss: 0.631491] [G loss: 0.070650]\n",
            "[Epoch 27/200] [Batch 77/938] [D loss: 0.637966] [G loss: 0.077114]\n",
            "[Epoch 27/200] [Batch 78/938] [D loss: 0.681737] [G loss: 0.066646]\n",
            "[Epoch 27/200] [Batch 79/938] [D loss: 0.629770] [G loss: 0.073527]\n",
            "[Epoch 27/200] [Batch 80/938] [D loss: 0.618113] [G loss: 0.069874]\n",
            "[Epoch 27/200] [Batch 81/938] [D loss: 0.626349] [G loss: 0.071659]\n",
            "[Epoch 27/200] [Batch 82/938] [D loss: 0.644017] [G loss: 0.072473]\n",
            "[Epoch 27/200] [Batch 83/938] [D loss: 0.652826] [G loss: 0.073265]\n",
            "[Epoch 27/200] [Batch 84/938] [D loss: 0.671433] [G loss: 0.074074]\n",
            "[Epoch 27/200] [Batch 85/938] [D loss: 0.670112] [G loss: 0.071973]\n",
            "[Epoch 27/200] [Batch 86/938] [D loss: 0.608478] [G loss: 0.073830]\n",
            "[Epoch 27/200] [Batch 87/938] [D loss: 0.658630] [G loss: 0.078641]\n",
            "[Epoch 27/200] [Batch 88/938] [D loss: 0.684498] [G loss: 0.077193]\n",
            "[Epoch 27/200] [Batch 89/938] [D loss: 0.664358] [G loss: 0.072310]\n",
            "[Epoch 27/200] [Batch 90/938] [D loss: 0.670092] [G loss: 0.072263]\n",
            "[Epoch 27/200] [Batch 91/938] [D loss: 0.627492] [G loss: 0.077951]\n",
            "[Epoch 27/200] [Batch 92/938] [D loss: 0.630726] [G loss: 0.068879]\n",
            "[Epoch 27/200] [Batch 93/938] [D loss: 0.631491] [G loss: 0.070900]\n",
            "[Epoch 27/200] [Batch 94/938] [D loss: 0.661116] [G loss: 0.065783]\n",
            "[Epoch 27/200] [Batch 95/938] [D loss: 0.620163] [G loss: 0.075720]\n",
            "[Epoch 27/200] [Batch 96/938] [D loss: 0.651269] [G loss: 0.066744]\n",
            "[Epoch 27/200] [Batch 97/938] [D loss: 0.625939] [G loss: 0.073331]\n",
            "[Epoch 27/200] [Batch 98/938] [D loss: 0.630407] [G loss: 0.069471]\n",
            "[Epoch 27/200] [Batch 99/938] [D loss: 0.625956] [G loss: 0.076169]\n",
            "[Epoch 27/200] [Batch 100/938] [D loss: 0.631539] [G loss: 0.072574]\n",
            "[Epoch 27/200] [Batch 101/938] [D loss: 0.638417] [G loss: 0.076798]\n",
            "[Epoch 27/200] [Batch 102/938] [D loss: 0.632056] [G loss: 0.073158]\n",
            "[Epoch 27/200] [Batch 103/938] [D loss: 0.619934] [G loss: 0.071624]\n",
            "[Epoch 27/200] [Batch 104/938] [D loss: 0.641712] [G loss: 0.067724]\n",
            "[Epoch 27/200] [Batch 105/938] [D loss: 0.638927] [G loss: 0.072070]\n",
            "[Epoch 27/200] [Batch 106/938] [D loss: 0.606419] [G loss: 0.071634]\n",
            "[Epoch 27/200] [Batch 107/938] [D loss: 0.642941] [G loss: 0.080605]\n",
            "[Epoch 27/200] [Batch 108/938] [D loss: 0.622019] [G loss: 0.070397]\n",
            "[Epoch 27/200] [Batch 109/938] [D loss: 0.646566] [G loss: 0.069827]\n",
            "[Epoch 27/200] [Batch 110/938] [D loss: 0.641020] [G loss: 0.069629]\n",
            "[Epoch 27/200] [Batch 111/938] [D loss: 0.634165] [G loss: 0.071220]\n",
            "[Epoch 27/200] [Batch 112/938] [D loss: 0.637596] [G loss: 0.075418]\n",
            "[Epoch 27/200] [Batch 113/938] [D loss: 0.664728] [G loss: 0.076184]\n",
            "[Epoch 27/200] [Batch 114/938] [D loss: 0.617001] [G loss: 0.075650]\n",
            "[Epoch 27/200] [Batch 115/938] [D loss: 0.663855] [G loss: 0.073055]\n",
            "[Epoch 27/200] [Batch 116/938] [D loss: 0.649480] [G loss: 0.073227]\n",
            "[Epoch 27/200] [Batch 117/938] [D loss: 0.636219] [G loss: 0.071274]\n",
            "[Epoch 27/200] [Batch 118/938] [D loss: 0.607072] [G loss: 0.076518]\n",
            "[Epoch 27/200] [Batch 119/938] [D loss: 0.648280] [G loss: 0.070517]\n",
            "[Epoch 27/200] [Batch 120/938] [D loss: 0.654173] [G loss: 0.077094]\n",
            "[Epoch 27/200] [Batch 121/938] [D loss: 0.657702] [G loss: 0.074555]\n",
            "[Epoch 27/200] [Batch 122/938] [D loss: 0.611706] [G loss: 0.073717]\n",
            "[Epoch 27/200] [Batch 123/938] [D loss: 0.641551] [G loss: 0.073371]\n",
            "[Epoch 27/200] [Batch 124/938] [D loss: 0.657810] [G loss: 0.074206]\n",
            "[Epoch 27/200] [Batch 125/938] [D loss: 0.687194] [G loss: 0.075086]\n",
            "[Epoch 27/200] [Batch 126/938] [D loss: 0.622869] [G loss: 0.080338]\n",
            "[Epoch 27/200] [Batch 127/938] [D loss: 0.658439] [G loss: 0.069244]\n",
            "[Epoch 27/200] [Batch 128/938] [D loss: 0.634144] [G loss: 0.070127]\n",
            "[Epoch 27/200] [Batch 129/938] [D loss: 0.625940] [G loss: 0.068530]\n",
            "[Epoch 27/200] [Batch 130/938] [D loss: 0.673365] [G loss: 0.081323]\n",
            "[Epoch 27/200] [Batch 131/938] [D loss: 0.638385] [G loss: 0.071554]\n",
            "[Epoch 27/200] [Batch 132/938] [D loss: 0.638014] [G loss: 0.068957]\n",
            "[Epoch 27/200] [Batch 133/938] [D loss: 0.618303] [G loss: 0.074716]\n",
            "[Epoch 27/200] [Batch 134/938] [D loss: 0.614599] [G loss: 0.071814]\n",
            "[Epoch 27/200] [Batch 135/938] [D loss: 0.625192] [G loss: 0.071062]\n",
            "[Epoch 27/200] [Batch 136/938] [D loss: 0.624622] [G loss: 0.072982]\n",
            "[Epoch 27/200] [Batch 137/938] [D loss: 0.667620] [G loss: 0.070258]\n",
            "[Epoch 27/200] [Batch 138/938] [D loss: 0.657307] [G loss: 0.072619]\n",
            "[Epoch 27/200] [Batch 139/938] [D loss: 0.641570] [G loss: 0.068327]\n",
            "[Epoch 27/200] [Batch 140/938] [D loss: 0.635070] [G loss: 0.071231]\n",
            "[Epoch 27/200] [Batch 141/938] [D loss: 0.637307] [G loss: 0.067708]\n",
            "[Epoch 27/200] [Batch 142/938] [D loss: 0.630638] [G loss: 0.064861]\n",
            "[Epoch 27/200] [Batch 143/938] [D loss: 0.641870] [G loss: 0.071032]\n",
            "[Epoch 27/200] [Batch 144/938] [D loss: 0.644307] [G loss: 0.066084]\n",
            "[Epoch 27/200] [Batch 145/938] [D loss: 0.603829] [G loss: 0.074424]\n",
            "[Epoch 27/200] [Batch 146/938] [D loss: 0.647485] [G loss: 0.072019]\n",
            "[Epoch 27/200] [Batch 147/938] [D loss: 0.619795] [G loss: 0.071100]\n",
            "[Epoch 27/200] [Batch 148/938] [D loss: 0.604369] [G loss: 0.075200]\n",
            "[Epoch 27/200] [Batch 149/938] [D loss: 0.640791] [G loss: 0.072277]\n",
            "[Epoch 27/200] [Batch 150/938] [D loss: 0.676391] [G loss: 0.076141]\n",
            "[Epoch 27/200] [Batch 151/938] [D loss: 0.636462] [G loss: 0.072429]\n",
            "[Epoch 27/200] [Batch 152/938] [D loss: 0.664674] [G loss: 0.068256]\n",
            "[Epoch 27/200] [Batch 153/938] [D loss: 0.630358] [G loss: 0.078842]\n",
            "[Epoch 27/200] [Batch 154/938] [D loss: 0.651684] [G loss: 0.068345]\n",
            "[Epoch 27/200] [Batch 155/938] [D loss: 0.632204] [G loss: 0.077498]\n",
            "[Epoch 27/200] [Batch 156/938] [D loss: 0.639211] [G loss: 0.077760]\n",
            "[Epoch 27/200] [Batch 157/938] [D loss: 0.622312] [G loss: 0.068744]\n",
            "[Epoch 27/200] [Batch 158/938] [D loss: 0.621174] [G loss: 0.066579]\n",
            "[Epoch 27/200] [Batch 159/938] [D loss: 0.620270] [G loss: 0.072929]\n",
            "[Epoch 27/200] [Batch 160/938] [D loss: 0.637237] [G loss: 0.067823]\n",
            "[Epoch 27/200] [Batch 161/938] [D loss: 0.591625] [G loss: 0.072966]\n",
            "[Epoch 27/200] [Batch 162/938] [D loss: 0.632357] [G loss: 0.070854]\n",
            "[Epoch 27/200] [Batch 163/938] [D loss: 0.622542] [G loss: 0.074087]\n",
            "[Epoch 27/200] [Batch 164/938] [D loss: 0.638169] [G loss: 0.072753]\n",
            "[Epoch 27/200] [Batch 165/938] [D loss: 0.636320] [G loss: 0.073189]\n",
            "[Epoch 27/200] [Batch 166/938] [D loss: 0.659335] [G loss: 0.072161]\n",
            "[Epoch 27/200] [Batch 167/938] [D loss: 0.630988] [G loss: 0.076573]\n",
            "[Epoch 27/200] [Batch 168/938] [D loss: 0.641383] [G loss: 0.071189]\n",
            "[Epoch 27/200] [Batch 169/938] [D loss: 0.649924] [G loss: 0.071304]\n",
            "[Epoch 27/200] [Batch 170/938] [D loss: 0.611996] [G loss: 0.078323]\n",
            "[Epoch 27/200] [Batch 171/938] [D loss: 0.634098] [G loss: 0.072327]\n",
            "[Epoch 27/200] [Batch 172/938] [D loss: 0.605688] [G loss: 0.075782]\n",
            "[Epoch 27/200] [Batch 173/938] [D loss: 0.647650] [G loss: 0.074985]\n",
            "[Epoch 27/200] [Batch 174/938] [D loss: 0.636453] [G loss: 0.075353]\n",
            "[Epoch 27/200] [Batch 175/938] [D loss: 0.650799] [G loss: 0.071925]\n",
            "[Epoch 27/200] [Batch 176/938] [D loss: 0.621624] [G loss: 0.069710]\n",
            "[Epoch 27/200] [Batch 177/938] [D loss: 0.649530] [G loss: 0.070482]\n",
            "[Epoch 27/200] [Batch 178/938] [D loss: 0.668906] [G loss: 0.066783]\n",
            "[Epoch 27/200] [Batch 179/938] [D loss: 0.620646] [G loss: 0.076938]\n",
            "[Epoch 27/200] [Batch 180/938] [D loss: 0.673342] [G loss: 0.075536]\n",
            "[Epoch 27/200] [Batch 181/938] [D loss: 0.647390] [G loss: 0.069635]\n",
            "[Epoch 27/200] [Batch 182/938] [D loss: 0.653062] [G loss: 0.062870]\n",
            "[Epoch 27/200] [Batch 183/938] [D loss: 0.661398] [G loss: 0.076413]\n",
            "[Epoch 27/200] [Batch 184/938] [D loss: 0.621046] [G loss: 0.069971]\n",
            "[Epoch 27/200] [Batch 185/938] [D loss: 0.644504] [G loss: 0.072301]\n",
            "[Epoch 27/200] [Batch 186/938] [D loss: 0.619062] [G loss: 0.077553]\n",
            "[Epoch 27/200] [Batch 187/938] [D loss: 0.635847] [G loss: 0.071674]\n",
            "[Epoch 27/200] [Batch 188/938] [D loss: 0.625927] [G loss: 0.069731]\n",
            "[Epoch 27/200] [Batch 189/938] [D loss: 0.648689] [G loss: 0.070737]\n",
            "[Epoch 27/200] [Batch 190/938] [D loss: 0.646426] [G loss: 0.072101]\n",
            "[Epoch 27/200] [Batch 191/938] [D loss: 0.573379] [G loss: 0.070642]\n",
            "[Epoch 27/200] [Batch 192/938] [D loss: 0.618984] [G loss: 0.077139]\n",
            "[Epoch 27/200] [Batch 193/938] [D loss: 0.627104] [G loss: 0.069452]\n",
            "[Epoch 27/200] [Batch 194/938] [D loss: 0.612049] [G loss: 0.065686]\n",
            "[Epoch 27/200] [Batch 195/938] [D loss: 0.651320] [G loss: 0.075167]\n",
            "[Epoch 27/200] [Batch 196/938] [D loss: 0.636170] [G loss: 0.073055]\n",
            "[Epoch 27/200] [Batch 197/938] [D loss: 0.646040] [G loss: 0.078843]\n",
            "[Epoch 27/200] [Batch 198/938] [D loss: 0.623251] [G loss: 0.070949]\n",
            "[Epoch 27/200] [Batch 199/938] [D loss: 0.639572] [G loss: 0.077496]\n",
            "[Epoch 27/200] [Batch 200/938] [D loss: 0.629110] [G loss: 0.077372]\n",
            "[Epoch 27/200] [Batch 201/938] [D loss: 0.597918] [G loss: 0.075619]\n",
            "[Epoch 27/200] [Batch 202/938] [D loss: 0.623818] [G loss: 0.069727]\n",
            "[Epoch 27/200] [Batch 203/938] [D loss: 0.655509] [G loss: 0.071022]\n",
            "[Epoch 27/200] [Batch 204/938] [D loss: 0.639225] [G loss: 0.078301]\n",
            "[Epoch 27/200] [Batch 205/938] [D loss: 0.637189] [G loss: 0.067262]\n",
            "[Epoch 27/200] [Batch 206/938] [D loss: 0.618030] [G loss: 0.073457]\n",
            "[Epoch 27/200] [Batch 207/938] [D loss: 0.626362] [G loss: 0.075012]\n",
            "[Epoch 27/200] [Batch 208/938] [D loss: 0.641786] [G loss: 0.074493]\n",
            "[Epoch 27/200] [Batch 209/938] [D loss: 0.647835] [G loss: 0.076375]\n",
            "[Epoch 27/200] [Batch 210/938] [D loss: 0.597194] [G loss: 0.065006]\n",
            "[Epoch 27/200] [Batch 211/938] [D loss: 0.650697] [G loss: 0.068829]\n",
            "[Epoch 27/200] [Batch 212/938] [D loss: 0.661577] [G loss: 0.072854]\n",
            "[Epoch 27/200] [Batch 213/938] [D loss: 0.665331] [G loss: 0.070581]\n",
            "[Epoch 27/200] [Batch 214/938] [D loss: 0.616254] [G loss: 0.082429]\n",
            "[Epoch 27/200] [Batch 215/938] [D loss: 0.616065] [G loss: 0.075601]\n",
            "[Epoch 27/200] [Batch 216/938] [D loss: 0.595093] [G loss: 0.072436]\n",
            "[Epoch 27/200] [Batch 217/938] [D loss: 0.629040] [G loss: 0.070601]\n",
            "[Epoch 27/200] [Batch 218/938] [D loss: 0.614584] [G loss: 0.069567]\n",
            "[Epoch 27/200] [Batch 219/938] [D loss: 0.631902] [G loss: 0.070679]\n",
            "[Epoch 27/200] [Batch 220/938] [D loss: 0.621208] [G loss: 0.070366]\n",
            "[Epoch 27/200] [Batch 221/938] [D loss: 0.611715] [G loss: 0.069611]\n",
            "[Epoch 27/200] [Batch 222/938] [D loss: 0.654570] [G loss: 0.078158]\n",
            "[Epoch 27/200] [Batch 223/938] [D loss: 0.633738] [G loss: 0.071637]\n",
            "[Epoch 27/200] [Batch 224/938] [D loss: 0.645440] [G loss: 0.063741]\n",
            "[Epoch 27/200] [Batch 225/938] [D loss: 0.605277] [G loss: 0.075748]\n",
            "[Epoch 27/200] [Batch 226/938] [D loss: 0.642922] [G loss: 0.073130]\n",
            "[Epoch 27/200] [Batch 227/938] [D loss: 0.641958] [G loss: 0.078905]\n",
            "[Epoch 27/200] [Batch 228/938] [D loss: 0.605983] [G loss: 0.066710]\n",
            "[Epoch 27/200] [Batch 229/938] [D loss: 0.622840] [G loss: 0.066673]\n",
            "[Epoch 27/200] [Batch 230/938] [D loss: 0.599917] [G loss: 0.073317]\n",
            "[Epoch 27/200] [Batch 231/938] [D loss: 0.607959] [G loss: 0.070648]\n",
            "[Epoch 27/200] [Batch 232/938] [D loss: 0.663862] [G loss: 0.080570]\n",
            "[Epoch 27/200] [Batch 233/938] [D loss: 0.615085] [G loss: 0.072051]\n",
            "[Epoch 27/200] [Batch 234/938] [D loss: 0.626063] [G loss: 0.073508]\n",
            "[Epoch 27/200] [Batch 235/938] [D loss: 0.630124] [G loss: 0.072655]\n",
            "[Epoch 27/200] [Batch 236/938] [D loss: 0.641997] [G loss: 0.071693]\n",
            "[Epoch 27/200] [Batch 237/938] [D loss: 0.628950] [G loss: 0.074605]\n",
            "[Epoch 27/200] [Batch 238/938] [D loss: 0.632585] [G loss: 0.070317]\n",
            "[Epoch 27/200] [Batch 239/938] [D loss: 0.644013] [G loss: 0.072615]\n",
            "[Epoch 27/200] [Batch 240/938] [D loss: 0.624720] [G loss: 0.077813]\n",
            "[Epoch 27/200] [Batch 241/938] [D loss: 0.634851] [G loss: 0.076087]\n",
            "[Epoch 27/200] [Batch 242/938] [D loss: 0.641165] [G loss: 0.079492]\n",
            "[Epoch 27/200] [Batch 243/938] [D loss: 0.647077] [G loss: 0.074851]\n",
            "[Epoch 27/200] [Batch 244/938] [D loss: 0.626492] [G loss: 0.076006]\n",
            "[Epoch 27/200] [Batch 245/938] [D loss: 0.624790] [G loss: 0.076451]\n",
            "[Epoch 27/200] [Batch 246/938] [D loss: 0.619274] [G loss: 0.072269]\n",
            "[Epoch 27/200] [Batch 247/938] [D loss: 0.613991] [G loss: 0.069630]\n",
            "[Epoch 27/200] [Batch 248/938] [D loss: 0.667115] [G loss: 0.068578]\n",
            "[Epoch 27/200] [Batch 249/938] [D loss: 0.642046] [G loss: 0.078820]\n",
            "[Epoch 27/200] [Batch 250/938] [D loss: 0.643962] [G loss: 0.067466]\n",
            "[Epoch 27/200] [Batch 251/938] [D loss: 0.644667] [G loss: 0.074499]\n",
            "[Epoch 27/200] [Batch 252/938] [D loss: 0.619841] [G loss: 0.071551]\n",
            "[Epoch 27/200] [Batch 253/938] [D loss: 0.624696] [G loss: 0.073820]\n",
            "[Epoch 27/200] [Batch 254/938] [D loss: 0.647823] [G loss: 0.073782]\n",
            "[Epoch 27/200] [Batch 255/938] [D loss: 0.648680] [G loss: 0.075635]\n",
            "[Epoch 27/200] [Batch 256/938] [D loss: 0.611448] [G loss: 0.070399]\n",
            "[Epoch 27/200] [Batch 257/938] [D loss: 0.665323] [G loss: 0.068964]\n",
            "[Epoch 27/200] [Batch 258/938] [D loss: 0.660084] [G loss: 0.075182]\n",
            "[Epoch 27/200] [Batch 259/938] [D loss: 0.667727] [G loss: 0.073963]\n",
            "[Epoch 27/200] [Batch 260/938] [D loss: 0.655077] [G loss: 0.085538]\n",
            "[Epoch 27/200] [Batch 261/938] [D loss: 0.651272] [G loss: 0.073105]\n",
            "[Epoch 27/200] [Batch 262/938] [D loss: 0.595364] [G loss: 0.070008]\n",
            "[Epoch 27/200] [Batch 263/938] [D loss: 0.642878] [G loss: 0.073537]\n",
            "[Epoch 27/200] [Batch 264/938] [D loss: 0.618853] [G loss: 0.068961]\n",
            "[Epoch 27/200] [Batch 265/938] [D loss: 0.633319] [G loss: 0.073759]\n",
            "[Epoch 27/200] [Batch 266/938] [D loss: 0.685566] [G loss: 0.072324]\n",
            "[Epoch 27/200] [Batch 267/938] [D loss: 0.657894] [G loss: 0.068001]\n",
            "[Epoch 27/200] [Batch 268/938] [D loss: 0.643746] [G loss: 0.067593]\n",
            "[Epoch 27/200] [Batch 269/938] [D loss: 0.617443] [G loss: 0.073189]\n",
            "[Epoch 27/200] [Batch 270/938] [D loss: 0.645079] [G loss: 0.065733]\n",
            "[Epoch 27/200] [Batch 271/938] [D loss: 0.631372] [G loss: 0.072705]\n",
            "[Epoch 27/200] [Batch 272/938] [D loss: 0.646107] [G loss: 0.077906]\n",
            "[Epoch 27/200] [Batch 273/938] [D loss: 0.614500] [G loss: 0.078710]\n",
            "[Epoch 27/200] [Batch 274/938] [D loss: 0.636764] [G loss: 0.072951]\n",
            "[Epoch 27/200] [Batch 275/938] [D loss: 0.663740] [G loss: 0.074779]\n",
            "[Epoch 27/200] [Batch 276/938] [D loss: 0.673780] [G loss: 0.069504]\n",
            "[Epoch 27/200] [Batch 277/938] [D loss: 0.657472] [G loss: 0.068050]\n",
            "[Epoch 27/200] [Batch 278/938] [D loss: 0.642726] [G loss: 0.075579]\n",
            "[Epoch 27/200] [Batch 279/938] [D loss: 0.627283] [G loss: 0.076263]\n",
            "[Epoch 27/200] [Batch 280/938] [D loss: 0.661411] [G loss: 0.067276]\n",
            "[Epoch 27/200] [Batch 281/938] [D loss: 0.626094] [G loss: 0.079629]\n",
            "[Epoch 27/200] [Batch 282/938] [D loss: 0.617947] [G loss: 0.069566]\n",
            "[Epoch 27/200] [Batch 283/938] [D loss: 0.623922] [G loss: 0.078933]\n",
            "[Epoch 27/200] [Batch 284/938] [D loss: 0.623528] [G loss: 0.075152]\n",
            "[Epoch 27/200] [Batch 285/938] [D loss: 0.631356] [G loss: 0.064300]\n",
            "[Epoch 27/200] [Batch 286/938] [D loss: 0.634673] [G loss: 0.068263]\n",
            "[Epoch 27/200] [Batch 287/938] [D loss: 0.638081] [G loss: 0.066334]\n",
            "[Epoch 27/200] [Batch 288/938] [D loss: 0.625514] [G loss: 0.066811]\n",
            "[Epoch 27/200] [Batch 289/938] [D loss: 0.662273] [G loss: 0.075585]\n",
            "[Epoch 27/200] [Batch 290/938] [D loss: 0.627654] [G loss: 0.077694]\n",
            "[Epoch 27/200] [Batch 291/938] [D loss: 0.652360] [G loss: 0.074058]\n",
            "[Epoch 27/200] [Batch 292/938] [D loss: 0.636843] [G loss: 0.075041]\n",
            "[Epoch 27/200] [Batch 293/938] [D loss: 0.641825] [G loss: 0.074960]\n",
            "[Epoch 27/200] [Batch 294/938] [D loss: 0.629762] [G loss: 0.069937]\n",
            "[Epoch 27/200] [Batch 295/938] [D loss: 0.669086] [G loss: 0.068351]\n",
            "[Epoch 27/200] [Batch 296/938] [D loss: 0.629689] [G loss: 0.067959]\n",
            "[Epoch 27/200] [Batch 297/938] [D loss: 0.641606] [G loss: 0.071786]\n",
            "[Epoch 27/200] [Batch 298/938] [D loss: 0.622387] [G loss: 0.070917]\n",
            "[Epoch 27/200] [Batch 299/938] [D loss: 0.581579] [G loss: 0.073059]\n",
            "[Epoch 27/200] [Batch 300/938] [D loss: 0.629181] [G loss: 0.076480]\n",
            "[Epoch 27/200] [Batch 301/938] [D loss: 0.645243] [G loss: 0.076318]\n",
            "[Epoch 27/200] [Batch 302/938] [D loss: 0.620961] [G loss: 0.071813]\n",
            "[Epoch 27/200] [Batch 303/938] [D loss: 0.636242] [G loss: 0.076122]\n",
            "[Epoch 27/200] [Batch 304/938] [D loss: 0.634954] [G loss: 0.077942]\n",
            "[Epoch 27/200] [Batch 305/938] [D loss: 0.613935] [G loss: 0.069394]\n",
            "[Epoch 27/200] [Batch 306/938] [D loss: 0.641992] [G loss: 0.064515]\n",
            "[Epoch 27/200] [Batch 307/938] [D loss: 0.632705] [G loss: 0.068346]\n",
            "[Epoch 27/200] [Batch 308/938] [D loss: 0.602544] [G loss: 0.078242]\n",
            "[Epoch 27/200] [Batch 309/938] [D loss: 0.666533] [G loss: 0.076415]\n",
            "[Epoch 27/200] [Batch 310/938] [D loss: 0.647869] [G loss: 0.076465]\n",
            "[Epoch 27/200] [Batch 311/938] [D loss: 0.644631] [G loss: 0.070617]\n",
            "[Epoch 27/200] [Batch 312/938] [D loss: 0.644631] [G loss: 0.068352]\n",
            "[Epoch 27/200] [Batch 313/938] [D loss: 0.670474] [G loss: 0.073539]\n",
            "[Epoch 27/200] [Batch 314/938] [D loss: 0.669546] [G loss: 0.070640]\n",
            "[Epoch 27/200] [Batch 315/938] [D loss: 0.641291] [G loss: 0.070713]\n",
            "[Epoch 27/200] [Batch 316/938] [D loss: 0.643004] [G loss: 0.073163]\n",
            "[Epoch 27/200] [Batch 317/938] [D loss: 0.672700] [G loss: 0.069230]\n",
            "[Epoch 27/200] [Batch 318/938] [D loss: 0.622065] [G loss: 0.081708]\n",
            "[Epoch 27/200] [Batch 319/938] [D loss: 0.640089] [G loss: 0.069955]\n",
            "[Epoch 27/200] [Batch 320/938] [D loss: 0.634188] [G loss: 0.075032]\n",
            "[Epoch 27/200] [Batch 321/938] [D loss: 0.692778] [G loss: 0.068065]\n",
            "[Epoch 27/200] [Batch 322/938] [D loss: 0.651512] [G loss: 0.071037]\n",
            "[Epoch 27/200] [Batch 323/938] [D loss: 0.637295] [G loss: 0.072958]\n",
            "[Epoch 27/200] [Batch 324/938] [D loss: 0.632787] [G loss: 0.076738]\n",
            "[Epoch 27/200] [Batch 325/938] [D loss: 0.613301] [G loss: 0.071319]\n",
            "[Epoch 27/200] [Batch 326/938] [D loss: 0.630718] [G loss: 0.071654]\n",
            "[Epoch 27/200] [Batch 327/938] [D loss: 0.609321] [G loss: 0.070334]\n",
            "[Epoch 27/200] [Batch 328/938] [D loss: 0.659818] [G loss: 0.074329]\n",
            "[Epoch 27/200] [Batch 329/938] [D loss: 0.626698] [G loss: 0.067827]\n",
            "[Epoch 27/200] [Batch 330/938] [D loss: 0.619527] [G loss: 0.075663]\n",
            "[Epoch 27/200] [Batch 331/938] [D loss: 0.605269] [G loss: 0.074870]\n",
            "[Epoch 27/200] [Batch 332/938] [D loss: 0.658822] [G loss: 0.079888]\n",
            "[Epoch 27/200] [Batch 333/938] [D loss: 0.611655] [G loss: 0.066341]\n",
            "[Epoch 27/200] [Batch 334/938] [D loss: 0.620033] [G loss: 0.067139]\n",
            "[Epoch 27/200] [Batch 335/938] [D loss: 0.632537] [G loss: 0.064599]\n",
            "[Epoch 27/200] [Batch 336/938] [D loss: 0.647276] [G loss: 0.075829]\n",
            "[Epoch 27/200] [Batch 337/938] [D loss: 0.672488] [G loss: 0.068213]\n",
            "[Epoch 27/200] [Batch 338/938] [D loss: 0.630589] [G loss: 0.068663]\n",
            "[Epoch 27/200] [Batch 339/938] [D loss: 0.612102] [G loss: 0.074293]\n",
            "[Epoch 27/200] [Batch 340/938] [D loss: 0.623525] [G loss: 0.078409]\n",
            "[Epoch 27/200] [Batch 341/938] [D loss: 0.676089] [G loss: 0.064293]\n",
            "[Epoch 27/200] [Batch 342/938] [D loss: 0.620552] [G loss: 0.069226]\n",
            "[Epoch 27/200] [Batch 343/938] [D loss: 0.638501] [G loss: 0.071040]\n",
            "[Epoch 27/200] [Batch 344/938] [D loss: 0.634547] [G loss: 0.071813]\n",
            "[Epoch 27/200] [Batch 345/938] [D loss: 0.668102] [G loss: 0.066374]\n",
            "[Epoch 27/200] [Batch 346/938] [D loss: 0.610066] [G loss: 0.073394]\n",
            "[Epoch 27/200] [Batch 347/938] [D loss: 0.669960] [G loss: 0.071096]\n",
            "[Epoch 27/200] [Batch 348/938] [D loss: 0.663710] [G loss: 0.079208]\n",
            "[Epoch 27/200] [Batch 349/938] [D loss: 0.648224] [G loss: 0.071973]\n",
            "[Epoch 27/200] [Batch 350/938] [D loss: 0.611129] [G loss: 0.069972]\n",
            "[Epoch 27/200] [Batch 351/938] [D loss: 0.635549] [G loss: 0.066426]\n",
            "[Epoch 27/200] [Batch 352/938] [D loss: 0.638304] [G loss: 0.077010]\n",
            "[Epoch 27/200] [Batch 353/938] [D loss: 0.642905] [G loss: 0.072726]\n",
            "[Epoch 27/200] [Batch 354/938] [D loss: 0.626396] [G loss: 0.065013]\n",
            "[Epoch 27/200] [Batch 355/938] [D loss: 0.610809] [G loss: 0.074576]\n",
            "[Epoch 27/200] [Batch 356/938] [D loss: 0.603294] [G loss: 0.064357]\n",
            "[Epoch 27/200] [Batch 357/938] [D loss: 0.635705] [G loss: 0.067762]\n",
            "[Epoch 27/200] [Batch 358/938] [D loss: 0.657786] [G loss: 0.068266]\n",
            "[Epoch 27/200] [Batch 359/938] [D loss: 0.637798] [G loss: 0.073533]\n",
            "[Epoch 27/200] [Batch 360/938] [D loss: 0.600502] [G loss: 0.069502]\n",
            "[Epoch 27/200] [Batch 361/938] [D loss: 0.659316] [G loss: 0.077017]\n",
            "[Epoch 27/200] [Batch 362/938] [D loss: 0.629035] [G loss: 0.072418]\n",
            "[Epoch 27/200] [Batch 363/938] [D loss: 0.638421] [G loss: 0.077541]\n",
            "[Epoch 27/200] [Batch 364/938] [D loss: 0.663827] [G loss: 0.077188]\n",
            "[Epoch 27/200] [Batch 365/938] [D loss: 0.663729] [G loss: 0.074084]\n",
            "[Epoch 27/200] [Batch 366/938] [D loss: 0.602320] [G loss: 0.074193]\n",
            "[Epoch 27/200] [Batch 367/938] [D loss: 0.635498] [G loss: 0.069633]\n",
            "[Epoch 27/200] [Batch 368/938] [D loss: 0.664765] [G loss: 0.075876]\n",
            "[Epoch 27/200] [Batch 369/938] [D loss: 0.605388] [G loss: 0.074122]\n",
            "[Epoch 27/200] [Batch 370/938] [D loss: 0.652453] [G loss: 0.071976]\n",
            "[Epoch 27/200] [Batch 371/938] [D loss: 0.615815] [G loss: 0.071633]\n",
            "[Epoch 27/200] [Batch 372/938] [D loss: 0.660129] [G loss: 0.073291]\n",
            "[Epoch 27/200] [Batch 373/938] [D loss: 0.626969] [G loss: 0.066231]\n",
            "[Epoch 27/200] [Batch 374/938] [D loss: 0.633953] [G loss: 0.084504]\n",
            "[Epoch 27/200] [Batch 375/938] [D loss: 0.623499] [G loss: 0.073641]\n",
            "[Epoch 27/200] [Batch 376/938] [D loss: 0.611576] [G loss: 0.077086]\n",
            "[Epoch 27/200] [Batch 377/938] [D loss: 0.643124] [G loss: 0.073908]\n",
            "[Epoch 27/200] [Batch 378/938] [D loss: 0.624180] [G loss: 0.071724]\n",
            "[Epoch 27/200] [Batch 379/938] [D loss: 0.638014] [G loss: 0.072816]\n",
            "[Epoch 27/200] [Batch 380/938] [D loss: 0.618258] [G loss: 0.071751]\n",
            "[Epoch 27/200] [Batch 381/938] [D loss: 0.612118] [G loss: 0.069779]\n",
            "[Epoch 27/200] [Batch 382/938] [D loss: 0.613253] [G loss: 0.066920]\n",
            "[Epoch 27/200] [Batch 383/938] [D loss: 0.617385] [G loss: 0.074483]\n",
            "[Epoch 27/200] [Batch 384/938] [D loss: 0.610594] [G loss: 0.073193]\n",
            "[Epoch 27/200] [Batch 385/938] [D loss: 0.648314] [G loss: 0.074570]\n",
            "[Epoch 27/200] [Batch 386/938] [D loss: 0.614041] [G loss: 0.077832]\n",
            "[Epoch 27/200] [Batch 387/938] [D loss: 0.645394] [G loss: 0.071376]\n",
            "[Epoch 27/200] [Batch 388/938] [D loss: 0.628293] [G loss: 0.070548]\n",
            "[Epoch 27/200] [Batch 389/938] [D loss: 0.644483] [G loss: 0.065062]\n",
            "[Epoch 27/200] [Batch 390/938] [D loss: 0.641996] [G loss: 0.070722]\n",
            "[Epoch 27/200] [Batch 391/938] [D loss: 0.636137] [G loss: 0.063055]\n",
            "[Epoch 27/200] [Batch 392/938] [D loss: 0.640955] [G loss: 0.068238]\n",
            "[Epoch 27/200] [Batch 393/938] [D loss: 0.626441] [G loss: 0.079681]\n",
            "[Epoch 27/200] [Batch 394/938] [D loss: 0.614665] [G loss: 0.068780]\n",
            "[Epoch 27/200] [Batch 395/938] [D loss: 0.642426] [G loss: 0.071199]\n",
            "[Epoch 27/200] [Batch 396/938] [D loss: 0.638388] [G loss: 0.069406]\n",
            "[Epoch 27/200] [Batch 397/938] [D loss: 0.607844] [G loss: 0.071723]\n",
            "[Epoch 27/200] [Batch 398/938] [D loss: 0.652500] [G loss: 0.069192]\n",
            "[Epoch 27/200] [Batch 399/938] [D loss: 0.659545] [G loss: 0.072632]\n",
            "[Epoch 27/200] [Batch 400/938] [D loss: 0.653428] [G loss: 0.072255]\n",
            "[Epoch 27/200] [Batch 401/938] [D loss: 0.643430] [G loss: 0.073595]\n",
            "[Epoch 27/200] [Batch 402/938] [D loss: 0.608637] [G loss: 0.074829]\n",
            "[Epoch 27/200] [Batch 403/938] [D loss: 0.664992] [G loss: 0.080193]\n",
            "[Epoch 27/200] [Batch 404/938] [D loss: 0.619918] [G loss: 0.072854]\n",
            "[Epoch 27/200] [Batch 405/938] [D loss: 0.628518] [G loss: 0.076774]\n",
            "[Epoch 27/200] [Batch 406/938] [D loss: 0.622041] [G loss: 0.074633]\n",
            "[Epoch 27/200] [Batch 407/938] [D loss: 0.646394] [G loss: 0.070696]\n",
            "[Epoch 27/200] [Batch 408/938] [D loss: 0.664993] [G loss: 0.072444]\n",
            "[Epoch 27/200] [Batch 409/938] [D loss: 0.626831] [G loss: 0.071837]\n",
            "[Epoch 27/200] [Batch 410/938] [D loss: 0.611907] [G loss: 0.068657]\n",
            "[Epoch 27/200] [Batch 411/938] [D loss: 0.683279] [G loss: 0.068610]\n",
            "[Epoch 27/200] [Batch 412/938] [D loss: 0.644774] [G loss: 0.071402]\n",
            "[Epoch 27/200] [Batch 413/938] [D loss: 0.634368] [G loss: 0.069488]\n",
            "[Epoch 27/200] [Batch 414/938] [D loss: 0.647785] [G loss: 0.072925]\n",
            "[Epoch 27/200] [Batch 415/938] [D loss: 0.645178] [G loss: 0.069820]\n",
            "[Epoch 27/200] [Batch 416/938] [D loss: 0.630645] [G loss: 0.073500]\n",
            "[Epoch 27/200] [Batch 417/938] [D loss: 0.659204] [G loss: 0.067422]\n",
            "[Epoch 27/200] [Batch 418/938] [D loss: 0.647911] [G loss: 0.067814]\n",
            "[Epoch 27/200] [Batch 419/938] [D loss: 0.677808] [G loss: 0.071332]\n",
            "[Epoch 27/200] [Batch 420/938] [D loss: 0.611607] [G loss: 0.081863]\n",
            "[Epoch 27/200] [Batch 421/938] [D loss: 0.643819] [G loss: 0.074458]\n",
            "[Epoch 27/200] [Batch 422/938] [D loss: 0.604646] [G loss: 0.072643]\n",
            "[Epoch 27/200] [Batch 423/938] [D loss: 0.645490] [G loss: 0.071430]\n",
            "[Epoch 27/200] [Batch 424/938] [D loss: 0.615931] [G loss: 0.070192]\n",
            "[Epoch 27/200] [Batch 425/938] [D loss: 0.628105] [G loss: 0.075092]\n",
            "[Epoch 27/200] [Batch 426/938] [D loss: 0.641394] [G loss: 0.072899]\n",
            "[Epoch 27/200] [Batch 427/938] [D loss: 0.650030] [G loss: 0.070272]\n",
            "[Epoch 27/200] [Batch 428/938] [D loss: 0.635803] [G loss: 0.069621]\n",
            "[Epoch 27/200] [Batch 429/938] [D loss: 0.662646] [G loss: 0.073886]\n",
            "[Epoch 27/200] [Batch 430/938] [D loss: 0.658880] [G loss: 0.073981]\n",
            "[Epoch 27/200] [Batch 431/938] [D loss: 0.637362] [G loss: 0.072561]\n",
            "[Epoch 27/200] [Batch 432/938] [D loss: 0.652063] [G loss: 0.079705]\n",
            "[Epoch 27/200] [Batch 433/938] [D loss: 0.650971] [G loss: 0.078667]\n",
            "[Epoch 27/200] [Batch 434/938] [D loss: 0.623581] [G loss: 0.076077]\n",
            "[Epoch 27/200] [Batch 435/938] [D loss: 0.637801] [G loss: 0.067986]\n",
            "[Epoch 27/200] [Batch 436/938] [D loss: 0.650631] [G loss: 0.069869]\n",
            "[Epoch 27/200] [Batch 437/938] [D loss: 0.631199] [G loss: 0.069601]\n",
            "[Epoch 27/200] [Batch 438/938] [D loss: 0.653126] [G loss: 0.067700]\n",
            "[Epoch 27/200] [Batch 439/938] [D loss: 0.632132] [G loss: 0.080545]\n",
            "[Epoch 27/200] [Batch 440/938] [D loss: 0.625117] [G loss: 0.073711]\n",
            "[Epoch 27/200] [Batch 441/938] [D loss: 0.670534] [G loss: 0.071443]\n",
            "[Epoch 27/200] [Batch 442/938] [D loss: 0.629376] [G loss: 0.073168]\n",
            "[Epoch 27/200] [Batch 443/938] [D loss: 0.621071] [G loss: 0.071958]\n",
            "[Epoch 27/200] [Batch 444/938] [D loss: 0.680570] [G loss: 0.069196]\n",
            "[Epoch 27/200] [Batch 445/938] [D loss: 0.630587] [G loss: 0.067928]\n",
            "[Epoch 27/200] [Batch 446/938] [D loss: 0.669223] [G loss: 0.069021]\n",
            "[Epoch 27/200] [Batch 447/938] [D loss: 0.616853] [G loss: 0.073627]\n",
            "[Epoch 27/200] [Batch 448/938] [D loss: 0.611236] [G loss: 0.072630]\n",
            "[Epoch 27/200] [Batch 449/938] [D loss: 0.647321] [G loss: 0.073297]\n",
            "[Epoch 27/200] [Batch 450/938] [D loss: 0.600190] [G loss: 0.065911]\n",
            "[Epoch 27/200] [Batch 451/938] [D loss: 0.622987] [G loss: 0.073487]\n",
            "[Epoch 27/200] [Batch 452/938] [D loss: 0.635461] [G loss: 0.073118]\n",
            "[Epoch 27/200] [Batch 453/938] [D loss: 0.633576] [G loss: 0.076475]\n",
            "[Epoch 27/200] [Batch 454/938] [D loss: 0.645840] [G loss: 0.071752]\n",
            "[Epoch 27/200] [Batch 455/938] [D loss: 0.644542] [G loss: 0.071279]\n",
            "[Epoch 27/200] [Batch 456/938] [D loss: 0.620206] [G loss: 0.068238]\n",
            "[Epoch 27/200] [Batch 457/938] [D loss: 0.638770] [G loss: 0.069232]\n",
            "[Epoch 27/200] [Batch 458/938] [D loss: 0.631221] [G loss: 0.082346]\n",
            "[Epoch 27/200] [Batch 459/938] [D loss: 0.630215] [G loss: 0.073801]\n",
            "[Epoch 27/200] [Batch 460/938] [D loss: 0.673592] [G loss: 0.072902]\n",
            "[Epoch 27/200] [Batch 461/938] [D loss: 0.626389] [G loss: 0.078316]\n",
            "[Epoch 27/200] [Batch 462/938] [D loss: 0.641825] [G loss: 0.082420]\n",
            "[Epoch 27/200] [Batch 463/938] [D loss: 0.616416] [G loss: 0.066195]\n",
            "[Epoch 27/200] [Batch 464/938] [D loss: 0.650385] [G loss: 0.074666]\n",
            "[Epoch 27/200] [Batch 465/938] [D loss: 0.631726] [G loss: 0.071390]\n",
            "[Epoch 27/200] [Batch 466/938] [D loss: 0.662743] [G loss: 0.071485]\n",
            "[Epoch 27/200] [Batch 467/938] [D loss: 0.621880] [G loss: 0.065521]\n",
            "[Epoch 27/200] [Batch 468/938] [D loss: 0.613957] [G loss: 0.069667]\n",
            "[Epoch 27/200] [Batch 469/938] [D loss: 0.654260] [G loss: 0.078076]\n",
            "[Epoch 27/200] [Batch 470/938] [D loss: 0.614884] [G loss: 0.067108]\n",
            "[Epoch 27/200] [Batch 471/938] [D loss: 0.654857] [G loss: 0.073340]\n",
            "[Epoch 27/200] [Batch 472/938] [D loss: 0.671739] [G loss: 0.065440]\n",
            "[Epoch 27/200] [Batch 473/938] [D loss: 0.648045] [G loss: 0.068800]\n",
            "[Epoch 27/200] [Batch 474/938] [D loss: 0.653858] [G loss: 0.075172]\n",
            "[Epoch 27/200] [Batch 475/938] [D loss: 0.653587] [G loss: 0.079467]\n",
            "[Epoch 27/200] [Batch 476/938] [D loss: 0.657483] [G loss: 0.069853]\n",
            "[Epoch 27/200] [Batch 477/938] [D loss: 0.623269] [G loss: 0.074996]\n",
            "[Epoch 27/200] [Batch 478/938] [D loss: 0.666038] [G loss: 0.072797]\n",
            "[Epoch 27/200] [Batch 479/938] [D loss: 0.641643] [G loss: 0.071007]\n",
            "[Epoch 27/200] [Batch 480/938] [D loss: 0.622580] [G loss: 0.078729]\n",
            "[Epoch 27/200] [Batch 481/938] [D loss: 0.621604] [G loss: 0.070266]\n",
            "[Epoch 27/200] [Batch 482/938] [D loss: 0.643744] [G loss: 0.070221]\n",
            "[Epoch 27/200] [Batch 483/938] [D loss: 0.655944] [G loss: 0.080053]\n",
            "[Epoch 27/200] [Batch 484/938] [D loss: 0.623822] [G loss: 0.076999]\n",
            "[Epoch 27/200] [Batch 485/938] [D loss: 0.620276] [G loss: 0.069518]\n",
            "[Epoch 27/200] [Batch 486/938] [D loss: 0.639922] [G loss: 0.069464]\n",
            "[Epoch 27/200] [Batch 487/938] [D loss: 0.598474] [G loss: 0.072843]\n",
            "[Epoch 27/200] [Batch 488/938] [D loss: 0.619884] [G loss: 0.068241]\n",
            "[Epoch 27/200] [Batch 489/938] [D loss: 0.617368] [G loss: 0.075080]\n",
            "[Epoch 27/200] [Batch 490/938] [D loss: 0.636701] [G loss: 0.079618]\n",
            "[Epoch 27/200] [Batch 491/938] [D loss: 0.652862] [G loss: 0.073495]\n",
            "[Epoch 27/200] [Batch 492/938] [D loss: 0.659380] [G loss: 0.076723]\n",
            "[Epoch 27/200] [Batch 493/938] [D loss: 0.638502] [G loss: 0.080198]\n",
            "[Epoch 27/200] [Batch 494/938] [D loss: 0.622358] [G loss: 0.070910]\n",
            "[Epoch 27/200] [Batch 495/938] [D loss: 0.664340] [G loss: 0.065216]\n",
            "[Epoch 27/200] [Batch 496/938] [D loss: 0.615646] [G loss: 0.075428]\n",
            "[Epoch 27/200] [Batch 497/938] [D loss: 0.658672] [G loss: 0.069928]\n",
            "[Epoch 27/200] [Batch 498/938] [D loss: 0.641591] [G loss: 0.074606]\n",
            "[Epoch 27/200] [Batch 499/938] [D loss: 0.622828] [G loss: 0.075518]\n",
            "[Epoch 27/200] [Batch 500/938] [D loss: 0.648632] [G loss: 0.071206]\n",
            "[Epoch 27/200] [Batch 501/938] [D loss: 0.628507] [G loss: 0.071892]\n",
            "[Epoch 27/200] [Batch 502/938] [D loss: 0.619363] [G loss: 0.069575]\n",
            "[Epoch 27/200] [Batch 503/938] [D loss: 0.652343] [G loss: 0.078148]\n",
            "[Epoch 27/200] [Batch 504/938] [D loss: 0.582496] [G loss: 0.069722]\n",
            "[Epoch 27/200] [Batch 505/938] [D loss: 0.658127] [G loss: 0.075770]\n",
            "[Epoch 27/200] [Batch 506/938] [D loss: 0.629837] [G loss: 0.073507]\n",
            "[Epoch 27/200] [Batch 507/938] [D loss: 0.658500] [G loss: 0.076175]\n",
            "[Epoch 27/200] [Batch 508/938] [D loss: 0.628570] [G loss: 0.075874]\n",
            "[Epoch 27/200] [Batch 509/938] [D loss: 0.627529] [G loss: 0.070861]\n",
            "[Epoch 27/200] [Batch 510/938] [D loss: 0.653366] [G loss: 0.073502]\n",
            "[Epoch 27/200] [Batch 511/938] [D loss: 0.644246] [G loss: 0.063954]\n",
            "[Epoch 27/200] [Batch 512/938] [D loss: 0.662903] [G loss: 0.067090]\n",
            "[Epoch 27/200] [Batch 513/938] [D loss: 0.614328] [G loss: 0.068966]\n",
            "[Epoch 27/200] [Batch 514/938] [D loss: 0.644484] [G loss: 0.069902]\n",
            "[Epoch 27/200] [Batch 515/938] [D loss: 0.641632] [G loss: 0.072276]\n",
            "[Epoch 27/200] [Batch 516/938] [D loss: 0.600268] [G loss: 0.074292]\n",
            "[Epoch 27/200] [Batch 517/938] [D loss: 0.663104] [G loss: 0.069111]\n",
            "[Epoch 27/200] [Batch 518/938] [D loss: 0.667856] [G loss: 0.080729]\n",
            "[Epoch 27/200] [Batch 519/938] [D loss: 0.685634] [G loss: 0.079294]\n",
            "[Epoch 27/200] [Batch 520/938] [D loss: 0.617131] [G loss: 0.070749]\n",
            "[Epoch 27/200] [Batch 521/938] [D loss: 0.608649] [G loss: 0.070213]\n",
            "[Epoch 27/200] [Batch 522/938] [D loss: 0.631274] [G loss: 0.072976]\n",
            "[Epoch 27/200] [Batch 523/938] [D loss: 0.626811] [G loss: 0.071277]\n",
            "[Epoch 27/200] [Batch 524/938] [D loss: 0.671508] [G loss: 0.065112]\n",
            "[Epoch 27/200] [Batch 525/938] [D loss: 0.646182] [G loss: 0.071580]\n",
            "[Epoch 27/200] [Batch 526/938] [D loss: 0.667574] [G loss: 0.073627]\n",
            "[Epoch 27/200] [Batch 527/938] [D loss: 0.646256] [G loss: 0.073291]\n",
            "[Epoch 27/200] [Batch 528/938] [D loss: 0.640220] [G loss: 0.074651]\n",
            "[Epoch 27/200] [Batch 529/938] [D loss: 0.620725] [G loss: 0.074491]\n",
            "[Epoch 27/200] [Batch 530/938] [D loss: 0.646232] [G loss: 0.068558]\n",
            "[Epoch 27/200] [Batch 531/938] [D loss: 0.635229] [G loss: 0.078365]\n",
            "[Epoch 27/200] [Batch 532/938] [D loss: 0.629606] [G loss: 0.070397]\n",
            "[Epoch 27/200] [Batch 533/938] [D loss: 0.635011] [G loss: 0.080983]\n",
            "[Epoch 27/200] [Batch 534/938] [D loss: 0.634949] [G loss: 0.078433]\n",
            "[Epoch 27/200] [Batch 535/938] [D loss: 0.640898] [G loss: 0.076234]\n",
            "[Epoch 27/200] [Batch 536/938] [D loss: 0.672161] [G loss: 0.067778]\n",
            "[Epoch 27/200] [Batch 537/938] [D loss: 0.651602] [G loss: 0.073430]\n",
            "[Epoch 27/200] [Batch 538/938] [D loss: 0.618831] [G loss: 0.066623]\n",
            "[Epoch 27/200] [Batch 539/938] [D loss: 0.619415] [G loss: 0.074573]\n",
            "[Epoch 27/200] [Batch 540/938] [D loss: 0.684867] [G loss: 0.069850]\n",
            "[Epoch 27/200] [Batch 541/938] [D loss: 0.624300] [G loss: 0.070397]\n",
            "[Epoch 27/200] [Batch 542/938] [D loss: 0.633160] [G loss: 0.076311]\n",
            "[Epoch 27/200] [Batch 543/938] [D loss: 0.630540] [G loss: 0.071797]\n",
            "[Epoch 27/200] [Batch 544/938] [D loss: 0.639172] [G loss: 0.064597]\n",
            "[Epoch 27/200] [Batch 545/938] [D loss: 0.651393] [G loss: 0.078222]\n",
            "[Epoch 27/200] [Batch 546/938] [D loss: 0.632553] [G loss: 0.070341]\n",
            "[Epoch 27/200] [Batch 547/938] [D loss: 0.626153] [G loss: 0.067062]\n",
            "[Epoch 27/200] [Batch 548/938] [D loss: 0.588402] [G loss: 0.076073]\n",
            "[Epoch 27/200] [Batch 549/938] [D loss: 0.647274] [G loss: 0.074344]\n",
            "[Epoch 27/200] [Batch 550/938] [D loss: 0.651783] [G loss: 0.074089]\n",
            "[Epoch 27/200] [Batch 551/938] [D loss: 0.642975] [G loss: 0.067329]\n",
            "[Epoch 27/200] [Batch 552/938] [D loss: 0.616945] [G loss: 0.069602]\n",
            "[Epoch 27/200] [Batch 553/938] [D loss: 0.658178] [G loss: 0.070670]\n",
            "[Epoch 27/200] [Batch 554/938] [D loss: 0.663542] [G loss: 0.067546]\n",
            "[Epoch 27/200] [Batch 555/938] [D loss: 0.576451] [G loss: 0.068102]\n",
            "[Epoch 27/200] [Batch 556/938] [D loss: 0.674296] [G loss: 0.074437]\n",
            "[Epoch 27/200] [Batch 557/938] [D loss: 0.654678] [G loss: 0.064635]\n",
            "[Epoch 27/200] [Batch 558/938] [D loss: 0.642671] [G loss: 0.073090]\n",
            "[Epoch 27/200] [Batch 559/938] [D loss: 0.623270] [G loss: 0.075500]\n",
            "[Epoch 27/200] [Batch 560/938] [D loss: 0.586911] [G loss: 0.077330]\n",
            "[Epoch 27/200] [Batch 561/938] [D loss: 0.630967] [G loss: 0.076911]\n",
            "[Epoch 27/200] [Batch 562/938] [D loss: 0.620009] [G loss: 0.071413]\n",
            "[Epoch 27/200] [Batch 563/938] [D loss: 0.668607] [G loss: 0.069028]\n",
            "[Epoch 27/200] [Batch 564/938] [D loss: 0.643320] [G loss: 0.069064]\n",
            "[Epoch 27/200] [Batch 565/938] [D loss: 0.649896] [G loss: 0.067283]\n",
            "[Epoch 27/200] [Batch 566/938] [D loss: 0.622128] [G loss: 0.080872]\n",
            "[Epoch 27/200] [Batch 567/938] [D loss: 0.638786] [G loss: 0.078378]\n",
            "[Epoch 27/200] [Batch 568/938] [D loss: 0.625602] [G loss: 0.063487]\n",
            "[Epoch 27/200] [Batch 569/938] [D loss: 0.666507] [G loss: 0.076761]\n",
            "[Epoch 27/200] [Batch 570/938] [D loss: 0.652557] [G loss: 0.069072]\n",
            "[Epoch 27/200] [Batch 571/938] [D loss: 0.642905] [G loss: 0.068718]\n",
            "[Epoch 27/200] [Batch 572/938] [D loss: 0.639593] [G loss: 0.071244]\n",
            "[Epoch 27/200] [Batch 573/938] [D loss: 0.643374] [G loss: 0.067577]\n",
            "[Epoch 27/200] [Batch 574/938] [D loss: 0.648726] [G loss: 0.069514]\n",
            "[Epoch 27/200] [Batch 575/938] [D loss: 0.625463] [G loss: 0.075329]\n",
            "[Epoch 27/200] [Batch 576/938] [D loss: 0.626157] [G loss: 0.066953]\n",
            "[Epoch 27/200] [Batch 577/938] [D loss: 0.648571] [G loss: 0.086032]\n",
            "[Epoch 27/200] [Batch 578/938] [D loss: 0.618418] [G loss: 0.074077]\n",
            "[Epoch 27/200] [Batch 579/938] [D loss: 0.619548] [G loss: 0.068121]\n",
            "[Epoch 27/200] [Batch 580/938] [D loss: 0.628954] [G loss: 0.073522]\n",
            "[Epoch 27/200] [Batch 581/938] [D loss: 0.631465] [G loss: 0.071665]\n",
            "[Epoch 27/200] [Batch 582/938] [D loss: 0.625655] [G loss: 0.074112]\n",
            "[Epoch 27/200] [Batch 583/938] [D loss: 0.652265] [G loss: 0.077420]\n",
            "[Epoch 27/200] [Batch 584/938] [D loss: 0.670814] [G loss: 0.070911]\n",
            "[Epoch 27/200] [Batch 585/938] [D loss: 0.630077] [G loss: 0.075124]\n",
            "[Epoch 27/200] [Batch 586/938] [D loss: 0.610595] [G loss: 0.076453]\n",
            "[Epoch 27/200] [Batch 587/938] [D loss: 0.637143] [G loss: 0.065825]\n",
            "[Epoch 27/200] [Batch 588/938] [D loss: 0.656263] [G loss: 0.076551]\n",
            "[Epoch 27/200] [Batch 589/938] [D loss: 0.610544] [G loss: 0.073726]\n",
            "[Epoch 27/200] [Batch 590/938] [D loss: 0.642588] [G loss: 0.068212]\n",
            "[Epoch 27/200] [Batch 591/938] [D loss: 0.626163] [G loss: 0.070780]\n",
            "[Epoch 27/200] [Batch 592/938] [D loss: 0.608071] [G loss: 0.078323]\n",
            "[Epoch 27/200] [Batch 593/938] [D loss: 0.618017] [G loss: 0.073865]\n",
            "[Epoch 27/200] [Batch 594/938] [D loss: 0.633783] [G loss: 0.075894]\n",
            "[Epoch 27/200] [Batch 595/938] [D loss: 0.637155] [G loss: 0.071375]\n",
            "[Epoch 27/200] [Batch 596/938] [D loss: 0.669194] [G loss: 0.069364]\n",
            "[Epoch 27/200] [Batch 597/938] [D loss: 0.670985] [G loss: 0.076912]\n",
            "[Epoch 27/200] [Batch 598/938] [D loss: 0.638284] [G loss: 0.069936]\n",
            "[Epoch 27/200] [Batch 599/938] [D loss: 0.649120] [G loss: 0.080722]\n",
            "[Epoch 27/200] [Batch 600/938] [D loss: 0.629457] [G loss: 0.071616]\n",
            "[Epoch 27/200] [Batch 601/938] [D loss: 0.627473] [G loss: 0.080897]\n",
            "[Epoch 27/200] [Batch 602/938] [D loss: 0.645082] [G loss: 0.068979]\n",
            "[Epoch 27/200] [Batch 603/938] [D loss: 0.628420] [G loss: 0.066984]\n",
            "[Epoch 27/200] [Batch 604/938] [D loss: 0.664941] [G loss: 0.079573]\n",
            "[Epoch 27/200] [Batch 605/938] [D loss: 0.671643] [G loss: 0.067876]\n",
            "[Epoch 27/200] [Batch 606/938] [D loss: 0.644575] [G loss: 0.074985]\n",
            "[Epoch 27/200] [Batch 607/938] [D loss: 0.653000] [G loss: 0.070317]\n",
            "[Epoch 27/200] [Batch 608/938] [D loss: 0.635530] [G loss: 0.070154]\n",
            "[Epoch 27/200] [Batch 609/938] [D loss: 0.622504] [G loss: 0.064156]\n",
            "[Epoch 27/200] [Batch 610/938] [D loss: 0.614798] [G loss: 0.067410]\n",
            "[Epoch 27/200] [Batch 611/938] [D loss: 0.610258] [G loss: 0.071375]\n",
            "[Epoch 27/200] [Batch 612/938] [D loss: 0.622753] [G loss: 0.064261]\n",
            "[Epoch 27/200] [Batch 613/938] [D loss: 0.661778] [G loss: 0.070082]\n",
            "[Epoch 27/200] [Batch 614/938] [D loss: 0.626322] [G loss: 0.072764]\n",
            "[Epoch 27/200] [Batch 615/938] [D loss: 0.635807] [G loss: 0.079005]\n",
            "[Epoch 27/200] [Batch 616/938] [D loss: 0.596245] [G loss: 0.071429]\n",
            "[Epoch 27/200] [Batch 617/938] [D loss: 0.640843] [G loss: 0.069342]\n",
            "[Epoch 27/200] [Batch 618/938] [D loss: 0.628964] [G loss: 0.071407]\n",
            "[Epoch 27/200] [Batch 619/938] [D loss: 0.640946] [G loss: 0.075618]\n",
            "[Epoch 27/200] [Batch 620/938] [D loss: 0.644257] [G loss: 0.073427]\n",
            "[Epoch 27/200] [Batch 621/938] [D loss: 0.641665] [G loss: 0.072918]\n",
            "[Epoch 27/200] [Batch 622/938] [D loss: 0.652504] [G loss: 0.074675]\n",
            "[Epoch 27/200] [Batch 623/938] [D loss: 0.650188] [G loss: 0.074277]\n",
            "[Epoch 27/200] [Batch 624/938] [D loss: 0.626002] [G loss: 0.076812]\n",
            "[Epoch 27/200] [Batch 625/938] [D loss: 0.622145] [G loss: 0.076713]\n",
            "[Epoch 27/200] [Batch 626/938] [D loss: 0.635666] [G loss: 0.077205]\n",
            "[Epoch 27/200] [Batch 627/938] [D loss: 0.694282] [G loss: 0.069771]\n",
            "[Epoch 27/200] [Batch 628/938] [D loss: 0.639417] [G loss: 0.072861]\n",
            "[Epoch 27/200] [Batch 629/938] [D loss: 0.613388] [G loss: 0.076993]\n",
            "[Epoch 27/200] [Batch 630/938] [D loss: 0.628491] [G loss: 0.070373]\n",
            "[Epoch 27/200] [Batch 631/938] [D loss: 0.628610] [G loss: 0.074504]\n",
            "[Epoch 27/200] [Batch 632/938] [D loss: 0.618579] [G loss: 0.077993]\n",
            "[Epoch 27/200] [Batch 633/938] [D loss: 0.616811] [G loss: 0.082555]\n",
            "[Epoch 27/200] [Batch 634/938] [D loss: 0.644795] [G loss: 0.078814]\n",
            "[Epoch 27/200] [Batch 635/938] [D loss: 0.667328] [G loss: 0.070033]\n",
            "[Epoch 27/200] [Batch 636/938] [D loss: 0.645428] [G loss: 0.078237]\n",
            "[Epoch 27/200] [Batch 637/938] [D loss: 0.653128] [G loss: 0.071872]\n",
            "[Epoch 27/200] [Batch 638/938] [D loss: 0.652824] [G loss: 0.075494]\n",
            "[Epoch 27/200] [Batch 639/938] [D loss: 0.611002] [G loss: 0.072321]\n",
            "[Epoch 27/200] [Batch 640/938] [D loss: 0.653264] [G loss: 0.072664]\n",
            "[Epoch 27/200] [Batch 641/938] [D loss: 0.617389] [G loss: 0.065698]\n",
            "[Epoch 27/200] [Batch 642/938] [D loss: 0.636591] [G loss: 0.079062]\n",
            "[Epoch 27/200] [Batch 643/938] [D loss: 0.639801] [G loss: 0.080039]\n",
            "[Epoch 27/200] [Batch 644/938] [D loss: 0.645858] [G loss: 0.069525]\n",
            "[Epoch 27/200] [Batch 645/938] [D loss: 0.614177] [G loss: 0.075075]\n",
            "[Epoch 27/200] [Batch 646/938] [D loss: 0.627062] [G loss: 0.071599]\n",
            "[Epoch 27/200] [Batch 647/938] [D loss: 0.617687] [G loss: 0.074298]\n",
            "[Epoch 27/200] [Batch 648/938] [D loss: 0.603712] [G loss: 0.072890]\n",
            "[Epoch 27/200] [Batch 649/938] [D loss: 0.615065] [G loss: 0.068291]\n",
            "[Epoch 27/200] [Batch 650/938] [D loss: 0.625644] [G loss: 0.067955]\n",
            "[Epoch 27/200] [Batch 651/938] [D loss: 0.621004] [G loss: 0.072397]\n",
            "[Epoch 27/200] [Batch 652/938] [D loss: 0.653533] [G loss: 0.069590]\n",
            "[Epoch 27/200] [Batch 653/938] [D loss: 0.648087] [G loss: 0.075997]\n",
            "[Epoch 27/200] [Batch 654/938] [D loss: 0.645236] [G loss: 0.068965]\n",
            "[Epoch 27/200] [Batch 655/938] [D loss: 0.637563] [G loss: 0.065642]\n",
            "[Epoch 27/200] [Batch 656/938] [D loss: 0.636817] [G loss: 0.072702]\n",
            "[Epoch 27/200] [Batch 657/938] [D loss: 0.604900] [G loss: 0.071922]\n",
            "[Epoch 27/200] [Batch 658/938] [D loss: 0.620289] [G loss: 0.070204]\n",
            "[Epoch 27/200] [Batch 659/938] [D loss: 0.638564] [G loss: 0.071857]\n",
            "[Epoch 27/200] [Batch 660/938] [D loss: 0.615425] [G loss: 0.074003]\n",
            "[Epoch 27/200] [Batch 661/938] [D loss: 0.619240] [G loss: 0.070115]\n",
            "[Epoch 27/200] [Batch 662/938] [D loss: 0.634026] [G loss: 0.064779]\n",
            "[Epoch 27/200] [Batch 663/938] [D loss: 0.615920] [G loss: 0.073667]\n",
            "[Epoch 27/200] [Batch 664/938] [D loss: 0.649928] [G loss: 0.082569]\n",
            "[Epoch 27/200] [Batch 665/938] [D loss: 0.621308] [G loss: 0.076985]\n",
            "[Epoch 27/200] [Batch 666/938] [D loss: 0.620941] [G loss: 0.074782]\n",
            "[Epoch 27/200] [Batch 667/938] [D loss: 0.634732] [G loss: 0.072912]\n",
            "[Epoch 27/200] [Batch 668/938] [D loss: 0.639391] [G loss: 0.072669]\n",
            "[Epoch 27/200] [Batch 669/938] [D loss: 0.657709] [G loss: 0.070929]\n",
            "[Epoch 27/200] [Batch 670/938] [D loss: 0.634773] [G loss: 0.069659]\n",
            "[Epoch 27/200] [Batch 671/938] [D loss: 0.620757] [G loss: 0.072681]\n",
            "[Epoch 27/200] [Batch 672/938] [D loss: 0.648367] [G loss: 0.074452]\n",
            "[Epoch 27/200] [Batch 673/938] [D loss: 0.631963] [G loss: 0.079531]\n",
            "[Epoch 27/200] [Batch 674/938] [D loss: 0.623558] [G loss: 0.074179]\n",
            "[Epoch 27/200] [Batch 675/938] [D loss: 0.610142] [G loss: 0.074677]\n",
            "[Epoch 27/200] [Batch 676/938] [D loss: 0.604605] [G loss: 0.074326]\n",
            "[Epoch 27/200] [Batch 677/938] [D loss: 0.616256] [G loss: 0.073130]\n",
            "[Epoch 27/200] [Batch 678/938] [D loss: 0.628032] [G loss: 0.070882]\n",
            "[Epoch 27/200] [Batch 679/938] [D loss: 0.601144] [G loss: 0.067031]\n",
            "[Epoch 27/200] [Batch 680/938] [D loss: 0.613516] [G loss: 0.070865]\n",
            "[Epoch 27/200] [Batch 681/938] [D loss: 0.567330] [G loss: 0.068152]\n",
            "[Epoch 27/200] [Batch 682/938] [D loss: 0.639207] [G loss: 0.075906]\n",
            "[Epoch 27/200] [Batch 683/938] [D loss: 0.594272] [G loss: 0.071443]\n",
            "[Epoch 27/200] [Batch 684/938] [D loss: 0.632669] [G loss: 0.076481]\n",
            "[Epoch 27/200] [Batch 685/938] [D loss: 0.607474] [G loss: 0.067698]\n",
            "[Epoch 27/200] [Batch 686/938] [D loss: 0.618175] [G loss: 0.069810]\n",
            "[Epoch 27/200] [Batch 687/938] [D loss: 0.619903] [G loss: 0.070088]\n",
            "[Epoch 27/200] [Batch 688/938] [D loss: 0.625805] [G loss: 0.067917]\n",
            "[Epoch 27/200] [Batch 689/938] [D loss: 0.624145] [G loss: 0.073588]\n",
            "[Epoch 27/200] [Batch 690/938] [D loss: 0.625405] [G loss: 0.067021]\n",
            "[Epoch 27/200] [Batch 691/938] [D loss: 0.651055] [G loss: 0.071799]\n",
            "[Epoch 27/200] [Batch 692/938] [D loss: 0.650622] [G loss: 0.077321]\n",
            "[Epoch 27/200] [Batch 693/938] [D loss: 0.665385] [G loss: 0.068216]\n",
            "[Epoch 27/200] [Batch 694/938] [D loss: 0.608763] [G loss: 0.068911]\n",
            "[Epoch 27/200] [Batch 695/938] [D loss: 0.635576] [G loss: 0.069471]\n",
            "[Epoch 27/200] [Batch 696/938] [D loss: 0.612764] [G loss: 0.065565]\n",
            "[Epoch 27/200] [Batch 697/938] [D loss: 0.633891] [G loss: 0.073882]\n",
            "[Epoch 27/200] [Batch 698/938] [D loss: 0.673915] [G loss: 0.066889]\n",
            "[Epoch 27/200] [Batch 699/938] [D loss: 0.644410] [G loss: 0.070506]\n",
            "[Epoch 27/200] [Batch 700/938] [D loss: 0.601400] [G loss: 0.074052]\n",
            "[Epoch 27/200] [Batch 701/938] [D loss: 0.630332] [G loss: 0.076258]\n",
            "[Epoch 27/200] [Batch 702/938] [D loss: 0.630124] [G loss: 0.074388]\n",
            "[Epoch 27/200] [Batch 703/938] [D loss: 0.673681] [G loss: 0.076609]\n",
            "[Epoch 27/200] [Batch 704/938] [D loss: 0.637595] [G loss: 0.068969]\n",
            "[Epoch 27/200] [Batch 705/938] [D loss: 0.652713] [G loss: 0.071028]\n",
            "[Epoch 27/200] [Batch 706/938] [D loss: 0.619482] [G loss: 0.079102]\n",
            "[Epoch 27/200] [Batch 707/938] [D loss: 0.630553] [G loss: 0.071835]\n",
            "[Epoch 27/200] [Batch 708/938] [D loss: 0.626022] [G loss: 0.077278]\n",
            "[Epoch 27/200] [Batch 709/938] [D loss: 0.630885] [G loss: 0.065891]\n",
            "[Epoch 27/200] [Batch 710/938] [D loss: 0.633400] [G loss: 0.078138]\n",
            "[Epoch 27/200] [Batch 711/938] [D loss: 0.626175] [G loss: 0.070294]\n",
            "[Epoch 27/200] [Batch 712/938] [D loss: 0.666601] [G loss: 0.069446]\n",
            "[Epoch 27/200] [Batch 713/938] [D loss: 0.652431] [G loss: 0.073130]\n",
            "[Epoch 27/200] [Batch 714/938] [D loss: 0.621219] [G loss: 0.076002]\n",
            "[Epoch 27/200] [Batch 715/938] [D loss: 0.632408] [G loss: 0.076369]\n",
            "[Epoch 27/200] [Batch 716/938] [D loss: 0.666075] [G loss: 0.068352]\n",
            "[Epoch 27/200] [Batch 717/938] [D loss: 0.643314] [G loss: 0.070174]\n",
            "[Epoch 27/200] [Batch 718/938] [D loss: 0.617689] [G loss: 0.069288]\n",
            "[Epoch 27/200] [Batch 719/938] [D loss: 0.630756] [G loss: 0.075684]\n",
            "[Epoch 27/200] [Batch 720/938] [D loss: 0.632158] [G loss: 0.072552]\n",
            "[Epoch 27/200] [Batch 721/938] [D loss: 0.647344] [G loss: 0.074202]\n",
            "[Epoch 27/200] [Batch 722/938] [D loss: 0.668185] [G loss: 0.072961]\n",
            "[Epoch 27/200] [Batch 723/938] [D loss: 0.655350] [G loss: 0.068565]\n",
            "[Epoch 27/200] [Batch 724/938] [D loss: 0.662980] [G loss: 0.070578]\n",
            "[Epoch 27/200] [Batch 725/938] [D loss: 0.582791] [G loss: 0.077502]\n",
            "[Epoch 27/200] [Batch 726/938] [D loss: 0.630501] [G loss: 0.063123]\n",
            "[Epoch 27/200] [Batch 727/938] [D loss: 0.627081] [G loss: 0.072725]\n",
            "[Epoch 27/200] [Batch 728/938] [D loss: 0.604713] [G loss: 0.071684]\n",
            "[Epoch 27/200] [Batch 729/938] [D loss: 0.641427] [G loss: 0.068571]\n",
            "[Epoch 27/200] [Batch 730/938] [D loss: 0.610256] [G loss: 0.071043]\n",
            "[Epoch 27/200] [Batch 731/938] [D loss: 0.625839] [G loss: 0.076181]\n",
            "[Epoch 27/200] [Batch 732/938] [D loss: 0.628943] [G loss: 0.071108]\n",
            "[Epoch 27/200] [Batch 733/938] [D loss: 0.598941] [G loss: 0.075283]\n",
            "[Epoch 27/200] [Batch 734/938] [D loss: 0.620632] [G loss: 0.077034]\n",
            "[Epoch 27/200] [Batch 735/938] [D loss: 0.608451] [G loss: 0.074110]\n",
            "[Epoch 27/200] [Batch 736/938] [D loss: 0.654615] [G loss: 0.071642]\n",
            "[Epoch 27/200] [Batch 737/938] [D loss: 0.596105] [G loss: 0.075070]\n",
            "[Epoch 27/200] [Batch 738/938] [D loss: 0.617575] [G loss: 0.075000]\n",
            "[Epoch 27/200] [Batch 739/938] [D loss: 0.663782] [G loss: 0.073580]\n",
            "[Epoch 27/200] [Batch 740/938] [D loss: 0.613000] [G loss: 0.067515]\n",
            "[Epoch 27/200] [Batch 741/938] [D loss: 0.591020] [G loss: 0.077839]\n",
            "[Epoch 27/200] [Batch 742/938] [D loss: 0.617971] [G loss: 0.078038]\n",
            "[Epoch 27/200] [Batch 743/938] [D loss: 0.655249] [G loss: 0.070285]\n",
            "[Epoch 27/200] [Batch 744/938] [D loss: 0.614369] [G loss: 0.077410]\n",
            "[Epoch 27/200] [Batch 745/938] [D loss: 0.615885] [G loss: 0.074287]\n",
            "[Epoch 27/200] [Batch 746/938] [D loss: 0.584030] [G loss: 0.067815]\n",
            "[Epoch 27/200] [Batch 747/938] [D loss: 0.637888] [G loss: 0.070143]\n",
            "[Epoch 27/200] [Batch 748/938] [D loss: 0.648931] [G loss: 0.072892]\n",
            "[Epoch 27/200] [Batch 749/938] [D loss: 0.636418] [G loss: 0.071276]\n",
            "[Epoch 27/200] [Batch 750/938] [D loss: 0.654141] [G loss: 0.068559]\n",
            "[Epoch 27/200] [Batch 751/938] [D loss: 0.657691] [G loss: 0.075895]\n",
            "[Epoch 27/200] [Batch 752/938] [D loss: 0.633223] [G loss: 0.081268]\n",
            "[Epoch 27/200] [Batch 753/938] [D loss: 0.657503] [G loss: 0.067747]\n",
            "[Epoch 27/200] [Batch 754/938] [D loss: 0.686222] [G loss: 0.068339]\n",
            "[Epoch 27/200] [Batch 755/938] [D loss: 0.619139] [G loss: 0.072518]\n",
            "[Epoch 27/200] [Batch 756/938] [D loss: 0.616998] [G loss: 0.079492]\n",
            "[Epoch 27/200] [Batch 757/938] [D loss: 0.648668] [G loss: 0.075439]\n",
            "[Epoch 27/200] [Batch 758/938] [D loss: 0.633207] [G loss: 0.073027]\n",
            "[Epoch 27/200] [Batch 759/938] [D loss: 0.626899] [G loss: 0.074830]\n",
            "[Epoch 27/200] [Batch 760/938] [D loss: 0.646826] [G loss: 0.077036]\n",
            "[Epoch 27/200] [Batch 761/938] [D loss: 0.629624] [G loss: 0.078228]\n",
            "[Epoch 27/200] [Batch 762/938] [D loss: 0.624428] [G loss: 0.078605]\n",
            "[Epoch 27/200] [Batch 763/938] [D loss: 0.638076] [G loss: 0.076213]\n",
            "[Epoch 27/200] [Batch 764/938] [D loss: 0.624537] [G loss: 0.067624]\n",
            "[Epoch 27/200] [Batch 765/938] [D loss: 0.655115] [G loss: 0.072630]\n",
            "[Epoch 27/200] [Batch 766/938] [D loss: 0.634942] [G loss: 0.069084]\n",
            "[Epoch 27/200] [Batch 767/938] [D loss: 0.658938] [G loss: 0.066762]\n",
            "[Epoch 27/200] [Batch 768/938] [D loss: 0.624603] [G loss: 0.065145]\n",
            "[Epoch 27/200] [Batch 769/938] [D loss: 0.655513] [G loss: 0.067113]\n",
            "[Epoch 27/200] [Batch 770/938] [D loss: 0.652646] [G loss: 0.075011]\n",
            "[Epoch 27/200] [Batch 771/938] [D loss: 0.672652] [G loss: 0.075594]\n",
            "[Epoch 27/200] [Batch 772/938] [D loss: 0.640787] [G loss: 0.071028]\n",
            "[Epoch 27/200] [Batch 773/938] [D loss: 0.633220] [G loss: 0.075021]\n",
            "[Epoch 27/200] [Batch 774/938] [D loss: 0.618757] [G loss: 0.074161]\n",
            "[Epoch 27/200] [Batch 775/938] [D loss: 0.652545] [G loss: 0.077871]\n",
            "[Epoch 27/200] [Batch 776/938] [D loss: 0.627761] [G loss: 0.065470]\n",
            "[Epoch 27/200] [Batch 777/938] [D loss: 0.651977] [G loss: 0.078705]\n",
            "[Epoch 27/200] [Batch 778/938] [D loss: 0.647393] [G loss: 0.080361]\n",
            "[Epoch 27/200] [Batch 779/938] [D loss: 0.624997] [G loss: 0.072948]\n",
            "[Epoch 27/200] [Batch 780/938] [D loss: 0.613659] [G loss: 0.074294]\n",
            "[Epoch 27/200] [Batch 781/938] [D loss: 0.627770] [G loss: 0.075094]\n",
            "[Epoch 27/200] [Batch 782/938] [D loss: 0.646281] [G loss: 0.066376]\n",
            "[Epoch 27/200] [Batch 783/938] [D loss: 0.623325] [G loss: 0.069163]\n",
            "[Epoch 27/200] [Batch 784/938] [D loss: 0.631889] [G loss: 0.074438]\n",
            "[Epoch 27/200] [Batch 785/938] [D loss: 0.633051] [G loss: 0.077840]\n",
            "[Epoch 27/200] [Batch 786/938] [D loss: 0.648698] [G loss: 0.065947]\n",
            "[Epoch 27/200] [Batch 787/938] [D loss: 0.643858] [G loss: 0.085812]\n",
            "[Epoch 27/200] [Batch 788/938] [D loss: 0.606981] [G loss: 0.068852]\n",
            "[Epoch 27/200] [Batch 789/938] [D loss: 0.652864] [G loss: 0.077388]\n",
            "[Epoch 27/200] [Batch 790/938] [D loss: 0.662442] [G loss: 0.069797]\n",
            "[Epoch 27/200] [Batch 791/938] [D loss: 0.666341] [G loss: 0.069937]\n",
            "[Epoch 27/200] [Batch 792/938] [D loss: 0.642105] [G loss: 0.074187]\n",
            "[Epoch 27/200] [Batch 793/938] [D loss: 0.611860] [G loss: 0.067782]\n",
            "[Epoch 27/200] [Batch 794/938] [D loss: 0.602317] [G loss: 0.068683]\n",
            "[Epoch 27/200] [Batch 795/938] [D loss: 0.646382] [G loss: 0.066672]\n",
            "[Epoch 27/200] [Batch 796/938] [D loss: 0.649029] [G loss: 0.067482]\n",
            "[Epoch 27/200] [Batch 797/938] [D loss: 0.606040] [G loss: 0.072961]\n",
            "[Epoch 27/200] [Batch 798/938] [D loss: 0.664739] [G loss: 0.072663]\n",
            "[Epoch 27/200] [Batch 799/938] [D loss: 0.657494] [G loss: 0.083739]\n",
            "[Epoch 27/200] [Batch 800/938] [D loss: 0.572350] [G loss: 0.073470]\n",
            "[Epoch 27/200] [Batch 801/938] [D loss: 0.632633] [G loss: 0.065407]\n",
            "[Epoch 27/200] [Batch 802/938] [D loss: 0.642183] [G loss: 0.072190]\n",
            "[Epoch 27/200] [Batch 803/938] [D loss: 0.649880] [G loss: 0.073140]\n",
            "[Epoch 27/200] [Batch 804/938] [D loss: 0.608361] [G loss: 0.072603]\n",
            "[Epoch 27/200] [Batch 805/938] [D loss: 0.620604] [G loss: 0.077184]\n",
            "[Epoch 27/200] [Batch 806/938] [D loss: 0.672729] [G loss: 0.072425]\n",
            "[Epoch 27/200] [Batch 807/938] [D loss: 0.642982] [G loss: 0.073521]\n",
            "[Epoch 27/200] [Batch 808/938] [D loss: 0.644012] [G loss: 0.060197]\n",
            "[Epoch 27/200] [Batch 809/938] [D loss: 0.624765] [G loss: 0.076582]\n",
            "[Epoch 27/200] [Batch 810/938] [D loss: 0.626653] [G loss: 0.067531]\n",
            "[Epoch 27/200] [Batch 811/938] [D loss: 0.628864] [G loss: 0.067198]\n",
            "[Epoch 27/200] [Batch 812/938] [D loss: 0.601946] [G loss: 0.073747]\n",
            "[Epoch 27/200] [Batch 813/938] [D loss: 0.624724] [G loss: 0.072063]\n",
            "[Epoch 27/200] [Batch 814/938] [D loss: 0.634115] [G loss: 0.068824]\n",
            "[Epoch 27/200] [Batch 815/938] [D loss: 0.623150] [G loss: 0.075793]\n",
            "[Epoch 27/200] [Batch 816/938] [D loss: 0.658080] [G loss: 0.073366]\n",
            "[Epoch 27/200] [Batch 817/938] [D loss: 0.621113] [G loss: 0.071788]\n",
            "[Epoch 27/200] [Batch 818/938] [D loss: 0.620988] [G loss: 0.070588]\n",
            "[Epoch 27/200] [Batch 819/938] [D loss: 0.640526] [G loss: 0.070673]\n",
            "[Epoch 27/200] [Batch 820/938] [D loss: 0.650498] [G loss: 0.066665]\n",
            "[Epoch 27/200] [Batch 821/938] [D loss: 0.591404] [G loss: 0.072958]\n",
            "[Epoch 27/200] [Batch 822/938] [D loss: 0.633864] [G loss: 0.075611]\n",
            "[Epoch 27/200] [Batch 823/938] [D loss: 0.606549] [G loss: 0.073822]\n",
            "[Epoch 27/200] [Batch 824/938] [D loss: 0.664225] [G loss: 0.069862]\n",
            "[Epoch 27/200] [Batch 825/938] [D loss: 0.633847] [G loss: 0.071749]\n",
            "[Epoch 27/200] [Batch 826/938] [D loss: 0.620794] [G loss: 0.065643]\n",
            "[Epoch 27/200] [Batch 827/938] [D loss: 0.641761] [G loss: 0.067635]\n",
            "[Epoch 27/200] [Batch 828/938] [D loss: 0.645051] [G loss: 0.066991]\n",
            "[Epoch 27/200] [Batch 829/938] [D loss: 0.629733] [G loss: 0.074789]\n",
            "[Epoch 27/200] [Batch 830/938] [D loss: 0.621172] [G loss: 0.072398]\n",
            "[Epoch 27/200] [Batch 831/938] [D loss: 0.611175] [G loss: 0.070627]\n",
            "[Epoch 27/200] [Batch 832/938] [D loss: 0.617752] [G loss: 0.070987]\n",
            "[Epoch 27/200] [Batch 833/938] [D loss: 0.621843] [G loss: 0.070628]\n",
            "[Epoch 27/200] [Batch 834/938] [D loss: 0.625850] [G loss: 0.067248]\n",
            "[Epoch 27/200] [Batch 835/938] [D loss: 0.618416] [G loss: 0.071782]\n",
            "[Epoch 27/200] [Batch 836/938] [D loss: 0.597905] [G loss: 0.066471]\n",
            "[Epoch 27/200] [Batch 837/938] [D loss: 0.630674] [G loss: 0.070849]\n",
            "[Epoch 27/200] [Batch 838/938] [D loss: 0.627087] [G loss: 0.072218]\n",
            "[Epoch 27/200] [Batch 839/938] [D loss: 0.629605] [G loss: 0.070954]\n",
            "[Epoch 27/200] [Batch 840/938] [D loss: 0.650060] [G loss: 0.070891]\n",
            "[Epoch 27/200] [Batch 841/938] [D loss: 0.658999] [G loss: 0.075961]\n",
            "[Epoch 27/200] [Batch 842/938] [D loss: 0.639622] [G loss: 0.075809]\n",
            "[Epoch 27/200] [Batch 843/938] [D loss: 0.625275] [G loss: 0.074023]\n",
            "[Epoch 27/200] [Batch 844/938] [D loss: 0.630078] [G loss: 0.069971]\n",
            "[Epoch 27/200] [Batch 845/938] [D loss: 0.622412] [G loss: 0.076041]\n",
            "[Epoch 27/200] [Batch 846/938] [D loss: 0.625860] [G loss: 0.066723]\n",
            "[Epoch 27/200] [Batch 847/938] [D loss: 0.662120] [G loss: 0.072909]\n",
            "[Epoch 27/200] [Batch 848/938] [D loss: 0.624036] [G loss: 0.069019]\n",
            "[Epoch 27/200] [Batch 849/938] [D loss: 0.668101] [G loss: 0.068899]\n",
            "[Epoch 27/200] [Batch 850/938] [D loss: 0.653775] [G loss: 0.072864]\n",
            "[Epoch 27/200] [Batch 851/938] [D loss: 0.656080] [G loss: 0.070121]\n",
            "[Epoch 27/200] [Batch 852/938] [D loss: 0.650573] [G loss: 0.070929]\n",
            "[Epoch 27/200] [Batch 853/938] [D loss: 0.623387] [G loss: 0.074925]\n",
            "[Epoch 27/200] [Batch 854/938] [D loss: 0.663483] [G loss: 0.069317]\n",
            "[Epoch 27/200] [Batch 855/938] [D loss: 0.634819] [G loss: 0.074222]\n",
            "[Epoch 27/200] [Batch 856/938] [D loss: 0.647494] [G loss: 0.078279]\n",
            "[Epoch 27/200] [Batch 857/938] [D loss: 0.632136] [G loss: 0.073177]\n",
            "[Epoch 27/200] [Batch 858/938] [D loss: 0.651237] [G loss: 0.070235]\n",
            "[Epoch 27/200] [Batch 859/938] [D loss: 0.657879] [G loss: 0.070023]\n",
            "[Epoch 27/200] [Batch 860/938] [D loss: 0.655652] [G loss: 0.065930]\n",
            "[Epoch 27/200] [Batch 861/938] [D loss: 0.635033] [G loss: 0.077060]\n",
            "[Epoch 27/200] [Batch 862/938] [D loss: 0.656615] [G loss: 0.073278]\n",
            "[Epoch 27/200] [Batch 863/938] [D loss: 0.632719] [G loss: 0.065494]\n",
            "[Epoch 27/200] [Batch 864/938] [D loss: 0.625492] [G loss: 0.070920]\n",
            "[Epoch 27/200] [Batch 865/938] [D loss: 0.629506] [G loss: 0.068759]\n",
            "[Epoch 27/200] [Batch 866/938] [D loss: 0.634872] [G loss: 0.069233]\n",
            "[Epoch 27/200] [Batch 867/938] [D loss: 0.636096] [G loss: 0.079861]\n",
            "[Epoch 27/200] [Batch 868/938] [D loss: 0.656457] [G loss: 0.065386]\n",
            "[Epoch 27/200] [Batch 869/938] [D loss: 0.641358] [G loss: 0.077117]\n",
            "[Epoch 27/200] [Batch 870/938] [D loss: 0.614099] [G loss: 0.074690]\n",
            "[Epoch 27/200] [Batch 871/938] [D loss: 0.668432] [G loss: 0.073834]\n",
            "[Epoch 27/200] [Batch 872/938] [D loss: 0.626943] [G loss: 0.077890]\n",
            "[Epoch 27/200] [Batch 873/938] [D loss: 0.617162] [G loss: 0.072529]\n",
            "[Epoch 27/200] [Batch 874/938] [D loss: 0.631280] [G loss: 0.068737]\n",
            "[Epoch 27/200] [Batch 875/938] [D loss: 0.626235] [G loss: 0.071349]\n",
            "[Epoch 27/200] [Batch 876/938] [D loss: 0.657415] [G loss: 0.070025]\n",
            "[Epoch 27/200] [Batch 877/938] [D loss: 0.651457] [G loss: 0.075108]\n",
            "[Epoch 27/200] [Batch 878/938] [D loss: 0.653510] [G loss: 0.070164]\n",
            "[Epoch 27/200] [Batch 879/938] [D loss: 0.665533] [G loss: 0.071282]\n",
            "[Epoch 27/200] [Batch 880/938] [D loss: 0.626842] [G loss: 0.074029]\n",
            "[Epoch 27/200] [Batch 881/938] [D loss: 0.619681] [G loss: 0.074944]\n",
            "[Epoch 27/200] [Batch 882/938] [D loss: 0.662446] [G loss: 0.073713]\n",
            "[Epoch 27/200] [Batch 883/938] [D loss: 0.644138] [G loss: 0.069507]\n",
            "[Epoch 27/200] [Batch 884/938] [D loss: 0.650023] [G loss: 0.075056]\n",
            "[Epoch 27/200] [Batch 885/938] [D loss: 0.672947] [G loss: 0.078445]\n",
            "[Epoch 27/200] [Batch 886/938] [D loss: 0.647578] [G loss: 0.072169]\n",
            "[Epoch 27/200] [Batch 887/938] [D loss: 0.650267] [G loss: 0.080158]\n",
            "[Epoch 27/200] [Batch 888/938] [D loss: 0.677499] [G loss: 0.070600]\n",
            "[Epoch 27/200] [Batch 889/938] [D loss: 0.585255] [G loss: 0.063793]\n",
            "[Epoch 27/200] [Batch 890/938] [D loss: 0.628901] [G loss: 0.072427]\n",
            "[Epoch 27/200] [Batch 891/938] [D loss: 0.627646] [G loss: 0.080766]\n",
            "[Epoch 27/200] [Batch 892/938] [D loss: 0.624248] [G loss: 0.075011]\n",
            "[Epoch 27/200] [Batch 893/938] [D loss: 0.626407] [G loss: 0.073532]\n",
            "[Epoch 27/200] [Batch 894/938] [D loss: 0.634911] [G loss: 0.071884]\n",
            "[Epoch 27/200] [Batch 895/938] [D loss: 0.613312] [G loss: 0.071164]\n",
            "[Epoch 27/200] [Batch 896/938] [D loss: 0.653615] [G loss: 0.075844]\n",
            "[Epoch 27/200] [Batch 897/938] [D loss: 0.603714] [G loss: 0.078372]\n",
            "[Epoch 27/200] [Batch 898/938] [D loss: 0.609052] [G loss: 0.070903]\n",
            "[Epoch 27/200] [Batch 899/938] [D loss: 0.637544] [G loss: 0.072301]\n",
            "[Epoch 27/200] [Batch 900/938] [D loss: 0.642067] [G loss: 0.070405]\n",
            "[Epoch 27/200] [Batch 901/938] [D loss: 0.623104] [G loss: 0.073970]\n",
            "[Epoch 27/200] [Batch 902/938] [D loss: 0.651872] [G loss: 0.067219]\n",
            "[Epoch 27/200] [Batch 903/938] [D loss: 0.593121] [G loss: 0.073860]\n",
            "[Epoch 27/200] [Batch 904/938] [D loss: 0.637272] [G loss: 0.074633]\n",
            "[Epoch 27/200] [Batch 905/938] [D loss: 0.620803] [G loss: 0.074394]\n",
            "[Epoch 27/200] [Batch 906/938] [D loss: 0.661281] [G loss: 0.068273]\n",
            "[Epoch 27/200] [Batch 907/938] [D loss: 0.642941] [G loss: 0.067379]\n",
            "[Epoch 27/200] [Batch 908/938] [D loss: 0.665273] [G loss: 0.076129]\n",
            "[Epoch 27/200] [Batch 909/938] [D loss: 0.639046] [G loss: 0.078638]\n",
            "[Epoch 27/200] [Batch 910/938] [D loss: 0.627394] [G loss: 0.073756]\n",
            "[Epoch 27/200] [Batch 911/938] [D loss: 0.638190] [G loss: 0.075182]\n",
            "[Epoch 27/200] [Batch 912/938] [D loss: 0.639662] [G loss: 0.073680]\n",
            "[Epoch 27/200] [Batch 913/938] [D loss: 0.636543] [G loss: 0.069967]\n",
            "[Epoch 27/200] [Batch 914/938] [D loss: 0.656923] [G loss: 0.069533]\n",
            "[Epoch 27/200] [Batch 915/938] [D loss: 0.625609] [G loss: 0.074393]\n",
            "[Epoch 27/200] [Batch 916/938] [D loss: 0.609059] [G loss: 0.072621]\n",
            "[Epoch 27/200] [Batch 917/938] [D loss: 0.631207] [G loss: 0.071432]\n",
            "[Epoch 27/200] [Batch 918/938] [D loss: 0.612124] [G loss: 0.069547]\n",
            "[Epoch 27/200] [Batch 919/938] [D loss: 0.636292] [G loss: 0.072727]\n",
            "[Epoch 27/200] [Batch 920/938] [D loss: 0.623858] [G loss: 0.076783]\n",
            "[Epoch 27/200] [Batch 921/938] [D loss: 0.632814] [G loss: 0.069948]\n",
            "[Epoch 27/200] [Batch 922/938] [D loss: 0.635411] [G loss: 0.069819]\n",
            "[Epoch 27/200] [Batch 923/938] [D loss: 0.635025] [G loss: 0.071121]\n",
            "[Epoch 27/200] [Batch 924/938] [D loss: 0.665365] [G loss: 0.068658]\n",
            "[Epoch 27/200] [Batch 925/938] [D loss: 0.634968] [G loss: 0.068386]\n",
            "[Epoch 27/200] [Batch 926/938] [D loss: 0.632107] [G loss: 0.070040]\n",
            "[Epoch 27/200] [Batch 927/938] [D loss: 0.633801] [G loss: 0.069556]\n",
            "[Epoch 27/200] [Batch 928/938] [D loss: 0.648926] [G loss: 0.070192]\n",
            "[Epoch 27/200] [Batch 929/938] [D loss: 0.689932] [G loss: 0.070995]\n",
            "[Epoch 27/200] [Batch 930/938] [D loss: 0.660756] [G loss: 0.073410]\n",
            "[Epoch 27/200] [Batch 931/938] [D loss: 0.629230] [G loss: 0.076426]\n",
            "[Epoch 27/200] [Batch 932/938] [D loss: 0.610863] [G loss: 0.070595]\n",
            "[Epoch 27/200] [Batch 933/938] [D loss: 0.623436] [G loss: 0.075038]\n",
            "[Epoch 27/200] [Batch 934/938] [D loss: 0.621007] [G loss: 0.070550]\n",
            "[Epoch 27/200] [Batch 935/938] [D loss: 0.607974] [G loss: 0.075020]\n",
            "[Epoch 27/200] [Batch 936/938] [D loss: 0.625073] [G loss: 0.068286]\n",
            "[Epoch 27/200] [Batch 937/938] [D loss: 0.663149] [G loss: 0.071342]\n",
            "[Epoch 28/200] [Batch 0/938] [D loss: 0.640409] [G loss: 0.069685]\n",
            "[Epoch 28/200] [Batch 1/938] [D loss: 0.655933] [G loss: 0.065622]\n",
            "[Epoch 28/200] [Batch 2/938] [D loss: 0.632425] [G loss: 0.067608]\n",
            "[Epoch 28/200] [Batch 3/938] [D loss: 0.660596] [G loss: 0.077093]\n",
            "[Epoch 28/200] [Batch 4/938] [D loss: 0.618913] [G loss: 0.073988]\n",
            "[Epoch 28/200] [Batch 5/938] [D loss: 0.633811] [G loss: 0.070939]\n",
            "[Epoch 28/200] [Batch 6/938] [D loss: 0.654470] [G loss: 0.071387]\n",
            "[Epoch 28/200] [Batch 7/938] [D loss: 0.615264] [G loss: 0.071275]\n",
            "[Epoch 28/200] [Batch 8/938] [D loss: 0.647558] [G loss: 0.074396]\n",
            "[Epoch 28/200] [Batch 9/938] [D loss: 0.670290] [G loss: 0.064064]\n",
            "[Epoch 28/200] [Batch 10/938] [D loss: 0.628241] [G loss: 0.081424]\n",
            "[Epoch 28/200] [Batch 11/938] [D loss: 0.623702] [G loss: 0.067383]\n",
            "[Epoch 28/200] [Batch 12/938] [D loss: 0.642075] [G loss: 0.071625]\n",
            "[Epoch 28/200] [Batch 13/938] [D loss: 0.650164] [G loss: 0.071137]\n",
            "[Epoch 28/200] [Batch 14/938] [D loss: 0.603844] [G loss: 0.074761]\n",
            "[Epoch 28/200] [Batch 15/938] [D loss: 0.619354] [G loss: 0.069112]\n",
            "[Epoch 28/200] [Batch 16/938] [D loss: 0.639744] [G loss: 0.070281]\n",
            "[Epoch 28/200] [Batch 17/938] [D loss: 0.653045] [G loss: 0.078758]\n",
            "[Epoch 28/200] [Batch 18/938] [D loss: 0.654766] [G loss: 0.069895]\n",
            "[Epoch 28/200] [Batch 19/938] [D loss: 0.599284] [G loss: 0.073140]\n",
            "[Epoch 28/200] [Batch 20/938] [D loss: 0.613933] [G loss: 0.068880]\n",
            "[Epoch 28/200] [Batch 21/938] [D loss: 0.649867] [G loss: 0.065959]\n",
            "[Epoch 28/200] [Batch 22/938] [D loss: 0.660165] [G loss: 0.073203]\n",
            "[Epoch 28/200] [Batch 23/938] [D loss: 0.598790] [G loss: 0.071465]\n",
            "[Epoch 28/200] [Batch 24/938] [D loss: 0.639989] [G loss: 0.068815]\n",
            "[Epoch 28/200] [Batch 25/938] [D loss: 0.674971] [G loss: 0.071645]\n",
            "[Epoch 28/200] [Batch 26/938] [D loss: 0.644139] [G loss: 0.064099]\n",
            "[Epoch 28/200] [Batch 27/938] [D loss: 0.599440] [G loss: 0.071956]\n",
            "[Epoch 28/200] [Batch 28/938] [D loss: 0.645709] [G loss: 0.075273]\n",
            "[Epoch 28/200] [Batch 29/938] [D loss: 0.636188] [G loss: 0.063460]\n",
            "[Epoch 28/200] [Batch 30/938] [D loss: 0.653561] [G loss: 0.077273]\n",
            "[Epoch 28/200] [Batch 31/938] [D loss: 0.642143] [G loss: 0.072407]\n",
            "[Epoch 28/200] [Batch 32/938] [D loss: 0.637450] [G loss: 0.072427]\n",
            "[Epoch 28/200] [Batch 33/938] [D loss: 0.646296] [G loss: 0.069518]\n",
            "[Epoch 28/200] [Batch 34/938] [D loss: 0.636985] [G loss: 0.065480]\n",
            "[Epoch 28/200] [Batch 35/938] [D loss: 0.634691] [G loss: 0.070702]\n",
            "[Epoch 28/200] [Batch 36/938] [D loss: 0.649165] [G loss: 0.073102]\n",
            "[Epoch 28/200] [Batch 37/938] [D loss: 0.624818] [G loss: 0.066315]\n",
            "[Epoch 28/200] [Batch 38/938] [D loss: 0.651474] [G loss: 0.074789]\n",
            "[Epoch 28/200] [Batch 39/938] [D loss: 0.621650] [G loss: 0.073298]\n",
            "[Epoch 28/200] [Batch 40/938] [D loss: 0.628584] [G loss: 0.068542]\n",
            "[Epoch 28/200] [Batch 41/938] [D loss: 0.618924] [G loss: 0.070783]\n",
            "[Epoch 28/200] [Batch 42/938] [D loss: 0.677211] [G loss: 0.064501]\n",
            "[Epoch 28/200] [Batch 43/938] [D loss: 0.667178] [G loss: 0.075844]\n",
            "[Epoch 28/200] [Batch 44/938] [D loss: 0.615857] [G loss: 0.079443]\n",
            "[Epoch 28/200] [Batch 45/938] [D loss: 0.638545] [G loss: 0.069333]\n",
            "[Epoch 28/200] [Batch 46/938] [D loss: 0.663108] [G loss: 0.071156]\n",
            "[Epoch 28/200] [Batch 47/938] [D loss: 0.580811] [G loss: 0.067063]\n",
            "[Epoch 28/200] [Batch 48/938] [D loss: 0.621203] [G loss: 0.077382]\n",
            "[Epoch 28/200] [Batch 49/938] [D loss: 0.636400] [G loss: 0.075916]\n",
            "[Epoch 28/200] [Batch 50/938] [D loss: 0.616153] [G loss: 0.068087]\n",
            "[Epoch 28/200] [Batch 51/938] [D loss: 0.622709] [G loss: 0.066797]\n",
            "[Epoch 28/200] [Batch 52/938] [D loss: 0.626006] [G loss: 0.072224]\n",
            "[Epoch 28/200] [Batch 53/938] [D loss: 0.629678] [G loss: 0.069215]\n",
            "[Epoch 28/200] [Batch 54/938] [D loss: 0.654885] [G loss: 0.075929]\n",
            "[Epoch 28/200] [Batch 55/938] [D loss: 0.635045] [G loss: 0.068638]\n",
            "[Epoch 28/200] [Batch 56/938] [D loss: 0.643049] [G loss: 0.073624]\n",
            "[Epoch 28/200] [Batch 57/938] [D loss: 0.639963] [G loss: 0.068604]\n",
            "[Epoch 28/200] [Batch 58/938] [D loss: 0.628006] [G loss: 0.071889]\n",
            "[Epoch 28/200] [Batch 59/938] [D loss: 0.606070] [G loss: 0.074851]\n",
            "[Epoch 28/200] [Batch 60/938] [D loss: 0.646590] [G loss: 0.068925]\n",
            "[Epoch 28/200] [Batch 61/938] [D loss: 0.640862] [G loss: 0.070448]\n",
            "[Epoch 28/200] [Batch 62/938] [D loss: 0.622894] [G loss: 0.074366]\n",
            "[Epoch 28/200] [Batch 63/938] [D loss: 0.606058] [G loss: 0.068914]\n",
            "[Epoch 28/200] [Batch 64/938] [D loss: 0.653818] [G loss: 0.070925]\n",
            "[Epoch 28/200] [Batch 65/938] [D loss: 0.634799] [G loss: 0.065087]\n",
            "[Epoch 28/200] [Batch 66/938] [D loss: 0.606251] [G loss: 0.073156]\n",
            "[Epoch 28/200] [Batch 67/938] [D loss: 0.621837] [G loss: 0.071974]\n",
            "[Epoch 28/200] [Batch 68/938] [D loss: 0.629059] [G loss: 0.070008]\n",
            "[Epoch 28/200] [Batch 69/938] [D loss: 0.689596] [G loss: 0.072629]\n",
            "[Epoch 28/200] [Batch 70/938] [D loss: 0.607264] [G loss: 0.074101]\n",
            "[Epoch 28/200] [Batch 71/938] [D loss: 0.618529] [G loss: 0.071672]\n",
            "[Epoch 28/200] [Batch 72/938] [D loss: 0.629162] [G loss: 0.080103]\n",
            "[Epoch 28/200] [Batch 73/938] [D loss: 0.672890] [G loss: 0.071765]\n",
            "[Epoch 28/200] [Batch 74/938] [D loss: 0.635435] [G loss: 0.071342]\n",
            "[Epoch 28/200] [Batch 75/938] [D loss: 0.664130] [G loss: 0.075621]\n",
            "[Epoch 28/200] [Batch 76/938] [D loss: 0.645238] [G loss: 0.068781]\n",
            "[Epoch 28/200] [Batch 77/938] [D loss: 0.648955] [G loss: 0.075920]\n",
            "[Epoch 28/200] [Batch 78/938] [D loss: 0.659436] [G loss: 0.066892]\n",
            "[Epoch 28/200] [Batch 79/938] [D loss: 0.629481] [G loss: 0.070047]\n",
            "[Epoch 28/200] [Batch 80/938] [D loss: 0.606111] [G loss: 0.074125]\n",
            "[Epoch 28/200] [Batch 81/938] [D loss: 0.627383] [G loss: 0.072402]\n",
            "[Epoch 28/200] [Batch 82/938] [D loss: 0.629474] [G loss: 0.075961]\n",
            "[Epoch 28/200] [Batch 83/938] [D loss: 0.618028] [G loss: 0.071588]\n",
            "[Epoch 28/200] [Batch 84/938] [D loss: 0.657308] [G loss: 0.069987]\n",
            "[Epoch 28/200] [Batch 85/938] [D loss: 0.628544] [G loss: 0.086147]\n",
            "[Epoch 28/200] [Batch 86/938] [D loss: 0.623806] [G loss: 0.074501]\n",
            "[Epoch 28/200] [Batch 87/938] [D loss: 0.601073] [G loss: 0.071852]\n",
            "[Epoch 28/200] [Batch 88/938] [D loss: 0.636496] [G loss: 0.070464]\n",
            "[Epoch 28/200] [Batch 89/938] [D loss: 0.640314] [G loss: 0.067918]\n",
            "[Epoch 28/200] [Batch 90/938] [D loss: 0.614166] [G loss: 0.084659]\n",
            "[Epoch 28/200] [Batch 91/938] [D loss: 0.616840] [G loss: 0.069652]\n",
            "[Epoch 28/200] [Batch 92/938] [D loss: 0.617269] [G loss: 0.079340]\n",
            "[Epoch 28/200] [Batch 93/938] [D loss: 0.617910] [G loss: 0.078622]\n",
            "[Epoch 28/200] [Batch 94/938] [D loss: 0.647594] [G loss: 0.073678]\n",
            "[Epoch 28/200] [Batch 95/938] [D loss: 0.616668] [G loss: 0.076446]\n",
            "[Epoch 28/200] [Batch 96/938] [D loss: 0.662195] [G loss: 0.069569]\n",
            "[Epoch 28/200] [Batch 97/938] [D loss: 0.636224] [G loss: 0.068585]\n",
            "[Epoch 28/200] [Batch 98/938] [D loss: 0.640143] [G loss: 0.065695]\n",
            "[Epoch 28/200] [Batch 99/938] [D loss: 0.633770] [G loss: 0.073163]\n",
            "[Epoch 28/200] [Batch 100/938] [D loss: 0.659493] [G loss: 0.075527]\n",
            "[Epoch 28/200] [Batch 101/938] [D loss: 0.593933] [G loss: 0.072032]\n",
            "[Epoch 28/200] [Batch 102/938] [D loss: 0.609460] [G loss: 0.076225]\n",
            "[Epoch 28/200] [Batch 103/938] [D loss: 0.649593] [G loss: 0.068824]\n",
            "[Epoch 28/200] [Batch 104/938] [D loss: 0.646934] [G loss: 0.073072]\n",
            "[Epoch 28/200] [Batch 105/938] [D loss: 0.634479] [G loss: 0.074704]\n",
            "[Epoch 28/200] [Batch 106/938] [D loss: 0.621513] [G loss: 0.064923]\n",
            "[Epoch 28/200] [Batch 107/938] [D loss: 0.630926] [G loss: 0.073299]\n",
            "[Epoch 28/200] [Batch 108/938] [D loss: 0.626388] [G loss: 0.074446]\n",
            "[Epoch 28/200] [Batch 109/938] [D loss: 0.639795] [G loss: 0.067906]\n",
            "[Epoch 28/200] [Batch 110/938] [D loss: 0.623636] [G loss: 0.070693]\n",
            "[Epoch 28/200] [Batch 111/938] [D loss: 0.615793] [G loss: 0.075480]\n",
            "[Epoch 28/200] [Batch 112/938] [D loss: 0.605107] [G loss: 0.069625]\n",
            "[Epoch 28/200] [Batch 113/938] [D loss: 0.649883] [G loss: 0.067320]\n",
            "[Epoch 28/200] [Batch 114/938] [D loss: 0.648147] [G loss: 0.061714]\n",
            "[Epoch 28/200] [Batch 115/938] [D loss: 0.624329] [G loss: 0.071443]\n",
            "[Epoch 28/200] [Batch 116/938] [D loss: 0.618296] [G loss: 0.069917]\n",
            "[Epoch 28/200] [Batch 117/938] [D loss: 0.647913] [G loss: 0.085756]\n",
            "[Epoch 28/200] [Batch 118/938] [D loss: 0.614895] [G loss: 0.072824]\n",
            "[Epoch 28/200] [Batch 119/938] [D loss: 0.657304] [G loss: 0.076592]\n",
            "[Epoch 28/200] [Batch 120/938] [D loss: 0.642337] [G loss: 0.070707]\n",
            "[Epoch 28/200] [Batch 121/938] [D loss: 0.693621] [G loss: 0.074729]\n",
            "[Epoch 28/200] [Batch 122/938] [D loss: 0.654769] [G loss: 0.071063]\n",
            "[Epoch 28/200] [Batch 123/938] [D loss: 0.625580] [G loss: 0.078160]\n",
            "[Epoch 28/200] [Batch 124/938] [D loss: 0.617764] [G loss: 0.071728]\n",
            "[Epoch 28/200] [Batch 125/938] [D loss: 0.663009] [G loss: 0.074885]\n",
            "[Epoch 28/200] [Batch 126/938] [D loss: 0.622989] [G loss: 0.073418]\n",
            "[Epoch 28/200] [Batch 127/938] [D loss: 0.608826] [G loss: 0.072860]\n",
            "[Epoch 28/200] [Batch 128/938] [D loss: 0.640114] [G loss: 0.068132]\n",
            "[Epoch 28/200] [Batch 129/938] [D loss: 0.605529] [G loss: 0.071796]\n",
            "[Epoch 28/200] [Batch 130/938] [D loss: 0.641754] [G loss: 0.077340]\n",
            "[Epoch 28/200] [Batch 131/938] [D loss: 0.633008] [G loss: 0.067804]\n",
            "[Epoch 28/200] [Batch 132/938] [D loss: 0.615160] [G loss: 0.068993]\n",
            "[Epoch 28/200] [Batch 133/938] [D loss: 0.632711] [G loss: 0.072918]\n",
            "[Epoch 28/200] [Batch 134/938] [D loss: 0.624209] [G loss: 0.070385]\n",
            "[Epoch 28/200] [Batch 135/938] [D loss: 0.594326] [G loss: 0.072132]\n",
            "[Epoch 28/200] [Batch 136/938] [D loss: 0.629817] [G loss: 0.074135]\n",
            "[Epoch 28/200] [Batch 137/938] [D loss: 0.643345] [G loss: 0.068377]\n",
            "[Epoch 28/200] [Batch 138/938] [D loss: 0.652148] [G loss: 0.069468]\n",
            "[Epoch 28/200] [Batch 139/938] [D loss: 0.669655] [G loss: 0.071995]\n",
            "[Epoch 28/200] [Batch 140/938] [D loss: 0.638650] [G loss: 0.080334]\n",
            "[Epoch 28/200] [Batch 141/938] [D loss: 0.625918] [G loss: 0.072919]\n",
            "[Epoch 28/200] [Batch 142/938] [D loss: 0.654182] [G loss: 0.064146]\n",
            "[Epoch 28/200] [Batch 143/938] [D loss: 0.608049] [G loss: 0.070573]\n",
            "[Epoch 28/200] [Batch 144/938] [D loss: 0.664858] [G loss: 0.068439]\n",
            "[Epoch 28/200] [Batch 145/938] [D loss: 0.605946] [G loss: 0.065318]\n",
            "[Epoch 28/200] [Batch 146/938] [D loss: 0.628852] [G loss: 0.062008]\n",
            "[Epoch 28/200] [Batch 147/938] [D loss: 0.666428] [G loss: 0.071816]\n",
            "[Epoch 28/200] [Batch 148/938] [D loss: 0.640202] [G loss: 0.068108]\n",
            "[Epoch 28/200] [Batch 149/938] [D loss: 0.642308] [G loss: 0.068561]\n",
            "[Epoch 28/200] [Batch 150/938] [D loss: 0.633396] [G loss: 0.060600]\n",
            "[Epoch 28/200] [Batch 151/938] [D loss: 0.620029] [G loss: 0.073563]\n",
            "[Epoch 28/200] [Batch 152/938] [D loss: 0.647033] [G loss: 0.075407]\n",
            "[Epoch 28/200] [Batch 153/938] [D loss: 0.632650] [G loss: 0.061437]\n",
            "[Epoch 28/200] [Batch 154/938] [D loss: 0.628382] [G loss: 0.071829]\n",
            "[Epoch 28/200] [Batch 155/938] [D loss: 0.592751] [G loss: 0.077701]\n",
            "[Epoch 28/200] [Batch 156/938] [D loss: 0.662393] [G loss: 0.070481]\n",
            "[Epoch 28/200] [Batch 157/938] [D loss: 0.628367] [G loss: 0.072328]\n",
            "[Epoch 28/200] [Batch 158/938] [D loss: 0.618447] [G loss: 0.072811]\n",
            "[Epoch 28/200] [Batch 159/938] [D loss: 0.644010] [G loss: 0.061887]\n",
            "[Epoch 28/200] [Batch 160/938] [D loss: 0.609243] [G loss: 0.074333]\n",
            "[Epoch 28/200] [Batch 161/938] [D loss: 0.645392] [G loss: 0.072626]\n",
            "[Epoch 28/200] [Batch 162/938] [D loss: 0.614779] [G loss: 0.070984]\n",
            "[Epoch 28/200] [Batch 163/938] [D loss: 0.669313] [G loss: 0.074096]\n",
            "[Epoch 28/200] [Batch 164/938] [D loss: 0.623905] [G loss: 0.075360]\n",
            "[Epoch 28/200] [Batch 165/938] [D loss: 0.604170] [G loss: 0.073490]\n",
            "[Epoch 28/200] [Batch 166/938] [D loss: 0.650278] [G loss: 0.072194]\n",
            "[Epoch 28/200] [Batch 167/938] [D loss: 0.645366] [G loss: 0.075817]\n",
            "[Epoch 28/200] [Batch 168/938] [D loss: 0.633432] [G loss: 0.073020]\n",
            "[Epoch 28/200] [Batch 169/938] [D loss: 0.640480] [G loss: 0.071955]\n",
            "[Epoch 28/200] [Batch 170/938] [D loss: 0.623023] [G loss: 0.078522]\n",
            "[Epoch 28/200] [Batch 171/938] [D loss: 0.643927] [G loss: 0.060601]\n",
            "[Epoch 28/200] [Batch 172/938] [D loss: 0.616275] [G loss: 0.074004]\n",
            "[Epoch 28/200] [Batch 173/938] [D loss: 0.617076] [G loss: 0.070383]\n",
            "[Epoch 28/200] [Batch 174/938] [D loss: 0.624561] [G loss: 0.079196]\n",
            "[Epoch 28/200] [Batch 175/938] [D loss: 0.646597] [G loss: 0.077495]\n",
            "[Epoch 28/200] [Batch 176/938] [D loss: 0.619096] [G loss: 0.070907]\n",
            "[Epoch 28/200] [Batch 177/938] [D loss: 0.619435] [G loss: 0.074445]\n",
            "[Epoch 28/200] [Batch 178/938] [D loss: 0.602800] [G loss: 0.071067]\n",
            "[Epoch 28/200] [Batch 179/938] [D loss: 0.649843] [G loss: 0.069003]\n",
            "[Epoch 28/200] [Batch 180/938] [D loss: 0.626372] [G loss: 0.073889]\n",
            "[Epoch 28/200] [Batch 181/938] [D loss: 0.695880] [G loss: 0.068887]\n",
            "[Epoch 28/200] [Batch 182/938] [D loss: 0.629761] [G loss: 0.074392]\n",
            "[Epoch 28/200] [Batch 183/938] [D loss: 0.616492] [G loss: 0.069646]\n",
            "[Epoch 28/200] [Batch 184/938] [D loss: 0.618150] [G loss: 0.071974]\n",
            "[Epoch 28/200] [Batch 185/938] [D loss: 0.651013] [G loss: 0.068568]\n",
            "[Epoch 28/200] [Batch 186/938] [D loss: 0.633413] [G loss: 0.069445]\n",
            "[Epoch 28/200] [Batch 187/938] [D loss: 0.609884] [G loss: 0.077552]\n",
            "[Epoch 28/200] [Batch 188/938] [D loss: 0.642151] [G loss: 0.078457]\n",
            "[Epoch 28/200] [Batch 189/938] [D loss: 0.617239] [G loss: 0.067031]\n",
            "[Epoch 28/200] [Batch 190/938] [D loss: 0.667253] [G loss: 0.077007]\n",
            "[Epoch 28/200] [Batch 191/938] [D loss: 0.636097] [G loss: 0.065181]\n",
            "[Epoch 28/200] [Batch 192/938] [D loss: 0.641474] [G loss: 0.071824]\n",
            "[Epoch 28/200] [Batch 193/938] [D loss: 0.608188] [G loss: 0.068519]\n",
            "[Epoch 28/200] [Batch 194/938] [D loss: 0.597686] [G loss: 0.073167]\n",
            "[Epoch 28/200] [Batch 195/938] [D loss: 0.636579] [G loss: 0.071045]\n",
            "[Epoch 28/200] [Batch 196/938] [D loss: 0.621283] [G loss: 0.067936]\n",
            "[Epoch 28/200] [Batch 197/938] [D loss: 0.632607] [G loss: 0.074114]\n",
            "[Epoch 28/200] [Batch 198/938] [D loss: 0.649739] [G loss: 0.071315]\n",
            "[Epoch 28/200] [Batch 199/938] [D loss: 0.623453] [G loss: 0.077867]\n",
            "[Epoch 28/200] [Batch 200/938] [D loss: 0.614309] [G loss: 0.070904]\n",
            "[Epoch 28/200] [Batch 201/938] [D loss: 0.615648] [G loss: 0.076142]\n",
            "[Epoch 28/200] [Batch 202/938] [D loss: 0.643610] [G loss: 0.074352]\n",
            "[Epoch 28/200] [Batch 203/938] [D loss: 0.653387] [G loss: 0.076655]\n",
            "[Epoch 28/200] [Batch 204/938] [D loss: 0.637376] [G loss: 0.078624]\n",
            "[Epoch 28/200] [Batch 205/938] [D loss: 0.652496] [G loss: 0.072056]\n",
            "[Epoch 28/200] [Batch 206/938] [D loss: 0.644213] [G loss: 0.075201]\n",
            "[Epoch 28/200] [Batch 207/938] [D loss: 0.638672] [G loss: 0.065602]\n",
            "[Epoch 28/200] [Batch 208/938] [D loss: 0.667015] [G loss: 0.062200]\n",
            "[Epoch 28/200] [Batch 209/938] [D loss: 0.613245] [G loss: 0.068801]\n",
            "[Epoch 28/200] [Batch 210/938] [D loss: 0.665862] [G loss: 0.065873]\n",
            "[Epoch 28/200] [Batch 211/938] [D loss: 0.608026] [G loss: 0.079314]\n",
            "[Epoch 28/200] [Batch 212/938] [D loss: 0.663546] [G loss: 0.070262]\n",
            "[Epoch 28/200] [Batch 213/938] [D loss: 0.599650] [G loss: 0.081618]\n",
            "[Epoch 28/200] [Batch 214/938] [D loss: 0.621842] [G loss: 0.074573]\n",
            "[Epoch 28/200] [Batch 215/938] [D loss: 0.595635] [G loss: 0.066532]\n",
            "[Epoch 28/200] [Batch 216/938] [D loss: 0.621630] [G loss: 0.066174]\n",
            "[Epoch 28/200] [Batch 217/938] [D loss: 0.643841] [G loss: 0.069968]\n",
            "[Epoch 28/200] [Batch 218/938] [D loss: 0.644955] [G loss: 0.073559]\n",
            "[Epoch 28/200] [Batch 219/938] [D loss: 0.619934] [G loss: 0.071007]\n",
            "[Epoch 28/200] [Batch 220/938] [D loss: 0.601594] [G loss: 0.072086]\n",
            "[Epoch 28/200] [Batch 221/938] [D loss: 0.627941] [G loss: 0.065781]\n",
            "[Epoch 28/200] [Batch 222/938] [D loss: 0.643154] [G loss: 0.067307]\n",
            "[Epoch 28/200] [Batch 223/938] [D loss: 0.625056] [G loss: 0.080493]\n",
            "[Epoch 28/200] [Batch 224/938] [D loss: 0.612689] [G loss: 0.074369]\n",
            "[Epoch 28/200] [Batch 225/938] [D loss: 0.628222] [G loss: 0.067707]\n",
            "[Epoch 28/200] [Batch 226/938] [D loss: 0.638103] [G loss: 0.067459]\n",
            "[Epoch 28/200] [Batch 227/938] [D loss: 0.617630] [G loss: 0.073362]\n",
            "[Epoch 28/200] [Batch 228/938] [D loss: 0.636803] [G loss: 0.074340]\n",
            "[Epoch 28/200] [Batch 229/938] [D loss: 0.603761] [G loss: 0.073615]\n",
            "[Epoch 28/200] [Batch 230/938] [D loss: 0.620912] [G loss: 0.072025]\n",
            "[Epoch 28/200] [Batch 231/938] [D loss: 0.627656] [G loss: 0.072165]\n",
            "[Epoch 28/200] [Batch 232/938] [D loss: 0.649257] [G loss: 0.076340]\n",
            "[Epoch 28/200] [Batch 233/938] [D loss: 0.618802] [G loss: 0.067865]\n",
            "[Epoch 28/200] [Batch 234/938] [D loss: 0.630302] [G loss: 0.065827]\n",
            "[Epoch 28/200] [Batch 235/938] [D loss: 0.651253] [G loss: 0.078656]\n",
            "[Epoch 28/200] [Batch 236/938] [D loss: 0.610570] [G loss: 0.074871]\n",
            "[Epoch 28/200] [Batch 237/938] [D loss: 0.618617] [G loss: 0.069415]\n",
            "[Epoch 28/200] [Batch 238/938] [D loss: 0.665660] [G loss: 0.069105]\n",
            "[Epoch 28/200] [Batch 239/938] [D loss: 0.664068] [G loss: 0.076614]\n",
            "[Epoch 28/200] [Batch 240/938] [D loss: 0.601559] [G loss: 0.074502]\n",
            "[Epoch 28/200] [Batch 241/938] [D loss: 0.647479] [G loss: 0.068076]\n",
            "[Epoch 28/200] [Batch 242/938] [D loss: 0.616600] [G loss: 0.073011]\n",
            "[Epoch 28/200] [Batch 243/938] [D loss: 0.614799] [G loss: 0.079374]\n",
            "[Epoch 28/200] [Batch 244/938] [D loss: 0.631493] [G loss: 0.070996]\n",
            "[Epoch 28/200] [Batch 245/938] [D loss: 0.596990] [G loss: 0.072919]\n",
            "[Epoch 28/200] [Batch 246/938] [D loss: 0.622152] [G loss: 0.080565]\n",
            "[Epoch 28/200] [Batch 247/938] [D loss: 0.601783] [G loss: 0.074126]\n",
            "[Epoch 28/200] [Batch 248/938] [D loss: 0.650275] [G loss: 0.070317]\n",
            "[Epoch 28/200] [Batch 249/938] [D loss: 0.649053] [G loss: 0.075189]\n",
            "[Epoch 28/200] [Batch 250/938] [D loss: 0.630623] [G loss: 0.078192]\n",
            "[Epoch 28/200] [Batch 251/938] [D loss: 0.653016] [G loss: 0.072740]\n",
            "[Epoch 28/200] [Batch 252/938] [D loss: 0.638263] [G loss: 0.064718]\n",
            "[Epoch 28/200] [Batch 253/938] [D loss: 0.615579] [G loss: 0.074026]\n",
            "[Epoch 28/200] [Batch 254/938] [D loss: 0.613492] [G loss: 0.069626]\n",
            "[Epoch 28/200] [Batch 255/938] [D loss: 0.645174] [G loss: 0.072782]\n",
            "[Epoch 28/200] [Batch 256/938] [D loss: 0.678424] [G loss: 0.075808]\n",
            "[Epoch 28/200] [Batch 257/938] [D loss: 0.610881] [G loss: 0.068636]\n",
            "[Epoch 28/200] [Batch 258/938] [D loss: 0.638207] [G loss: 0.074759]\n",
            "[Epoch 28/200] [Batch 259/938] [D loss: 0.610978] [G loss: 0.072099]\n",
            "[Epoch 28/200] [Batch 260/938] [D loss: 0.621015] [G loss: 0.078340]\n",
            "[Epoch 28/200] [Batch 261/938] [D loss: 0.649672] [G loss: 0.067753]\n",
            "[Epoch 28/200] [Batch 262/938] [D loss: 0.619019] [G loss: 0.074372]\n",
            "[Epoch 28/200] [Batch 263/938] [D loss: 0.624080] [G loss: 0.068386]\n",
            "[Epoch 28/200] [Batch 264/938] [D loss: 0.647356] [G loss: 0.071750]\n",
            "[Epoch 28/200] [Batch 265/938] [D loss: 0.647356] [G loss: 0.075298]\n",
            "[Epoch 28/200] [Batch 266/938] [D loss: 0.673618] [G loss: 0.066983]\n",
            "[Epoch 28/200] [Batch 267/938] [D loss: 0.629243] [G loss: 0.074947]\n",
            "[Epoch 28/200] [Batch 268/938] [D loss: 0.626446] [G loss: 0.075044]\n",
            "[Epoch 28/200] [Batch 269/938] [D loss: 0.610281] [G loss: 0.073566]\n",
            "[Epoch 28/200] [Batch 270/938] [D loss: 0.656864] [G loss: 0.066385]\n",
            "[Epoch 28/200] [Batch 271/938] [D loss: 0.603624] [G loss: 0.072130]\n",
            "[Epoch 28/200] [Batch 272/938] [D loss: 0.645259] [G loss: 0.078123]\n",
            "[Epoch 28/200] [Batch 273/938] [D loss: 0.657540] [G loss: 0.067767]\n",
            "[Epoch 28/200] [Batch 274/938] [D loss: 0.648112] [G loss: 0.070027]\n",
            "[Epoch 28/200] [Batch 275/938] [D loss: 0.581149] [G loss: 0.072379]\n",
            "[Epoch 28/200] [Batch 276/938] [D loss: 0.636141] [G loss: 0.066947]\n",
            "[Epoch 28/200] [Batch 277/938] [D loss: 0.620032] [G loss: 0.068801]\n",
            "[Epoch 28/200] [Batch 278/938] [D loss: 0.623819] [G loss: 0.068996]\n",
            "[Epoch 28/200] [Batch 279/938] [D loss: 0.618308] [G loss: 0.077710]\n",
            "[Epoch 28/200] [Batch 280/938] [D loss: 0.648846] [G loss: 0.074721]\n",
            "[Epoch 28/200] [Batch 281/938] [D loss: 0.653835] [G loss: 0.075292]\n",
            "[Epoch 28/200] [Batch 282/938] [D loss: 0.654906] [G loss: 0.068988]\n",
            "[Epoch 28/200] [Batch 283/938] [D loss: 0.641424] [G loss: 0.062154]\n",
            "[Epoch 28/200] [Batch 284/938] [D loss: 0.625981] [G loss: 0.075704]\n",
            "[Epoch 28/200] [Batch 285/938] [D loss: 0.643278] [G loss: 0.064901]\n",
            "[Epoch 28/200] [Batch 286/938] [D loss: 0.618981] [G loss: 0.065954]\n",
            "[Epoch 28/200] [Batch 287/938] [D loss: 0.649076] [G loss: 0.078006]\n",
            "[Epoch 28/200] [Batch 288/938] [D loss: 0.665577] [G loss: 0.069182]\n",
            "[Epoch 28/200] [Batch 289/938] [D loss: 0.695203] [G loss: 0.070476]\n",
            "[Epoch 28/200] [Batch 290/938] [D loss: 0.605461] [G loss: 0.075195]\n",
            "[Epoch 28/200] [Batch 291/938] [D loss: 0.637389] [G loss: 0.072877]\n",
            "[Epoch 28/200] [Batch 292/938] [D loss: 0.615096] [G loss: 0.072621]\n",
            "[Epoch 28/200] [Batch 293/938] [D loss: 0.615954] [G loss: 0.071437]\n",
            "[Epoch 28/200] [Batch 294/938] [D loss: 0.634785] [G loss: 0.067095]\n",
            "[Epoch 28/200] [Batch 295/938] [D loss: 0.572759] [G loss: 0.077166]\n",
            "[Epoch 28/200] [Batch 296/938] [D loss: 0.645127] [G loss: 0.070181]\n",
            "[Epoch 28/200] [Batch 297/938] [D loss: 0.628649] [G loss: 0.070910]\n",
            "[Epoch 28/200] [Batch 298/938] [D loss: 0.632213] [G loss: 0.067162]\n",
            "[Epoch 28/200] [Batch 299/938] [D loss: 0.596767] [G loss: 0.074489]\n",
            "[Epoch 28/200] [Batch 300/938] [D loss: 0.622618] [G loss: 0.070708]\n",
            "[Epoch 28/200] [Batch 301/938] [D loss: 0.614521] [G loss: 0.074556]\n",
            "[Epoch 28/200] [Batch 302/938] [D loss: 0.604293] [G loss: 0.069051]\n",
            "[Epoch 28/200] [Batch 303/938] [D loss: 0.641354] [G loss: 0.075169]\n",
            "[Epoch 28/200] [Batch 304/938] [D loss: 0.630914] [G loss: 0.064460]\n",
            "[Epoch 28/200] [Batch 305/938] [D loss: 0.630961] [G loss: 0.071962]\n",
            "[Epoch 28/200] [Batch 306/938] [D loss: 0.649344] [G loss: 0.081029]\n",
            "[Epoch 28/200] [Batch 307/938] [D loss: 0.668624] [G loss: 0.076249]\n",
            "[Epoch 28/200] [Batch 308/938] [D loss: 0.641049] [G loss: 0.070401]\n",
            "[Epoch 28/200] [Batch 309/938] [D loss: 0.627564] [G loss: 0.070416]\n",
            "[Epoch 28/200] [Batch 310/938] [D loss: 0.621541] [G loss: 0.073142]\n",
            "[Epoch 28/200] [Batch 311/938] [D loss: 0.611850] [G loss: 0.073865]\n",
            "[Epoch 28/200] [Batch 312/938] [D loss: 0.618503] [G loss: 0.072991]\n",
            "[Epoch 28/200] [Batch 313/938] [D loss: 0.624258] [G loss: 0.072927]\n",
            "[Epoch 28/200] [Batch 314/938] [D loss: 0.650189] [G loss: 0.076282]\n",
            "[Epoch 28/200] [Batch 315/938] [D loss: 0.632255] [G loss: 0.074776]\n",
            "[Epoch 28/200] [Batch 316/938] [D loss: 0.656709] [G loss: 0.067839]\n",
            "[Epoch 28/200] [Batch 317/938] [D loss: 0.630207] [G loss: 0.078270]\n",
            "[Epoch 28/200] [Batch 318/938] [D loss: 0.605199] [G loss: 0.073843]\n",
            "[Epoch 28/200] [Batch 319/938] [D loss: 0.619253] [G loss: 0.069580]\n",
            "[Epoch 28/200] [Batch 320/938] [D loss: 0.647804] [G loss: 0.074649]\n",
            "[Epoch 28/200] [Batch 321/938] [D loss: 0.646419] [G loss: 0.069326]\n",
            "[Epoch 28/200] [Batch 322/938] [D loss: 0.619182] [G loss: 0.068108]\n",
            "[Epoch 28/200] [Batch 323/938] [D loss: 0.624057] [G loss: 0.071720]\n",
            "[Epoch 28/200] [Batch 324/938] [D loss: 0.652552] [G loss: 0.063466]\n",
            "[Epoch 28/200] [Batch 325/938] [D loss: 0.644413] [G loss: 0.069607]\n",
            "[Epoch 28/200] [Batch 326/938] [D loss: 0.637299] [G loss: 0.072057]\n",
            "[Epoch 28/200] [Batch 327/938] [D loss: 0.645259] [G loss: 0.076632]\n",
            "[Epoch 28/200] [Batch 328/938] [D loss: 0.628499] [G loss: 0.071140]\n",
            "[Epoch 28/200] [Batch 329/938] [D loss: 0.601333] [G loss: 0.071126]\n",
            "[Epoch 28/200] [Batch 330/938] [D loss: 0.639053] [G loss: 0.067534]\n",
            "[Epoch 28/200] [Batch 331/938] [D loss: 0.638887] [G loss: 0.069195]\n",
            "[Epoch 28/200] [Batch 332/938] [D loss: 0.630236] [G loss: 0.070714]\n",
            "[Epoch 28/200] [Batch 333/938] [D loss: 0.658131] [G loss: 0.070913]\n",
            "[Epoch 28/200] [Batch 334/938] [D loss: 0.684737] [G loss: 0.069355]\n",
            "[Epoch 28/200] [Batch 335/938] [D loss: 0.629960] [G loss: 0.066780]\n",
            "[Epoch 28/200] [Batch 336/938] [D loss: 0.642515] [G loss: 0.067964]\n",
            "[Epoch 28/200] [Batch 337/938] [D loss: 0.660736] [G loss: 0.071419]\n",
            "[Epoch 28/200] [Batch 338/938] [D loss: 0.657666] [G loss: 0.075739]\n",
            "[Epoch 28/200] [Batch 339/938] [D loss: 0.629578] [G loss: 0.074043]\n",
            "[Epoch 28/200] [Batch 340/938] [D loss: 0.614261] [G loss: 0.072085]\n",
            "[Epoch 28/200] [Batch 341/938] [D loss: 0.598748] [G loss: 0.071185]\n",
            "[Epoch 28/200] [Batch 342/938] [D loss: 0.636281] [G loss: 0.074764]\n",
            "[Epoch 28/200] [Batch 343/938] [D loss: 0.652971] [G loss: 0.076763]\n",
            "[Epoch 28/200] [Batch 344/938] [D loss: 0.648118] [G loss: 0.073523]\n",
            "[Epoch 28/200] [Batch 345/938] [D loss: 0.657582] [G loss: 0.071792]\n",
            "[Epoch 28/200] [Batch 346/938] [D loss: 0.638613] [G loss: 0.067868]\n",
            "[Epoch 28/200] [Batch 347/938] [D loss: 0.663396] [G loss: 0.062740]\n",
            "[Epoch 28/200] [Batch 348/938] [D loss: 0.627338] [G loss: 0.069048]\n",
            "[Epoch 28/200] [Batch 349/938] [D loss: 0.642305] [G loss: 0.072621]\n",
            "[Epoch 28/200] [Batch 350/938] [D loss: 0.653976] [G loss: 0.072604]\n",
            "[Epoch 28/200] [Batch 351/938] [D loss: 0.623478] [G loss: 0.065014]\n",
            "[Epoch 28/200] [Batch 352/938] [D loss: 0.601990] [G loss: 0.076071]\n",
            "[Epoch 28/200] [Batch 353/938] [D loss: 0.661529] [G loss: 0.078450]\n",
            "[Epoch 28/200] [Batch 354/938] [D loss: 0.665126] [G loss: 0.078797]\n",
            "[Epoch 28/200] [Batch 355/938] [D loss: 0.622568] [G loss: 0.074116]\n",
            "[Epoch 28/200] [Batch 356/938] [D loss: 0.661072] [G loss: 0.071964]\n",
            "[Epoch 28/200] [Batch 357/938] [D loss: 0.630926] [G loss: 0.081422]\n",
            "[Epoch 28/200] [Batch 358/938] [D loss: 0.602071] [G loss: 0.070836]\n",
            "[Epoch 28/200] [Batch 359/938] [D loss: 0.623311] [G loss: 0.069048]\n",
            "[Epoch 28/200] [Batch 360/938] [D loss: 0.631055] [G loss: 0.080991]\n",
            "[Epoch 28/200] [Batch 361/938] [D loss: 0.645972] [G loss: 0.071300]\n",
            "[Epoch 28/200] [Batch 362/938] [D loss: 0.633447] [G loss: 0.074117]\n",
            "[Epoch 28/200] [Batch 363/938] [D loss: 0.663339] [G loss: 0.080325]\n",
            "[Epoch 28/200] [Batch 364/938] [D loss: 0.650776] [G loss: 0.068391]\n",
            "[Epoch 28/200] [Batch 365/938] [D loss: 0.639849] [G loss: 0.077215]\n",
            "[Epoch 28/200] [Batch 366/938] [D loss: 0.645997] [G loss: 0.076668]\n",
            "[Epoch 28/200] [Batch 367/938] [D loss: 0.630005] [G loss: 0.069391]\n",
            "[Epoch 28/200] [Batch 368/938] [D loss: 0.631859] [G loss: 0.075332]\n",
            "[Epoch 28/200] [Batch 369/938] [D loss: 0.644040] [G loss: 0.071439]\n",
            "[Epoch 28/200] [Batch 370/938] [D loss: 0.651210] [G loss: 0.075566]\n",
            "[Epoch 28/200] [Batch 371/938] [D loss: 0.613060] [G loss: 0.077319]\n",
            "[Epoch 28/200] [Batch 372/938] [D loss: 0.676200] [G loss: 0.070439]\n",
            "[Epoch 28/200] [Batch 373/938] [D loss: 0.635656] [G loss: 0.079237]\n",
            "[Epoch 28/200] [Batch 374/938] [D loss: 0.629469] [G loss: 0.069256]\n",
            "[Epoch 28/200] [Batch 375/938] [D loss: 0.669578] [G loss: 0.077601]\n",
            "[Epoch 28/200] [Batch 376/938] [D loss: 0.634784] [G loss: 0.068419]\n",
            "[Epoch 28/200] [Batch 377/938] [D loss: 0.616123] [G loss: 0.072802]\n",
            "[Epoch 28/200] [Batch 378/938] [D loss: 0.617402] [G loss: 0.077008]\n",
            "[Epoch 28/200] [Batch 379/938] [D loss: 0.679796] [G loss: 0.072526]\n",
            "[Epoch 28/200] [Batch 380/938] [D loss: 0.614115] [G loss: 0.068155]\n",
            "[Epoch 28/200] [Batch 381/938] [D loss: 0.662974] [G loss: 0.068023]\n",
            "[Epoch 28/200] [Batch 382/938] [D loss: 0.650785] [G loss: 0.068925]\n",
            "[Epoch 28/200] [Batch 383/938] [D loss: 0.627992] [G loss: 0.075887]\n",
            "[Epoch 28/200] [Batch 384/938] [D loss: 0.635584] [G loss: 0.073854]\n",
            "[Epoch 28/200] [Batch 385/938] [D loss: 0.608466] [G loss: 0.069441]\n",
            "[Epoch 28/200] [Batch 386/938] [D loss: 0.649249] [G loss: 0.069756]\n",
            "[Epoch 28/200] [Batch 387/938] [D loss: 0.663080] [G loss: 0.080106]\n",
            "[Epoch 28/200] [Batch 388/938] [D loss: 0.603525] [G loss: 0.065839]\n",
            "[Epoch 28/200] [Batch 389/938] [D loss: 0.619263] [G loss: 0.070848]\n",
            "[Epoch 28/200] [Batch 390/938] [D loss: 0.604861] [G loss: 0.076758]\n",
            "[Epoch 28/200] [Batch 391/938] [D loss: 0.656466] [G loss: 0.075055]\n",
            "[Epoch 28/200] [Batch 392/938] [D loss: 0.628711] [G loss: 0.073571]\n",
            "[Epoch 28/200] [Batch 393/938] [D loss: 0.639702] [G loss: 0.069800]\n",
            "[Epoch 28/200] [Batch 394/938] [D loss: 0.648838] [G loss: 0.078474]\n",
            "[Epoch 28/200] [Batch 395/938] [D loss: 0.645124] [G loss: 0.067651]\n",
            "[Epoch 28/200] [Batch 396/938] [D loss: 0.655018] [G loss: 0.072575]\n",
            "[Epoch 28/200] [Batch 397/938] [D loss: 0.658481] [G loss: 0.069541]\n",
            "[Epoch 28/200] [Batch 398/938] [D loss: 0.638049] [G loss: 0.072911]\n",
            "[Epoch 28/200] [Batch 399/938] [D loss: 0.618570] [G loss: 0.071389]\n",
            "[Epoch 28/200] [Batch 400/938] [D loss: 0.675516] [G loss: 0.067705]\n",
            "[Epoch 28/200] [Batch 401/938] [D loss: 0.622217] [G loss: 0.065929]\n",
            "[Epoch 28/200] [Batch 402/938] [D loss: 0.623523] [G loss: 0.071904]\n",
            "[Epoch 28/200] [Batch 403/938] [D loss: 0.619516] [G loss: 0.067711]\n",
            "[Epoch 28/200] [Batch 404/938] [D loss: 0.611633] [G loss: 0.072425]\n",
            "[Epoch 28/200] [Batch 405/938] [D loss: 0.673427] [G loss: 0.069660]\n",
            "[Epoch 28/200] [Batch 406/938] [D loss: 0.647992] [G loss: 0.078332]\n",
            "[Epoch 28/200] [Batch 407/938] [D loss: 0.643865] [G loss: 0.069052]\n",
            "[Epoch 28/200] [Batch 408/938] [D loss: 0.628697] [G loss: 0.074126]\n",
            "[Epoch 28/200] [Batch 409/938] [D loss: 0.667148] [G loss: 0.069734]\n",
            "[Epoch 28/200] [Batch 410/938] [D loss: 0.686239] [G loss: 0.066233]\n",
            "[Epoch 28/200] [Batch 411/938] [D loss: 0.641585] [G loss: 0.071869]\n",
            "[Epoch 28/200] [Batch 412/938] [D loss: 0.668080] [G loss: 0.067383]\n",
            "[Epoch 28/200] [Batch 413/938] [D loss: 0.633165] [G loss: 0.073731]\n",
            "[Epoch 28/200] [Batch 414/938] [D loss: 0.654059] [G loss: 0.072720]\n",
            "[Epoch 28/200] [Batch 415/938] [D loss: 0.604430] [G loss: 0.072305]\n",
            "[Epoch 28/200] [Batch 416/938] [D loss: 0.618885] [G loss: 0.069245]\n",
            "[Epoch 28/200] [Batch 417/938] [D loss: 0.649405] [G loss: 0.071058]\n",
            "[Epoch 28/200] [Batch 418/938] [D loss: 0.585072] [G loss: 0.073896]\n",
            "[Epoch 28/200] [Batch 419/938] [D loss: 0.649887] [G loss: 0.073660]\n",
            "[Epoch 28/200] [Batch 420/938] [D loss: 0.597262] [G loss: 0.066626]\n",
            "[Epoch 28/200] [Batch 421/938] [D loss: 0.665643] [G loss: 0.082039]\n",
            "[Epoch 28/200] [Batch 422/938] [D loss: 0.643264] [G loss: 0.073632]\n",
            "[Epoch 28/200] [Batch 423/938] [D loss: 0.623873] [G loss: 0.068841]\n",
            "[Epoch 28/200] [Batch 424/938] [D loss: 0.616422] [G loss: 0.072231]\n",
            "[Epoch 28/200] [Batch 425/938] [D loss: 0.584189] [G loss: 0.071737]\n",
            "[Epoch 28/200] [Batch 426/938] [D loss: 0.597625] [G loss: 0.071771]\n",
            "[Epoch 28/200] [Batch 427/938] [D loss: 0.659140] [G loss: 0.072940]\n",
            "[Epoch 28/200] [Batch 428/938] [D loss: 0.634408] [G loss: 0.075548]\n",
            "[Epoch 28/200] [Batch 429/938] [D loss: 0.627140] [G loss: 0.068535]\n",
            "[Epoch 28/200] [Batch 430/938] [D loss: 0.618975] [G loss: 0.068307]\n",
            "[Epoch 28/200] [Batch 431/938] [D loss: 0.638940] [G loss: 0.077211]\n",
            "[Epoch 28/200] [Batch 432/938] [D loss: 0.591752] [G loss: 0.079828]\n",
            "[Epoch 28/200] [Batch 433/938] [D loss: 0.623768] [G loss: 0.077976]\n",
            "[Epoch 28/200] [Batch 434/938] [D loss: 0.639876] [G loss: 0.078806]\n",
            "[Epoch 28/200] [Batch 435/938] [D loss: 0.650254] [G loss: 0.068309]\n",
            "[Epoch 28/200] [Batch 436/938] [D loss: 0.608378] [G loss: 0.071562]\n",
            "[Epoch 28/200] [Batch 437/938] [D loss: 0.624826] [G loss: 0.068376]\n",
            "[Epoch 28/200] [Batch 438/938] [D loss: 0.614618] [G loss: 0.072620]\n",
            "[Epoch 28/200] [Batch 439/938] [D loss: 0.624764] [G loss: 0.071285]\n",
            "[Epoch 28/200] [Batch 440/938] [D loss: 0.659477] [G loss: 0.066499]\n",
            "[Epoch 28/200] [Batch 441/938] [D loss: 0.657554] [G loss: 0.068347]\n",
            "[Epoch 28/200] [Batch 442/938] [D loss: 0.628752] [G loss: 0.069599]\n",
            "[Epoch 28/200] [Batch 443/938] [D loss: 0.604576] [G loss: 0.069311]\n",
            "[Epoch 28/200] [Batch 444/938] [D loss: 0.624109] [G loss: 0.073146]\n",
            "[Epoch 28/200] [Batch 445/938] [D loss: 0.663448] [G loss: 0.071049]\n",
            "[Epoch 28/200] [Batch 446/938] [D loss: 0.612269] [G loss: 0.075849]\n",
            "[Epoch 28/200] [Batch 447/938] [D loss: 0.665601] [G loss: 0.082748]\n",
            "[Epoch 28/200] [Batch 448/938] [D loss: 0.633250] [G loss: 0.071189]\n",
            "[Epoch 28/200] [Batch 449/938] [D loss: 0.644732] [G loss: 0.071939]\n",
            "[Epoch 28/200] [Batch 450/938] [D loss: 0.669859] [G loss: 0.070903]\n",
            "[Epoch 28/200] [Batch 451/938] [D loss: 0.614457] [G loss: 0.079772]\n",
            "[Epoch 28/200] [Batch 452/938] [D loss: 0.583789] [G loss: 0.074670]\n",
            "[Epoch 28/200] [Batch 453/938] [D loss: 0.614558] [G loss: 0.066063]\n",
            "[Epoch 28/200] [Batch 454/938] [D loss: 0.676682] [G loss: 0.074523]\n",
            "[Epoch 28/200] [Batch 455/938] [D loss: 0.652694] [G loss: 0.070350]\n",
            "[Epoch 28/200] [Batch 456/938] [D loss: 0.626929] [G loss: 0.065340]\n",
            "[Epoch 28/200] [Batch 457/938] [D loss: 0.632692] [G loss: 0.065734]\n",
            "[Epoch 28/200] [Batch 458/938] [D loss: 0.648731] [G loss: 0.069873]\n",
            "[Epoch 28/200] [Batch 459/938] [D loss: 0.676898] [G loss: 0.072595]\n",
            "[Epoch 28/200] [Batch 460/938] [D loss: 0.650555] [G loss: 0.079973]\n",
            "[Epoch 28/200] [Batch 461/938] [D loss: 0.657840] [G loss: 0.068076]\n",
            "[Epoch 28/200] [Batch 462/938] [D loss: 0.643067] [G loss: 0.071837]\n",
            "[Epoch 28/200] [Batch 463/938] [D loss: 0.639593] [G loss: 0.064548]\n",
            "[Epoch 28/200] [Batch 464/938] [D loss: 0.633483] [G loss: 0.071583]\n",
            "[Epoch 28/200] [Batch 465/938] [D loss: 0.662269] [G loss: 0.071808]\n",
            "[Epoch 28/200] [Batch 466/938] [D loss: 0.640087] [G loss: 0.070196]\n",
            "[Epoch 28/200] [Batch 467/938] [D loss: 0.624600] [G loss: 0.079658]\n",
            "[Epoch 28/200] [Batch 468/938] [D loss: 0.636956] [G loss: 0.074937]\n",
            "[Epoch 28/200] [Batch 469/938] [D loss: 0.632570] [G loss: 0.066697]\n",
            "[Epoch 28/200] [Batch 470/938] [D loss: 0.624404] [G loss: 0.073822]\n",
            "[Epoch 28/200] [Batch 471/938] [D loss: 0.634492] [G loss: 0.065969]\n",
            "[Epoch 28/200] [Batch 472/938] [D loss: 0.653404] [G loss: 0.070064]\n",
            "[Epoch 28/200] [Batch 473/938] [D loss: 0.635097] [G loss: 0.072571]\n",
            "[Epoch 28/200] [Batch 474/938] [D loss: 0.607139] [G loss: 0.067387]\n",
            "[Epoch 28/200] [Batch 475/938] [D loss: 0.640244] [G loss: 0.071128]\n",
            "[Epoch 28/200] [Batch 476/938] [D loss: 0.678949] [G loss: 0.070942]\n",
            "[Epoch 28/200] [Batch 477/938] [D loss: 0.625025] [G loss: 0.074197]\n",
            "[Epoch 28/200] [Batch 478/938] [D loss: 0.627321] [G loss: 0.065080]\n",
            "[Epoch 28/200] [Batch 479/938] [D loss: 0.634139] [G loss: 0.069599]\n",
            "[Epoch 28/200] [Batch 480/938] [D loss: 0.619737] [G loss: 0.070123]\n",
            "[Epoch 28/200] [Batch 481/938] [D loss: 0.615752] [G loss: 0.074111]\n",
            "[Epoch 28/200] [Batch 482/938] [D loss: 0.650501] [G loss: 0.068852]\n",
            "[Epoch 28/200] [Batch 483/938] [D loss: 0.639203] [G loss: 0.072935]\n",
            "[Epoch 28/200] [Batch 484/938] [D loss: 0.630194] [G loss: 0.076042]\n",
            "[Epoch 28/200] [Batch 485/938] [D loss: 0.639140] [G loss: 0.068667]\n",
            "[Epoch 28/200] [Batch 486/938] [D loss: 0.634905] [G loss: 0.077147]\n",
            "[Epoch 28/200] [Batch 487/938] [D loss: 0.638736] [G loss: 0.073117]\n",
            "[Epoch 28/200] [Batch 488/938] [D loss: 0.631281] [G loss: 0.071985]\n",
            "[Epoch 28/200] [Batch 489/938] [D loss: 0.646195] [G loss: 0.065136]\n",
            "[Epoch 28/200] [Batch 490/938] [D loss: 0.678737] [G loss: 0.077325]\n",
            "[Epoch 28/200] [Batch 491/938] [D loss: 0.631097] [G loss: 0.067948]\n",
            "[Epoch 28/200] [Batch 492/938] [D loss: 0.646465] [G loss: 0.072230]\n",
            "[Epoch 28/200] [Batch 493/938] [D loss: 0.676630] [G loss: 0.067902]\n",
            "[Epoch 28/200] [Batch 494/938] [D loss: 0.646688] [G loss: 0.075641]\n",
            "[Epoch 28/200] [Batch 495/938] [D loss: 0.611824] [G loss: 0.070509]\n",
            "[Epoch 28/200] [Batch 496/938] [D loss: 0.644955] [G loss: 0.068640]\n",
            "[Epoch 28/200] [Batch 497/938] [D loss: 0.636680] [G loss: 0.076317]\n",
            "[Epoch 28/200] [Batch 498/938] [D loss: 0.627193] [G loss: 0.079514]\n",
            "[Epoch 28/200] [Batch 499/938] [D loss: 0.646838] [G loss: 0.070156]\n",
            "[Epoch 28/200] [Batch 500/938] [D loss: 0.652948] [G loss: 0.071276]\n",
            "[Epoch 28/200] [Batch 501/938] [D loss: 0.626196] [G loss: 0.070751]\n",
            "[Epoch 28/200] [Batch 502/938] [D loss: 0.640090] [G loss: 0.073680]\n",
            "[Epoch 28/200] [Batch 503/938] [D loss: 0.588084] [G loss: 0.071267]\n",
            "[Epoch 28/200] [Batch 504/938] [D loss: 0.620196] [G loss: 0.072682]\n",
            "[Epoch 28/200] [Batch 505/938] [D loss: 0.657139] [G loss: 0.070653]\n",
            "[Epoch 28/200] [Batch 506/938] [D loss: 0.609859] [G loss: 0.071698]\n",
            "[Epoch 28/200] [Batch 507/938] [D loss: 0.654189] [G loss: 0.075065]\n",
            "[Epoch 28/200] [Batch 508/938] [D loss: 0.611261] [G loss: 0.084769]\n",
            "[Epoch 28/200] [Batch 509/938] [D loss: 0.644354] [G loss: 0.070849]\n",
            "[Epoch 28/200] [Batch 510/938] [D loss: 0.658351] [G loss: 0.070175]\n",
            "[Epoch 28/200] [Batch 511/938] [D loss: 0.583560] [G loss: 0.077659]\n",
            "[Epoch 28/200] [Batch 512/938] [D loss: 0.663378] [G loss: 0.074502]\n",
            "[Epoch 28/200] [Batch 513/938] [D loss: 0.684725] [G loss: 0.073149]\n",
            "[Epoch 28/200] [Batch 514/938] [D loss: 0.661235] [G loss: 0.070818]\n",
            "[Epoch 28/200] [Batch 515/938] [D loss: 0.682792] [G loss: 0.072189]\n",
            "[Epoch 28/200] [Batch 516/938] [D loss: 0.663542] [G loss: 0.068742]\n",
            "[Epoch 28/200] [Batch 517/938] [D loss: 0.635888] [G loss: 0.070829]\n",
            "[Epoch 28/200] [Batch 518/938] [D loss: 0.666154] [G loss: 0.075606]\n",
            "[Epoch 28/200] [Batch 519/938] [D loss: 0.631831] [G loss: 0.071797]\n",
            "[Epoch 28/200] [Batch 520/938] [D loss: 0.595474] [G loss: 0.067054]\n",
            "[Epoch 28/200] [Batch 521/938] [D loss: 0.657607] [G loss: 0.066467]\n",
            "[Epoch 28/200] [Batch 522/938] [D loss: 0.636412] [G loss: 0.074262]\n",
            "[Epoch 28/200] [Batch 523/938] [D loss: 0.609827] [G loss: 0.080132]\n",
            "[Epoch 28/200] [Batch 524/938] [D loss: 0.655703] [G loss: 0.069177]\n",
            "[Epoch 28/200] [Batch 525/938] [D loss: 0.623043] [G loss: 0.070757]\n",
            "[Epoch 28/200] [Batch 526/938] [D loss: 0.634931] [G loss: 0.084611]\n",
            "[Epoch 28/200] [Batch 527/938] [D loss: 0.630203] [G loss: 0.072924]\n",
            "[Epoch 28/200] [Batch 528/938] [D loss: 0.640483] [G loss: 0.065072]\n",
            "[Epoch 28/200] [Batch 529/938] [D loss: 0.639393] [G loss: 0.066951]\n",
            "[Epoch 28/200] [Batch 530/938] [D loss: 0.638343] [G loss: 0.071197]\n",
            "[Epoch 28/200] [Batch 531/938] [D loss: 0.641627] [G loss: 0.067961]\n",
            "[Epoch 28/200] [Batch 532/938] [D loss: 0.643218] [G loss: 0.062139]\n",
            "[Epoch 28/200] [Batch 533/938] [D loss: 0.618713] [G loss: 0.074421]\n",
            "[Epoch 28/200] [Batch 534/938] [D loss: 0.609076] [G loss: 0.078054]\n",
            "[Epoch 28/200] [Batch 535/938] [D loss: 0.621993] [G loss: 0.072786]\n",
            "[Epoch 28/200] [Batch 536/938] [D loss: 0.660779] [G loss: 0.078326]\n",
            "[Epoch 28/200] [Batch 537/938] [D loss: 0.635629] [G loss: 0.077294]\n",
            "[Epoch 28/200] [Batch 538/938] [D loss: 0.623528] [G loss: 0.073220]\n",
            "[Epoch 28/200] [Batch 539/938] [D loss: 0.633654] [G loss: 0.071591]\n",
            "[Epoch 28/200] [Batch 540/938] [D loss: 0.614940] [G loss: 0.071045]\n",
            "[Epoch 28/200] [Batch 541/938] [D loss: 0.612715] [G loss: 0.069858]\n",
            "[Epoch 28/200] [Batch 542/938] [D loss: 0.632065] [G loss: 0.081505]\n",
            "[Epoch 28/200] [Batch 543/938] [D loss: 0.641976] [G loss: 0.075238]\n",
            "[Epoch 28/200] [Batch 544/938] [D loss: 0.659820] [G loss: 0.073271]\n",
            "[Epoch 28/200] [Batch 545/938] [D loss: 0.626987] [G loss: 0.070881]\n",
            "[Epoch 28/200] [Batch 546/938] [D loss: 0.603219] [G loss: 0.075669]\n",
            "[Epoch 28/200] [Batch 547/938] [D loss: 0.637238] [G loss: 0.075326]\n",
            "[Epoch 28/200] [Batch 548/938] [D loss: 0.651121] [G loss: 0.074769]\n",
            "[Epoch 28/200] [Batch 549/938] [D loss: 0.633589] [G loss: 0.078438]\n",
            "[Epoch 28/200] [Batch 550/938] [D loss: 0.645781] [G loss: 0.068423]\n",
            "[Epoch 28/200] [Batch 551/938] [D loss: 0.652006] [G loss: 0.076065]\n",
            "[Epoch 28/200] [Batch 552/938] [D loss: 0.670300] [G loss: 0.067970]\n",
            "[Epoch 28/200] [Batch 553/938] [D loss: 0.620610] [G loss: 0.075931]\n",
            "[Epoch 28/200] [Batch 554/938] [D loss: 0.654486] [G loss: 0.070285]\n",
            "[Epoch 28/200] [Batch 555/938] [D loss: 0.602614] [G loss: 0.077666]\n",
            "[Epoch 28/200] [Batch 556/938] [D loss: 0.638867] [G loss: 0.075949]\n",
            "[Epoch 28/200] [Batch 557/938] [D loss: 0.621106] [G loss: 0.077389]\n",
            "[Epoch 28/200] [Batch 558/938] [D loss: 0.644029] [G loss: 0.084318]\n",
            "[Epoch 28/200] [Batch 559/938] [D loss: 0.629792] [G loss: 0.074852]\n",
            "[Epoch 28/200] [Batch 560/938] [D loss: 0.624570] [G loss: 0.086979]\n",
            "[Epoch 28/200] [Batch 561/938] [D loss: 0.630177] [G loss: 0.074979]\n",
            "[Epoch 28/200] [Batch 562/938] [D loss: 0.649295] [G loss: 0.075826]\n",
            "[Epoch 28/200] [Batch 563/938] [D loss: 0.637777] [G loss: 0.072917]\n",
            "[Epoch 28/200] [Batch 564/938] [D loss: 0.606208] [G loss: 0.064113]\n",
            "[Epoch 28/200] [Batch 565/938] [D loss: 0.658037] [G loss: 0.066180]\n",
            "[Epoch 28/200] [Batch 566/938] [D loss: 0.659884] [G loss: 0.072926]\n",
            "[Epoch 28/200] [Batch 567/938] [D loss: 0.598179] [G loss: 0.077661]\n",
            "[Epoch 28/200] [Batch 568/938] [D loss: 0.650108] [G loss: 0.074803]\n",
            "[Epoch 28/200] [Batch 569/938] [D loss: 0.622658] [G loss: 0.068439]\n",
            "[Epoch 28/200] [Batch 570/938] [D loss: 0.627535] [G loss: 0.074960]\n",
            "[Epoch 28/200] [Batch 571/938] [D loss: 0.631761] [G loss: 0.073511]\n",
            "[Epoch 28/200] [Batch 572/938] [D loss: 0.604494] [G loss: 0.071978]\n",
            "[Epoch 28/200] [Batch 573/938] [D loss: 0.657624] [G loss: 0.073249]\n",
            "[Epoch 28/200] [Batch 574/938] [D loss: 0.620720] [G loss: 0.074585]\n",
            "[Epoch 28/200] [Batch 575/938] [D loss: 0.662973] [G loss: 0.072425]\n",
            "[Epoch 28/200] [Batch 576/938] [D loss: 0.654818] [G loss: 0.067467]\n",
            "[Epoch 28/200] [Batch 577/938] [D loss: 0.608227] [G loss: 0.075212]\n",
            "[Epoch 28/200] [Batch 578/938] [D loss: 0.637610] [G loss: 0.071506]\n",
            "[Epoch 28/200] [Batch 579/938] [D loss: 0.631368] [G loss: 0.073644]\n",
            "[Epoch 28/200] [Batch 580/938] [D loss: 0.628431] [G loss: 0.072060]\n",
            "[Epoch 28/200] [Batch 581/938] [D loss: 0.652965] [G loss: 0.070885]\n",
            "[Epoch 28/200] [Batch 582/938] [D loss: 0.654209] [G loss: 0.073621]\n",
            "[Epoch 28/200] [Batch 583/938] [D loss: 0.636429] [G loss: 0.067438]\n",
            "[Epoch 28/200] [Batch 584/938] [D loss: 0.647275] [G loss: 0.059642]\n",
            "[Epoch 28/200] [Batch 585/938] [D loss: 0.633354] [G loss: 0.067527]\n",
            "[Epoch 28/200] [Batch 586/938] [D loss: 0.663624] [G loss: 0.075730]\n",
            "[Epoch 28/200] [Batch 587/938] [D loss: 0.627776] [G loss: 0.070413]\n",
            "[Epoch 28/200] [Batch 588/938] [D loss: 0.637601] [G loss: 0.069610]\n",
            "[Epoch 28/200] [Batch 589/938] [D loss: 0.604229] [G loss: 0.080134]\n",
            "[Epoch 28/200] [Batch 590/938] [D loss: 0.640615] [G loss: 0.075663]\n",
            "[Epoch 28/200] [Batch 591/938] [D loss: 0.655797] [G loss: 0.079569]\n",
            "[Epoch 28/200] [Batch 592/938] [D loss: 0.637441] [G loss: 0.073541]\n",
            "[Epoch 28/200] [Batch 593/938] [D loss: 0.638860] [G loss: 0.071772]\n",
            "[Epoch 28/200] [Batch 594/938] [D loss: 0.665365] [G loss: 0.068045]\n",
            "[Epoch 28/200] [Batch 595/938] [D loss: 0.647593] [G loss: 0.070198]\n",
            "[Epoch 28/200] [Batch 596/938] [D loss: 0.604333] [G loss: 0.074792]\n",
            "[Epoch 28/200] [Batch 597/938] [D loss: 0.657336] [G loss: 0.065618]\n",
            "[Epoch 28/200] [Batch 598/938] [D loss: 0.615817] [G loss: 0.073278]\n",
            "[Epoch 28/200] [Batch 599/938] [D loss: 0.624002] [G loss: 0.062633]\n",
            "[Epoch 28/200] [Batch 600/938] [D loss: 0.612764] [G loss: 0.070295]\n",
            "[Epoch 28/200] [Batch 601/938] [D loss: 0.667144] [G loss: 0.064239]\n",
            "[Epoch 28/200] [Batch 602/938] [D loss: 0.623303] [G loss: 0.082177]\n",
            "[Epoch 28/200] [Batch 603/938] [D loss: 0.636321] [G loss: 0.080706]\n",
            "[Epoch 28/200] [Batch 604/938] [D loss: 0.623968] [G loss: 0.070713]\n",
            "[Epoch 28/200] [Batch 605/938] [D loss: 0.642333] [G loss: 0.071934]\n",
            "[Epoch 28/200] [Batch 606/938] [D loss: 0.633361] [G loss: 0.078349]\n",
            "[Epoch 28/200] [Batch 607/938] [D loss: 0.650174] [G loss: 0.068161]\n",
            "[Epoch 28/200] [Batch 608/938] [D loss: 0.630466] [G loss: 0.078739]\n",
            "[Epoch 28/200] [Batch 609/938] [D loss: 0.625712] [G loss: 0.074816]\n",
            "[Epoch 28/200] [Batch 610/938] [D loss: 0.622219] [G loss: 0.069728]\n",
            "[Epoch 28/200] [Batch 611/938] [D loss: 0.600352] [G loss: 0.069447]\n",
            "[Epoch 28/200] [Batch 612/938] [D loss: 0.615332] [G loss: 0.070409]\n",
            "[Epoch 28/200] [Batch 613/938] [D loss: 0.599202] [G loss: 0.075281]\n",
            "[Epoch 28/200] [Batch 614/938] [D loss: 0.661189] [G loss: 0.073484]\n",
            "[Epoch 28/200] [Batch 615/938] [D loss: 0.654890] [G loss: 0.071051]\n",
            "[Epoch 28/200] [Batch 616/938] [D loss: 0.653501] [G loss: 0.080089]\n",
            "[Epoch 28/200] [Batch 617/938] [D loss: 0.600197] [G loss: 0.073347]\n",
            "[Epoch 28/200] [Batch 618/938] [D loss: 0.641433] [G loss: 0.074579]\n",
            "[Epoch 28/200] [Batch 619/938] [D loss: 0.654278] [G loss: 0.078571]\n",
            "[Epoch 28/200] [Batch 620/938] [D loss: 0.651814] [G loss: 0.067947]\n",
            "[Epoch 28/200] [Batch 621/938] [D loss: 0.610292] [G loss: 0.065861]\n",
            "[Epoch 28/200] [Batch 622/938] [D loss: 0.601385] [G loss: 0.070085]\n",
            "[Epoch 28/200] [Batch 623/938] [D loss: 0.639302] [G loss: 0.073822]\n",
            "[Epoch 28/200] [Batch 624/938] [D loss: 0.618677] [G loss: 0.073578]\n",
            "[Epoch 28/200] [Batch 625/938] [D loss: 0.643443] [G loss: 0.071197]\n",
            "[Epoch 28/200] [Batch 626/938] [D loss: 0.620695] [G loss: 0.071969]\n",
            "[Epoch 28/200] [Batch 627/938] [D loss: 0.663647] [G loss: 0.065989]\n",
            "[Epoch 28/200] [Batch 628/938] [D loss: 0.664130] [G loss: 0.072795]\n",
            "[Epoch 28/200] [Batch 629/938] [D loss: 0.659260] [G loss: 0.077192]\n",
            "[Epoch 28/200] [Batch 630/938] [D loss: 0.605295] [G loss: 0.074811]\n",
            "[Epoch 28/200] [Batch 631/938] [D loss: 0.631107] [G loss: 0.070782]\n",
            "[Epoch 28/200] [Batch 632/938] [D loss: 0.608750] [G loss: 0.079240]\n",
            "[Epoch 28/200] [Batch 633/938] [D loss: 0.659840] [G loss: 0.073637]\n",
            "[Epoch 28/200] [Batch 634/938] [D loss: 0.644999] [G loss: 0.067346]\n",
            "[Epoch 28/200] [Batch 635/938] [D loss: 0.628730] [G loss: 0.070859]\n",
            "[Epoch 28/200] [Batch 636/938] [D loss: 0.653871] [G loss: 0.072422]\n",
            "[Epoch 28/200] [Batch 637/938] [D loss: 0.623936] [G loss: 0.075193]\n",
            "[Epoch 28/200] [Batch 638/938] [D loss: 0.632433] [G loss: 0.069930]\n",
            "[Epoch 28/200] [Batch 639/938] [D loss: 0.666693] [G loss: 0.067166]\n",
            "[Epoch 28/200] [Batch 640/938] [D loss: 0.668605] [G loss: 0.072007]\n",
            "[Epoch 28/200] [Batch 641/938] [D loss: 0.616641] [G loss: 0.077241]\n",
            "[Epoch 28/200] [Batch 642/938] [D loss: 0.645208] [G loss: 0.070210]\n",
            "[Epoch 28/200] [Batch 643/938] [D loss: 0.663538] [G loss: 0.067415]\n",
            "[Epoch 28/200] [Batch 644/938] [D loss: 0.623973] [G loss: 0.066603]\n",
            "[Epoch 28/200] [Batch 645/938] [D loss: 0.609816] [G loss: 0.073815]\n",
            "[Epoch 28/200] [Batch 646/938] [D loss: 0.605998] [G loss: 0.071955]\n",
            "[Epoch 28/200] [Batch 647/938] [D loss: 0.625809] [G loss: 0.071733]\n",
            "[Epoch 28/200] [Batch 648/938] [D loss: 0.651589] [G loss: 0.073328]\n",
            "[Epoch 28/200] [Batch 649/938] [D loss: 0.626476] [G loss: 0.072782]\n",
            "[Epoch 28/200] [Batch 650/938] [D loss: 0.619926] [G loss: 0.069203]\n",
            "[Epoch 28/200] [Batch 651/938] [D loss: 0.601035] [G loss: 0.071539]\n",
            "[Epoch 28/200] [Batch 652/938] [D loss: 0.640747] [G loss: 0.069699]\n",
            "[Epoch 28/200] [Batch 653/938] [D loss: 0.623255] [G loss: 0.075042]\n",
            "[Epoch 28/200] [Batch 654/938] [D loss: 0.644418] [G loss: 0.067141]\n",
            "[Epoch 28/200] [Batch 655/938] [D loss: 0.620979] [G loss: 0.069499]\n",
            "[Epoch 28/200] [Batch 656/938] [D loss: 0.658973] [G loss: 0.069449]\n",
            "[Epoch 28/200] [Batch 657/938] [D loss: 0.631943] [G loss: 0.077631]\n",
            "[Epoch 28/200] [Batch 658/938] [D loss: 0.664377] [G loss: 0.075721]\n",
            "[Epoch 28/200] [Batch 659/938] [D loss: 0.667308] [G loss: 0.071239]\n",
            "[Epoch 28/200] [Batch 660/938] [D loss: 0.641813] [G loss: 0.074788]\n",
            "[Epoch 28/200] [Batch 661/938] [D loss: 0.687866] [G loss: 0.076506]\n",
            "[Epoch 28/200] [Batch 662/938] [D loss: 0.622607] [G loss: 0.071116]\n",
            "[Epoch 28/200] [Batch 663/938] [D loss: 0.664222] [G loss: 0.075509]\n",
            "[Epoch 28/200] [Batch 664/938] [D loss: 0.623762] [G loss: 0.072869]\n",
            "[Epoch 28/200] [Batch 665/938] [D loss: 0.634578] [G loss: 0.076529]\n",
            "[Epoch 28/200] [Batch 666/938] [D loss: 0.645779] [G loss: 0.076947]\n",
            "[Epoch 28/200] [Batch 667/938] [D loss: 0.617042] [G loss: 0.074137]\n",
            "[Epoch 28/200] [Batch 668/938] [D loss: 0.613449] [G loss: 0.079307]\n",
            "[Epoch 28/200] [Batch 669/938] [D loss: 0.654043] [G loss: 0.075417]\n",
            "[Epoch 28/200] [Batch 670/938] [D loss: 0.640526] [G loss: 0.065875]\n",
            "[Epoch 28/200] [Batch 671/938] [D loss: 0.626663] [G loss: 0.078169]\n",
            "[Epoch 28/200] [Batch 672/938] [D loss: 0.624154] [G loss: 0.067113]\n",
            "[Epoch 28/200] [Batch 673/938] [D loss: 0.648991] [G loss: 0.077494]\n",
            "[Epoch 28/200] [Batch 674/938] [D loss: 0.640485] [G loss: 0.068288]\n",
            "[Epoch 28/200] [Batch 675/938] [D loss: 0.591808] [G loss: 0.074539]\n",
            "[Epoch 28/200] [Batch 676/938] [D loss: 0.611868] [G loss: 0.064601]\n",
            "[Epoch 28/200] [Batch 677/938] [D loss: 0.611764] [G loss: 0.075204]\n",
            "[Epoch 28/200] [Batch 678/938] [D loss: 0.628935] [G loss: 0.076393]\n",
            "[Epoch 28/200] [Batch 679/938] [D loss: 0.681912] [G loss: 0.073814]\n",
            "[Epoch 28/200] [Batch 680/938] [D loss: 0.626455] [G loss: 0.071047]\n",
            "[Epoch 28/200] [Batch 681/938] [D loss: 0.636787] [G loss: 0.066897]\n",
            "[Epoch 28/200] [Batch 682/938] [D loss: 0.637018] [G loss: 0.069912]\n",
            "[Epoch 28/200] [Batch 683/938] [D loss: 0.662220] [G loss: 0.065745]\n",
            "[Epoch 28/200] [Batch 684/938] [D loss: 0.649548] [G loss: 0.066808]\n",
            "[Epoch 28/200] [Batch 685/938] [D loss: 0.607415] [G loss: 0.070532]\n",
            "[Epoch 28/200] [Batch 686/938] [D loss: 0.644020] [G loss: 0.071724]\n",
            "[Epoch 28/200] [Batch 687/938] [D loss: 0.637349] [G loss: 0.072829]\n",
            "[Epoch 28/200] [Batch 688/938] [D loss: 0.668811] [G loss: 0.070666]\n",
            "[Epoch 28/200] [Batch 689/938] [D loss: 0.674096] [G loss: 0.074421]\n",
            "[Epoch 28/200] [Batch 690/938] [D loss: 0.620415] [G loss: 0.065926]\n",
            "[Epoch 28/200] [Batch 691/938] [D loss: 0.609357] [G loss: 0.079033]\n",
            "[Epoch 28/200] [Batch 692/938] [D loss: 0.672766] [G loss: 0.071556]\n",
            "[Epoch 28/200] [Batch 693/938] [D loss: 0.604325] [G loss: 0.078326]\n",
            "[Epoch 28/200] [Batch 694/938] [D loss: 0.664856] [G loss: 0.076378]\n",
            "[Epoch 28/200] [Batch 695/938] [D loss: 0.647376] [G loss: 0.072152]\n",
            "[Epoch 28/200] [Batch 696/938] [D loss: 0.643016] [G loss: 0.073272]\n",
            "[Epoch 28/200] [Batch 697/938] [D loss: 0.662877] [G loss: 0.072286]\n",
            "[Epoch 28/200] [Batch 698/938] [D loss: 0.604663] [G loss: 0.072822]\n",
            "[Epoch 28/200] [Batch 699/938] [D loss: 0.643479] [G loss: 0.076854]\n",
            "[Epoch 28/200] [Batch 700/938] [D loss: 0.632235] [G loss: 0.072302]\n",
            "[Epoch 28/200] [Batch 701/938] [D loss: 0.659430] [G loss: 0.073527]\n",
            "[Epoch 28/200] [Batch 702/938] [D loss: 0.633950] [G loss: 0.072304]\n",
            "[Epoch 28/200] [Batch 703/938] [D loss: 0.629177] [G loss: 0.065980]\n",
            "[Epoch 28/200] [Batch 704/938] [D loss: 0.652350] [G loss: 0.067321]\n",
            "[Epoch 28/200] [Batch 705/938] [D loss: 0.659307] [G loss: 0.066906]\n",
            "[Epoch 28/200] [Batch 706/938] [D loss: 0.654608] [G loss: 0.073774]\n",
            "[Epoch 28/200] [Batch 707/938] [D loss: 0.646919] [G loss: 0.070228]\n",
            "[Epoch 28/200] [Batch 708/938] [D loss: 0.588976] [G loss: 0.075277]\n",
            "[Epoch 28/200] [Batch 709/938] [D loss: 0.642832] [G loss: 0.074201]\n",
            "[Epoch 28/200] [Batch 710/938] [D loss: 0.646964] [G loss: 0.067358]\n",
            "[Epoch 28/200] [Batch 711/938] [D loss: 0.626744] [G loss: 0.073879]\n",
            "[Epoch 28/200] [Batch 712/938] [D loss: 0.647986] [G loss: 0.076862]\n",
            "[Epoch 28/200] [Batch 713/938] [D loss: 0.647092] [G loss: 0.069508]\n",
            "[Epoch 28/200] [Batch 714/938] [D loss: 0.624870] [G loss: 0.071102]\n",
            "[Epoch 28/200] [Batch 715/938] [D loss: 0.653330] [G loss: 0.076811]\n",
            "[Epoch 28/200] [Batch 716/938] [D loss: 0.606981] [G loss: 0.069629]\n",
            "[Epoch 28/200] [Batch 717/938] [D loss: 0.652661] [G loss: 0.069247]\n",
            "[Epoch 28/200] [Batch 718/938] [D loss: 0.623985] [G loss: 0.083291]\n",
            "[Epoch 28/200] [Batch 719/938] [D loss: 0.644498] [G loss: 0.076538]\n",
            "[Epoch 28/200] [Batch 720/938] [D loss: 0.601526] [G loss: 0.077204]\n",
            "[Epoch 28/200] [Batch 721/938] [D loss: 0.651746] [G loss: 0.074668]\n",
            "[Epoch 28/200] [Batch 722/938] [D loss: 0.637971] [G loss: 0.069098]\n",
            "[Epoch 28/200] [Batch 723/938] [D loss: 0.651026] [G loss: 0.069891]\n",
            "[Epoch 28/200] [Batch 724/938] [D loss: 0.629158] [G loss: 0.071367]\n",
            "[Epoch 28/200] [Batch 725/938] [D loss: 0.645359] [G loss: 0.071646]\n",
            "[Epoch 28/200] [Batch 726/938] [D loss: 0.627350] [G loss: 0.072500]\n",
            "[Epoch 28/200] [Batch 727/938] [D loss: 0.602466] [G loss: 0.065477]\n",
            "[Epoch 28/200] [Batch 728/938] [D loss: 0.610453] [G loss: 0.068544]\n",
            "[Epoch 28/200] [Batch 729/938] [D loss: 0.631071] [G loss: 0.072129]\n",
            "[Epoch 28/200] [Batch 730/938] [D loss: 0.636796] [G loss: 0.066516]\n",
            "[Epoch 28/200] [Batch 731/938] [D loss: 0.644657] [G loss: 0.067177]\n",
            "[Epoch 28/200] [Batch 732/938] [D loss: 0.655430] [G loss: 0.090422]\n",
            "[Epoch 28/200] [Batch 733/938] [D loss: 0.647536] [G loss: 0.066727]\n",
            "[Epoch 28/200] [Batch 734/938] [D loss: 0.635027] [G loss: 0.072231]\n",
            "[Epoch 28/200] [Batch 735/938] [D loss: 0.622973] [G loss: 0.069866]\n",
            "[Epoch 28/200] [Batch 736/938] [D loss: 0.633198] [G loss: 0.065616]\n",
            "[Epoch 28/200] [Batch 737/938] [D loss: 0.621130] [G loss: 0.076707]\n",
            "[Epoch 28/200] [Batch 738/938] [D loss: 0.607934] [G loss: 0.070858]\n",
            "[Epoch 28/200] [Batch 739/938] [D loss: 0.643564] [G loss: 0.083197]\n",
            "[Epoch 28/200] [Batch 740/938] [D loss: 0.627871] [G loss: 0.070591]\n",
            "[Epoch 28/200] [Batch 741/938] [D loss: 0.634874] [G loss: 0.075300]\n",
            "[Epoch 28/200] [Batch 742/938] [D loss: 0.633789] [G loss: 0.076992]\n",
            "[Epoch 28/200] [Batch 743/938] [D loss: 0.621259] [G loss: 0.066117]\n",
            "[Epoch 28/200] [Batch 744/938] [D loss: 0.631023] [G loss: 0.079882]\n",
            "[Epoch 28/200] [Batch 745/938] [D loss: 0.643139] [G loss: 0.073575]\n",
            "[Epoch 28/200] [Batch 746/938] [D loss: 0.602382] [G loss: 0.068724]\n",
            "[Epoch 28/200] [Batch 747/938] [D loss: 0.616617] [G loss: 0.072755]\n",
            "[Epoch 28/200] [Batch 748/938] [D loss: 0.645684] [G loss: 0.076651]\n",
            "[Epoch 28/200] [Batch 749/938] [D loss: 0.666846] [G loss: 0.066887]\n",
            "[Epoch 28/200] [Batch 750/938] [D loss: 0.627165] [G loss: 0.073033]\n",
            "[Epoch 28/200] [Batch 751/938] [D loss: 0.641852] [G loss: 0.064190]\n",
            "[Epoch 28/200] [Batch 752/938] [D loss: 0.607740] [G loss: 0.064292]\n",
            "[Epoch 28/200] [Batch 753/938] [D loss: 0.638263] [G loss: 0.077163]\n",
            "[Epoch 28/200] [Batch 754/938] [D loss: 0.625209] [G loss: 0.068286]\n",
            "[Epoch 28/200] [Batch 755/938] [D loss: 0.652455] [G loss: 0.074054]\n",
            "[Epoch 28/200] [Batch 756/938] [D loss: 0.612998] [G loss: 0.079060]\n",
            "[Epoch 28/200] [Batch 757/938] [D loss: 0.634658] [G loss: 0.074100]\n",
            "[Epoch 28/200] [Batch 758/938] [D loss: 0.643249] [G loss: 0.076459]\n",
            "[Epoch 28/200] [Batch 759/938] [D loss: 0.660092] [G loss: 0.077875]\n",
            "[Epoch 28/200] [Batch 760/938] [D loss: 0.619174] [G loss: 0.069965]\n",
            "[Epoch 28/200] [Batch 761/938] [D loss: 0.659633] [G loss: 0.069945]\n",
            "[Epoch 28/200] [Batch 762/938] [D loss: 0.639741] [G loss: 0.072566]\n",
            "[Epoch 28/200] [Batch 763/938] [D loss: 0.617197] [G loss: 0.073617]\n",
            "[Epoch 28/200] [Batch 764/938] [D loss: 0.630549] [G loss: 0.066996]\n",
            "[Epoch 28/200] [Batch 765/938] [D loss: 0.651957] [G loss: 0.079229]\n",
            "[Epoch 28/200] [Batch 766/938] [D loss: 0.600530] [G loss: 0.073599]\n",
            "[Epoch 28/200] [Batch 767/938] [D loss: 0.649584] [G loss: 0.066463]\n",
            "[Epoch 28/200] [Batch 768/938] [D loss: 0.645048] [G loss: 0.075920]\n",
            "[Epoch 28/200] [Batch 769/938] [D loss: 0.622211] [G loss: 0.069558]\n",
            "[Epoch 28/200] [Batch 770/938] [D loss: 0.622922] [G loss: 0.069673]\n",
            "[Epoch 28/200] [Batch 771/938] [D loss: 0.638406] [G loss: 0.086138]\n",
            "[Epoch 28/200] [Batch 772/938] [D loss: 0.608739] [G loss: 0.071329]\n",
            "[Epoch 28/200] [Batch 773/938] [D loss: 0.668092] [G loss: 0.067527]\n",
            "[Epoch 28/200] [Batch 774/938] [D loss: 0.629725] [G loss: 0.071050]\n",
            "[Epoch 28/200] [Batch 775/938] [D loss: 0.637138] [G loss: 0.072733]\n",
            "[Epoch 28/200] [Batch 776/938] [D loss: 0.638496] [G loss: 0.073383]\n",
            "[Epoch 28/200] [Batch 777/938] [D loss: 0.667995] [G loss: 0.066332]\n",
            "[Epoch 28/200] [Batch 778/938] [D loss: 0.634762] [G loss: 0.075976]\n",
            "[Epoch 28/200] [Batch 779/938] [D loss: 0.621674] [G loss: 0.063796]\n",
            "[Epoch 28/200] [Batch 780/938] [D loss: 0.627914] [G loss: 0.082809]\n",
            "[Epoch 28/200] [Batch 781/938] [D loss: 0.630622] [G loss: 0.080152]\n",
            "[Epoch 28/200] [Batch 782/938] [D loss: 0.623111] [G loss: 0.072080]\n",
            "[Epoch 28/200] [Batch 783/938] [D loss: 0.636887] [G loss: 0.072702]\n",
            "[Epoch 28/200] [Batch 784/938] [D loss: 0.670212] [G loss: 0.078141]\n",
            "[Epoch 28/200] [Batch 785/938] [D loss: 0.661534] [G loss: 0.077178]\n",
            "[Epoch 28/200] [Batch 786/938] [D loss: 0.656178] [G loss: 0.072379]\n",
            "[Epoch 28/200] [Batch 787/938] [D loss: 0.641155] [G loss: 0.077436]\n",
            "[Epoch 28/200] [Batch 788/938] [D loss: 0.654399] [G loss: 0.075248]\n",
            "[Epoch 28/200] [Batch 789/938] [D loss: 0.640542] [G loss: 0.073663]\n",
            "[Epoch 28/200] [Batch 790/938] [D loss: 0.629847] [G loss: 0.066560]\n",
            "[Epoch 28/200] [Batch 791/938] [D loss: 0.638643] [G loss: 0.074437]\n",
            "[Epoch 28/200] [Batch 792/938] [D loss: 0.619290] [G loss: 0.065967]\n",
            "[Epoch 28/200] [Batch 793/938] [D loss: 0.642264] [G loss: 0.070522]\n",
            "[Epoch 28/200] [Batch 794/938] [D loss: 0.683618] [G loss: 0.068211]\n",
            "[Epoch 28/200] [Batch 795/938] [D loss: 0.629484] [G loss: 0.067250]\n",
            "[Epoch 28/200] [Batch 796/938] [D loss: 0.650727] [G loss: 0.069316]\n",
            "[Epoch 28/200] [Batch 797/938] [D loss: 0.612262] [G loss: 0.063008]\n",
            "[Epoch 28/200] [Batch 798/938] [D loss: 0.647743] [G loss: 0.068738]\n",
            "[Epoch 28/200] [Batch 799/938] [D loss: 0.649423] [G loss: 0.068549]\n",
            "[Epoch 28/200] [Batch 800/938] [D loss: 0.643208] [G loss: 0.066496]\n",
            "[Epoch 28/200] [Batch 801/938] [D loss: 0.638637] [G loss: 0.070733]\n",
            "[Epoch 28/200] [Batch 802/938] [D loss: 0.632968] [G loss: 0.074557]\n",
            "[Epoch 28/200] [Batch 803/938] [D loss: 0.611853] [G loss: 0.071798]\n",
            "[Epoch 28/200] [Batch 804/938] [D loss: 0.616026] [G loss: 0.077412]\n",
            "[Epoch 28/200] [Batch 805/938] [D loss: 0.640381] [G loss: 0.065079]\n",
            "[Epoch 28/200] [Batch 806/938] [D loss: 0.638316] [G loss: 0.064608]\n",
            "[Epoch 28/200] [Batch 807/938] [D loss: 0.602545] [G loss: 0.075057]\n",
            "[Epoch 28/200] [Batch 808/938] [D loss: 0.630036] [G loss: 0.076230]\n",
            "[Epoch 28/200] [Batch 809/938] [D loss: 0.603735] [G loss: 0.070997]\n",
            "[Epoch 28/200] [Batch 810/938] [D loss: 0.655368] [G loss: 0.082551]\n",
            "[Epoch 28/200] [Batch 811/938] [D loss: 0.668916] [G loss: 0.074906]\n",
            "[Epoch 28/200] [Batch 812/938] [D loss: 0.634625] [G loss: 0.071264]\n",
            "[Epoch 28/200] [Batch 813/938] [D loss: 0.639760] [G loss: 0.065731]\n",
            "[Epoch 28/200] [Batch 814/938] [D loss: 0.620491] [G loss: 0.073486]\n",
            "[Epoch 28/200] [Batch 815/938] [D loss: 0.625352] [G loss: 0.068807]\n",
            "[Epoch 28/200] [Batch 816/938] [D loss: 0.630494] [G loss: 0.068788]\n",
            "[Epoch 28/200] [Batch 817/938] [D loss: 0.635537] [G loss: 0.067610]\n",
            "[Epoch 28/200] [Batch 818/938] [D loss: 0.660949] [G loss: 0.069660]\n",
            "[Epoch 28/200] [Batch 819/938] [D loss: 0.610726] [G loss: 0.073856]\n",
            "[Epoch 28/200] [Batch 820/938] [D loss: 0.662349] [G loss: 0.069023]\n",
            "[Epoch 28/200] [Batch 821/938] [D loss: 0.635909] [G loss: 0.073262]\n",
            "[Epoch 28/200] [Batch 822/938] [D loss: 0.642780] [G loss: 0.075692]\n",
            "[Epoch 28/200] [Batch 823/938] [D loss: 0.593053] [G loss: 0.071198]\n",
            "[Epoch 28/200] [Batch 824/938] [D loss: 0.614555] [G loss: 0.073544]\n",
            "[Epoch 28/200] [Batch 825/938] [D loss: 0.634318] [G loss: 0.065834]\n",
            "[Epoch 28/200] [Batch 826/938] [D loss: 0.654337] [G loss: 0.071082]\n",
            "[Epoch 28/200] [Batch 827/938] [D loss: 0.665433] [G loss: 0.069861]\n",
            "[Epoch 28/200] [Batch 828/938] [D loss: 0.660435] [G loss: 0.078560]\n",
            "[Epoch 28/200] [Batch 829/938] [D loss: 0.661232] [G loss: 0.070486]\n",
            "[Epoch 28/200] [Batch 830/938] [D loss: 0.625565] [G loss: 0.064403]\n",
            "[Epoch 28/200] [Batch 831/938] [D loss: 0.621080] [G loss: 0.068378]\n",
            "[Epoch 28/200] [Batch 832/938] [D loss: 0.631593] [G loss: 0.070456]\n",
            "[Epoch 28/200] [Batch 833/938] [D loss: 0.623230] [G loss: 0.074786]\n",
            "[Epoch 28/200] [Batch 834/938] [D loss: 0.630540] [G loss: 0.071016]\n",
            "[Epoch 28/200] [Batch 835/938] [D loss: 0.636301] [G loss: 0.074958]\n",
            "[Epoch 28/200] [Batch 836/938] [D loss: 0.671371] [G loss: 0.068283]\n",
            "[Epoch 28/200] [Batch 837/938] [D loss: 0.647601] [G loss: 0.075076]\n",
            "[Epoch 28/200] [Batch 838/938] [D loss: 0.618366] [G loss: 0.070629]\n",
            "[Epoch 28/200] [Batch 839/938] [D loss: 0.631578] [G loss: 0.072476]\n",
            "[Epoch 28/200] [Batch 840/938] [D loss: 0.633748] [G loss: 0.072255]\n",
            "[Epoch 28/200] [Batch 841/938] [D loss: 0.661911] [G loss: 0.073313]\n",
            "[Epoch 28/200] [Batch 842/938] [D loss: 0.621276] [G loss: 0.067815]\n",
            "[Epoch 28/200] [Batch 843/938] [D loss: 0.622346] [G loss: 0.073761]\n",
            "[Epoch 28/200] [Batch 844/938] [D loss: 0.611781] [G loss: 0.083315]\n",
            "[Epoch 28/200] [Batch 845/938] [D loss: 0.628415] [G loss: 0.082340]\n",
            "[Epoch 28/200] [Batch 846/938] [D loss: 0.644164] [G loss: 0.070115]\n",
            "[Epoch 28/200] [Batch 847/938] [D loss: 0.636091] [G loss: 0.066738]\n",
            "[Epoch 28/200] [Batch 848/938] [D loss: 0.617756] [G loss: 0.078231]\n",
            "[Epoch 28/200] [Batch 849/938] [D loss: 0.630899] [G loss: 0.081896]\n",
            "[Epoch 28/200] [Batch 850/938] [D loss: 0.639607] [G loss: 0.075922]\n",
            "[Epoch 28/200] [Batch 851/938] [D loss: 0.637770] [G loss: 0.064340]\n",
            "[Epoch 28/200] [Batch 852/938] [D loss: 0.646918] [G loss: 0.066020]\n",
            "[Epoch 28/200] [Batch 853/938] [D loss: 0.634681] [G loss: 0.074442]\n",
            "[Epoch 28/200] [Batch 854/938] [D loss: 0.639153] [G loss: 0.069792]\n",
            "[Epoch 28/200] [Batch 855/938] [D loss: 0.614264] [G loss: 0.071162]\n",
            "[Epoch 28/200] [Batch 856/938] [D loss: 0.630266] [G loss: 0.073624]\n",
            "[Epoch 28/200] [Batch 857/938] [D loss: 0.641385] [G loss: 0.072443]\n",
            "[Epoch 28/200] [Batch 858/938] [D loss: 0.635761] [G loss: 0.072502]\n",
            "[Epoch 28/200] [Batch 859/938] [D loss: 0.623685] [G loss: 0.070638]\n",
            "[Epoch 28/200] [Batch 860/938] [D loss: 0.613683] [G loss: 0.070947]\n",
            "[Epoch 28/200] [Batch 861/938] [D loss: 0.601709] [G loss: 0.068756]\n",
            "[Epoch 28/200] [Batch 862/938] [D loss: 0.607525] [G loss: 0.064868]\n",
            "[Epoch 28/200] [Batch 863/938] [D loss: 0.657814] [G loss: 0.072649]\n",
            "[Epoch 28/200] [Batch 864/938] [D loss: 0.632169] [G loss: 0.064994]\n",
            "[Epoch 28/200] [Batch 865/938] [D loss: 0.667746] [G loss: 0.070938]\n",
            "[Epoch 28/200] [Batch 866/938] [D loss: 0.617490] [G loss: 0.076626]\n",
            "[Epoch 28/200] [Batch 867/938] [D loss: 0.640751] [G loss: 0.064672]\n",
            "[Epoch 28/200] [Batch 868/938] [D loss: 0.600905] [G loss: 0.077062]\n",
            "[Epoch 28/200] [Batch 869/938] [D loss: 0.634851] [G loss: 0.078080]\n",
            "[Epoch 28/200] [Batch 870/938] [D loss: 0.646757] [G loss: 0.070214]\n",
            "[Epoch 28/200] [Batch 871/938] [D loss: 0.628650] [G loss: 0.080062]\n",
            "[Epoch 28/200] [Batch 872/938] [D loss: 0.599068] [G loss: 0.077326]\n",
            "[Epoch 28/200] [Batch 873/938] [D loss: 0.663102] [G loss: 0.072309]\n",
            "[Epoch 28/200] [Batch 874/938] [D loss: 0.616153] [G loss: 0.070098]\n",
            "[Epoch 28/200] [Batch 875/938] [D loss: 0.618684] [G loss: 0.076450]\n",
            "[Epoch 28/200] [Batch 876/938] [D loss: 0.599990] [G loss: 0.073020]\n",
            "[Epoch 28/200] [Batch 877/938] [D loss: 0.624808] [G loss: 0.068948]\n",
            "[Epoch 28/200] [Batch 878/938] [D loss: 0.634412] [G loss: 0.070182]\n",
            "[Epoch 28/200] [Batch 879/938] [D loss: 0.630947] [G loss: 0.074324]\n",
            "[Epoch 28/200] [Batch 880/938] [D loss: 0.618009] [G loss: 0.076425]\n",
            "[Epoch 28/200] [Batch 881/938] [D loss: 0.584161] [G loss: 0.071215]\n",
            "[Epoch 28/200] [Batch 882/938] [D loss: 0.647372] [G loss: 0.076227]\n",
            "[Epoch 28/200] [Batch 883/938] [D loss: 0.632184] [G loss: 0.076813]\n",
            "[Epoch 28/200] [Batch 884/938] [D loss: 0.668145] [G loss: 0.068259]\n",
            "[Epoch 28/200] [Batch 885/938] [D loss: 0.650633] [G loss: 0.066581]\n",
            "[Epoch 28/200] [Batch 886/938] [D loss: 0.663289] [G loss: 0.078707]\n",
            "[Epoch 28/200] [Batch 887/938] [D loss: 0.618236] [G loss: 0.069942]\n",
            "[Epoch 28/200] [Batch 888/938] [D loss: 0.698276] [G loss: 0.072364]\n",
            "[Epoch 28/200] [Batch 889/938] [D loss: 0.640910] [G loss: 0.076424]\n",
            "[Epoch 28/200] [Batch 890/938] [D loss: 0.630952] [G loss: 0.068339]\n",
            "[Epoch 28/200] [Batch 891/938] [D loss: 0.622811] [G loss: 0.073028]\n",
            "[Epoch 28/200] [Batch 892/938] [D loss: 0.619993] [G loss: 0.061775]\n",
            "[Epoch 28/200] [Batch 893/938] [D loss: 0.630749] [G loss: 0.069966]\n",
            "[Epoch 28/200] [Batch 894/938] [D loss: 0.594841] [G loss: 0.078440]\n",
            "[Epoch 28/200] [Batch 895/938] [D loss: 0.662026] [G loss: 0.077803]\n",
            "[Epoch 28/200] [Batch 896/938] [D loss: 0.622000] [G loss: 0.075682]\n",
            "[Epoch 28/200] [Batch 897/938] [D loss: 0.659405] [G loss: 0.067234]\n",
            "[Epoch 28/200] [Batch 898/938] [D loss: 0.646198] [G loss: 0.074211]\n",
            "[Epoch 28/200] [Batch 899/938] [D loss: 0.641208] [G loss: 0.078363]\n",
            "[Epoch 28/200] [Batch 900/938] [D loss: 0.633726] [G loss: 0.078460]\n",
            "[Epoch 28/200] [Batch 901/938] [D loss: 0.659097] [G loss: 0.079271]\n",
            "[Epoch 28/200] [Batch 902/938] [D loss: 0.651790] [G loss: 0.076259]\n",
            "[Epoch 28/200] [Batch 903/938] [D loss: 0.629651] [G loss: 0.075081]\n",
            "[Epoch 28/200] [Batch 904/938] [D loss: 0.628434] [G loss: 0.074392]\n",
            "[Epoch 28/200] [Batch 905/938] [D loss: 0.628662] [G loss: 0.074065]\n",
            "[Epoch 28/200] [Batch 906/938] [D loss: 0.624463] [G loss: 0.077844]\n",
            "[Epoch 28/200] [Batch 907/938] [D loss: 0.649655] [G loss: 0.071449]\n",
            "[Epoch 28/200] [Batch 908/938] [D loss: 0.628534] [G loss: 0.068432]\n",
            "[Epoch 28/200] [Batch 909/938] [D loss: 0.641303] [G loss: 0.079086]\n",
            "[Epoch 28/200] [Batch 910/938] [D loss: 0.629521] [G loss: 0.071523]\n",
            "[Epoch 28/200] [Batch 911/938] [D loss: 0.661372] [G loss: 0.068363]\n",
            "[Epoch 28/200] [Batch 912/938] [D loss: 0.631050] [G loss: 0.077527]\n",
            "[Epoch 28/200] [Batch 913/938] [D loss: 0.635970] [G loss: 0.067587]\n",
            "[Epoch 28/200] [Batch 914/938] [D loss: 0.651458] [G loss: 0.074573]\n",
            "[Epoch 28/200] [Batch 915/938] [D loss: 0.642754] [G loss: 0.070504]\n",
            "[Epoch 28/200] [Batch 916/938] [D loss: 0.626471] [G loss: 0.071311]\n",
            "[Epoch 28/200] [Batch 917/938] [D loss: 0.663511] [G loss: 0.071280]\n",
            "[Epoch 28/200] [Batch 918/938] [D loss: 0.600697] [G loss: 0.072603]\n",
            "[Epoch 28/200] [Batch 919/938] [D loss: 0.657892] [G loss: 0.069400]\n",
            "[Epoch 28/200] [Batch 920/938] [D loss: 0.644742] [G loss: 0.067944]\n",
            "[Epoch 28/200] [Batch 921/938] [D loss: 0.653568] [G loss: 0.070138]\n",
            "[Epoch 28/200] [Batch 922/938] [D loss: 0.601753] [G loss: 0.078006]\n",
            "[Epoch 28/200] [Batch 923/938] [D loss: 0.630087] [G loss: 0.069053]\n",
            "[Epoch 28/200] [Batch 924/938] [D loss: 0.663431] [G loss: 0.075942]\n",
            "[Epoch 28/200] [Batch 925/938] [D loss: 0.607334] [G loss: 0.075494]\n",
            "[Epoch 28/200] [Batch 926/938] [D loss: 0.631043] [G loss: 0.068790]\n",
            "[Epoch 28/200] [Batch 927/938] [D loss: 0.649289] [G loss: 0.073787]\n",
            "[Epoch 28/200] [Batch 928/938] [D loss: 0.673490] [G loss: 0.077416]\n",
            "[Epoch 28/200] [Batch 929/938] [D loss: 0.622595] [G loss: 0.080408]\n",
            "[Epoch 28/200] [Batch 930/938] [D loss: 0.620806] [G loss: 0.064132]\n",
            "[Epoch 28/200] [Batch 931/938] [D loss: 0.632436] [G loss: 0.074398]\n",
            "[Epoch 28/200] [Batch 932/938] [D loss: 0.626266] [G loss: 0.070963]\n",
            "[Epoch 28/200] [Batch 933/938] [D loss: 0.628927] [G loss: 0.074114]\n",
            "[Epoch 28/200] [Batch 934/938] [D loss: 0.645128] [G loss: 0.071749]\n",
            "[Epoch 28/200] [Batch 935/938] [D loss: 0.617853] [G loss: 0.069077]\n",
            "[Epoch 28/200] [Batch 936/938] [D loss: 0.648790] [G loss: 0.069202]\n",
            "[Epoch 28/200] [Batch 937/938] [D loss: 0.599748] [G loss: 0.071462]\n",
            "[Epoch 29/200] [Batch 0/938] [D loss: 0.628423] [G loss: 0.072967]\n",
            "[Epoch 29/200] [Batch 1/938] [D loss: 0.636295] [G loss: 0.079037]\n",
            "[Epoch 29/200] [Batch 2/938] [D loss: 0.660435] [G loss: 0.070577]\n",
            "[Epoch 29/200] [Batch 3/938] [D loss: 0.628266] [G loss: 0.072280]\n",
            "[Epoch 29/200] [Batch 4/938] [D loss: 0.655811] [G loss: 0.075111]\n",
            "[Epoch 29/200] [Batch 5/938] [D loss: 0.598452] [G loss: 0.072555]\n",
            "[Epoch 29/200] [Batch 6/938] [D loss: 0.634313] [G loss: 0.069002]\n",
            "[Epoch 29/200] [Batch 7/938] [D loss: 0.632065] [G loss: 0.067138]\n",
            "[Epoch 29/200] [Batch 8/938] [D loss: 0.621814] [G loss: 0.072005]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-ae794703fb6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Adversarial ground truths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1iC9n0v6WA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}