{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01. MNIST_AAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO7kHp4RsQe5F+gxVgtjzpV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steve-YJ/Extracting-Important-Feature-of-Malimg-using-VAE/blob/master/01_MNIST_AAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFUH7VEp5Bz3",
        "colab_type": "text"
      },
      "source": [
        "## Reference\n",
        "* god....!: https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/aae/aae.py\n",
        "\n",
        "### What I want to do\n",
        "* run AAE \n",
        "* practicing train\n",
        "\n",
        "* from 20.07.15.wed<br>\n",
        "* prace & make my own work flow<br>\n",
        "    * continue: https://github.com/Steve-YJ/Colab_Exercise/blob/master/Again_Training_Exp05_Just_20Epochs.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fS38MY-58P9",
        "colab_type": "text"
      },
      "source": [
        "## 00. Mount Drive\n",
        "\n",
        "* If you use colab, first mount driver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NJaYzi-85Dn",
        "colab_type": "text"
      },
      "source": [
        "First, always check if your GPU is possible or not\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKjLf6sh4fkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "5386fd1e-ddc3-4fd7-af6e-644b154c3ff6"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 15 11:48:44 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kss7fKHM9LFj",
        "colab_type": "text"
      },
      "source": [
        "set 'autoreload'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t13_t5qH6DPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIGr7YlF9TZi",
        "colab_type": "text"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGPG-pJo6DSE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "886a0f55-528a-467a-8009-5f48094f93e0"
      },
      "source": [
        "# drive mount\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A-1bsK69jsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "678df2fb-9786-4034-f3ec-8c7ee62d3518"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgOqQ4rm9jk5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "baf3c094-dcfe-40b3-e1ab-99a4cdc53e65"
      },
      "source": [
        "%cd drive/My\\ Drive/Post_InfoSec_Exp\n",
        "! pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Post_InfoSec_Exp\n",
            "/content/drive/My Drive/Post_InfoSec_Exp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo9M83Ix6D3g",
        "colab_type": "text"
      },
      "source": [
        "## 01. Library Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3BsDGHI6DUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOkr6zX6-K8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs(\"images\", exist_ok=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlTLvJ0u6GT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_shape = (1, 32, 32)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaUKfNkO6Hfm",
        "colab_type": "text"
      },
      "source": [
        "## 02. Data Preprocessing\n",
        "* Load dataset\n",
        "* preprocess it\n",
        "    * transforms\n",
        "    * make custom dataset\n",
        "    * train_test split\n",
        "    * make train loader, test loader\n",
        "\n",
        "* work Flow\n",
        "    * transforms module 사용해서 image data compose\n",
        "        * size 조정 및 normalize, tensor 변환\n",
        "        * Image Folder를 이용해 dataload\n",
        "        * dataset split: train dataset, test dataset\n",
        "        * DataLoader로 batch단위 dataset 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81yyEjRl6GWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configure data loader\n",
        "\n",
        "os.makedirs(\"./data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"./data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(32), \n",
        "             transforms.ToTensor(),\n",
        "             transforms.Normalize([0.5], [0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size = 64,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOzcPwFi6R5b",
        "colab_type": "text"
      },
      "source": [
        "# 03. Define Adversarial Variational AutoEncoder Class\n",
        "\n",
        "* Encoder Class\n",
        "* Decoder Class\n",
        "* Discriminator Class\n",
        "* Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v9NKI-4_rqd",
        "colab_type": "text"
      },
      "source": [
        "### 3-1. Encoder Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3uDND6p6Vf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(img_shape)), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.mu = nn.Linear(512, 10)      # 10: latent dim\n",
        "        self.logvar = nn.Linear(512, 10)  # 10: latent dim\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.shape[0], -1)\n",
        "        x = self.model(img_flat)\n",
        "        mu = self.mu(x)\n",
        "        logvar = self.logvar(x)\n",
        "        z = reparameterization(mu, logvar)\n",
        "        return z "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tbleCgU_qhk",
        "colab_type": "text"
      },
      "source": [
        "### 3-2. Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-kcpVe6BLNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(10, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, int(np.prod(img_shape))),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img_flat = self.model(z)\n",
        "        img = img_flat.view(img_flat.shape[0], *img_shape)\n",
        "        return img"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XByElreCCU5",
        "colab_type": "text"
      },
      "source": [
        "### 3-3. Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxS4PlrvCCB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "class Discriminator(nn.Module):\n",
        "    def __int__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(10, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        validity = self.model(z)\n",
        "        return validity\n",
        "'''\n",
        "# missing i... ;;\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(10, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        validity = self.model(z)\n",
        "        return validity"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHqN9lQ-CkxD",
        "colab_type": "text"
      },
      "source": [
        "### reparameterization module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5BhTQekCnhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reparameterization(mu, logvar):\n",
        "    std = torch.exp(logvar / 2)\n",
        "    sampled_z = Variable(Tensor(np.random.normal(0, 1, (mu.size(0), 10))))\n",
        "    z = sampled_z * std + mu\n",
        "    return z"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16KAJde9XWcV",
        "colab_type": "text"
      },
      "source": [
        "### Define Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXszRozK6V8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use binary cross-entropy loss\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "pixelwise_loss = torch.nn.L1Loss()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2veA6ejHVfY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b2a92cf0-a788-44ec-d331-610b0902bc2f"
      },
      "source": [
        "discriminator.parameters()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7fef981a9678>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inxN0iHvXQ02",
        "colab_type": "text"
      },
      "source": [
        "### Initialize Generator & Discriminator\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmPLPvZ0XiO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize generator and discriminator\n",
        "encoder = Encoder()\n",
        "decoder = Decoder()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    encoder.cuda()\n",
        "    decoder.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "    pixelwise_loss.cuda()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWYBdu_SDWA7",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHDEU370UNRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_G = torch.optim.Adam(\n",
        "    itertools.chain(encoder.parameters(), decoder.parameters()), lr=0.0002, betas=(0.5, 0.999)\n",
        ")\n",
        "# optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLBGg5ucU_Do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_image(n_row, batches_done):\n",
        "    \"\"\"Saves a grid of generated digits\"\"\"\n",
        "    # Sample noise\n",
        "    z = Variable(Tensor(np.random.normal(0, 1, (n_row ** 2, 10))))\n",
        "    gen_imgs = decoder(z)\n",
        "    save_image(gen_imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqbb-ZkS7d9x",
        "colab_type": "text"
      },
      "source": [
        "## 04. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4Yk-d6Z6V_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dddc88c4-34ea-47b1-bb72-1b8e228a0651"
      },
      "source": [
        "for epoch in range(200):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        encoded_imgs = encoder(real_imgs)\n",
        "        decoded_imgs = decoder(encoded_imgs)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = 0.001 * adversarial_loss(discriminator(encoded_imgs), valid) + 0.999 * pixelwise_loss(\n",
        "            decoded_imgs, real_imgs\n",
        "        )\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Sample noise as discriminator ground truth\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], 10))))\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(z), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(encoded_imgs.detach()), fake)\n",
        "        d_loss = 0.5 * (real_loss + fake_loss)\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, 200, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "        )\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % 400 == 0:\n",
        "            sample_image(n_row=10, batches_done=batches_done)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0/200] [Batch 0/938] [D loss: 0.697496] [G loss: 0.916604]\n",
            "[Epoch 0/200] [Batch 1/938] [D loss: 0.697014] [G loss: 0.914032]\n",
            "[Epoch 0/200] [Batch 2/938] [D loss: 0.697648] [G loss: 0.914530]\n",
            "[Epoch 0/200] [Batch 3/938] [D loss: 0.685569] [G loss: 0.919160]\n",
            "[Epoch 0/200] [Batch 4/938] [D loss: 0.691651] [G loss: 0.917538]\n",
            "[Epoch 0/200] [Batch 5/938] [D loss: 0.698837] [G loss: 0.914731]\n",
            "[Epoch 0/200] [Batch 6/938] [D loss: 0.693931] [G loss: 0.914616]\n",
            "[Epoch 0/200] [Batch 7/938] [D loss: 0.696431] [G loss: 0.915203]\n",
            "[Epoch 0/200] [Batch 8/938] [D loss: 0.692038] [G loss: 0.915675]\n",
            "[Epoch 0/200] [Batch 9/938] [D loss: 0.694737] [G loss: 0.914583]\n",
            "[Epoch 0/200] [Batch 10/938] [D loss: 0.700737] [G loss: 0.920999]\n",
            "[Epoch 0/200] [Batch 11/938] [D loss: 0.701460] [G loss: 0.913850]\n",
            "[Epoch 0/200] [Batch 12/938] [D loss: 0.690443] [G loss: 0.912294]\n",
            "[Epoch 0/200] [Batch 13/938] [D loss: 0.696941] [G loss: 0.916601]\n",
            "[Epoch 0/200] [Batch 14/938] [D loss: 0.696271] [G loss: 0.914377]\n",
            "[Epoch 0/200] [Batch 15/938] [D loss: 0.701807] [G loss: 0.912455]\n",
            "[Epoch 0/200] [Batch 16/938] [D loss: 0.689484] [G loss: 0.915841]\n",
            "[Epoch 0/200] [Batch 17/938] [D loss: 0.697041] [G loss: 0.918691]\n",
            "[Epoch 0/200] [Batch 18/938] [D loss: 0.696547] [G loss: 0.912656]\n",
            "[Epoch 0/200] [Batch 19/938] [D loss: 0.696624] [G loss: 0.917803]\n",
            "[Epoch 0/200] [Batch 20/938] [D loss: 0.697445] [G loss: 0.917010]\n",
            "[Epoch 0/200] [Batch 21/938] [D loss: 0.694289] [G loss: 0.915786]\n",
            "[Epoch 0/200] [Batch 22/938] [D loss: 0.694726] [G loss: 0.912300]\n",
            "[Epoch 0/200] [Batch 23/938] [D loss: 0.697642] [G loss: 0.912961]\n",
            "[Epoch 0/200] [Batch 24/938] [D loss: 0.694097] [G loss: 0.912761]\n",
            "[Epoch 0/200] [Batch 25/938] [D loss: 0.695264] [G loss: 0.911633]\n",
            "[Epoch 0/200] [Batch 26/938] [D loss: 0.695357] [G loss: 0.918052]\n",
            "[Epoch 0/200] [Batch 27/938] [D loss: 0.702346] [G loss: 0.914671]\n",
            "[Epoch 0/200] [Batch 28/938] [D loss: 0.696427] [G loss: 0.910496]\n",
            "[Epoch 0/200] [Batch 29/938] [D loss: 0.693223] [G loss: 0.914895]\n",
            "[Epoch 0/200] [Batch 30/938] [D loss: 0.688359] [G loss: 0.913918]\n",
            "[Epoch 0/200] [Batch 31/938] [D loss: 0.693309] [G loss: 0.917324]\n",
            "[Epoch 0/200] [Batch 32/938] [D loss: 0.692075] [G loss: 0.916731]\n",
            "[Epoch 0/200] [Batch 33/938] [D loss: 0.695779] [G loss: 0.919071]\n",
            "[Epoch 0/200] [Batch 34/938] [D loss: 0.698089] [G loss: 0.914577]\n",
            "[Epoch 0/200] [Batch 35/938] [D loss: 0.688578] [G loss: 0.913373]\n",
            "[Epoch 0/200] [Batch 36/938] [D loss: 0.693811] [G loss: 0.916175]\n",
            "[Epoch 0/200] [Batch 37/938] [D loss: 0.697413] [G loss: 0.914176]\n",
            "[Epoch 0/200] [Batch 38/938] [D loss: 0.691696] [G loss: 0.917490]\n",
            "[Epoch 0/200] [Batch 39/938] [D loss: 0.696832] [G loss: 0.913431]\n",
            "[Epoch 0/200] [Batch 40/938] [D loss: 0.694546] [G loss: 0.915500]\n",
            "[Epoch 0/200] [Batch 41/938] [D loss: 0.696500] [G loss: 0.914213]\n",
            "[Epoch 0/200] [Batch 42/938] [D loss: 0.696008] [G loss: 0.912560]\n",
            "[Epoch 0/200] [Batch 43/938] [D loss: 0.692733] [G loss: 0.915574]\n",
            "[Epoch 0/200] [Batch 44/938] [D loss: 0.691492] [G loss: 0.913383]\n",
            "[Epoch 0/200] [Batch 45/938] [D loss: 0.699962] [G loss: 0.919058]\n",
            "[Epoch 0/200] [Batch 46/938] [D loss: 0.697483] [G loss: 0.912697]\n",
            "[Epoch 0/200] [Batch 47/938] [D loss: 0.695078] [G loss: 0.916132]\n",
            "[Epoch 0/200] [Batch 48/938] [D loss: 0.699567] [G loss: 0.915804]\n",
            "[Epoch 0/200] [Batch 49/938] [D loss: 0.691509] [G loss: 0.916512]\n",
            "[Epoch 0/200] [Batch 50/938] [D loss: 0.698023] [G loss: 0.915592]\n",
            "[Epoch 0/200] [Batch 51/938] [D loss: 0.697081] [G loss: 0.915097]\n",
            "[Epoch 0/200] [Batch 52/938] [D loss: 0.689364] [G loss: 0.913717]\n",
            "[Epoch 0/200] [Batch 53/938] [D loss: 0.698597] [G loss: 0.917153]\n",
            "[Epoch 0/200] [Batch 54/938] [D loss: 0.692468] [G loss: 0.916326]\n",
            "[Epoch 0/200] [Batch 55/938] [D loss: 0.688836] [G loss: 0.916611]\n",
            "[Epoch 0/200] [Batch 56/938] [D loss: 0.686985] [G loss: 0.915166]\n",
            "[Epoch 0/200] [Batch 57/938] [D loss: 0.695941] [G loss: 0.916226]\n",
            "[Epoch 0/200] [Batch 58/938] [D loss: 0.691157] [G loss: 0.917762]\n",
            "[Epoch 0/200] [Batch 59/938] [D loss: 0.691063] [G loss: 0.915755]\n",
            "[Epoch 0/200] [Batch 60/938] [D loss: 0.694181] [G loss: 0.915775]\n",
            "[Epoch 0/200] [Batch 61/938] [D loss: 0.695000] [G loss: 0.911792]\n",
            "[Epoch 0/200] [Batch 62/938] [D loss: 0.696488] [G loss: 0.912061]\n",
            "[Epoch 0/200] [Batch 63/938] [D loss: 0.694708] [G loss: 0.913113]\n",
            "[Epoch 0/200] [Batch 64/938] [D loss: 0.699380] [G loss: 0.916496]\n",
            "[Epoch 0/200] [Batch 65/938] [D loss: 0.699443] [G loss: 0.912077]\n",
            "[Epoch 0/200] [Batch 66/938] [D loss: 0.693706] [G loss: 0.917662]\n",
            "[Epoch 0/200] [Batch 67/938] [D loss: 0.693354] [G loss: 0.911685]\n",
            "[Epoch 0/200] [Batch 68/938] [D loss: 0.697179] [G loss: 0.914065]\n",
            "[Epoch 0/200] [Batch 69/938] [D loss: 0.689846] [G loss: 0.915632]\n",
            "[Epoch 0/200] [Batch 70/938] [D loss: 0.696715] [G loss: 0.913693]\n",
            "[Epoch 0/200] [Batch 71/938] [D loss: 0.691496] [G loss: 0.917318]\n",
            "[Epoch 0/200] [Batch 72/938] [D loss: 0.697087] [G loss: 0.913475]\n",
            "[Epoch 0/200] [Batch 73/938] [D loss: 0.697193] [G loss: 0.916322]\n",
            "[Epoch 0/200] [Batch 74/938] [D loss: 0.696498] [G loss: 0.916164]\n",
            "[Epoch 0/200] [Batch 75/938] [D loss: 0.693817] [G loss: 0.916825]\n",
            "[Epoch 0/200] [Batch 76/938] [D loss: 0.694491] [G loss: 0.911446]\n",
            "[Epoch 0/200] [Batch 77/938] [D loss: 0.693679] [G loss: 0.913487]\n",
            "[Epoch 0/200] [Batch 78/938] [D loss: 0.699030] [G loss: 0.914145]\n",
            "[Epoch 0/200] [Batch 79/938] [D loss: 0.695403] [G loss: 0.918652]\n",
            "[Epoch 0/200] [Batch 80/938] [D loss: 0.692568] [G loss: 0.917459]\n",
            "[Epoch 0/200] [Batch 81/938] [D loss: 0.698012] [G loss: 0.916627]\n",
            "[Epoch 0/200] [Batch 82/938] [D loss: 0.695370] [G loss: 0.917698]\n",
            "[Epoch 0/200] [Batch 83/938] [D loss: 0.688153] [G loss: 0.917371]\n",
            "[Epoch 0/200] [Batch 84/938] [D loss: 0.687165] [G loss: 0.914964]\n",
            "[Epoch 0/200] [Batch 85/938] [D loss: 0.693821] [G loss: 0.912446]\n",
            "[Epoch 0/200] [Batch 86/938] [D loss: 0.699982] [G loss: 0.914062]\n",
            "[Epoch 0/200] [Batch 87/938] [D loss: 0.694311] [G loss: 0.917873]\n",
            "[Epoch 0/200] [Batch 88/938] [D loss: 0.695314] [G loss: 0.916979]\n",
            "[Epoch 0/200] [Batch 89/938] [D loss: 0.696342] [G loss: 0.912095]\n",
            "[Epoch 0/200] [Batch 90/938] [D loss: 0.700718] [G loss: 0.912877]\n",
            "[Epoch 0/200] [Batch 91/938] [D loss: 0.697104] [G loss: 0.917661]\n",
            "[Epoch 0/200] [Batch 92/938] [D loss: 0.696522] [G loss: 0.917471]\n",
            "[Epoch 0/200] [Batch 93/938] [D loss: 0.693587] [G loss: 0.916532]\n",
            "[Epoch 0/200] [Batch 94/938] [D loss: 0.697185] [G loss: 0.916983]\n",
            "[Epoch 0/200] [Batch 95/938] [D loss: 0.693422] [G loss: 0.916343]\n",
            "[Epoch 0/200] [Batch 96/938] [D loss: 0.696365] [G loss: 0.916038]\n",
            "[Epoch 0/200] [Batch 97/938] [D loss: 0.700496] [G loss: 0.915946]\n",
            "[Epoch 0/200] [Batch 98/938] [D loss: 0.693254] [G loss: 0.916792]\n",
            "[Epoch 0/200] [Batch 99/938] [D loss: 0.693328] [G loss: 0.916424]\n",
            "[Epoch 0/200] [Batch 100/938] [D loss: 0.696562] [G loss: 0.913293]\n",
            "[Epoch 0/200] [Batch 101/938] [D loss: 0.696323] [G loss: 0.916082]\n",
            "[Epoch 0/200] [Batch 102/938] [D loss: 0.695459] [G loss: 0.913265]\n",
            "[Epoch 0/200] [Batch 103/938] [D loss: 0.700036] [G loss: 0.911825]\n",
            "[Epoch 0/200] [Batch 104/938] [D loss: 0.689955] [G loss: 0.913315]\n",
            "[Epoch 0/200] [Batch 105/938] [D loss: 0.697142] [G loss: 0.911548]\n",
            "[Epoch 0/200] [Batch 106/938] [D loss: 0.697789] [G loss: 0.917411]\n",
            "[Epoch 0/200] [Batch 107/938] [D loss: 0.697490] [G loss: 0.918811]\n",
            "[Epoch 0/200] [Batch 108/938] [D loss: 0.690401] [G loss: 0.917939]\n",
            "[Epoch 0/200] [Batch 109/938] [D loss: 0.692020] [G loss: 0.917792]\n",
            "[Epoch 0/200] [Batch 110/938] [D loss: 0.697140] [G loss: 0.916349]\n",
            "[Epoch 0/200] [Batch 111/938] [D loss: 0.694192] [G loss: 0.913696]\n",
            "[Epoch 0/200] [Batch 112/938] [D loss: 0.692429] [G loss: 0.915533]\n",
            "[Epoch 0/200] [Batch 113/938] [D loss: 0.695284] [G loss: 0.918638]\n",
            "[Epoch 0/200] [Batch 114/938] [D loss: 0.698644] [G loss: 0.916653]\n",
            "[Epoch 0/200] [Batch 115/938] [D loss: 0.696749] [G loss: 0.915160]\n",
            "[Epoch 0/200] [Batch 116/938] [D loss: 0.696375] [G loss: 0.918013]\n",
            "[Epoch 0/200] [Batch 117/938] [D loss: 0.697668] [G loss: 0.911781]\n",
            "[Epoch 0/200] [Batch 118/938] [D loss: 0.697842] [G loss: 0.917771]\n",
            "[Epoch 0/200] [Batch 119/938] [D loss: 0.695685] [G loss: 0.916745]\n",
            "[Epoch 0/200] [Batch 120/938] [D loss: 0.697218] [G loss: 0.918784]\n",
            "[Epoch 0/200] [Batch 121/938] [D loss: 0.694376] [G loss: 0.917263]\n",
            "[Epoch 0/200] [Batch 122/938] [D loss: 0.697470] [G loss: 0.918264]\n",
            "[Epoch 0/200] [Batch 123/938] [D loss: 0.693091] [G loss: 0.912912]\n",
            "[Epoch 0/200] [Batch 124/938] [D loss: 0.688876] [G loss: 0.914467]\n",
            "[Epoch 0/200] [Batch 125/938] [D loss: 0.692063] [G loss: 0.911644]\n",
            "[Epoch 0/200] [Batch 126/938] [D loss: 0.693363] [G loss: 0.912371]\n",
            "[Epoch 0/200] [Batch 127/938] [D loss: 0.702708] [G loss: 0.911847]\n",
            "[Epoch 0/200] [Batch 128/938] [D loss: 0.697498] [G loss: 0.916302]\n",
            "[Epoch 0/200] [Batch 129/938] [D loss: 0.692291] [G loss: 0.919983]\n",
            "[Epoch 0/200] [Batch 130/938] [D loss: 0.694639] [G loss: 0.919296]\n",
            "[Epoch 0/200] [Batch 131/938] [D loss: 0.699566] [G loss: 0.919905]\n",
            "[Epoch 0/200] [Batch 132/938] [D loss: 0.689975] [G loss: 0.914276]\n",
            "[Epoch 0/200] [Batch 133/938] [D loss: 0.696322] [G loss: 0.913876]\n",
            "[Epoch 0/200] [Batch 134/938] [D loss: 0.694318] [G loss: 0.917981]\n",
            "[Epoch 0/200] [Batch 135/938] [D loss: 0.699764] [G loss: 0.916421]\n",
            "[Epoch 0/200] [Batch 136/938] [D loss: 0.688906] [G loss: 0.915709]\n",
            "[Epoch 0/200] [Batch 137/938] [D loss: 0.695423] [G loss: 0.916856]\n",
            "[Epoch 0/200] [Batch 138/938] [D loss: 0.694875] [G loss: 0.913655]\n",
            "[Epoch 0/200] [Batch 139/938] [D loss: 0.699582] [G loss: 0.916269]\n",
            "[Epoch 0/200] [Batch 140/938] [D loss: 0.700208] [G loss: 0.914671]\n",
            "[Epoch 0/200] [Batch 141/938] [D loss: 0.697001] [G loss: 0.913349]\n",
            "[Epoch 0/200] [Batch 142/938] [D loss: 0.696126] [G loss: 0.915282]\n",
            "[Epoch 0/200] [Batch 143/938] [D loss: 0.694173] [G loss: 0.916521]\n",
            "[Epoch 0/200] [Batch 144/938] [D loss: 0.698094] [G loss: 0.913910]\n",
            "[Epoch 0/200] [Batch 145/938] [D loss: 0.693332] [G loss: 0.909537]\n",
            "[Epoch 0/200] [Batch 146/938] [D loss: 0.695409] [G loss: 0.911542]\n",
            "[Epoch 0/200] [Batch 147/938] [D loss: 0.692989] [G loss: 0.917580]\n",
            "[Epoch 0/200] [Batch 148/938] [D loss: 0.696963] [G loss: 0.917257]\n",
            "[Epoch 0/200] [Batch 149/938] [D loss: 0.697223] [G loss: 0.914272]\n",
            "[Epoch 0/200] [Batch 150/938] [D loss: 0.698732] [G loss: 0.914141]\n",
            "[Epoch 0/200] [Batch 151/938] [D loss: 0.695600] [G loss: 0.916822]\n",
            "[Epoch 0/200] [Batch 152/938] [D loss: 0.697315] [G loss: 0.914499]\n",
            "[Epoch 0/200] [Batch 153/938] [D loss: 0.693254] [G loss: 0.915122]\n",
            "[Epoch 0/200] [Batch 154/938] [D loss: 0.690923] [G loss: 0.917092]\n",
            "[Epoch 0/200] [Batch 155/938] [D loss: 0.696537] [G loss: 0.915724]\n",
            "[Epoch 0/200] [Batch 156/938] [D loss: 0.702863] [G loss: 0.913220]\n",
            "[Epoch 0/200] [Batch 157/938] [D loss: 0.694715] [G loss: 0.912095]\n",
            "[Epoch 0/200] [Batch 158/938] [D loss: 0.700361] [G loss: 0.918423]\n",
            "[Epoch 0/200] [Batch 159/938] [D loss: 0.693548] [G loss: 0.915050]\n",
            "[Epoch 0/200] [Batch 160/938] [D loss: 0.692989] [G loss: 0.915570]\n",
            "[Epoch 0/200] [Batch 161/938] [D loss: 0.691980] [G loss: 0.917220]\n",
            "[Epoch 0/200] [Batch 162/938] [D loss: 0.700074] [G loss: 0.915101]\n",
            "[Epoch 0/200] [Batch 163/938] [D loss: 0.690119] [G loss: 0.916039]\n",
            "[Epoch 0/200] [Batch 164/938] [D loss: 0.697666] [G loss: 0.912696]\n",
            "[Epoch 0/200] [Batch 165/938] [D loss: 0.702887] [G loss: 0.914662]\n",
            "[Epoch 0/200] [Batch 166/938] [D loss: 0.689016] [G loss: 0.912144]\n",
            "[Epoch 0/200] [Batch 167/938] [D loss: 0.695008] [G loss: 0.914092]\n",
            "[Epoch 0/200] [Batch 168/938] [D loss: 0.695453] [G loss: 0.915583]\n",
            "[Epoch 0/200] [Batch 169/938] [D loss: 0.703071] [G loss: 0.919961]\n",
            "[Epoch 0/200] [Batch 170/938] [D loss: 0.698092] [G loss: 0.914261]\n",
            "[Epoch 0/200] [Batch 171/938] [D loss: 0.697184] [G loss: 0.912187]\n",
            "[Epoch 0/200] [Batch 172/938] [D loss: 0.699131] [G loss: 0.913165]\n",
            "[Epoch 0/200] [Batch 173/938] [D loss: 0.689544] [G loss: 0.915368]\n",
            "[Epoch 0/200] [Batch 174/938] [D loss: 0.695748] [G loss: 0.910483]\n",
            "[Epoch 0/200] [Batch 175/938] [D loss: 0.691944] [G loss: 0.915368]\n",
            "[Epoch 0/200] [Batch 176/938] [D loss: 0.695845] [G loss: 0.912556]\n",
            "[Epoch 0/200] [Batch 177/938] [D loss: 0.690359] [G loss: 0.914571]\n",
            "[Epoch 0/200] [Batch 178/938] [D loss: 0.696409] [G loss: 0.913738]\n",
            "[Epoch 0/200] [Batch 179/938] [D loss: 0.695508] [G loss: 0.914240]\n",
            "[Epoch 0/200] [Batch 180/938] [D loss: 0.695894] [G loss: 0.917833]\n",
            "[Epoch 0/200] [Batch 181/938] [D loss: 0.695992] [G loss: 0.917628]\n",
            "[Epoch 0/200] [Batch 182/938] [D loss: 0.696808] [G loss: 0.918955]\n",
            "[Epoch 0/200] [Batch 183/938] [D loss: 0.696937] [G loss: 0.915774]\n",
            "[Epoch 0/200] [Batch 184/938] [D loss: 0.692122] [G loss: 0.914534]\n",
            "[Epoch 0/200] [Batch 185/938] [D loss: 0.699813] [G loss: 0.913247]\n",
            "[Epoch 0/200] [Batch 186/938] [D loss: 0.698550] [G loss: 0.913197]\n",
            "[Epoch 0/200] [Batch 187/938] [D loss: 0.692212] [G loss: 0.920947]\n",
            "[Epoch 0/200] [Batch 188/938] [D loss: 0.692959] [G loss: 0.914199]\n",
            "[Epoch 0/200] [Batch 189/938] [D loss: 0.692368] [G loss: 0.917430]\n",
            "[Epoch 0/200] [Batch 190/938] [D loss: 0.698417] [G loss: 0.916793]\n",
            "[Epoch 0/200] [Batch 191/938] [D loss: 0.699164] [G loss: 0.914141]\n",
            "[Epoch 0/200] [Batch 192/938] [D loss: 0.695202] [G loss: 0.916114]\n",
            "[Epoch 0/200] [Batch 193/938] [D loss: 0.700650] [G loss: 0.913985]\n",
            "[Epoch 0/200] [Batch 194/938] [D loss: 0.698562] [G loss: 0.914645]\n",
            "[Epoch 0/200] [Batch 195/938] [D loss: 0.696509] [G loss: 0.914989]\n",
            "[Epoch 0/200] [Batch 196/938] [D loss: 0.695260] [G loss: 0.912172]\n",
            "[Epoch 0/200] [Batch 197/938] [D loss: 0.695069] [G loss: 0.913557]\n",
            "[Epoch 0/200] [Batch 198/938] [D loss: 0.700013] [G loss: 0.916811]\n",
            "[Epoch 0/200] [Batch 199/938] [D loss: 0.700591] [G loss: 0.915884]\n",
            "[Epoch 0/200] [Batch 200/938] [D loss: 0.693576] [G loss: 0.913559]\n",
            "[Epoch 0/200] [Batch 201/938] [D loss: 0.700238] [G loss: 0.918275]\n",
            "[Epoch 0/200] [Batch 202/938] [D loss: 0.693570] [G loss: 0.913047]\n",
            "[Epoch 0/200] [Batch 203/938] [D loss: 0.701310] [G loss: 0.914625]\n",
            "[Epoch 0/200] [Batch 204/938] [D loss: 0.697516] [G loss: 0.916468]\n",
            "[Epoch 0/200] [Batch 205/938] [D loss: 0.694260] [G loss: 0.916902]\n",
            "[Epoch 0/200] [Batch 206/938] [D loss: 0.694636] [G loss: 0.916071]\n",
            "[Epoch 0/200] [Batch 207/938] [D loss: 0.692486] [G loss: 0.912596]\n",
            "[Epoch 0/200] [Batch 208/938] [D loss: 0.690778] [G loss: 0.913566]\n",
            "[Epoch 0/200] [Batch 209/938] [D loss: 0.694312] [G loss: 0.916516]\n",
            "[Epoch 0/200] [Batch 210/938] [D loss: 0.698343] [G loss: 0.914149]\n",
            "[Epoch 0/200] [Batch 211/938] [D loss: 0.690373] [G loss: 0.915682]\n",
            "[Epoch 0/200] [Batch 212/938] [D loss: 0.698925] [G loss: 0.916413]\n",
            "[Epoch 0/200] [Batch 213/938] [D loss: 0.697240] [G loss: 0.914245]\n",
            "[Epoch 0/200] [Batch 214/938] [D loss: 0.698736] [G loss: 0.913279]\n",
            "[Epoch 0/200] [Batch 215/938] [D loss: 0.702422] [G loss: 0.917511]\n",
            "[Epoch 0/200] [Batch 216/938] [D loss: 0.695842] [G loss: 0.919600]\n",
            "[Epoch 0/200] [Batch 217/938] [D loss: 0.690669] [G loss: 0.914840]\n",
            "[Epoch 0/200] [Batch 218/938] [D loss: 0.691231] [G loss: 0.917526]\n",
            "[Epoch 0/200] [Batch 219/938] [D loss: 0.692210] [G loss: 0.916484]\n",
            "[Epoch 0/200] [Batch 220/938] [D loss: 0.696292] [G loss: 0.914169]\n",
            "[Epoch 0/200] [Batch 221/938] [D loss: 0.697917] [G loss: 0.916295]\n",
            "[Epoch 0/200] [Batch 222/938] [D loss: 0.695611] [G loss: 0.914462]\n",
            "[Epoch 0/200] [Batch 223/938] [D loss: 0.694787] [G loss: 0.916013]\n",
            "[Epoch 0/200] [Batch 224/938] [D loss: 0.695728] [G loss: 0.915515]\n",
            "[Epoch 0/200] [Batch 225/938] [D loss: 0.698563] [G loss: 0.913796]\n",
            "[Epoch 0/200] [Batch 226/938] [D loss: 0.700642] [G loss: 0.914765]\n",
            "[Epoch 0/200] [Batch 227/938] [D loss: 0.698985] [G loss: 0.916008]\n",
            "[Epoch 0/200] [Batch 228/938] [D loss: 0.697175] [G loss: 0.921753]\n",
            "[Epoch 0/200] [Batch 229/938] [D loss: 0.696300] [G loss: 0.920389]\n",
            "[Epoch 0/200] [Batch 230/938] [D loss: 0.698307] [G loss: 0.914341]\n",
            "[Epoch 0/200] [Batch 231/938] [D loss: 0.696455] [G loss: 0.917264]\n",
            "[Epoch 0/200] [Batch 232/938] [D loss: 0.701411] [G loss: 0.914292]\n",
            "[Epoch 0/200] [Batch 233/938] [D loss: 0.698333] [G loss: 0.911462]\n",
            "[Epoch 0/200] [Batch 234/938] [D loss: 0.699220] [G loss: 0.915502]\n",
            "[Epoch 0/200] [Batch 235/938] [D loss: 0.697365] [G loss: 0.915770]\n",
            "[Epoch 0/200] [Batch 236/938] [D loss: 0.694149] [G loss: 0.911783]\n",
            "[Epoch 0/200] [Batch 237/938] [D loss: 0.697542] [G loss: 0.913898]\n",
            "[Epoch 0/200] [Batch 238/938] [D loss: 0.693456] [G loss: 0.915202]\n",
            "[Epoch 0/200] [Batch 239/938] [D loss: 0.694139] [G loss: 0.913158]\n",
            "[Epoch 0/200] [Batch 240/938] [D loss: 0.693462] [G loss: 0.915671]\n",
            "[Epoch 0/200] [Batch 241/938] [D loss: 0.693591] [G loss: 0.914712]\n",
            "[Epoch 0/200] [Batch 242/938] [D loss: 0.693837] [G loss: 0.913096]\n",
            "[Epoch 0/200] [Batch 243/938] [D loss: 0.700639] [G loss: 0.916357]\n",
            "[Epoch 0/200] [Batch 244/938] [D loss: 0.697655] [G loss: 0.916104]\n",
            "[Epoch 0/200] [Batch 245/938] [D loss: 0.699289] [G loss: 0.915524]\n",
            "[Epoch 0/200] [Batch 246/938] [D loss: 0.691040] [G loss: 0.918911]\n",
            "[Epoch 0/200] [Batch 247/938] [D loss: 0.697301] [G loss: 0.917800]\n",
            "[Epoch 0/200] [Batch 248/938] [D loss: 0.696556] [G loss: 0.915560]\n",
            "[Epoch 0/200] [Batch 249/938] [D loss: 0.694693] [G loss: 0.918846]\n",
            "[Epoch 0/200] [Batch 250/938] [D loss: 0.692529] [G loss: 0.914300]\n",
            "[Epoch 0/200] [Batch 251/938] [D loss: 0.695319] [G loss: 0.913025]\n",
            "[Epoch 0/200] [Batch 252/938] [D loss: 0.694758] [G loss: 0.914896]\n",
            "[Epoch 0/200] [Batch 253/938] [D loss: 0.695295] [G loss: 0.913134]\n",
            "[Epoch 0/200] [Batch 254/938] [D loss: 0.700762] [G loss: 0.912879]\n",
            "[Epoch 0/200] [Batch 255/938] [D loss: 0.698661] [G loss: 0.912050]\n",
            "[Epoch 0/200] [Batch 256/938] [D loss: 0.688579] [G loss: 0.913378]\n",
            "[Epoch 0/200] [Batch 257/938] [D loss: 0.692371] [G loss: 0.917972]\n",
            "[Epoch 0/200] [Batch 258/938] [D loss: 0.696038] [G loss: 0.914252]\n",
            "[Epoch 0/200] [Batch 259/938] [D loss: 0.699800] [G loss: 0.911819]\n",
            "[Epoch 0/200] [Batch 260/938] [D loss: 0.693927] [G loss: 0.913222]\n",
            "[Epoch 0/200] [Batch 261/938] [D loss: 0.697999] [G loss: 0.915740]\n",
            "[Epoch 0/200] [Batch 262/938] [D loss: 0.694966] [G loss: 0.917566]\n",
            "[Epoch 0/200] [Batch 263/938] [D loss: 0.694245] [G loss: 0.918917]\n",
            "[Epoch 0/200] [Batch 264/938] [D loss: 0.694230] [G loss: 0.915918]\n",
            "[Epoch 0/200] [Batch 265/938] [D loss: 0.699713] [G loss: 0.913231]\n",
            "[Epoch 0/200] [Batch 266/938] [D loss: 0.691429] [G loss: 0.907204]\n",
            "[Epoch 0/200] [Batch 267/938] [D loss: 0.694537] [G loss: 0.917102]\n",
            "[Epoch 0/200] [Batch 268/938] [D loss: 0.691590] [G loss: 0.913796]\n",
            "[Epoch 0/200] [Batch 269/938] [D loss: 0.694472] [G loss: 0.917841]\n",
            "[Epoch 0/200] [Batch 270/938] [D loss: 0.695490] [G loss: 0.917123]\n",
            "[Epoch 0/200] [Batch 271/938] [D loss: 0.693482] [G loss: 0.916903]\n",
            "[Epoch 0/200] [Batch 272/938] [D loss: 0.694327] [G loss: 0.914143]\n",
            "[Epoch 0/200] [Batch 273/938] [D loss: 0.696357] [G loss: 0.915239]\n",
            "[Epoch 0/200] [Batch 274/938] [D loss: 0.695011] [G loss: 0.915190]\n",
            "[Epoch 0/200] [Batch 275/938] [D loss: 0.691844] [G loss: 0.917579]\n",
            "[Epoch 0/200] [Batch 276/938] [D loss: 0.692090] [G loss: 0.916086]\n",
            "[Epoch 0/200] [Batch 277/938] [D loss: 0.694822] [G loss: 0.914858]\n",
            "[Epoch 0/200] [Batch 278/938] [D loss: 0.695503] [G loss: 0.909823]\n",
            "[Epoch 0/200] [Batch 279/938] [D loss: 0.689982] [G loss: 0.916271]\n",
            "[Epoch 0/200] [Batch 280/938] [D loss: 0.697857] [G loss: 0.915062]\n",
            "[Epoch 0/200] [Batch 281/938] [D loss: 0.691837] [G loss: 0.913013]\n",
            "[Epoch 0/200] [Batch 282/938] [D loss: 0.694257] [G loss: 0.914806]\n",
            "[Epoch 0/200] [Batch 283/938] [D loss: 0.702323] [G loss: 0.913828]\n",
            "[Epoch 0/200] [Batch 284/938] [D loss: 0.690072] [G loss: 0.915343]\n",
            "[Epoch 0/200] [Batch 285/938] [D loss: 0.697415] [G loss: 0.917559]\n",
            "[Epoch 0/200] [Batch 286/938] [D loss: 0.697853] [G loss: 0.914381]\n",
            "[Epoch 0/200] [Batch 287/938] [D loss: 0.698882] [G loss: 0.917571]\n",
            "[Epoch 0/200] [Batch 288/938] [D loss: 0.701369] [G loss: 0.916745]\n",
            "[Epoch 0/200] [Batch 289/938] [D loss: 0.694009] [G loss: 0.911923]\n",
            "[Epoch 0/200] [Batch 290/938] [D loss: 0.697537] [G loss: 0.909679]\n",
            "[Epoch 0/200] [Batch 291/938] [D loss: 0.694016] [G loss: 0.912373]\n",
            "[Epoch 0/200] [Batch 292/938] [D loss: 0.692941] [G loss: 0.915903]\n",
            "[Epoch 0/200] [Batch 293/938] [D loss: 0.690659] [G loss: 0.909668]\n",
            "[Epoch 0/200] [Batch 294/938] [D loss: 0.690467] [G loss: 0.917186]\n",
            "[Epoch 0/200] [Batch 295/938] [D loss: 0.697558] [G loss: 0.915742]\n",
            "[Epoch 0/200] [Batch 296/938] [D loss: 0.693419] [G loss: 0.916373]\n",
            "[Epoch 0/200] [Batch 297/938] [D loss: 0.695430] [G loss: 0.915874]\n",
            "[Epoch 0/200] [Batch 298/938] [D loss: 0.694024] [G loss: 0.916950]\n",
            "[Epoch 0/200] [Batch 299/938] [D loss: 0.690820] [G loss: 0.915419]\n",
            "[Epoch 0/200] [Batch 300/938] [D loss: 0.698699] [G loss: 0.914973]\n",
            "[Epoch 0/200] [Batch 301/938] [D loss: 0.697873] [G loss: 0.912119]\n",
            "[Epoch 0/200] [Batch 302/938] [D loss: 0.688164] [G loss: 0.917379]\n",
            "[Epoch 0/200] [Batch 303/938] [D loss: 0.700533] [G loss: 0.914237]\n",
            "[Epoch 0/200] [Batch 304/938] [D loss: 0.695191] [G loss: 0.916641]\n",
            "[Epoch 0/200] [Batch 305/938] [D loss: 0.691097] [G loss: 0.914328]\n",
            "[Epoch 0/200] [Batch 306/938] [D loss: 0.692371] [G loss: 0.915672]\n",
            "[Epoch 0/200] [Batch 307/938] [D loss: 0.695337] [G loss: 0.914666]\n",
            "[Epoch 0/200] [Batch 308/938] [D loss: 0.697896] [G loss: 0.914069]\n",
            "[Epoch 0/200] [Batch 309/938] [D loss: 0.696157] [G loss: 0.917383]\n",
            "[Epoch 0/200] [Batch 310/938] [D loss: 0.695338] [G loss: 0.917409]\n",
            "[Epoch 0/200] [Batch 311/938] [D loss: 0.696576] [G loss: 0.915142]\n",
            "[Epoch 0/200] [Batch 312/938] [D loss: 0.693503] [G loss: 0.913342]\n",
            "[Epoch 0/200] [Batch 313/938] [D loss: 0.692544] [G loss: 0.915852]\n",
            "[Epoch 0/200] [Batch 314/938] [D loss: 0.698054] [G loss: 0.916611]\n",
            "[Epoch 0/200] [Batch 315/938] [D loss: 0.688727] [G loss: 0.919079]\n",
            "[Epoch 0/200] [Batch 316/938] [D loss: 0.696934] [G loss: 0.915976]\n",
            "[Epoch 0/200] [Batch 317/938] [D loss: 0.695569] [G loss: 0.917242]\n",
            "[Epoch 0/200] [Batch 318/938] [D loss: 0.701404] [G loss: 0.912361]\n",
            "[Epoch 0/200] [Batch 319/938] [D loss: 0.695860] [G loss: 0.911935]\n",
            "[Epoch 0/200] [Batch 320/938] [D loss: 0.693860] [G loss: 0.911695]\n",
            "[Epoch 0/200] [Batch 321/938] [D loss: 0.693632] [G loss: 0.915026]\n",
            "[Epoch 0/200] [Batch 322/938] [D loss: 0.697099] [G loss: 0.917545]\n",
            "[Epoch 0/200] [Batch 323/938] [D loss: 0.695032] [G loss: 0.910394]\n",
            "[Epoch 0/200] [Batch 324/938] [D loss: 0.697089] [G loss: 0.914764]\n",
            "[Epoch 0/200] [Batch 325/938] [D loss: 0.694633] [G loss: 0.913060]\n",
            "[Epoch 0/200] [Batch 326/938] [D loss: 0.693183] [G loss: 0.917544]\n",
            "[Epoch 0/200] [Batch 327/938] [D loss: 0.695518] [G loss: 0.913678]\n",
            "[Epoch 0/200] [Batch 328/938] [D loss: 0.690995] [G loss: 0.914247]\n",
            "[Epoch 0/200] [Batch 329/938] [D loss: 0.697374] [G loss: 0.914826]\n",
            "[Epoch 0/200] [Batch 330/938] [D loss: 0.699084] [G loss: 0.915666]\n",
            "[Epoch 0/200] [Batch 331/938] [D loss: 0.697271] [G loss: 0.911995]\n",
            "[Epoch 0/200] [Batch 332/938] [D loss: 0.694232] [G loss: 0.911914]\n",
            "[Epoch 0/200] [Batch 333/938] [D loss: 0.693193] [G loss: 0.914774]\n",
            "[Epoch 0/200] [Batch 334/938] [D loss: 0.696884] [G loss: 0.916758]\n",
            "[Epoch 0/200] [Batch 335/938] [D loss: 0.694915] [G loss: 0.917530]\n",
            "[Epoch 0/200] [Batch 336/938] [D loss: 0.697327] [G loss: 0.917391]\n",
            "[Epoch 0/200] [Batch 337/938] [D loss: 0.694468] [G loss: 0.916677]\n",
            "[Epoch 0/200] [Batch 338/938] [D loss: 0.696442] [G loss: 0.912902]\n",
            "[Epoch 0/200] [Batch 339/938] [D loss: 0.695677] [G loss: 0.910412]\n",
            "[Epoch 0/200] [Batch 340/938] [D loss: 0.697925] [G loss: 0.916392]\n",
            "[Epoch 0/200] [Batch 341/938] [D loss: 0.695813] [G loss: 0.916277]\n",
            "[Epoch 0/200] [Batch 342/938] [D loss: 0.692875] [G loss: 0.916952]\n",
            "[Epoch 0/200] [Batch 343/938] [D loss: 0.702933] [G loss: 0.914037]\n",
            "[Epoch 0/200] [Batch 344/938] [D loss: 0.699147] [G loss: 0.916081]\n",
            "[Epoch 0/200] [Batch 345/938] [D loss: 0.694283] [G loss: 0.915796]\n",
            "[Epoch 0/200] [Batch 346/938] [D loss: 0.699214] [G loss: 0.916115]\n",
            "[Epoch 0/200] [Batch 347/938] [D loss: 0.691496] [G loss: 0.913373]\n",
            "[Epoch 0/200] [Batch 348/938] [D loss: 0.697914] [G loss: 0.917433]\n",
            "[Epoch 0/200] [Batch 349/938] [D loss: 0.696378] [G loss: 0.913624]\n",
            "[Epoch 0/200] [Batch 350/938] [D loss: 0.696738] [G loss: 0.918903]\n",
            "[Epoch 0/200] [Batch 351/938] [D loss: 0.696292] [G loss: 0.913016]\n",
            "[Epoch 0/200] [Batch 352/938] [D loss: 0.700406] [G loss: 0.913131]\n",
            "[Epoch 0/200] [Batch 353/938] [D loss: 0.696671] [G loss: 0.917419]\n",
            "[Epoch 0/200] [Batch 354/938] [D loss: 0.698575] [G loss: 0.916927]\n",
            "[Epoch 0/200] [Batch 355/938] [D loss: 0.695991] [G loss: 0.915370]\n",
            "[Epoch 0/200] [Batch 356/938] [D loss: 0.696565] [G loss: 0.915533]\n",
            "[Epoch 0/200] [Batch 357/938] [D loss: 0.696093] [G loss: 0.911384]\n",
            "[Epoch 0/200] [Batch 358/938] [D loss: 0.694844] [G loss: 0.919618]\n",
            "[Epoch 0/200] [Batch 359/938] [D loss: 0.697921] [G loss: 0.915110]\n",
            "[Epoch 0/200] [Batch 360/938] [D loss: 0.700373] [G loss: 0.918792]\n",
            "[Epoch 0/200] [Batch 361/938] [D loss: 0.694345] [G loss: 0.914674]\n",
            "[Epoch 0/200] [Batch 362/938] [D loss: 0.695123] [G loss: 0.910980]\n",
            "[Epoch 0/200] [Batch 363/938] [D loss: 0.695602] [G loss: 0.911862]\n",
            "[Epoch 0/200] [Batch 364/938] [D loss: 0.691162] [G loss: 0.916582]\n",
            "[Epoch 0/200] [Batch 365/938] [D loss: 0.696350] [G loss: 0.915683]\n",
            "[Epoch 0/200] [Batch 366/938] [D loss: 0.693498] [G loss: 0.918006]\n",
            "[Epoch 0/200] [Batch 367/938] [D loss: 0.693032] [G loss: 0.915616]\n",
            "[Epoch 0/200] [Batch 368/938] [D loss: 0.695094] [G loss: 0.917669]\n",
            "[Epoch 0/200] [Batch 369/938] [D loss: 0.693772] [G loss: 0.917660]\n",
            "[Epoch 0/200] [Batch 370/938] [D loss: 0.698622] [G loss: 0.912321]\n",
            "[Epoch 0/200] [Batch 371/938] [D loss: 0.698859] [G loss: 0.914036]\n",
            "[Epoch 0/200] [Batch 372/938] [D loss: 0.697838] [G loss: 0.915482]\n",
            "[Epoch 0/200] [Batch 373/938] [D loss: 0.699792] [G loss: 0.913418]\n",
            "[Epoch 0/200] [Batch 374/938] [D loss: 0.697479] [G loss: 0.911810]\n",
            "[Epoch 0/200] [Batch 375/938] [D loss: 0.694519] [G loss: 0.914425]\n",
            "[Epoch 0/200] [Batch 376/938] [D loss: 0.695148] [G loss: 0.913694]\n",
            "[Epoch 0/200] [Batch 377/938] [D loss: 0.694803] [G loss: 0.914186]\n",
            "[Epoch 0/200] [Batch 378/938] [D loss: 0.687577] [G loss: 0.914398]\n",
            "[Epoch 0/200] [Batch 379/938] [D loss: 0.695502] [G loss: 0.913146]\n",
            "[Epoch 0/200] [Batch 380/938] [D loss: 0.697865] [G loss: 0.914002]\n",
            "[Epoch 0/200] [Batch 381/938] [D loss: 0.687342] [G loss: 0.916565]\n",
            "[Epoch 0/200] [Batch 382/938] [D loss: 0.689347] [G loss: 0.920704]\n",
            "[Epoch 0/200] [Batch 383/938] [D loss: 0.691118] [G loss: 0.913389]\n",
            "[Epoch 0/200] [Batch 384/938] [D loss: 0.698593] [G loss: 0.918170]\n",
            "[Epoch 0/200] [Batch 385/938] [D loss: 0.694173] [G loss: 0.913453]\n",
            "[Epoch 0/200] [Batch 386/938] [D loss: 0.692740] [G loss: 0.913202]\n",
            "[Epoch 0/200] [Batch 387/938] [D loss: 0.691123] [G loss: 0.916821]\n",
            "[Epoch 0/200] [Batch 388/938] [D loss: 0.698774] [G loss: 0.914804]\n",
            "[Epoch 0/200] [Batch 389/938] [D loss: 0.693892] [G loss: 0.912592]\n",
            "[Epoch 0/200] [Batch 390/938] [D loss: 0.696861] [G loss: 0.916056]\n",
            "[Epoch 0/200] [Batch 391/938] [D loss: 0.696188] [G loss: 0.918123]\n",
            "[Epoch 0/200] [Batch 392/938] [D loss: 0.692206] [G loss: 0.913709]\n",
            "[Epoch 0/200] [Batch 393/938] [D loss: 0.695512] [G loss: 0.917845]\n",
            "[Epoch 0/200] [Batch 394/938] [D loss: 0.694577] [G loss: 0.918058]\n",
            "[Epoch 0/200] [Batch 395/938] [D loss: 0.691025] [G loss: 0.921099]\n",
            "[Epoch 0/200] [Batch 396/938] [D loss: 0.693855] [G loss: 0.916270]\n",
            "[Epoch 0/200] [Batch 397/938] [D loss: 0.698631] [G loss: 0.916375]\n",
            "[Epoch 0/200] [Batch 398/938] [D loss: 0.696193] [G loss: 0.915659]\n",
            "[Epoch 0/200] [Batch 399/938] [D loss: 0.691143] [G loss: 0.912052]\n",
            "[Epoch 0/200] [Batch 400/938] [D loss: 0.696390] [G loss: 0.911407]\n",
            "[Epoch 0/200] [Batch 401/938] [D loss: 0.699785] [G loss: 0.916772]\n",
            "[Epoch 0/200] [Batch 402/938] [D loss: 0.698123] [G loss: 0.913110]\n",
            "[Epoch 0/200] [Batch 403/938] [D loss: 0.691602] [G loss: 0.914097]\n",
            "[Epoch 0/200] [Batch 404/938] [D loss: 0.693578] [G loss: 0.916774]\n",
            "[Epoch 0/200] [Batch 405/938] [D loss: 0.691639] [G loss: 0.917457]\n",
            "[Epoch 0/200] [Batch 406/938] [D loss: 0.693478] [G loss: 0.914822]\n",
            "[Epoch 0/200] [Batch 407/938] [D loss: 0.692949] [G loss: 0.919128]\n",
            "[Epoch 0/200] [Batch 408/938] [D loss: 0.692612] [G loss: 0.913597]\n",
            "[Epoch 0/200] [Batch 409/938] [D loss: 0.701308] [G loss: 0.916368]\n",
            "[Epoch 0/200] [Batch 410/938] [D loss: 0.695261] [G loss: 0.913770]\n",
            "[Epoch 0/200] [Batch 411/938] [D loss: 0.694253] [G loss: 0.916077]\n",
            "[Epoch 0/200] [Batch 412/938] [D loss: 0.702464] [G loss: 0.913053]\n",
            "[Epoch 0/200] [Batch 413/938] [D loss: 0.697929] [G loss: 0.912271]\n",
            "[Epoch 0/200] [Batch 414/938] [D loss: 0.700300] [G loss: 0.913352]\n",
            "[Epoch 0/200] [Batch 415/938] [D loss: 0.698091] [G loss: 0.921039]\n",
            "[Epoch 0/200] [Batch 416/938] [D loss: 0.692359] [G loss: 0.917252]\n",
            "[Epoch 0/200] [Batch 417/938] [D loss: 0.698378] [G loss: 0.920014]\n",
            "[Epoch 0/200] [Batch 418/938] [D loss: 0.697205] [G loss: 0.912260]\n",
            "[Epoch 0/200] [Batch 419/938] [D loss: 0.694737] [G loss: 0.916228]\n",
            "[Epoch 0/200] [Batch 420/938] [D loss: 0.696291] [G loss: 0.914806]\n",
            "[Epoch 0/200] [Batch 421/938] [D loss: 0.695176] [G loss: 0.914122]\n",
            "[Epoch 0/200] [Batch 422/938] [D loss: 0.696741] [G loss: 0.916942]\n",
            "[Epoch 0/200] [Batch 423/938] [D loss: 0.696881] [G loss: 0.916732]\n",
            "[Epoch 0/200] [Batch 424/938] [D loss: 0.693297] [G loss: 0.919130]\n",
            "[Epoch 0/200] [Batch 425/938] [D loss: 0.693258] [G loss: 0.917869]\n",
            "[Epoch 0/200] [Batch 426/938] [D loss: 0.699125] [G loss: 0.914484]\n",
            "[Epoch 0/200] [Batch 427/938] [D loss: 0.692264] [G loss: 0.918852]\n",
            "[Epoch 0/200] [Batch 428/938] [D loss: 0.692283] [G loss: 0.917093]\n",
            "[Epoch 0/200] [Batch 429/938] [D loss: 0.693848] [G loss: 0.912963]\n",
            "[Epoch 0/200] [Batch 430/938] [D loss: 0.694662] [G loss: 0.914498]\n",
            "[Epoch 0/200] [Batch 431/938] [D loss: 0.691805] [G loss: 0.913131]\n",
            "[Epoch 0/200] [Batch 432/938] [D loss: 0.694929] [G loss: 0.913877]\n",
            "[Epoch 0/200] [Batch 433/938] [D loss: 0.695059] [G loss: 0.910514]\n",
            "[Epoch 0/200] [Batch 434/938] [D loss: 0.697738] [G loss: 0.914913]\n",
            "[Epoch 0/200] [Batch 435/938] [D loss: 0.699773] [G loss: 0.916152]\n",
            "[Epoch 0/200] [Batch 436/938] [D loss: 0.692217] [G loss: 0.912310]\n",
            "[Epoch 0/200] [Batch 437/938] [D loss: 0.694076] [G loss: 0.910723]\n",
            "[Epoch 0/200] [Batch 438/938] [D loss: 0.699791] [G loss: 0.919148]\n",
            "[Epoch 0/200] [Batch 439/938] [D loss: 0.695753] [G loss: 0.910862]\n",
            "[Epoch 0/200] [Batch 440/938] [D loss: 0.696281] [G loss: 0.918461]\n",
            "[Epoch 0/200] [Batch 441/938] [D loss: 0.697560] [G loss: 0.916885]\n",
            "[Epoch 0/200] [Batch 442/938] [D loss: 0.695056] [G loss: 0.908336]\n",
            "[Epoch 0/200] [Batch 443/938] [D loss: 0.698242] [G loss: 0.919047]\n",
            "[Epoch 0/200] [Batch 444/938] [D loss: 0.695687] [G loss: 0.914174]\n",
            "[Epoch 0/200] [Batch 445/938] [D loss: 0.697100] [G loss: 0.913891]\n",
            "[Epoch 0/200] [Batch 446/938] [D loss: 0.694214] [G loss: 0.917028]\n",
            "[Epoch 0/200] [Batch 447/938] [D loss: 0.690115] [G loss: 0.918394]\n",
            "[Epoch 0/200] [Batch 448/938] [D loss: 0.695931] [G loss: 0.912629]\n",
            "[Epoch 0/200] [Batch 449/938] [D loss: 0.698284] [G loss: 0.915586]\n",
            "[Epoch 0/200] [Batch 450/938] [D loss: 0.697933] [G loss: 0.916174]\n",
            "[Epoch 0/200] [Batch 451/938] [D loss: 0.697663] [G loss: 0.911318]\n",
            "[Epoch 0/200] [Batch 452/938] [D loss: 0.692183] [G loss: 0.918270]\n",
            "[Epoch 0/200] [Batch 453/938] [D loss: 0.696999] [G loss: 0.915823]\n",
            "[Epoch 0/200] [Batch 454/938] [D loss: 0.698689] [G loss: 0.916537]\n",
            "[Epoch 0/200] [Batch 455/938] [D loss: 0.695062] [G loss: 0.918214]\n",
            "[Epoch 0/200] [Batch 456/938] [D loss: 0.692657] [G loss: 0.918360]\n",
            "[Epoch 0/200] [Batch 457/938] [D loss: 0.693724] [G loss: 0.918028]\n",
            "[Epoch 0/200] [Batch 458/938] [D loss: 0.692019] [G loss: 0.916896]\n",
            "[Epoch 0/200] [Batch 459/938] [D loss: 0.695050] [G loss: 0.911378]\n",
            "[Epoch 0/200] [Batch 460/938] [D loss: 0.703187] [G loss: 0.914726]\n",
            "[Epoch 0/200] [Batch 461/938] [D loss: 0.698504] [G loss: 0.918182]\n",
            "[Epoch 0/200] [Batch 462/938] [D loss: 0.691480] [G loss: 0.913069]\n",
            "[Epoch 0/200] [Batch 463/938] [D loss: 0.695546] [G loss: 0.911515]\n",
            "[Epoch 0/200] [Batch 464/938] [D loss: 0.699419] [G loss: 0.918480]\n",
            "[Epoch 0/200] [Batch 465/938] [D loss: 0.699453] [G loss: 0.913946]\n",
            "[Epoch 0/200] [Batch 466/938] [D loss: 0.693828] [G loss: 0.912339]\n",
            "[Epoch 0/200] [Batch 467/938] [D loss: 0.691647] [G loss: 0.918458]\n",
            "[Epoch 0/200] [Batch 468/938] [D loss: 0.702613] [G loss: 0.911928]\n",
            "[Epoch 0/200] [Batch 469/938] [D loss: 0.693013] [G loss: 0.916100]\n",
            "[Epoch 0/200] [Batch 470/938] [D loss: 0.696484] [G loss: 0.917081]\n",
            "[Epoch 0/200] [Batch 471/938] [D loss: 0.691996] [G loss: 0.916958]\n",
            "[Epoch 0/200] [Batch 472/938] [D loss: 0.691222] [G loss: 0.911969]\n",
            "[Epoch 0/200] [Batch 473/938] [D loss: 0.698361] [G loss: 0.920044]\n",
            "[Epoch 0/200] [Batch 474/938] [D loss: 0.695831] [G loss: 0.915045]\n",
            "[Epoch 0/200] [Batch 475/938] [D loss: 0.691910] [G loss: 0.915555]\n",
            "[Epoch 0/200] [Batch 476/938] [D loss: 0.691013] [G loss: 0.909291]\n",
            "[Epoch 0/200] [Batch 477/938] [D loss: 0.695155] [G loss: 0.912943]\n",
            "[Epoch 0/200] [Batch 478/938] [D loss: 0.694239] [G loss: 0.914811]\n",
            "[Epoch 0/200] [Batch 479/938] [D loss: 0.696336] [G loss: 0.912293]\n",
            "[Epoch 0/200] [Batch 480/938] [D loss: 0.698270] [G loss: 0.911905]\n",
            "[Epoch 0/200] [Batch 481/938] [D loss: 0.697064] [G loss: 0.914470]\n",
            "[Epoch 0/200] [Batch 482/938] [D loss: 0.703056] [G loss: 0.916287]\n",
            "[Epoch 0/200] [Batch 483/938] [D loss: 0.697530] [G loss: 0.915014]\n",
            "[Epoch 0/200] [Batch 484/938] [D loss: 0.690633] [G loss: 0.912640]\n",
            "[Epoch 0/200] [Batch 485/938] [D loss: 0.701556] [G loss: 0.912595]\n",
            "[Epoch 0/200] [Batch 486/938] [D loss: 0.697460] [G loss: 0.912941]\n",
            "[Epoch 0/200] [Batch 487/938] [D loss: 0.692831] [G loss: 0.915906]\n",
            "[Epoch 0/200] [Batch 488/938] [D loss: 0.698214] [G loss: 0.915218]\n",
            "[Epoch 0/200] [Batch 489/938] [D loss: 0.695230] [G loss: 0.914879]\n",
            "[Epoch 0/200] [Batch 490/938] [D loss: 0.693819] [G loss: 0.911741]\n",
            "[Epoch 0/200] [Batch 491/938] [D loss: 0.696806] [G loss: 0.915055]\n",
            "[Epoch 0/200] [Batch 492/938] [D loss: 0.694372] [G loss: 0.915059]\n",
            "[Epoch 0/200] [Batch 493/938] [D loss: 0.698971] [G loss: 0.920421]\n",
            "[Epoch 0/200] [Batch 494/938] [D loss: 0.695876] [G loss: 0.909480]\n",
            "[Epoch 0/200] [Batch 495/938] [D loss: 0.692056] [G loss: 0.917647]\n",
            "[Epoch 0/200] [Batch 496/938] [D loss: 0.697153] [G loss: 0.915319]\n",
            "[Epoch 0/200] [Batch 497/938] [D loss: 0.698282] [G loss: 0.913258]\n",
            "[Epoch 0/200] [Batch 498/938] [D loss: 0.697515] [G loss: 0.914081]\n",
            "[Epoch 0/200] [Batch 499/938] [D loss: 0.690052] [G loss: 0.911480]\n",
            "[Epoch 0/200] [Batch 500/938] [D loss: 0.691218] [G loss: 0.914231]\n",
            "[Epoch 0/200] [Batch 501/938] [D loss: 0.693184] [G loss: 0.915174]\n",
            "[Epoch 0/200] [Batch 502/938] [D loss: 0.703071] [G loss: 0.914667]\n",
            "[Epoch 0/200] [Batch 503/938] [D loss: 0.694682] [G loss: 0.918486]\n",
            "[Epoch 0/200] [Batch 504/938] [D loss: 0.693657] [G loss: 0.918331]\n",
            "[Epoch 0/200] [Batch 505/938] [D loss: 0.690395] [G loss: 0.912678]\n",
            "[Epoch 0/200] [Batch 506/938] [D loss: 0.700069] [G loss: 0.918248]\n",
            "[Epoch 0/200] [Batch 507/938] [D loss: 0.699396] [G loss: 0.914447]\n",
            "[Epoch 0/200] [Batch 508/938] [D loss: 0.695287] [G loss: 0.919805]\n",
            "[Epoch 0/200] [Batch 509/938] [D loss: 0.698797] [G loss: 0.913671]\n",
            "[Epoch 0/200] [Batch 510/938] [D loss: 0.697827] [G loss: 0.914116]\n",
            "[Epoch 0/200] [Batch 511/938] [D loss: 0.693884] [G loss: 0.913777]\n",
            "[Epoch 0/200] [Batch 512/938] [D loss: 0.694000] [G loss: 0.915844]\n",
            "[Epoch 0/200] [Batch 513/938] [D loss: 0.700700] [G loss: 0.914605]\n",
            "[Epoch 0/200] [Batch 514/938] [D loss: 0.692894] [G loss: 0.917625]\n",
            "[Epoch 0/200] [Batch 515/938] [D loss: 0.698799] [G loss: 0.917084]\n",
            "[Epoch 0/200] [Batch 516/938] [D loss: 0.700514] [G loss: 0.912658]\n",
            "[Epoch 0/200] [Batch 517/938] [D loss: 0.696296] [G loss: 0.916567]\n",
            "[Epoch 0/200] [Batch 518/938] [D loss: 0.695117] [G loss: 0.918781]\n",
            "[Epoch 0/200] [Batch 519/938] [D loss: 0.702345] [G loss: 0.913399]\n",
            "[Epoch 0/200] [Batch 520/938] [D loss: 0.701383] [G loss: 0.914092]\n",
            "[Epoch 0/200] [Batch 521/938] [D loss: 0.689440] [G loss: 0.917430]\n",
            "[Epoch 0/200] [Batch 522/938] [D loss: 0.690872] [G loss: 0.914388]\n",
            "[Epoch 0/200] [Batch 523/938] [D loss: 0.692798] [G loss: 0.916833]\n",
            "[Epoch 0/200] [Batch 524/938] [D loss: 0.695162] [G loss: 0.919455]\n",
            "[Epoch 0/200] [Batch 525/938] [D loss: 0.699088] [G loss: 0.916073]\n",
            "[Epoch 0/200] [Batch 526/938] [D loss: 0.699234] [G loss: 0.914713]\n",
            "[Epoch 0/200] [Batch 527/938] [D loss: 0.693462] [G loss: 0.918111]\n",
            "[Epoch 0/200] [Batch 528/938] [D loss: 0.694483] [G loss: 0.911977]\n",
            "[Epoch 0/200] [Batch 529/938] [D loss: 0.693792] [G loss: 0.918598]\n",
            "[Epoch 0/200] [Batch 530/938] [D loss: 0.695358] [G loss: 0.918716]\n",
            "[Epoch 0/200] [Batch 531/938] [D loss: 0.696131] [G loss: 0.914628]\n",
            "[Epoch 0/200] [Batch 532/938] [D loss: 0.693235] [G loss: 0.915683]\n",
            "[Epoch 0/200] [Batch 533/938] [D loss: 0.694206] [G loss: 0.913531]\n",
            "[Epoch 0/200] [Batch 534/938] [D loss: 0.691322] [G loss: 0.914280]\n",
            "[Epoch 0/200] [Batch 535/938] [D loss: 0.698762] [G loss: 0.911729]\n",
            "[Epoch 0/200] [Batch 536/938] [D loss: 0.697283] [G loss: 0.918960]\n",
            "[Epoch 0/200] [Batch 537/938] [D loss: 0.687170] [G loss: 0.912090]\n",
            "[Epoch 0/200] [Batch 538/938] [D loss: 0.693255] [G loss: 0.913895]\n",
            "[Epoch 0/200] [Batch 539/938] [D loss: 0.693828] [G loss: 0.916535]\n",
            "[Epoch 0/200] [Batch 540/938] [D loss: 0.701514] [G loss: 0.914101]\n",
            "[Epoch 0/200] [Batch 541/938] [D loss: 0.691141] [G loss: 0.916723]\n",
            "[Epoch 0/200] [Batch 542/938] [D loss: 0.700658] [G loss: 0.917992]\n",
            "[Epoch 0/200] [Batch 543/938] [D loss: 0.695241] [G loss: 0.917961]\n",
            "[Epoch 0/200] [Batch 544/938] [D loss: 0.696287] [G loss: 0.910433]\n",
            "[Epoch 0/200] [Batch 545/938] [D loss: 0.693904] [G loss: 0.916724]\n",
            "[Epoch 0/200] [Batch 546/938] [D loss: 0.697094] [G loss: 0.916057]\n",
            "[Epoch 0/200] [Batch 547/938] [D loss: 0.692858] [G loss: 0.915641]\n",
            "[Epoch 0/200] [Batch 548/938] [D loss: 0.690592] [G loss: 0.916490]\n",
            "[Epoch 0/200] [Batch 549/938] [D loss: 0.695367] [G loss: 0.915042]\n",
            "[Epoch 0/200] [Batch 550/938] [D loss: 0.696483] [G loss: 0.911106]\n",
            "[Epoch 0/200] [Batch 551/938] [D loss: 0.693054] [G loss: 0.915224]\n",
            "[Epoch 0/200] [Batch 552/938] [D loss: 0.699880] [G loss: 0.915629]\n",
            "[Epoch 0/200] [Batch 553/938] [D loss: 0.697602] [G loss: 0.915482]\n",
            "[Epoch 0/200] [Batch 554/938] [D loss: 0.694186] [G loss: 0.916004]\n",
            "[Epoch 0/200] [Batch 555/938] [D loss: 0.692832] [G loss: 0.912300]\n",
            "[Epoch 0/200] [Batch 556/938] [D loss: 0.693622] [G loss: 0.912932]\n",
            "[Epoch 0/200] [Batch 557/938] [D loss: 0.694186] [G loss: 0.916951]\n",
            "[Epoch 0/200] [Batch 558/938] [D loss: 0.700853] [G loss: 0.916336]\n",
            "[Epoch 0/200] [Batch 559/938] [D loss: 0.693029] [G loss: 0.915429]\n",
            "[Epoch 0/200] [Batch 560/938] [D loss: 0.693811] [G loss: 0.919010]\n",
            "[Epoch 0/200] [Batch 561/938] [D loss: 0.704042] [G loss: 0.914050]\n",
            "[Epoch 0/200] [Batch 562/938] [D loss: 0.689341] [G loss: 0.918022]\n",
            "[Epoch 0/200] [Batch 563/938] [D loss: 0.697232] [G loss: 0.916292]\n",
            "[Epoch 0/200] [Batch 564/938] [D loss: 0.698087] [G loss: 0.915851]\n",
            "[Epoch 0/200] [Batch 565/938] [D loss: 0.695337] [G loss: 0.914248]\n",
            "[Epoch 0/200] [Batch 566/938] [D loss: 0.683794] [G loss: 0.917563]\n",
            "[Epoch 0/200] [Batch 567/938] [D loss: 0.689484] [G loss: 0.917571]\n",
            "[Epoch 0/200] [Batch 568/938] [D loss: 0.694558] [G loss: 0.917070]\n",
            "[Epoch 0/200] [Batch 569/938] [D loss: 0.696751] [G loss: 0.917203]\n",
            "[Epoch 0/200] [Batch 570/938] [D loss: 0.695287] [G loss: 0.917405]\n",
            "[Epoch 0/200] [Batch 571/938] [D loss: 0.692626] [G loss: 0.917328]\n",
            "[Epoch 0/200] [Batch 572/938] [D loss: 0.693092] [G loss: 0.911108]\n",
            "[Epoch 0/200] [Batch 573/938] [D loss: 0.701071] [G loss: 0.914357]\n",
            "[Epoch 0/200] [Batch 574/938] [D loss: 0.694950] [G loss: 0.914621]\n",
            "[Epoch 0/200] [Batch 575/938] [D loss: 0.697032] [G loss: 0.913763]\n",
            "[Epoch 0/200] [Batch 576/938] [D loss: 0.692889] [G loss: 0.912094]\n",
            "[Epoch 0/200] [Batch 577/938] [D loss: 0.695570] [G loss: 0.914770]\n",
            "[Epoch 0/200] [Batch 578/938] [D loss: 0.696272] [G loss: 0.907670]\n",
            "[Epoch 0/200] [Batch 579/938] [D loss: 0.694721] [G loss: 0.912184]\n",
            "[Epoch 0/200] [Batch 580/938] [D loss: 0.695703] [G loss: 0.912782]\n",
            "[Epoch 0/200] [Batch 581/938] [D loss: 0.689897] [G loss: 0.917411]\n",
            "[Epoch 0/200] [Batch 582/938] [D loss: 0.694346] [G loss: 0.913659]\n",
            "[Epoch 0/200] [Batch 583/938] [D loss: 0.691603] [G loss: 0.917658]\n",
            "[Epoch 0/200] [Batch 584/938] [D loss: 0.698475] [G loss: 0.918362]\n",
            "[Epoch 0/200] [Batch 585/938] [D loss: 0.695777] [G loss: 0.912456]\n",
            "[Epoch 0/200] [Batch 586/938] [D loss: 0.695192] [G loss: 0.917024]\n",
            "[Epoch 0/200] [Batch 587/938] [D loss: 0.690900] [G loss: 0.911663]\n",
            "[Epoch 0/200] [Batch 588/938] [D loss: 0.694623] [G loss: 0.914191]\n",
            "[Epoch 0/200] [Batch 589/938] [D loss: 0.696448] [G loss: 0.916505]\n",
            "[Epoch 0/200] [Batch 590/938] [D loss: 0.693801] [G loss: 0.920403]\n",
            "[Epoch 0/200] [Batch 591/938] [D loss: 0.696795] [G loss: 0.915686]\n",
            "[Epoch 0/200] [Batch 592/938] [D loss: 0.694067] [G loss: 0.914511]\n",
            "[Epoch 0/200] [Batch 593/938] [D loss: 0.698730] [G loss: 0.915866]\n",
            "[Epoch 0/200] [Batch 594/938] [D loss: 0.700519] [G loss: 0.910257]\n",
            "[Epoch 0/200] [Batch 595/938] [D loss: 0.698449] [G loss: 0.918100]\n",
            "[Epoch 0/200] [Batch 596/938] [D loss: 0.689580] [G loss: 0.916749]\n",
            "[Epoch 0/200] [Batch 597/938] [D loss: 0.691294] [G loss: 0.916406]\n",
            "[Epoch 0/200] [Batch 598/938] [D loss: 0.695321] [G loss: 0.918194]\n",
            "[Epoch 0/200] [Batch 599/938] [D loss: 0.691557] [G loss: 0.911969]\n",
            "[Epoch 0/200] [Batch 600/938] [D loss: 0.700015] [G loss: 0.915679]\n",
            "[Epoch 0/200] [Batch 601/938] [D loss: 0.694271] [G loss: 0.915515]\n",
            "[Epoch 0/200] [Batch 602/938] [D loss: 0.697080] [G loss: 0.914050]\n",
            "[Epoch 0/200] [Batch 603/938] [D loss: 0.696020] [G loss: 0.912846]\n",
            "[Epoch 0/200] [Batch 604/938] [D loss: 0.697471] [G loss: 0.917534]\n",
            "[Epoch 0/200] [Batch 605/938] [D loss: 0.697257] [G loss: 0.910615]\n",
            "[Epoch 0/200] [Batch 606/938] [D loss: 0.698303] [G loss: 0.913718]\n",
            "[Epoch 0/200] [Batch 607/938] [D loss: 0.696854] [G loss: 0.914086]\n",
            "[Epoch 0/200] [Batch 608/938] [D loss: 0.695842] [G loss: 0.911202]\n",
            "[Epoch 0/200] [Batch 609/938] [D loss: 0.696819] [G loss: 0.919731]\n",
            "[Epoch 0/200] [Batch 610/938] [D loss: 0.694112] [G loss: 0.912369]\n",
            "[Epoch 0/200] [Batch 611/938] [D loss: 0.695719] [G loss: 0.916121]\n",
            "[Epoch 0/200] [Batch 612/938] [D loss: 0.700526] [G loss: 0.915270]\n",
            "[Epoch 0/200] [Batch 613/938] [D loss: 0.699854] [G loss: 0.918187]\n",
            "[Epoch 0/200] [Batch 614/938] [D loss: 0.692246] [G loss: 0.912847]\n",
            "[Epoch 0/200] [Batch 615/938] [D loss: 0.692277] [G loss: 0.916128]\n",
            "[Epoch 0/200] [Batch 616/938] [D loss: 0.692353] [G loss: 0.914859]\n",
            "[Epoch 0/200] [Batch 617/938] [D loss: 0.693457] [G loss: 0.916466]\n",
            "[Epoch 0/200] [Batch 618/938] [D loss: 0.692451] [G loss: 0.913309]\n",
            "[Epoch 0/200] [Batch 619/938] [D loss: 0.695295] [G loss: 0.914080]\n",
            "[Epoch 0/200] [Batch 620/938] [D loss: 0.694441] [G loss: 0.917340]\n",
            "[Epoch 0/200] [Batch 621/938] [D loss: 0.696862] [G loss: 0.920822]\n",
            "[Epoch 0/200] [Batch 622/938] [D loss: 0.702168] [G loss: 0.916529]\n",
            "[Epoch 0/200] [Batch 623/938] [D loss: 0.698311] [G loss: 0.913341]\n",
            "[Epoch 0/200] [Batch 624/938] [D loss: 0.691624] [G loss: 0.917395]\n",
            "[Epoch 0/200] [Batch 625/938] [D loss: 0.692229] [G loss: 0.916222]\n",
            "[Epoch 0/200] [Batch 626/938] [D loss: 0.696704] [G loss: 0.912845]\n",
            "[Epoch 0/200] [Batch 627/938] [D loss: 0.692236] [G loss: 0.915503]\n",
            "[Epoch 0/200] [Batch 628/938] [D loss: 0.694018] [G loss: 0.913803]\n",
            "[Epoch 0/200] [Batch 629/938] [D loss: 0.699645] [G loss: 0.910360]\n",
            "[Epoch 0/200] [Batch 630/938] [D loss: 0.699716] [G loss: 0.916773]\n",
            "[Epoch 0/200] [Batch 631/938] [D loss: 0.692749] [G loss: 0.915407]\n",
            "[Epoch 0/200] [Batch 632/938] [D loss: 0.689711] [G loss: 0.912764]\n",
            "[Epoch 0/200] [Batch 633/938] [D loss: 0.698991] [G loss: 0.917880]\n",
            "[Epoch 0/200] [Batch 634/938] [D loss: 0.699532] [G loss: 0.913998]\n",
            "[Epoch 0/200] [Batch 635/938] [D loss: 0.697368] [G loss: 0.916909]\n",
            "[Epoch 0/200] [Batch 636/938] [D loss: 0.698786] [G loss: 0.917485]\n",
            "[Epoch 0/200] [Batch 637/938] [D loss: 0.696050] [G loss: 0.918174]\n",
            "[Epoch 0/200] [Batch 638/938] [D loss: 0.696867] [G loss: 0.917016]\n",
            "[Epoch 0/200] [Batch 639/938] [D loss: 0.701708] [G loss: 0.916605]\n",
            "[Epoch 0/200] [Batch 640/938] [D loss: 0.695656] [G loss: 0.914673]\n",
            "[Epoch 0/200] [Batch 641/938] [D loss: 0.694322] [G loss: 0.910357]\n",
            "[Epoch 0/200] [Batch 642/938] [D loss: 0.689169] [G loss: 0.915779]\n",
            "[Epoch 0/200] [Batch 643/938] [D loss: 0.690659] [G loss: 0.921519]\n",
            "[Epoch 0/200] [Batch 644/938] [D loss: 0.694044] [G loss: 0.916492]\n",
            "[Epoch 0/200] [Batch 645/938] [D loss: 0.690349] [G loss: 0.914808]\n",
            "[Epoch 0/200] [Batch 646/938] [D loss: 0.695173] [G loss: 0.915527]\n",
            "[Epoch 0/200] [Batch 647/938] [D loss: 0.699105] [G loss: 0.915558]\n",
            "[Epoch 0/200] [Batch 648/938] [D loss: 0.699697] [G loss: 0.914980]\n",
            "[Epoch 0/200] [Batch 649/938] [D loss: 0.691597] [G loss: 0.917479]\n",
            "[Epoch 0/200] [Batch 650/938] [D loss: 0.703375] [G loss: 0.918158]\n",
            "[Epoch 0/200] [Batch 651/938] [D loss: 0.695717] [G loss: 0.911439]\n",
            "[Epoch 0/200] [Batch 652/938] [D loss: 0.696787] [G loss: 0.912662]\n",
            "[Epoch 0/200] [Batch 653/938] [D loss: 0.702352] [G loss: 0.918711]\n",
            "[Epoch 0/200] [Batch 654/938] [D loss: 0.696782] [G loss: 0.915690]\n",
            "[Epoch 0/200] [Batch 655/938] [D loss: 0.698633] [G loss: 0.907031]\n",
            "[Epoch 0/200] [Batch 656/938] [D loss: 0.696430] [G loss: 0.914711]\n",
            "[Epoch 0/200] [Batch 657/938] [D loss: 0.694320] [G loss: 0.917870]\n",
            "[Epoch 0/200] [Batch 658/938] [D loss: 0.694297] [G loss: 0.914292]\n",
            "[Epoch 0/200] [Batch 659/938] [D loss: 0.692068] [G loss: 0.910716]\n",
            "[Epoch 0/200] [Batch 660/938] [D loss: 0.694926] [G loss: 0.919601]\n",
            "[Epoch 0/200] [Batch 661/938] [D loss: 0.691364] [G loss: 0.916040]\n",
            "[Epoch 0/200] [Batch 662/938] [D loss: 0.704013] [G loss: 0.911868]\n",
            "[Epoch 0/200] [Batch 663/938] [D loss: 0.692320] [G loss: 0.918902]\n",
            "[Epoch 0/200] [Batch 664/938] [D loss: 0.695816] [G loss: 0.909683]\n",
            "[Epoch 0/200] [Batch 665/938] [D loss: 0.693761] [G loss: 0.914670]\n",
            "[Epoch 0/200] [Batch 666/938] [D loss: 0.694945] [G loss: 0.914922]\n",
            "[Epoch 0/200] [Batch 667/938] [D loss: 0.697354] [G loss: 0.914496]\n",
            "[Epoch 0/200] [Batch 668/938] [D loss: 0.696102] [G loss: 0.912722]\n",
            "[Epoch 0/200] [Batch 669/938] [D loss: 0.696432] [G loss: 0.913298]\n",
            "[Epoch 0/200] [Batch 670/938] [D loss: 0.697065] [G loss: 0.916904]\n",
            "[Epoch 0/200] [Batch 671/938] [D loss: 0.697850] [G loss: 0.917539]\n",
            "[Epoch 0/200] [Batch 672/938] [D loss: 0.692113] [G loss: 0.916442]\n",
            "[Epoch 0/200] [Batch 673/938] [D loss: 0.694849] [G loss: 0.914329]\n",
            "[Epoch 0/200] [Batch 674/938] [D loss: 0.697078] [G loss: 0.913922]\n",
            "[Epoch 0/200] [Batch 675/938] [D loss: 0.693485] [G loss: 0.914844]\n",
            "[Epoch 0/200] [Batch 676/938] [D loss: 0.695481] [G loss: 0.914092]\n",
            "[Epoch 0/200] [Batch 677/938] [D loss: 0.693302] [G loss: 0.916129]\n",
            "[Epoch 0/200] [Batch 678/938] [D loss: 0.699362] [G loss: 0.914440]\n",
            "[Epoch 0/200] [Batch 679/938] [D loss: 0.696598] [G loss: 0.915204]\n",
            "[Epoch 0/200] [Batch 680/938] [D loss: 0.692964] [G loss: 0.916929]\n",
            "[Epoch 0/200] [Batch 681/938] [D loss: 0.691264] [G loss: 0.916276]\n",
            "[Epoch 0/200] [Batch 682/938] [D loss: 0.692349] [G loss: 0.915638]\n",
            "[Epoch 0/200] [Batch 683/938] [D loss: 0.693534] [G loss: 0.912315]\n",
            "[Epoch 0/200] [Batch 684/938] [D loss: 0.693326] [G loss: 0.919183]\n",
            "[Epoch 0/200] [Batch 685/938] [D loss: 0.689811] [G loss: 0.913725]\n",
            "[Epoch 0/200] [Batch 686/938] [D loss: 0.696010] [G loss: 0.915853]\n",
            "[Epoch 0/200] [Batch 687/938] [D loss: 0.705725] [G loss: 0.916764]\n",
            "[Epoch 0/200] [Batch 688/938] [D loss: 0.695865] [G loss: 0.914851]\n",
            "[Epoch 0/200] [Batch 689/938] [D loss: 0.689698] [G loss: 0.912657]\n",
            "[Epoch 0/200] [Batch 690/938] [D loss: 0.695803] [G loss: 0.915301]\n",
            "[Epoch 0/200] [Batch 691/938] [D loss: 0.692004] [G loss: 0.911799]\n",
            "[Epoch 0/200] [Batch 692/938] [D loss: 0.690652] [G loss: 0.913895]\n",
            "[Epoch 0/200] [Batch 693/938] [D loss: 0.693450] [G loss: 0.910973]\n",
            "[Epoch 0/200] [Batch 694/938] [D loss: 0.693016] [G loss: 0.913063]\n",
            "[Epoch 0/200] [Batch 695/938] [D loss: 0.694679] [G loss: 0.911619]\n",
            "[Epoch 0/200] [Batch 696/938] [D loss: 0.695228] [G loss: 0.914619]\n",
            "[Epoch 0/200] [Batch 697/938] [D loss: 0.696402] [G loss: 0.915848]\n",
            "[Epoch 0/200] [Batch 698/938] [D loss: 0.694259] [G loss: 0.914114]\n",
            "[Epoch 0/200] [Batch 699/938] [D loss: 0.696196] [G loss: 0.913258]\n",
            "[Epoch 0/200] [Batch 700/938] [D loss: 0.691895] [G loss: 0.913495]\n",
            "[Epoch 0/200] [Batch 701/938] [D loss: 0.698878] [G loss: 0.917504]\n",
            "[Epoch 0/200] [Batch 702/938] [D loss: 0.697369] [G loss: 0.914214]\n",
            "[Epoch 0/200] [Batch 703/938] [D loss: 0.695479] [G loss: 0.916897]\n",
            "[Epoch 0/200] [Batch 704/938] [D loss: 0.693336] [G loss: 0.915740]\n",
            "[Epoch 0/200] [Batch 705/938] [D loss: 0.692504] [G loss: 0.913988]\n",
            "[Epoch 0/200] [Batch 706/938] [D loss: 0.692486] [G loss: 0.914096]\n",
            "[Epoch 0/200] [Batch 707/938] [D loss: 0.701515] [G loss: 0.912215]\n",
            "[Epoch 0/200] [Batch 708/938] [D loss: 0.697464] [G loss: 0.910990]\n",
            "[Epoch 0/200] [Batch 709/938] [D loss: 0.696670] [G loss: 0.915836]\n",
            "[Epoch 0/200] [Batch 710/938] [D loss: 0.695268] [G loss: 0.921468]\n",
            "[Epoch 0/200] [Batch 711/938] [D loss: 0.698891] [G loss: 0.916032]\n",
            "[Epoch 0/200] [Batch 712/938] [D loss: 0.696504] [G loss: 0.915389]\n",
            "[Epoch 0/200] [Batch 713/938] [D loss: 0.701962] [G loss: 0.912872]\n",
            "[Epoch 0/200] [Batch 714/938] [D loss: 0.698972] [G loss: 0.914093]\n",
            "[Epoch 0/200] [Batch 715/938] [D loss: 0.696891] [G loss: 0.913480]\n",
            "[Epoch 0/200] [Batch 716/938] [D loss: 0.691461] [G loss: 0.915586]\n",
            "[Epoch 0/200] [Batch 717/938] [D loss: 0.696778] [G loss: 0.914984]\n",
            "[Epoch 0/200] [Batch 718/938] [D loss: 0.694731] [G loss: 0.916668]\n",
            "[Epoch 0/200] [Batch 719/938] [D loss: 0.696656] [G loss: 0.918110]\n",
            "[Epoch 0/200] [Batch 720/938] [D loss: 0.693488] [G loss: 0.917205]\n",
            "[Epoch 0/200] [Batch 721/938] [D loss: 0.695933] [G loss: 0.917160]\n",
            "[Epoch 0/200] [Batch 722/938] [D loss: 0.695342] [G loss: 0.914524]\n",
            "[Epoch 0/200] [Batch 723/938] [D loss: 0.693216] [G loss: 0.915283]\n",
            "[Epoch 0/200] [Batch 724/938] [D loss: 0.691207] [G loss: 0.916776]\n",
            "[Epoch 0/200] [Batch 725/938] [D loss: 0.699510] [G loss: 0.912259]\n",
            "[Epoch 0/200] [Batch 726/938] [D loss: 0.694625] [G loss: 0.914467]\n",
            "[Epoch 0/200] [Batch 727/938] [D loss: 0.698159] [G loss: 0.913046]\n",
            "[Epoch 0/200] [Batch 728/938] [D loss: 0.697931] [G loss: 0.916936]\n",
            "[Epoch 0/200] [Batch 729/938] [D loss: 0.697669] [G loss: 0.910748]\n",
            "[Epoch 0/200] [Batch 730/938] [D loss: 0.696651] [G loss: 0.913471]\n",
            "[Epoch 0/200] [Batch 731/938] [D loss: 0.693557] [G loss: 0.917331]\n",
            "[Epoch 0/200] [Batch 732/938] [D loss: 0.693574] [G loss: 0.917612]\n",
            "[Epoch 0/200] [Batch 733/938] [D loss: 0.693954] [G loss: 0.916539]\n",
            "[Epoch 0/200] [Batch 734/938] [D loss: 0.694838] [G loss: 0.913683]\n",
            "[Epoch 0/200] [Batch 735/938] [D loss: 0.697909] [G loss: 0.912675]\n",
            "[Epoch 0/200] [Batch 736/938] [D loss: 0.693876] [G loss: 0.917918]\n",
            "[Epoch 0/200] [Batch 737/938] [D loss: 0.695321] [G loss: 0.916649]\n",
            "[Epoch 0/200] [Batch 738/938] [D loss: 0.694966] [G loss: 0.912565]\n",
            "[Epoch 0/200] [Batch 739/938] [D loss: 0.694797] [G loss: 0.913343]\n",
            "[Epoch 0/200] [Batch 740/938] [D loss: 0.695707] [G loss: 0.917885]\n",
            "[Epoch 0/200] [Batch 741/938] [D loss: 0.695983] [G loss: 0.914447]\n",
            "[Epoch 0/200] [Batch 742/938] [D loss: 0.692718] [G loss: 0.918304]\n",
            "[Epoch 0/200] [Batch 743/938] [D loss: 0.695422] [G loss: 0.915602]\n",
            "[Epoch 0/200] [Batch 744/938] [D loss: 0.697156] [G loss: 0.912818]\n",
            "[Epoch 0/200] [Batch 745/938] [D loss: 0.692449] [G loss: 0.916243]\n",
            "[Epoch 0/200] [Batch 746/938] [D loss: 0.694163] [G loss: 0.916917]\n",
            "[Epoch 0/200] [Batch 747/938] [D loss: 0.698217] [G loss: 0.914487]\n",
            "[Epoch 0/200] [Batch 748/938] [D loss: 0.697419] [G loss: 0.916248]\n",
            "[Epoch 0/200] [Batch 749/938] [D loss: 0.693245] [G loss: 0.911938]\n",
            "[Epoch 0/200] [Batch 750/938] [D loss: 0.698645] [G loss: 0.915742]\n",
            "[Epoch 0/200] [Batch 751/938] [D loss: 0.703865] [G loss: 0.918912]\n",
            "[Epoch 0/200] [Batch 752/938] [D loss: 0.694334] [G loss: 0.919162]\n",
            "[Epoch 0/200] [Batch 753/938] [D loss: 0.697331] [G loss: 0.917376]\n",
            "[Epoch 0/200] [Batch 754/938] [D loss: 0.692198] [G loss: 0.915274]\n",
            "[Epoch 0/200] [Batch 755/938] [D loss: 0.692506] [G loss: 0.910298]\n",
            "[Epoch 0/200] [Batch 756/938] [D loss: 0.696115] [G loss: 0.914997]\n",
            "[Epoch 0/200] [Batch 757/938] [D loss: 0.694316] [G loss: 0.912999]\n",
            "[Epoch 0/200] [Batch 758/938] [D loss: 0.693160] [G loss: 0.914657]\n",
            "[Epoch 0/200] [Batch 759/938] [D loss: 0.693170] [G loss: 0.914528]\n",
            "[Epoch 0/200] [Batch 760/938] [D loss: 0.696949] [G loss: 0.915835]\n",
            "[Epoch 0/200] [Batch 761/938] [D loss: 0.690900] [G loss: 0.913488]\n",
            "[Epoch 0/200] [Batch 762/938] [D loss: 0.694194] [G loss: 0.913220]\n",
            "[Epoch 0/200] [Batch 763/938] [D loss: 0.689076] [G loss: 0.913381]\n",
            "[Epoch 0/200] [Batch 764/938] [D loss: 0.696238] [G loss: 0.912104]\n",
            "[Epoch 0/200] [Batch 765/938] [D loss: 0.688909] [G loss: 0.915393]\n",
            "[Epoch 0/200] [Batch 766/938] [D loss: 0.694447] [G loss: 0.913814]\n",
            "[Epoch 0/200] [Batch 767/938] [D loss: 0.695996] [G loss: 0.919177]\n",
            "[Epoch 0/200] [Batch 768/938] [D loss: 0.698051] [G loss: 0.908230]\n",
            "[Epoch 0/200] [Batch 769/938] [D loss: 0.699629] [G loss: 0.914046]\n",
            "[Epoch 0/200] [Batch 770/938] [D loss: 0.695132] [G loss: 0.916257]\n",
            "[Epoch 0/200] [Batch 771/938] [D loss: 0.690654] [G loss: 0.912889]\n",
            "[Epoch 0/200] [Batch 772/938] [D loss: 0.696711] [G loss: 0.912255]\n",
            "[Epoch 0/200] [Batch 773/938] [D loss: 0.692042] [G loss: 0.913816]\n",
            "[Epoch 0/200] [Batch 774/938] [D loss: 0.696824] [G loss: 0.917736]\n",
            "[Epoch 0/200] [Batch 775/938] [D loss: 0.689886] [G loss: 0.916603]\n",
            "[Epoch 0/200] [Batch 776/938] [D loss: 0.696289] [G loss: 0.915992]\n",
            "[Epoch 0/200] [Batch 777/938] [D loss: 0.695329] [G loss: 0.914529]\n",
            "[Epoch 0/200] [Batch 778/938] [D loss: 0.697327] [G loss: 0.918356]\n",
            "[Epoch 0/200] [Batch 779/938] [D loss: 0.692363] [G loss: 0.913041]\n",
            "[Epoch 0/200] [Batch 780/938] [D loss: 0.700140] [G loss: 0.916587]\n",
            "[Epoch 0/200] [Batch 781/938] [D loss: 0.693331] [G loss: 0.912290]\n",
            "[Epoch 0/200] [Batch 782/938] [D loss: 0.695978] [G loss: 0.913132]\n",
            "[Epoch 0/200] [Batch 783/938] [D loss: 0.696543] [G loss: 0.916196]\n",
            "[Epoch 0/200] [Batch 784/938] [D loss: 0.699939] [G loss: 0.917020]\n",
            "[Epoch 0/200] [Batch 785/938] [D loss: 0.697864] [G loss: 0.916089]\n",
            "[Epoch 0/200] [Batch 786/938] [D loss: 0.693391] [G loss: 0.917375]\n",
            "[Epoch 0/200] [Batch 787/938] [D loss: 0.696088] [G loss: 0.912512]\n",
            "[Epoch 0/200] [Batch 788/938] [D loss: 0.692784] [G loss: 0.915264]\n",
            "[Epoch 0/200] [Batch 789/938] [D loss: 0.690247] [G loss: 0.915409]\n",
            "[Epoch 0/200] [Batch 790/938] [D loss: 0.694916] [G loss: 0.916896]\n",
            "[Epoch 0/200] [Batch 791/938] [D loss: 0.689501] [G loss: 0.910831]\n",
            "[Epoch 0/200] [Batch 792/938] [D loss: 0.698306] [G loss: 0.916682]\n",
            "[Epoch 0/200] [Batch 793/938] [D loss: 0.701382] [G loss: 0.916633]\n",
            "[Epoch 0/200] [Batch 794/938] [D loss: 0.700755] [G loss: 0.915265]\n",
            "[Epoch 0/200] [Batch 795/938] [D loss: 0.695179] [G loss: 0.916868]\n",
            "[Epoch 0/200] [Batch 796/938] [D loss: 0.693587] [G loss: 0.921552]\n",
            "[Epoch 0/200] [Batch 797/938] [D loss: 0.694409] [G loss: 0.914328]\n",
            "[Epoch 0/200] [Batch 798/938] [D loss: 0.703882] [G loss: 0.916802]\n",
            "[Epoch 0/200] [Batch 799/938] [D loss: 0.694574] [G loss: 0.917207]\n",
            "[Epoch 0/200] [Batch 800/938] [D loss: 0.699311] [G loss: 0.916377]\n",
            "[Epoch 0/200] [Batch 801/938] [D loss: 0.689869] [G loss: 0.914230]\n",
            "[Epoch 0/200] [Batch 802/938] [D loss: 0.694397] [G loss: 0.915559]\n",
            "[Epoch 0/200] [Batch 803/938] [D loss: 0.691508] [G loss: 0.915717]\n",
            "[Epoch 0/200] [Batch 804/938] [D loss: 0.694428] [G loss: 0.913533]\n",
            "[Epoch 0/200] [Batch 805/938] [D loss: 0.695277] [G loss: 0.914709]\n",
            "[Epoch 0/200] [Batch 806/938] [D loss: 0.694513] [G loss: 0.908236]\n",
            "[Epoch 0/200] [Batch 807/938] [D loss: 0.693864] [G loss: 0.916545]\n",
            "[Epoch 0/200] [Batch 808/938] [D loss: 0.694469] [G loss: 0.912921]\n",
            "[Epoch 0/200] [Batch 809/938] [D loss: 0.697959] [G loss: 0.915091]\n",
            "[Epoch 0/200] [Batch 810/938] [D loss: 0.698828] [G loss: 0.914121]\n",
            "[Epoch 0/200] [Batch 811/938] [D loss: 0.696691] [G loss: 0.916426]\n",
            "[Epoch 0/200] [Batch 812/938] [D loss: 0.695806] [G loss: 0.916072]\n",
            "[Epoch 0/200] [Batch 813/938] [D loss: 0.698158] [G loss: 0.915729]\n",
            "[Epoch 0/200] [Batch 814/938] [D loss: 0.699207] [G loss: 0.920820]\n",
            "[Epoch 0/200] [Batch 815/938] [D loss: 0.698349] [G loss: 0.914047]\n",
            "[Epoch 0/200] [Batch 816/938] [D loss: 0.697175] [G loss: 0.912968]\n",
            "[Epoch 0/200] [Batch 817/938] [D loss: 0.692373] [G loss: 0.916525]\n",
            "[Epoch 0/200] [Batch 818/938] [D loss: 0.692417] [G loss: 0.914754]\n",
            "[Epoch 0/200] [Batch 819/938] [D loss: 0.695792] [G loss: 0.915160]\n",
            "[Epoch 0/200] [Batch 820/938] [D loss: 0.696294] [G loss: 0.913945]\n",
            "[Epoch 0/200] [Batch 821/938] [D loss: 0.694375] [G loss: 0.912642]\n",
            "[Epoch 0/200] [Batch 822/938] [D loss: 0.697614] [G loss: 0.913873]\n",
            "[Epoch 0/200] [Batch 823/938] [D loss: 0.693597] [G loss: 0.916992]\n",
            "[Epoch 0/200] [Batch 824/938] [D loss: 0.693965] [G loss: 0.916028]\n",
            "[Epoch 0/200] [Batch 825/938] [D loss: 0.693255] [G loss: 0.918602]\n",
            "[Epoch 0/200] [Batch 826/938] [D loss: 0.698394] [G loss: 0.917801]\n",
            "[Epoch 0/200] [Batch 827/938] [D loss: 0.697950] [G loss: 0.914169]\n",
            "[Epoch 0/200] [Batch 828/938] [D loss: 0.696754] [G loss: 0.917434]\n",
            "[Epoch 0/200] [Batch 829/938] [D loss: 0.694813] [G loss: 0.914261]\n",
            "[Epoch 0/200] [Batch 830/938] [D loss: 0.692313] [G loss: 0.914819]\n",
            "[Epoch 0/200] [Batch 831/938] [D loss: 0.697708] [G loss: 0.917012]\n",
            "[Epoch 0/200] [Batch 832/938] [D loss: 0.692945] [G loss: 0.914641]\n",
            "[Epoch 0/200] [Batch 833/938] [D loss: 0.697864] [G loss: 0.914204]\n",
            "[Epoch 0/200] [Batch 834/938] [D loss: 0.699667] [G loss: 0.912327]\n",
            "[Epoch 0/200] [Batch 835/938] [D loss: 0.692220] [G loss: 0.914592]\n",
            "[Epoch 0/200] [Batch 836/938] [D loss: 0.694851] [G loss: 0.916175]\n",
            "[Epoch 0/200] [Batch 837/938] [D loss: 0.696725] [G loss: 0.913363]\n",
            "[Epoch 0/200] [Batch 838/938] [D loss: 0.687434] [G loss: 0.917017]\n",
            "[Epoch 0/200] [Batch 839/938] [D loss: 0.693067] [G loss: 0.914846]\n",
            "[Epoch 0/200] [Batch 840/938] [D loss: 0.693876] [G loss: 0.916604]\n",
            "[Epoch 0/200] [Batch 841/938] [D loss: 0.699227] [G loss: 0.913241]\n",
            "[Epoch 0/200] [Batch 842/938] [D loss: 0.692867] [G loss: 0.917238]\n",
            "[Epoch 0/200] [Batch 843/938] [D loss: 0.697314] [G loss: 0.911648]\n",
            "[Epoch 0/200] [Batch 844/938] [D loss: 0.695680] [G loss: 0.914880]\n",
            "[Epoch 0/200] [Batch 845/938] [D loss: 0.695597] [G loss: 0.913401]\n",
            "[Epoch 0/200] [Batch 846/938] [D loss: 0.695097] [G loss: 0.911981]\n",
            "[Epoch 0/200] [Batch 847/938] [D loss: 0.695322] [G loss: 0.911748]\n",
            "[Epoch 0/200] [Batch 848/938] [D loss: 0.693330] [G loss: 0.916048]\n",
            "[Epoch 0/200] [Batch 849/938] [D loss: 0.695641] [G loss: 0.912667]\n",
            "[Epoch 0/200] [Batch 850/938] [D loss: 0.690218] [G loss: 0.917706]\n",
            "[Epoch 0/200] [Batch 851/938] [D loss: 0.694912] [G loss: 0.914912]\n",
            "[Epoch 0/200] [Batch 852/938] [D loss: 0.696725] [G loss: 0.915995]\n",
            "[Epoch 0/200] [Batch 853/938] [D loss: 0.695653] [G loss: 0.915622]\n",
            "[Epoch 0/200] [Batch 854/938] [D loss: 0.696526] [G loss: 0.915000]\n",
            "[Epoch 0/200] [Batch 855/938] [D loss: 0.697981] [G loss: 0.916747]\n",
            "[Epoch 0/200] [Batch 856/938] [D loss: 0.697734] [G loss: 0.912992]\n",
            "[Epoch 0/200] [Batch 857/938] [D loss: 0.698492] [G loss: 0.914965]\n",
            "[Epoch 0/200] [Batch 858/938] [D loss: 0.699934] [G loss: 0.915456]\n",
            "[Epoch 0/200] [Batch 859/938] [D loss: 0.698691] [G loss: 0.911604]\n",
            "[Epoch 0/200] [Batch 860/938] [D loss: 0.699938] [G loss: 0.912584]\n",
            "[Epoch 0/200] [Batch 861/938] [D loss: 0.701758] [G loss: 0.912910]\n",
            "[Epoch 0/200] [Batch 862/938] [D loss: 0.698240] [G loss: 0.916002]\n",
            "[Epoch 0/200] [Batch 863/938] [D loss: 0.691891] [G loss: 0.913993]\n",
            "[Epoch 0/200] [Batch 864/938] [D loss: 0.697309] [G loss: 0.918721]\n",
            "[Epoch 0/200] [Batch 865/938] [D loss: 0.702480] [G loss: 0.916600]\n",
            "[Epoch 0/200] [Batch 866/938] [D loss: 0.694335] [G loss: 0.912980]\n",
            "[Epoch 0/200] [Batch 867/938] [D loss: 0.695350] [G loss: 0.914119]\n",
            "[Epoch 0/200] [Batch 868/938] [D loss: 0.697997] [G loss: 0.911535]\n",
            "[Epoch 0/200] [Batch 869/938] [D loss: 0.692909] [G loss: 0.917505]\n",
            "[Epoch 0/200] [Batch 870/938] [D loss: 0.698277] [G loss: 0.914809]\n",
            "[Epoch 0/200] [Batch 871/938] [D loss: 0.696522] [G loss: 0.914307]\n",
            "[Epoch 0/200] [Batch 872/938] [D loss: 0.697475] [G loss: 0.915327]\n",
            "[Epoch 0/200] [Batch 873/938] [D loss: 0.697817] [G loss: 0.919138]\n",
            "[Epoch 0/200] [Batch 874/938] [D loss: 0.695265] [G loss: 0.914552]\n",
            "[Epoch 0/200] [Batch 875/938] [D loss: 0.698079] [G loss: 0.914452]\n",
            "[Epoch 0/200] [Batch 876/938] [D loss: 0.698488] [G loss: 0.915350]\n",
            "[Epoch 0/200] [Batch 877/938] [D loss: 0.698226] [G loss: 0.913271]\n",
            "[Epoch 0/200] [Batch 878/938] [D loss: 0.692284] [G loss: 0.912490]\n",
            "[Epoch 0/200] [Batch 879/938] [D loss: 0.692795] [G loss: 0.913315]\n",
            "[Epoch 0/200] [Batch 880/938] [D loss: 0.700307] [G loss: 0.913538]\n",
            "[Epoch 0/200] [Batch 881/938] [D loss: 0.695533] [G loss: 0.911658]\n",
            "[Epoch 0/200] [Batch 882/938] [D loss: 0.701460] [G loss: 0.911109]\n",
            "[Epoch 0/200] [Batch 883/938] [D loss: 0.692170] [G loss: 0.914726]\n",
            "[Epoch 0/200] [Batch 884/938] [D loss: 0.693640] [G loss: 0.916531]\n",
            "[Epoch 0/200] [Batch 885/938] [D loss: 0.698509] [G loss: 0.913166]\n",
            "[Epoch 0/200] [Batch 886/938] [D loss: 0.695412] [G loss: 0.915452]\n",
            "[Epoch 0/200] [Batch 887/938] [D loss: 0.694450] [G loss: 0.915006]\n",
            "[Epoch 0/200] [Batch 888/938] [D loss: 0.694842] [G loss: 0.915207]\n",
            "[Epoch 0/200] [Batch 889/938] [D loss: 0.697612] [G loss: 0.916645]\n",
            "[Epoch 0/200] [Batch 890/938] [D loss: 0.699439] [G loss: 0.914544]\n",
            "[Epoch 0/200] [Batch 891/938] [D loss: 0.694366] [G loss: 0.915760]\n",
            "[Epoch 0/200] [Batch 892/938] [D loss: 0.698726] [G loss: 0.912998]\n",
            "[Epoch 0/200] [Batch 893/938] [D loss: 0.695583] [G loss: 0.909044]\n",
            "[Epoch 0/200] [Batch 894/938] [D loss: 0.691794] [G loss: 0.917470]\n",
            "[Epoch 0/200] [Batch 895/938] [D loss: 0.693977] [G loss: 0.919595]\n",
            "[Epoch 0/200] [Batch 896/938] [D loss: 0.697103] [G loss: 0.915794]\n",
            "[Epoch 0/200] [Batch 897/938] [D loss: 0.697309] [G loss: 0.915842]\n",
            "[Epoch 0/200] [Batch 898/938] [D loss: 0.696900] [G loss: 0.913821]\n",
            "[Epoch 0/200] [Batch 899/938] [D loss: 0.696716] [G loss: 0.915577]\n",
            "[Epoch 0/200] [Batch 900/938] [D loss: 0.691358] [G loss: 0.915598]\n",
            "[Epoch 0/200] [Batch 901/938] [D loss: 0.696226] [G loss: 0.914063]\n",
            "[Epoch 0/200] [Batch 902/938] [D loss: 0.694938] [G loss: 0.912455]\n",
            "[Epoch 0/200] [Batch 903/938] [D loss: 0.700067] [G loss: 0.914929]\n",
            "[Epoch 0/200] [Batch 904/938] [D loss: 0.697759] [G loss: 0.916000]\n",
            "[Epoch 0/200] [Batch 905/938] [D loss: 0.693219] [G loss: 0.915095]\n",
            "[Epoch 0/200] [Batch 906/938] [D loss: 0.696759] [G loss: 0.913401]\n",
            "[Epoch 0/200] [Batch 907/938] [D loss: 0.698392] [G loss: 0.914374]\n",
            "[Epoch 0/200] [Batch 908/938] [D loss: 0.695177] [G loss: 0.910915]\n",
            "[Epoch 0/200] [Batch 909/938] [D loss: 0.695665] [G loss: 0.913630]\n",
            "[Epoch 0/200] [Batch 910/938] [D loss: 0.693128] [G loss: 0.914865]\n",
            "[Epoch 0/200] [Batch 911/938] [D loss: 0.694757] [G loss: 0.914856]\n",
            "[Epoch 0/200] [Batch 912/938] [D loss: 0.692475] [G loss: 0.916230]\n",
            "[Epoch 0/200] [Batch 913/938] [D loss: 0.691266] [G loss: 0.915023]\n",
            "[Epoch 0/200] [Batch 914/938] [D loss: 0.693502] [G loss: 0.915205]\n",
            "[Epoch 0/200] [Batch 915/938] [D loss: 0.690307] [G loss: 0.912880]\n",
            "[Epoch 0/200] [Batch 916/938] [D loss: 0.696927] [G loss: 0.914243]\n",
            "[Epoch 0/200] [Batch 917/938] [D loss: 0.694521] [G loss: 0.913208]\n",
            "[Epoch 0/200] [Batch 918/938] [D loss: 0.692676] [G loss: 0.914875]\n",
            "[Epoch 0/200] [Batch 919/938] [D loss: 0.696193] [G loss: 0.913831]\n",
            "[Epoch 0/200] [Batch 920/938] [D loss: 0.691645] [G loss: 0.915546]\n",
            "[Epoch 0/200] [Batch 921/938] [D loss: 0.698772] [G loss: 0.913917]\n",
            "[Epoch 0/200] [Batch 922/938] [D loss: 0.692738] [G loss: 0.914620]\n",
            "[Epoch 0/200] [Batch 923/938] [D loss: 0.697728] [G loss: 0.912561]\n",
            "[Epoch 0/200] [Batch 924/938] [D loss: 0.692061] [G loss: 0.915146]\n",
            "[Epoch 0/200] [Batch 925/938] [D loss: 0.692823] [G loss: 0.915116]\n",
            "[Epoch 0/200] [Batch 926/938] [D loss: 0.690330] [G loss: 0.914364]\n",
            "[Epoch 0/200] [Batch 927/938] [D loss: 0.696113] [G loss: 0.919536]\n",
            "[Epoch 0/200] [Batch 928/938] [D loss: 0.696602] [G loss: 0.918762]\n",
            "[Epoch 0/200] [Batch 929/938] [D loss: 0.701709] [G loss: 0.916140]\n",
            "[Epoch 0/200] [Batch 930/938] [D loss: 0.698155] [G loss: 0.915553]\n",
            "[Epoch 0/200] [Batch 931/938] [D loss: 0.695329] [G loss: 0.916954]\n",
            "[Epoch 0/200] [Batch 932/938] [D loss: 0.690643] [G loss: 0.914744]\n",
            "[Epoch 0/200] [Batch 933/938] [D loss: 0.698392] [G loss: 0.913894]\n",
            "[Epoch 0/200] [Batch 934/938] [D loss: 0.698173] [G loss: 0.913530]\n",
            "[Epoch 0/200] [Batch 935/938] [D loss: 0.691702] [G loss: 0.918282]\n",
            "[Epoch 0/200] [Batch 936/938] [D loss: 0.689546] [G loss: 0.914137]\n",
            "[Epoch 0/200] [Batch 937/938] [D loss: 0.701345] [G loss: 0.919668]\n",
            "[Epoch 1/200] [Batch 0/938] [D loss: 0.693105] [G loss: 0.913874]\n",
            "[Epoch 1/200] [Batch 1/938] [D loss: 0.694779] [G loss: 0.917801]\n",
            "[Epoch 1/200] [Batch 2/938] [D loss: 0.692688] [G loss: 0.913937]\n",
            "[Epoch 1/200] [Batch 3/938] [D loss: 0.696558] [G loss: 0.911638]\n",
            "[Epoch 1/200] [Batch 4/938] [D loss: 0.692224] [G loss: 0.918759]\n",
            "[Epoch 1/200] [Batch 5/938] [D loss: 0.696493] [G loss: 0.915271]\n",
            "[Epoch 1/200] [Batch 6/938] [D loss: 0.697476] [G loss: 0.913694]\n",
            "[Epoch 1/200] [Batch 7/938] [D loss: 0.697603] [G loss: 0.916902]\n",
            "[Epoch 1/200] [Batch 8/938] [D loss: 0.697190] [G loss: 0.911974]\n",
            "[Epoch 1/200] [Batch 9/938] [D loss: 0.696282] [G loss: 0.916704]\n",
            "[Epoch 1/200] [Batch 10/938] [D loss: 0.693046] [G loss: 0.915994]\n",
            "[Epoch 1/200] [Batch 11/938] [D loss: 0.697050] [G loss: 0.916587]\n",
            "[Epoch 1/200] [Batch 12/938] [D loss: 0.689498] [G loss: 0.912658]\n",
            "[Epoch 1/200] [Batch 13/938] [D loss: 0.696755] [G loss: 0.914801]\n",
            "[Epoch 1/200] [Batch 14/938] [D loss: 0.698857] [G loss: 0.913032]\n",
            "[Epoch 1/200] [Batch 15/938] [D loss: 0.698305] [G loss: 0.913827]\n",
            "[Epoch 1/200] [Batch 16/938] [D loss: 0.696338] [G loss: 0.914247]\n",
            "[Epoch 1/200] [Batch 17/938] [D loss: 0.696450] [G loss: 0.915969]\n",
            "[Epoch 1/200] [Batch 18/938] [D loss: 0.693911] [G loss: 0.914478]\n",
            "[Epoch 1/200] [Batch 19/938] [D loss: 0.696521] [G loss: 0.913629]\n",
            "[Epoch 1/200] [Batch 20/938] [D loss: 0.692734] [G loss: 0.916325]\n",
            "[Epoch 1/200] [Batch 21/938] [D loss: 0.697673] [G loss: 0.914528]\n",
            "[Epoch 1/200] [Batch 22/938] [D loss: 0.696228] [G loss: 0.914756]\n",
            "[Epoch 1/200] [Batch 23/938] [D loss: 0.689921] [G loss: 0.916440]\n",
            "[Epoch 1/200] [Batch 24/938] [D loss: 0.687747] [G loss: 0.913471]\n",
            "[Epoch 1/200] [Batch 25/938] [D loss: 0.696059] [G loss: 0.915116]\n",
            "[Epoch 1/200] [Batch 26/938] [D loss: 0.694241] [G loss: 0.919641]\n",
            "[Epoch 1/200] [Batch 27/938] [D loss: 0.695267] [G loss: 0.917421]\n",
            "[Epoch 1/200] [Batch 28/938] [D loss: 0.698692] [G loss: 0.912992]\n",
            "[Epoch 1/200] [Batch 29/938] [D loss: 0.688438] [G loss: 0.913003]\n",
            "[Epoch 1/200] [Batch 30/938] [D loss: 0.691215] [G loss: 0.911991]\n",
            "[Epoch 1/200] [Batch 31/938] [D loss: 0.691554] [G loss: 0.917646]\n",
            "[Epoch 1/200] [Batch 32/938] [D loss: 0.694699] [G loss: 0.912965]\n",
            "[Epoch 1/200] [Batch 33/938] [D loss: 0.687006] [G loss: 0.916254]\n",
            "[Epoch 1/200] [Batch 34/938] [D loss: 0.696190] [G loss: 0.910601]\n",
            "[Epoch 1/200] [Batch 35/938] [D loss: 0.691861] [G loss: 0.915454]\n",
            "[Epoch 1/200] [Batch 36/938] [D loss: 0.696785] [G loss: 0.919799]\n",
            "[Epoch 1/200] [Batch 37/938] [D loss: 0.694358] [G loss: 0.914262]\n",
            "[Epoch 1/200] [Batch 38/938] [D loss: 0.699435] [G loss: 0.911943]\n",
            "[Epoch 1/200] [Batch 39/938] [D loss: 0.699013] [G loss: 0.916100]\n",
            "[Epoch 1/200] [Batch 40/938] [D loss: 0.701140] [G loss: 0.912322]\n",
            "[Epoch 1/200] [Batch 41/938] [D loss: 0.697732] [G loss: 0.913713]\n",
            "[Epoch 1/200] [Batch 42/938] [D loss: 0.698251] [G loss: 0.908872]\n",
            "[Epoch 1/200] [Batch 43/938] [D loss: 0.695067] [G loss: 0.915043]\n",
            "[Epoch 1/200] [Batch 44/938] [D loss: 0.699595] [G loss: 0.918829]\n",
            "[Epoch 1/200] [Batch 45/938] [D loss: 0.698431] [G loss: 0.913781]\n",
            "[Epoch 1/200] [Batch 46/938] [D loss: 0.701504] [G loss: 0.916784]\n",
            "[Epoch 1/200] [Batch 47/938] [D loss: 0.697173] [G loss: 0.917172]\n",
            "[Epoch 1/200] [Batch 48/938] [D loss: 0.693996] [G loss: 0.914503]\n",
            "[Epoch 1/200] [Batch 49/938] [D loss: 0.693064] [G loss: 0.917353]\n",
            "[Epoch 1/200] [Batch 50/938] [D loss: 0.691131] [G loss: 0.912647]\n",
            "[Epoch 1/200] [Batch 51/938] [D loss: 0.694452] [G loss: 0.916822]\n",
            "[Epoch 1/200] [Batch 52/938] [D loss: 0.693614] [G loss: 0.916575]\n",
            "[Epoch 1/200] [Batch 53/938] [D loss: 0.696893] [G loss: 0.915629]\n",
            "[Epoch 1/200] [Batch 54/938] [D loss: 0.695383] [G loss: 0.914001]\n",
            "[Epoch 1/200] [Batch 55/938] [D loss: 0.695583] [G loss: 0.913652]\n",
            "[Epoch 1/200] [Batch 56/938] [D loss: 0.694439] [G loss: 0.916147]\n",
            "[Epoch 1/200] [Batch 57/938] [D loss: 0.690484] [G loss: 0.914853]\n",
            "[Epoch 1/200] [Batch 58/938] [D loss: 0.693053] [G loss: 0.915730]\n",
            "[Epoch 1/200] [Batch 59/938] [D loss: 0.695347] [G loss: 0.915648]\n",
            "[Epoch 1/200] [Batch 60/938] [D loss: 0.693677] [G loss: 0.916551]\n",
            "[Epoch 1/200] [Batch 61/938] [D loss: 0.689816] [G loss: 0.916066]\n",
            "[Epoch 1/200] [Batch 62/938] [D loss: 0.695324] [G loss: 0.913930]\n",
            "[Epoch 1/200] [Batch 63/938] [D loss: 0.700432] [G loss: 0.912775]\n",
            "[Epoch 1/200] [Batch 64/938] [D loss: 0.697826] [G loss: 0.912982]\n",
            "[Epoch 1/200] [Batch 65/938] [D loss: 0.694719] [G loss: 0.917994]\n",
            "[Epoch 1/200] [Batch 66/938] [D loss: 0.691865] [G loss: 0.916601]\n",
            "[Epoch 1/200] [Batch 67/938] [D loss: 0.696602] [G loss: 0.913563]\n",
            "[Epoch 1/200] [Batch 68/938] [D loss: 0.698824] [G loss: 0.915189]\n",
            "[Epoch 1/200] [Batch 69/938] [D loss: 0.691408] [G loss: 0.914019]\n",
            "[Epoch 1/200] [Batch 70/938] [D loss: 0.698448] [G loss: 0.916549]\n",
            "[Epoch 1/200] [Batch 71/938] [D loss: 0.702645] [G loss: 0.911411]\n",
            "[Epoch 1/200] [Batch 72/938] [D loss: 0.692308] [G loss: 0.918336]\n",
            "[Epoch 1/200] [Batch 73/938] [D loss: 0.698109] [G loss: 0.914578]\n",
            "[Epoch 1/200] [Batch 74/938] [D loss: 0.698713] [G loss: 0.917359]\n",
            "[Epoch 1/200] [Batch 75/938] [D loss: 0.694397] [G loss: 0.914655]\n",
            "[Epoch 1/200] [Batch 76/938] [D loss: 0.691188] [G loss: 0.914201]\n",
            "[Epoch 1/200] [Batch 77/938] [D loss: 0.695545] [G loss: 0.914248]\n",
            "[Epoch 1/200] [Batch 78/938] [D loss: 0.699671] [G loss: 0.913145]\n",
            "[Epoch 1/200] [Batch 79/938] [D loss: 0.694401] [G loss: 0.912409]\n",
            "[Epoch 1/200] [Batch 80/938] [D loss: 0.691904] [G loss: 0.917790]\n",
            "[Epoch 1/200] [Batch 81/938] [D loss: 0.697625] [G loss: 0.913299]\n",
            "[Epoch 1/200] [Batch 82/938] [D loss: 0.699118] [G loss: 0.918832]\n",
            "[Epoch 1/200] [Batch 83/938] [D loss: 0.697450] [G loss: 0.917573]\n",
            "[Epoch 1/200] [Batch 84/938] [D loss: 0.696595] [G loss: 0.915961]\n",
            "[Epoch 1/200] [Batch 85/938] [D loss: 0.694814] [G loss: 0.916116]\n",
            "[Epoch 1/200] [Batch 86/938] [D loss: 0.693165] [G loss: 0.913641]\n",
            "[Epoch 1/200] [Batch 87/938] [D loss: 0.694995] [G loss: 0.913287]\n",
            "[Epoch 1/200] [Batch 88/938] [D loss: 0.690194] [G loss: 0.917790]\n",
            "[Epoch 1/200] [Batch 89/938] [D loss: 0.699923] [G loss: 0.913223]\n",
            "[Epoch 1/200] [Batch 90/938] [D loss: 0.687587] [G loss: 0.913344]\n",
            "[Epoch 1/200] [Batch 91/938] [D loss: 0.698170] [G loss: 0.917053]\n",
            "[Epoch 1/200] [Batch 92/938] [D loss: 0.699036] [G loss: 0.910719]\n",
            "[Epoch 1/200] [Batch 93/938] [D loss: 0.697358] [G loss: 0.915613]\n",
            "[Epoch 1/200] [Batch 94/938] [D loss: 0.697937] [G loss: 0.916269]\n",
            "[Epoch 1/200] [Batch 95/938] [D loss: 0.702014] [G loss: 0.917864]\n",
            "[Epoch 1/200] [Batch 96/938] [D loss: 0.693917] [G loss: 0.920942]\n",
            "[Epoch 1/200] [Batch 97/938] [D loss: 0.699463] [G loss: 0.913977]\n",
            "[Epoch 1/200] [Batch 98/938] [D loss: 0.698762] [G loss: 0.911653]\n",
            "[Epoch 1/200] [Batch 99/938] [D loss: 0.694597] [G loss: 0.914460]\n",
            "[Epoch 1/200] [Batch 100/938] [D loss: 0.690783] [G loss: 0.916298]\n",
            "[Epoch 1/200] [Batch 101/938] [D loss: 0.696238] [G loss: 0.912332]\n",
            "[Epoch 1/200] [Batch 102/938] [D loss: 0.694407] [G loss: 0.915143]\n",
            "[Epoch 1/200] [Batch 103/938] [D loss: 0.692790] [G loss: 0.917488]\n",
            "[Epoch 1/200] [Batch 104/938] [D loss: 0.696574] [G loss: 0.909574]\n",
            "[Epoch 1/200] [Batch 105/938] [D loss: 0.694500] [G loss: 0.914476]\n",
            "[Epoch 1/200] [Batch 106/938] [D loss: 0.692863] [G loss: 0.915686]\n",
            "[Epoch 1/200] [Batch 107/938] [D loss: 0.697881] [G loss: 0.914895]\n",
            "[Epoch 1/200] [Batch 108/938] [D loss: 0.697654] [G loss: 0.913666]\n",
            "[Epoch 1/200] [Batch 109/938] [D loss: 0.693722] [G loss: 0.913903]\n",
            "[Epoch 1/200] [Batch 110/938] [D loss: 0.693897] [G loss: 0.919442]\n",
            "[Epoch 1/200] [Batch 111/938] [D loss: 0.694496] [G loss: 0.916984]\n",
            "[Epoch 1/200] [Batch 112/938] [D loss: 0.691531] [G loss: 0.915642]\n",
            "[Epoch 1/200] [Batch 113/938] [D loss: 0.697491] [G loss: 0.915534]\n",
            "[Epoch 1/200] [Batch 114/938] [D loss: 0.694565] [G loss: 0.919692]\n",
            "[Epoch 1/200] [Batch 115/938] [D loss: 0.699463] [G loss: 0.917603]\n",
            "[Epoch 1/200] [Batch 116/938] [D loss: 0.692252] [G loss: 0.912175]\n",
            "[Epoch 1/200] [Batch 117/938] [D loss: 0.697573] [G loss: 0.913464]\n",
            "[Epoch 1/200] [Batch 118/938] [D loss: 0.697927] [G loss: 0.915002]\n",
            "[Epoch 1/200] [Batch 119/938] [D loss: 0.697523] [G loss: 0.920688]\n",
            "[Epoch 1/200] [Batch 120/938] [D loss: 0.696321] [G loss: 0.919834]\n",
            "[Epoch 1/200] [Batch 121/938] [D loss: 0.701746] [G loss: 0.914957]\n",
            "[Epoch 1/200] [Batch 122/938] [D loss: 0.692546] [G loss: 0.918209]\n",
            "[Epoch 1/200] [Batch 123/938] [D loss: 0.698041] [G loss: 0.917008]\n",
            "[Epoch 1/200] [Batch 124/938] [D loss: 0.692630] [G loss: 0.912416]\n",
            "[Epoch 1/200] [Batch 125/938] [D loss: 0.699578] [G loss: 0.914018]\n",
            "[Epoch 1/200] [Batch 126/938] [D loss: 0.694125] [G loss: 0.908821]\n",
            "[Epoch 1/200] [Batch 127/938] [D loss: 0.692687] [G loss: 0.919142]\n",
            "[Epoch 1/200] [Batch 128/938] [D loss: 0.695532] [G loss: 0.920412]\n",
            "[Epoch 1/200] [Batch 129/938] [D loss: 0.690838] [G loss: 0.917384]\n",
            "[Epoch 1/200] [Batch 130/938] [D loss: 0.692737] [G loss: 0.915367]\n",
            "[Epoch 1/200] [Batch 131/938] [D loss: 0.691760] [G loss: 0.915990]\n",
            "[Epoch 1/200] [Batch 132/938] [D loss: 0.697731] [G loss: 0.917661]\n",
            "[Epoch 1/200] [Batch 133/938] [D loss: 0.691038] [G loss: 0.916638]\n",
            "[Epoch 1/200] [Batch 134/938] [D loss: 0.694383] [G loss: 0.914301]\n",
            "[Epoch 1/200] [Batch 135/938] [D loss: 0.699912] [G loss: 0.915753]\n",
            "[Epoch 1/200] [Batch 136/938] [D loss: 0.695524] [G loss: 0.922800]\n",
            "[Epoch 1/200] [Batch 137/938] [D loss: 0.699537] [G loss: 0.916905]\n",
            "[Epoch 1/200] [Batch 138/938] [D loss: 0.697736] [G loss: 0.919311]\n",
            "[Epoch 1/200] [Batch 139/938] [D loss: 0.693757] [G loss: 0.916270]\n",
            "[Epoch 1/200] [Batch 140/938] [D loss: 0.691254] [G loss: 0.919588]\n",
            "[Epoch 1/200] [Batch 141/938] [D loss: 0.693567] [G loss: 0.918272]\n",
            "[Epoch 1/200] [Batch 142/938] [D loss: 0.698601] [G loss: 0.914955]\n",
            "[Epoch 1/200] [Batch 143/938] [D loss: 0.697561] [G loss: 0.914268]\n",
            "[Epoch 1/200] [Batch 144/938] [D loss: 0.687507] [G loss: 0.917250]\n",
            "[Epoch 1/200] [Batch 145/938] [D loss: 0.694196] [G loss: 0.915826]\n",
            "[Epoch 1/200] [Batch 146/938] [D loss: 0.691319] [G loss: 0.917221]\n",
            "[Epoch 1/200] [Batch 147/938] [D loss: 0.695587] [G loss: 0.916519]\n",
            "[Epoch 1/200] [Batch 148/938] [D loss: 0.695690] [G loss: 0.917714]\n",
            "[Epoch 1/200] [Batch 149/938] [D loss: 0.696514] [G loss: 0.915703]\n",
            "[Epoch 1/200] [Batch 150/938] [D loss: 0.697714] [G loss: 0.912019]\n",
            "[Epoch 1/200] [Batch 151/938] [D loss: 0.690582] [G loss: 0.913190]\n",
            "[Epoch 1/200] [Batch 152/938] [D loss: 0.697134] [G loss: 0.914301]\n",
            "[Epoch 1/200] [Batch 153/938] [D loss: 0.699157] [G loss: 0.911452]\n",
            "[Epoch 1/200] [Batch 154/938] [D loss: 0.697748] [G loss: 0.915335]\n",
            "[Epoch 1/200] [Batch 155/938] [D loss: 0.696069] [G loss: 0.914108]\n",
            "[Epoch 1/200] [Batch 156/938] [D loss: 0.699591] [G loss: 0.912871]\n",
            "[Epoch 1/200] [Batch 157/938] [D loss: 0.692434] [G loss: 0.920739]\n",
            "[Epoch 1/200] [Batch 158/938] [D loss: 0.694006] [G loss: 0.916966]\n",
            "[Epoch 1/200] [Batch 159/938] [D loss: 0.699888] [G loss: 0.915986]\n",
            "[Epoch 1/200] [Batch 160/938] [D loss: 0.691903] [G loss: 0.916552]\n",
            "[Epoch 1/200] [Batch 161/938] [D loss: 0.692898] [G loss: 0.916863]\n",
            "[Epoch 1/200] [Batch 162/938] [D loss: 0.693639] [G loss: 0.916663]\n",
            "[Epoch 1/200] [Batch 163/938] [D loss: 0.691916] [G loss: 0.914871]\n",
            "[Epoch 1/200] [Batch 164/938] [D loss: 0.691948] [G loss: 0.915763]\n",
            "[Epoch 1/200] [Batch 165/938] [D loss: 0.695165] [G loss: 0.914860]\n",
            "[Epoch 1/200] [Batch 166/938] [D loss: 0.701677] [G loss: 0.914422]\n",
            "[Epoch 1/200] [Batch 167/938] [D loss: 0.694226] [G loss: 0.917791]\n",
            "[Epoch 1/200] [Batch 168/938] [D loss: 0.697089] [G loss: 0.914653]\n",
            "[Epoch 1/200] [Batch 169/938] [D loss: 0.689567] [G loss: 0.920581]\n",
            "[Epoch 1/200] [Batch 170/938] [D loss: 0.691436] [G loss: 0.915255]\n",
            "[Epoch 1/200] [Batch 171/938] [D loss: 0.696025] [G loss: 0.913217]\n",
            "[Epoch 1/200] [Batch 172/938] [D loss: 0.692457] [G loss: 0.914389]\n",
            "[Epoch 1/200] [Batch 173/938] [D loss: 0.691859] [G loss: 0.914863]\n",
            "[Epoch 1/200] [Batch 174/938] [D loss: 0.696435] [G loss: 0.913390]\n",
            "[Epoch 1/200] [Batch 175/938] [D loss: 0.695906] [G loss: 0.914752]\n",
            "[Epoch 1/200] [Batch 176/938] [D loss: 0.699193] [G loss: 0.916350]\n",
            "[Epoch 1/200] [Batch 177/938] [D loss: 0.695209] [G loss: 0.915236]\n",
            "[Epoch 1/200] [Batch 178/938] [D loss: 0.695354] [G loss: 0.912666]\n",
            "[Epoch 1/200] [Batch 179/938] [D loss: 0.692895] [G loss: 0.918921]\n",
            "[Epoch 1/200] [Batch 180/938] [D loss: 0.693433] [G loss: 0.914663]\n",
            "[Epoch 1/200] [Batch 181/938] [D loss: 0.700234] [G loss: 0.915785]\n",
            "[Epoch 1/200] [Batch 182/938] [D loss: 0.693191] [G loss: 0.916811]\n",
            "[Epoch 1/200] [Batch 183/938] [D loss: 0.694783] [G loss: 0.915104]\n",
            "[Epoch 1/200] [Batch 184/938] [D loss: 0.695200] [G loss: 0.913964]\n",
            "[Epoch 1/200] [Batch 185/938] [D loss: 0.694444] [G loss: 0.916045]\n",
            "[Epoch 1/200] [Batch 186/938] [D loss: 0.698497] [G loss: 0.916568]\n",
            "[Epoch 1/200] [Batch 187/938] [D loss: 0.696944] [G loss: 0.914711]\n",
            "[Epoch 1/200] [Batch 188/938] [D loss: 0.687879] [G loss: 0.917764]\n",
            "[Epoch 1/200] [Batch 189/938] [D loss: 0.697589] [G loss: 0.911204]\n",
            "[Epoch 1/200] [Batch 190/938] [D loss: 0.698534] [G loss: 0.912869]\n",
            "[Epoch 1/200] [Batch 191/938] [D loss: 0.696075] [G loss: 0.914497]\n",
            "[Epoch 1/200] [Batch 192/938] [D loss: 0.691745] [G loss: 0.914988]\n",
            "[Epoch 1/200] [Batch 193/938] [D loss: 0.694892] [G loss: 0.912591]\n",
            "[Epoch 1/200] [Batch 194/938] [D loss: 0.697746] [G loss: 0.919500]\n",
            "[Epoch 1/200] [Batch 195/938] [D loss: 0.697019] [G loss: 0.913731]\n",
            "[Epoch 1/200] [Batch 196/938] [D loss: 0.703262] [G loss: 0.916071]\n",
            "[Epoch 1/200] [Batch 197/938] [D loss: 0.697446] [G loss: 0.914854]\n",
            "[Epoch 1/200] [Batch 198/938] [D loss: 0.698493] [G loss: 0.917220]\n",
            "[Epoch 1/200] [Batch 199/938] [D loss: 0.698192] [G loss: 0.912222]\n",
            "[Epoch 1/200] [Batch 200/938] [D loss: 0.692151] [G loss: 0.911918]\n",
            "[Epoch 1/200] [Batch 201/938] [D loss: 0.687477] [G loss: 0.915639]\n",
            "[Epoch 1/200] [Batch 202/938] [D loss: 0.695524] [G loss: 0.914280]\n",
            "[Epoch 1/200] [Batch 203/938] [D loss: 0.691336] [G loss: 0.915751]\n",
            "[Epoch 1/200] [Batch 204/938] [D loss: 0.696721] [G loss: 0.915352]\n",
            "[Epoch 1/200] [Batch 205/938] [D loss: 0.700437] [G loss: 0.914448]\n",
            "[Epoch 1/200] [Batch 206/938] [D loss: 0.693657] [G loss: 0.916340]\n",
            "[Epoch 1/200] [Batch 207/938] [D loss: 0.699957] [G loss: 0.913509]\n",
            "[Epoch 1/200] [Batch 208/938] [D loss: 0.696657] [G loss: 0.910701]\n",
            "[Epoch 1/200] [Batch 209/938] [D loss: 0.697936] [G loss: 0.912720]\n",
            "[Epoch 1/200] [Batch 210/938] [D loss: 0.692191] [G loss: 0.910920]\n",
            "[Epoch 1/200] [Batch 211/938] [D loss: 0.690433] [G loss: 0.917324]\n",
            "[Epoch 1/200] [Batch 212/938] [D loss: 0.696120] [G loss: 0.914449]\n",
            "[Epoch 1/200] [Batch 213/938] [D loss: 0.702193] [G loss: 0.915728]\n",
            "[Epoch 1/200] [Batch 214/938] [D loss: 0.692050] [G loss: 0.910367]\n",
            "[Epoch 1/200] [Batch 215/938] [D loss: 0.694004] [G loss: 0.911898]\n",
            "[Epoch 1/200] [Batch 216/938] [D loss: 0.694599] [G loss: 0.915549]\n",
            "[Epoch 1/200] [Batch 217/938] [D loss: 0.691496] [G loss: 0.919891]\n",
            "[Epoch 1/200] [Batch 218/938] [D loss: 0.699183] [G loss: 0.914649]\n",
            "[Epoch 1/200] [Batch 219/938] [D loss: 0.697090] [G loss: 0.912996]\n",
            "[Epoch 1/200] [Batch 220/938] [D loss: 0.694983] [G loss: 0.919856]\n",
            "[Epoch 1/200] [Batch 221/938] [D loss: 0.696818] [G loss: 0.911993]\n",
            "[Epoch 1/200] [Batch 222/938] [D loss: 0.692746] [G loss: 0.916614]\n",
            "[Epoch 1/200] [Batch 223/938] [D loss: 0.694622] [G loss: 0.919235]\n",
            "[Epoch 1/200] [Batch 224/938] [D loss: 0.696005] [G loss: 0.913497]\n",
            "[Epoch 1/200] [Batch 225/938] [D loss: 0.695128] [G loss: 0.915612]\n",
            "[Epoch 1/200] [Batch 226/938] [D loss: 0.693067] [G loss: 0.914498]\n",
            "[Epoch 1/200] [Batch 227/938] [D loss: 0.695531] [G loss: 0.914464]\n",
            "[Epoch 1/200] [Batch 228/938] [D loss: 0.698278] [G loss: 0.918691]\n",
            "[Epoch 1/200] [Batch 229/938] [D loss: 0.699761] [G loss: 0.912577]\n",
            "[Epoch 1/200] [Batch 230/938] [D loss: 0.693256] [G loss: 0.913471]\n",
            "[Epoch 1/200] [Batch 231/938] [D loss: 0.692961] [G loss: 0.917614]\n",
            "[Epoch 1/200] [Batch 232/938] [D loss: 0.698977] [G loss: 0.918112]\n",
            "[Epoch 1/200] [Batch 233/938] [D loss: 0.694587] [G loss: 0.913061]\n",
            "[Epoch 1/200] [Batch 234/938] [D loss: 0.695485] [G loss: 0.911480]\n",
            "[Epoch 1/200] [Batch 235/938] [D loss: 0.701107] [G loss: 0.914770]\n",
            "[Epoch 1/200] [Batch 236/938] [D loss: 0.692462] [G loss: 0.913362]\n",
            "[Epoch 1/200] [Batch 237/938] [D loss: 0.692218] [G loss: 0.914510]\n",
            "[Epoch 1/200] [Batch 238/938] [D loss: 0.694029] [G loss: 0.915345]\n",
            "[Epoch 1/200] [Batch 239/938] [D loss: 0.699462] [G loss: 0.915449]\n",
            "[Epoch 1/200] [Batch 240/938] [D loss: 0.698105] [G loss: 0.918222]\n",
            "[Epoch 1/200] [Batch 241/938] [D loss: 0.691846] [G loss: 0.912567]\n",
            "[Epoch 1/200] [Batch 242/938] [D loss: 0.694533] [G loss: 0.913136]\n",
            "[Epoch 1/200] [Batch 243/938] [D loss: 0.697497] [G loss: 0.910872]\n",
            "[Epoch 1/200] [Batch 244/938] [D loss: 0.694643] [G loss: 0.916354]\n",
            "[Epoch 1/200] [Batch 245/938] [D loss: 0.698088] [G loss: 0.915557]\n",
            "[Epoch 1/200] [Batch 246/938] [D loss: 0.694528] [G loss: 0.914348]\n",
            "[Epoch 1/200] [Batch 247/938] [D loss: 0.696203] [G loss: 0.915566]\n",
            "[Epoch 1/200] [Batch 248/938] [D loss: 0.696355] [G loss: 0.916036]\n",
            "[Epoch 1/200] [Batch 249/938] [D loss: 0.698212] [G loss: 0.914553]\n",
            "[Epoch 1/200] [Batch 250/938] [D loss: 0.699030] [G loss: 0.914149]\n",
            "[Epoch 1/200] [Batch 251/938] [D loss: 0.692652] [G loss: 0.913644]\n",
            "[Epoch 1/200] [Batch 252/938] [D loss: 0.697601] [G loss: 0.916991]\n",
            "[Epoch 1/200] [Batch 253/938] [D loss: 0.693597] [G loss: 0.921284]\n",
            "[Epoch 1/200] [Batch 254/938] [D loss: 0.691684] [G loss: 0.914541]\n",
            "[Epoch 1/200] [Batch 255/938] [D loss: 0.695287] [G loss: 0.916070]\n",
            "[Epoch 1/200] [Batch 256/938] [D loss: 0.693621] [G loss: 0.911054]\n",
            "[Epoch 1/200] [Batch 257/938] [D loss: 0.693209] [G loss: 0.912410]\n",
            "[Epoch 1/200] [Batch 258/938] [D loss: 0.696141] [G loss: 0.913124]\n",
            "[Epoch 1/200] [Batch 259/938] [D loss: 0.694540] [G loss: 0.918937]\n",
            "[Epoch 1/200] [Batch 260/938] [D loss: 0.700592] [G loss: 0.914561]\n",
            "[Epoch 1/200] [Batch 261/938] [D loss: 0.702113] [G loss: 0.916243]\n",
            "[Epoch 1/200] [Batch 262/938] [D loss: 0.695527] [G loss: 0.917495]\n",
            "[Epoch 1/200] [Batch 263/938] [D loss: 0.698055] [G loss: 0.914694]\n",
            "[Epoch 1/200] [Batch 264/938] [D loss: 0.694212] [G loss: 0.918284]\n",
            "[Epoch 1/200] [Batch 265/938] [D loss: 0.691153] [G loss: 0.917325]\n",
            "[Epoch 1/200] [Batch 266/938] [D loss: 0.698484] [G loss: 0.913688]\n",
            "[Epoch 1/200] [Batch 267/938] [D loss: 0.695191] [G loss: 0.912448]\n",
            "[Epoch 1/200] [Batch 268/938] [D loss: 0.701100] [G loss: 0.917019]\n",
            "[Epoch 1/200] [Batch 269/938] [D loss: 0.695524] [G loss: 0.915485]\n",
            "[Epoch 1/200] [Batch 270/938] [D loss: 0.692677] [G loss: 0.917752]\n",
            "[Epoch 1/200] [Batch 271/938] [D loss: 0.694771] [G loss: 0.915648]\n",
            "[Epoch 1/200] [Batch 272/938] [D loss: 0.693505] [G loss: 0.918258]\n",
            "[Epoch 1/200] [Batch 273/938] [D loss: 0.698732] [G loss: 0.918677]\n",
            "[Epoch 1/200] [Batch 274/938] [D loss: 0.693633] [G loss: 0.916731]\n",
            "[Epoch 1/200] [Batch 275/938] [D loss: 0.693060] [G loss: 0.912185]\n",
            "[Epoch 1/200] [Batch 276/938] [D loss: 0.698065] [G loss: 0.915387]\n",
            "[Epoch 1/200] [Batch 277/938] [D loss: 0.696090] [G loss: 0.912735]\n",
            "[Epoch 1/200] [Batch 278/938] [D loss: 0.697110] [G loss: 0.914567]\n",
            "[Epoch 1/200] [Batch 279/938] [D loss: 0.691416] [G loss: 0.911810]\n",
            "[Epoch 1/200] [Batch 280/938] [D loss: 0.692403] [G loss: 0.911425]\n",
            "[Epoch 1/200] [Batch 281/938] [D loss: 0.697476] [G loss: 0.914579]\n",
            "[Epoch 1/200] [Batch 282/938] [D loss: 0.694989] [G loss: 0.911864]\n",
            "[Epoch 1/200] [Batch 283/938] [D loss: 0.691758] [G loss: 0.914770]\n",
            "[Epoch 1/200] [Batch 284/938] [D loss: 0.693823] [G loss: 0.914322]\n",
            "[Epoch 1/200] [Batch 285/938] [D loss: 0.689070] [G loss: 0.918522]\n",
            "[Epoch 1/200] [Batch 286/938] [D loss: 0.700981] [G loss: 0.916209]\n",
            "[Epoch 1/200] [Batch 287/938] [D loss: 0.693157] [G loss: 0.915654]\n",
            "[Epoch 1/200] [Batch 288/938] [D loss: 0.697298] [G loss: 0.915084]\n",
            "[Epoch 1/200] [Batch 289/938] [D loss: 0.688131] [G loss: 0.913188]\n",
            "[Epoch 1/200] [Batch 290/938] [D loss: 0.697224] [G loss: 0.912034]\n",
            "[Epoch 1/200] [Batch 291/938] [D loss: 0.692098] [G loss: 0.918660]\n",
            "[Epoch 1/200] [Batch 292/938] [D loss: 0.695458] [G loss: 0.913665]\n",
            "[Epoch 1/200] [Batch 293/938] [D loss: 0.692939] [G loss: 0.913038]\n",
            "[Epoch 1/200] [Batch 294/938] [D loss: 0.692690] [G loss: 0.919426]\n",
            "[Epoch 1/200] [Batch 295/938] [D loss: 0.691756] [G loss: 0.913342]\n",
            "[Epoch 1/200] [Batch 296/938] [D loss: 0.692971] [G loss: 0.912578]\n",
            "[Epoch 1/200] [Batch 297/938] [D loss: 0.697255] [G loss: 0.914087]\n",
            "[Epoch 1/200] [Batch 298/938] [D loss: 0.694268] [G loss: 0.918155]\n",
            "[Epoch 1/200] [Batch 299/938] [D loss: 0.702697] [G loss: 0.915345]\n",
            "[Epoch 1/200] [Batch 300/938] [D loss: 0.688989] [G loss: 0.921620]\n",
            "[Epoch 1/200] [Batch 301/938] [D loss: 0.694418] [G loss: 0.918249]\n",
            "[Epoch 1/200] [Batch 302/938] [D loss: 0.697535] [G loss: 0.913305]\n",
            "[Epoch 1/200] [Batch 303/938] [D loss: 0.694189] [G loss: 0.912544]\n",
            "[Epoch 1/200] [Batch 304/938] [D loss: 0.695648] [G loss: 0.910971]\n",
            "[Epoch 1/200] [Batch 305/938] [D loss: 0.694620] [G loss: 0.914376]\n",
            "[Epoch 1/200] [Batch 306/938] [D loss: 0.693139] [G loss: 0.911976]\n",
            "[Epoch 1/200] [Batch 307/938] [D loss: 0.700298] [G loss: 0.912652]\n",
            "[Epoch 1/200] [Batch 308/938] [D loss: 0.702136] [G loss: 0.917469]\n",
            "[Epoch 1/200] [Batch 309/938] [D loss: 0.693849] [G loss: 0.913521]\n",
            "[Epoch 1/200] [Batch 310/938] [D loss: 0.701057] [G loss: 0.916321]\n",
            "[Epoch 1/200] [Batch 311/938] [D loss: 0.688328] [G loss: 0.920581]\n",
            "[Epoch 1/200] [Batch 312/938] [D loss: 0.698081] [G loss: 0.916697]\n",
            "[Epoch 1/200] [Batch 313/938] [D loss: 0.698495] [G loss: 0.917227]\n",
            "[Epoch 1/200] [Batch 314/938] [D loss: 0.687903] [G loss: 0.910997]\n",
            "[Epoch 1/200] [Batch 315/938] [D loss: 0.693225] [G loss: 0.913671]\n",
            "[Epoch 1/200] [Batch 316/938] [D loss: 0.698545] [G loss: 0.916668]\n",
            "[Epoch 1/200] [Batch 317/938] [D loss: 0.699688] [G loss: 0.915661]\n",
            "[Epoch 1/200] [Batch 318/938] [D loss: 0.696409] [G loss: 0.916940]\n",
            "[Epoch 1/200] [Batch 319/938] [D loss: 0.697654] [G loss: 0.914459]\n",
            "[Epoch 1/200] [Batch 320/938] [D loss: 0.697996] [G loss: 0.915735]\n",
            "[Epoch 1/200] [Batch 321/938] [D loss: 0.695028] [G loss: 0.915764]\n",
            "[Epoch 1/200] [Batch 322/938] [D loss: 0.698634] [G loss: 0.915961]\n",
            "[Epoch 1/200] [Batch 323/938] [D loss: 0.694198] [G loss: 0.920267]\n",
            "[Epoch 1/200] [Batch 324/938] [D loss: 0.695838] [G loss: 0.911213]\n",
            "[Epoch 1/200] [Batch 325/938] [D loss: 0.697130] [G loss: 0.913346]\n",
            "[Epoch 1/200] [Batch 326/938] [D loss: 0.693468] [G loss: 0.912300]\n",
            "[Epoch 1/200] [Batch 327/938] [D loss: 0.702622] [G loss: 0.913068]\n",
            "[Epoch 1/200] [Batch 328/938] [D loss: 0.698259] [G loss: 0.916406]\n",
            "[Epoch 1/200] [Batch 329/938] [D loss: 0.702721] [G loss: 0.916426]\n",
            "[Epoch 1/200] [Batch 330/938] [D loss: 0.691663] [G loss: 0.912988]\n",
            "[Epoch 1/200] [Batch 331/938] [D loss: 0.698607] [G loss: 0.911790]\n",
            "[Epoch 1/200] [Batch 332/938] [D loss: 0.697152] [G loss: 0.912734]\n",
            "[Epoch 1/200] [Batch 333/938] [D loss: 0.693915] [G loss: 0.915406]\n",
            "[Epoch 1/200] [Batch 334/938] [D loss: 0.699063] [G loss: 0.918575]\n",
            "[Epoch 1/200] [Batch 335/938] [D loss: 0.696426] [G loss: 0.914572]\n",
            "[Epoch 1/200] [Batch 336/938] [D loss: 0.696441] [G loss: 0.917231]\n",
            "[Epoch 1/200] [Batch 337/938] [D loss: 0.695841] [G loss: 0.915169]\n",
            "[Epoch 1/200] [Batch 338/938] [D loss: 0.696145] [G loss: 0.919121]\n",
            "[Epoch 1/200] [Batch 339/938] [D loss: 0.697140] [G loss: 0.913288]\n",
            "[Epoch 1/200] [Batch 340/938] [D loss: 0.695157] [G loss: 0.915596]\n",
            "[Epoch 1/200] [Batch 341/938] [D loss: 0.694311] [G loss: 0.915715]\n",
            "[Epoch 1/200] [Batch 342/938] [D loss: 0.694767] [G loss: 0.913245]\n",
            "[Epoch 1/200] [Batch 343/938] [D loss: 0.699616] [G loss: 0.908470]\n",
            "[Epoch 1/200] [Batch 344/938] [D loss: 0.700713] [G loss: 0.911005]\n",
            "[Epoch 1/200] [Batch 345/938] [D loss: 0.691586] [G loss: 0.915888]\n",
            "[Epoch 1/200] [Batch 346/938] [D loss: 0.691472] [G loss: 0.919549]\n",
            "[Epoch 1/200] [Batch 347/938] [D loss: 0.700074] [G loss: 0.915162]\n",
            "[Epoch 1/200] [Batch 348/938] [D loss: 0.696146] [G loss: 0.914309]\n",
            "[Epoch 1/200] [Batch 349/938] [D loss: 0.697740] [G loss: 0.913367]\n",
            "[Epoch 1/200] [Batch 350/938] [D loss: 0.694676] [G loss: 0.912409]\n",
            "[Epoch 1/200] [Batch 351/938] [D loss: 0.695264] [G loss: 0.912407]\n",
            "[Epoch 1/200] [Batch 352/938] [D loss: 0.692120] [G loss: 0.917960]\n",
            "[Epoch 1/200] [Batch 353/938] [D loss: 0.691627] [G loss: 0.913007]\n",
            "[Epoch 1/200] [Batch 354/938] [D loss: 0.694911] [G loss: 0.917232]\n",
            "[Epoch 1/200] [Batch 355/938] [D loss: 0.692822] [G loss: 0.912967]\n",
            "[Epoch 1/200] [Batch 356/938] [D loss: 0.698837] [G loss: 0.914188]\n",
            "[Epoch 1/200] [Batch 357/938] [D loss: 0.703516] [G loss: 0.914350]\n",
            "[Epoch 1/200] [Batch 358/938] [D loss: 0.692158] [G loss: 0.915456]\n",
            "[Epoch 1/200] [Batch 359/938] [D loss: 0.691860] [G loss: 0.916726]\n",
            "[Epoch 1/200] [Batch 360/938] [D loss: 0.692699] [G loss: 0.915548]\n",
            "[Epoch 1/200] [Batch 361/938] [D loss: 0.696300] [G loss: 0.916328]\n",
            "[Epoch 1/200] [Batch 362/938] [D loss: 0.696049] [G loss: 0.920325]\n",
            "[Epoch 1/200] [Batch 363/938] [D loss: 0.692862] [G loss: 0.912697]\n",
            "[Epoch 1/200] [Batch 364/938] [D loss: 0.694502] [G loss: 0.914555]\n",
            "[Epoch 1/200] [Batch 365/938] [D loss: 0.700300] [G loss: 0.913054]\n",
            "[Epoch 1/200] [Batch 366/938] [D loss: 0.694819] [G loss: 0.915299]\n",
            "[Epoch 1/200] [Batch 367/938] [D loss: 0.697345] [G loss: 0.909803]\n",
            "[Epoch 1/200] [Batch 368/938] [D loss: 0.693885] [G loss: 0.913425]\n",
            "[Epoch 1/200] [Batch 369/938] [D loss: 0.695966] [G loss: 0.916023]\n",
            "[Epoch 1/200] [Batch 370/938] [D loss: 0.693213] [G loss: 0.910642]\n",
            "[Epoch 1/200] [Batch 371/938] [D loss: 0.696112] [G loss: 0.916155]\n",
            "[Epoch 1/200] [Batch 372/938] [D loss: 0.695261] [G loss: 0.915969]\n",
            "[Epoch 1/200] [Batch 373/938] [D loss: 0.694246] [G loss: 0.915582]\n",
            "[Epoch 1/200] [Batch 374/938] [D loss: 0.693262] [G loss: 0.914841]\n",
            "[Epoch 1/200] [Batch 375/938] [D loss: 0.693764] [G loss: 0.915057]\n",
            "[Epoch 1/200] [Batch 376/938] [D loss: 0.699163] [G loss: 0.914789]\n",
            "[Epoch 1/200] [Batch 377/938] [D loss: 0.698994] [G loss: 0.915526]\n",
            "[Epoch 1/200] [Batch 378/938] [D loss: 0.699377] [G loss: 0.915413]\n",
            "[Epoch 1/200] [Batch 379/938] [D loss: 0.690604] [G loss: 0.915612]\n",
            "[Epoch 1/200] [Batch 380/938] [D loss: 0.699474] [G loss: 0.911041]\n",
            "[Epoch 1/200] [Batch 381/938] [D loss: 0.699257] [G loss: 0.917032]\n",
            "[Epoch 1/200] [Batch 382/938] [D loss: 0.694638] [G loss: 0.918965]\n",
            "[Epoch 1/200] [Batch 383/938] [D loss: 0.688404] [G loss: 0.912335]\n",
            "[Epoch 1/200] [Batch 384/938] [D loss: 0.701040] [G loss: 0.914781]\n",
            "[Epoch 1/200] [Batch 385/938] [D loss: 0.695547] [G loss: 0.915397]\n",
            "[Epoch 1/200] [Batch 386/938] [D loss: 0.695972] [G loss: 0.914822]\n",
            "[Epoch 1/200] [Batch 387/938] [D loss: 0.693521] [G loss: 0.912650]\n",
            "[Epoch 1/200] [Batch 388/938] [D loss: 0.694539] [G loss: 0.915635]\n",
            "[Epoch 1/200] [Batch 389/938] [D loss: 0.694565] [G loss: 0.913363]\n",
            "[Epoch 1/200] [Batch 390/938] [D loss: 0.697948] [G loss: 0.914475]\n",
            "[Epoch 1/200] [Batch 391/938] [D loss: 0.692827] [G loss: 0.908516]\n",
            "[Epoch 1/200] [Batch 392/938] [D loss: 0.691898] [G loss: 0.917526]\n",
            "[Epoch 1/200] [Batch 393/938] [D loss: 0.694725] [G loss: 0.912981]\n",
            "[Epoch 1/200] [Batch 394/938] [D loss: 0.693974] [G loss: 0.917718]\n",
            "[Epoch 1/200] [Batch 395/938] [D loss: 0.693287] [G loss: 0.912140]\n",
            "[Epoch 1/200] [Batch 396/938] [D loss: 0.697410] [G loss: 0.918617]\n",
            "[Epoch 1/200] [Batch 397/938] [D loss: 0.697201] [G loss: 0.915454]\n",
            "[Epoch 1/200] [Batch 398/938] [D loss: 0.695351] [G loss: 0.913567]\n",
            "[Epoch 1/200] [Batch 399/938] [D loss: 0.696177] [G loss: 0.909347]\n",
            "[Epoch 1/200] [Batch 400/938] [D loss: 0.699022] [G loss: 0.912211]\n",
            "[Epoch 1/200] [Batch 401/938] [D loss: 0.689835] [G loss: 0.913903]\n",
            "[Epoch 1/200] [Batch 402/938] [D loss: 0.699569] [G loss: 0.911135]\n",
            "[Epoch 1/200] [Batch 403/938] [D loss: 0.693751] [G loss: 0.914789]\n",
            "[Epoch 1/200] [Batch 404/938] [D loss: 0.694800] [G loss: 0.912810]\n",
            "[Epoch 1/200] [Batch 405/938] [D loss: 0.691991] [G loss: 0.917800]\n",
            "[Epoch 1/200] [Batch 406/938] [D loss: 0.699519] [G loss: 0.917779]\n",
            "[Epoch 1/200] [Batch 407/938] [D loss: 0.695056] [G loss: 0.916561]\n",
            "[Epoch 1/200] [Batch 408/938] [D loss: 0.694483] [G loss: 0.921689]\n",
            "[Epoch 1/200] [Batch 409/938] [D loss: 0.695682] [G loss: 0.915230]\n",
            "[Epoch 1/200] [Batch 410/938] [D loss: 0.689863] [G loss: 0.914876]\n",
            "[Epoch 1/200] [Batch 411/938] [D loss: 0.695830] [G loss: 0.918040]\n",
            "[Epoch 1/200] [Batch 412/938] [D loss: 0.700593] [G loss: 0.920348]\n",
            "[Epoch 1/200] [Batch 413/938] [D loss: 0.702033] [G loss: 0.916213]\n",
            "[Epoch 1/200] [Batch 414/938] [D loss: 0.695564] [G loss: 0.912965]\n",
            "[Epoch 1/200] [Batch 415/938] [D loss: 0.692312] [G loss: 0.912883]\n",
            "[Epoch 1/200] [Batch 416/938] [D loss: 0.702347] [G loss: 0.920938]\n",
            "[Epoch 1/200] [Batch 417/938] [D loss: 0.693261] [G loss: 0.914011]\n",
            "[Epoch 1/200] [Batch 418/938] [D loss: 0.696272] [G loss: 0.917393]\n",
            "[Epoch 1/200] [Batch 419/938] [D loss: 0.698745] [G loss: 0.912568]\n",
            "[Epoch 1/200] [Batch 420/938] [D loss: 0.697870] [G loss: 0.915646]\n",
            "[Epoch 1/200] [Batch 421/938] [D loss: 0.698279] [G loss: 0.911996]\n",
            "[Epoch 1/200] [Batch 422/938] [D loss: 0.695888] [G loss: 0.917387]\n",
            "[Epoch 1/200] [Batch 423/938] [D loss: 0.700162] [G loss: 0.912946]\n",
            "[Epoch 1/200] [Batch 424/938] [D loss: 0.693790] [G loss: 0.913569]\n",
            "[Epoch 1/200] [Batch 425/938] [D loss: 0.697210] [G loss: 0.914652]\n",
            "[Epoch 1/200] [Batch 426/938] [D loss: 0.699705] [G loss: 0.916350]\n",
            "[Epoch 1/200] [Batch 427/938] [D loss: 0.694618] [G loss: 0.914991]\n",
            "[Epoch 1/200] [Batch 428/938] [D loss: 0.695783] [G loss: 0.917370]\n",
            "[Epoch 1/200] [Batch 429/938] [D loss: 0.689068] [G loss: 0.919907]\n",
            "[Epoch 1/200] [Batch 430/938] [D loss: 0.695783] [G loss: 0.917182]\n",
            "[Epoch 1/200] [Batch 431/938] [D loss: 0.697961] [G loss: 0.918137]\n",
            "[Epoch 1/200] [Batch 432/938] [D loss: 0.694198] [G loss: 0.913971]\n",
            "[Epoch 1/200] [Batch 433/938] [D loss: 0.695628] [G loss: 0.912741]\n",
            "[Epoch 1/200] [Batch 434/938] [D loss: 0.686869] [G loss: 0.914940]\n",
            "[Epoch 1/200] [Batch 435/938] [D loss: 0.698496] [G loss: 0.914359]\n",
            "[Epoch 1/200] [Batch 436/938] [D loss: 0.690667] [G loss: 0.916397]\n",
            "[Epoch 1/200] [Batch 437/938] [D loss: 0.694222] [G loss: 0.913193]\n",
            "[Epoch 1/200] [Batch 438/938] [D loss: 0.696762] [G loss: 0.914101]\n",
            "[Epoch 1/200] [Batch 439/938] [D loss: 0.696159] [G loss: 0.916969]\n",
            "[Epoch 1/200] [Batch 440/938] [D loss: 0.697669] [G loss: 0.920697]\n",
            "[Epoch 1/200] [Batch 441/938] [D loss: 0.696728] [G loss: 0.917624]\n",
            "[Epoch 1/200] [Batch 442/938] [D loss: 0.692660] [G loss: 0.913203]\n",
            "[Epoch 1/200] [Batch 443/938] [D loss: 0.693942] [G loss: 0.913306]\n",
            "[Epoch 1/200] [Batch 444/938] [D loss: 0.691929] [G loss: 0.916794]\n",
            "[Epoch 1/200] [Batch 445/938] [D loss: 0.700493] [G loss: 0.915054]\n",
            "[Epoch 1/200] [Batch 446/938] [D loss: 0.695321] [G loss: 0.915312]\n",
            "[Epoch 1/200] [Batch 447/938] [D loss: 0.690956] [G loss: 0.916748]\n",
            "[Epoch 1/200] [Batch 448/938] [D loss: 0.701562] [G loss: 0.917451]\n",
            "[Epoch 1/200] [Batch 449/938] [D loss: 0.700984] [G loss: 0.917330]\n",
            "[Epoch 1/200] [Batch 450/938] [D loss: 0.691494] [G loss: 0.917029]\n",
            "[Epoch 1/200] [Batch 451/938] [D loss: 0.703012] [G loss: 0.913269]\n",
            "[Epoch 1/200] [Batch 452/938] [D loss: 0.690390] [G loss: 0.915427]\n",
            "[Epoch 1/200] [Batch 453/938] [D loss: 0.699244] [G loss: 0.917526]\n",
            "[Epoch 1/200] [Batch 454/938] [D loss: 0.701892] [G loss: 0.911673]\n",
            "[Epoch 1/200] [Batch 455/938] [D loss: 0.699854] [G loss: 0.912808]\n",
            "[Epoch 1/200] [Batch 456/938] [D loss: 0.693563] [G loss: 0.913027]\n",
            "[Epoch 1/200] [Batch 457/938] [D loss: 0.699471] [G loss: 0.915312]\n",
            "[Epoch 1/200] [Batch 458/938] [D loss: 0.696171] [G loss: 0.911744]\n",
            "[Epoch 1/200] [Batch 459/938] [D loss: 0.697422] [G loss: 0.919253]\n",
            "[Epoch 1/200] [Batch 460/938] [D loss: 0.691476] [G loss: 0.917561]\n",
            "[Epoch 1/200] [Batch 461/938] [D loss: 0.693181] [G loss: 0.917193]\n",
            "[Epoch 1/200] [Batch 462/938] [D loss: 0.694800] [G loss: 0.909607]\n",
            "[Epoch 1/200] [Batch 463/938] [D loss: 0.693377] [G loss: 0.917482]\n",
            "[Epoch 1/200] [Batch 464/938] [D loss: 0.689314] [G loss: 0.911071]\n",
            "[Epoch 1/200] [Batch 465/938] [D loss: 0.700287] [G loss: 0.914584]\n",
            "[Epoch 1/200] [Batch 466/938] [D loss: 0.696931] [G loss: 0.911620]\n",
            "[Epoch 1/200] [Batch 467/938] [D loss: 0.691278] [G loss: 0.911244]\n",
            "[Epoch 1/200] [Batch 468/938] [D loss: 0.698902] [G loss: 0.911618]\n",
            "[Epoch 1/200] [Batch 469/938] [D loss: 0.687024] [G loss: 0.917743]\n",
            "[Epoch 1/200] [Batch 470/938] [D loss: 0.694061] [G loss: 0.913699]\n",
            "[Epoch 1/200] [Batch 471/938] [D loss: 0.691575] [G loss: 0.917843]\n",
            "[Epoch 1/200] [Batch 472/938] [D loss: 0.694638] [G loss: 0.914495]\n",
            "[Epoch 1/200] [Batch 473/938] [D loss: 0.699784] [G loss: 0.913577]\n",
            "[Epoch 1/200] [Batch 474/938] [D loss: 0.697455] [G loss: 0.915558]\n",
            "[Epoch 1/200] [Batch 475/938] [D loss: 0.690885] [G loss: 0.918006]\n",
            "[Epoch 1/200] [Batch 476/938] [D loss: 0.694800] [G loss: 0.909037]\n",
            "[Epoch 1/200] [Batch 477/938] [D loss: 0.693228] [G loss: 0.917841]\n",
            "[Epoch 1/200] [Batch 478/938] [D loss: 0.693779] [G loss: 0.920009]\n",
            "[Epoch 1/200] [Batch 479/938] [D loss: 0.694588] [G loss: 0.918534]\n",
            "[Epoch 1/200] [Batch 480/938] [D loss: 0.692528] [G loss: 0.915921]\n",
            "[Epoch 1/200] [Batch 481/938] [D loss: 0.693233] [G loss: 0.913981]\n",
            "[Epoch 1/200] [Batch 482/938] [D loss: 0.695786] [G loss: 0.914782]\n",
            "[Epoch 1/200] [Batch 483/938] [D loss: 0.700605] [G loss: 0.913200]\n",
            "[Epoch 1/200] [Batch 484/938] [D loss: 0.690979] [G loss: 0.914955]\n",
            "[Epoch 1/200] [Batch 485/938] [D loss: 0.696669] [G loss: 0.917216]\n",
            "[Epoch 1/200] [Batch 486/938] [D loss: 0.689949] [G loss: 0.915906]\n",
            "[Epoch 1/200] [Batch 487/938] [D loss: 0.692875] [G loss: 0.913010]\n",
            "[Epoch 1/200] [Batch 488/938] [D loss: 0.695550] [G loss: 0.914552]\n",
            "[Epoch 1/200] [Batch 489/938] [D loss: 0.687727] [G loss: 0.910044]\n",
            "[Epoch 1/200] [Batch 490/938] [D loss: 0.691606] [G loss: 0.911049]\n",
            "[Epoch 1/200] [Batch 491/938] [D loss: 0.696066] [G loss: 0.914095]\n",
            "[Epoch 1/200] [Batch 492/938] [D loss: 0.690999] [G loss: 0.915722]\n",
            "[Epoch 1/200] [Batch 493/938] [D loss: 0.691004] [G loss: 0.912930]\n",
            "[Epoch 1/200] [Batch 494/938] [D loss: 0.694521] [G loss: 0.918688]\n",
            "[Epoch 1/200] [Batch 495/938] [D loss: 0.694984] [G loss: 0.915101]\n",
            "[Epoch 1/200] [Batch 496/938] [D loss: 0.697998] [G loss: 0.913846]\n",
            "[Epoch 1/200] [Batch 497/938] [D loss: 0.695650] [G loss: 0.913961]\n",
            "[Epoch 1/200] [Batch 498/938] [D loss: 0.700025] [G loss: 0.916792]\n",
            "[Epoch 1/200] [Batch 499/938] [D loss: 0.695297] [G loss: 0.913268]\n",
            "[Epoch 1/200] [Batch 500/938] [D loss: 0.699007] [G loss: 0.914119]\n",
            "[Epoch 1/200] [Batch 501/938] [D loss: 0.693873] [G loss: 0.917185]\n",
            "[Epoch 1/200] [Batch 502/938] [D loss: 0.691739] [G loss: 0.916436]\n",
            "[Epoch 1/200] [Batch 503/938] [D loss: 0.693405] [G loss: 0.919348]\n",
            "[Epoch 1/200] [Batch 504/938] [D loss: 0.697576] [G loss: 0.916658]\n",
            "[Epoch 1/200] [Batch 505/938] [D loss: 0.695929] [G loss: 0.916304]\n",
            "[Epoch 1/200] [Batch 506/938] [D loss: 0.696519] [G loss: 0.916117]\n",
            "[Epoch 1/200] [Batch 507/938] [D loss: 0.694422] [G loss: 0.915920]\n",
            "[Epoch 1/200] [Batch 508/938] [D loss: 0.696291] [G loss: 0.912752]\n",
            "[Epoch 1/200] [Batch 509/938] [D loss: 0.689610] [G loss: 0.914466]\n",
            "[Epoch 1/200] [Batch 510/938] [D loss: 0.699423] [G loss: 0.917967]\n",
            "[Epoch 1/200] [Batch 511/938] [D loss: 0.698098] [G loss: 0.915941]\n",
            "[Epoch 1/200] [Batch 512/938] [D loss: 0.697903] [G loss: 0.915407]\n",
            "[Epoch 1/200] [Batch 513/938] [D loss: 0.688533] [G loss: 0.915337]\n",
            "[Epoch 1/200] [Batch 514/938] [D loss: 0.691096] [G loss: 0.915632]\n",
            "[Epoch 1/200] [Batch 515/938] [D loss: 0.700192] [G loss: 0.912476]\n",
            "[Epoch 1/200] [Batch 516/938] [D loss: 0.698925] [G loss: 0.916840]\n",
            "[Epoch 1/200] [Batch 517/938] [D loss: 0.697666] [G loss: 0.915699]\n",
            "[Epoch 1/200] [Batch 518/938] [D loss: 0.695686] [G loss: 0.914487]\n",
            "[Epoch 1/200] [Batch 519/938] [D loss: 0.695868] [G loss: 0.913273]\n",
            "[Epoch 1/200] [Batch 520/938] [D loss: 0.692261] [G loss: 0.914711]\n",
            "[Epoch 1/200] [Batch 521/938] [D loss: 0.692679] [G loss: 0.913047]\n",
            "[Epoch 1/200] [Batch 522/938] [D loss: 0.691048] [G loss: 0.915164]\n",
            "[Epoch 1/200] [Batch 523/938] [D loss: 0.696893] [G loss: 0.913775]\n",
            "[Epoch 1/200] [Batch 524/938] [D loss: 0.696684] [G loss: 0.917055]\n",
            "[Epoch 1/200] [Batch 525/938] [D loss: 0.698361] [G loss: 0.915061]\n",
            "[Epoch 1/200] [Batch 526/938] [D loss: 0.696557] [G loss: 0.915618]\n",
            "[Epoch 1/200] [Batch 527/938] [D loss: 0.696801] [G loss: 0.913350]\n",
            "[Epoch 1/200] [Batch 528/938] [D loss: 0.699673] [G loss: 0.914745]\n",
            "[Epoch 1/200] [Batch 529/938] [D loss: 0.696495] [G loss: 0.915510]\n",
            "[Epoch 1/200] [Batch 530/938] [D loss: 0.700638] [G loss: 0.916194]\n",
            "[Epoch 1/200] [Batch 531/938] [D loss: 0.696473] [G loss: 0.913765]\n",
            "[Epoch 1/200] [Batch 532/938] [D loss: 0.692905] [G loss: 0.915557]\n",
            "[Epoch 1/200] [Batch 533/938] [D loss: 0.691113] [G loss: 0.918653]\n",
            "[Epoch 1/200] [Batch 534/938] [D loss: 0.698353] [G loss: 0.909523]\n",
            "[Epoch 1/200] [Batch 535/938] [D loss: 0.694489] [G loss: 0.910317]\n",
            "[Epoch 1/200] [Batch 536/938] [D loss: 0.696209] [G loss: 0.918804]\n",
            "[Epoch 1/200] [Batch 537/938] [D loss: 0.694987] [G loss: 0.912502]\n",
            "[Epoch 1/200] [Batch 538/938] [D loss: 0.694915] [G loss: 0.912083]\n",
            "[Epoch 1/200] [Batch 539/938] [D loss: 0.701044] [G loss: 0.917804]\n",
            "[Epoch 1/200] [Batch 540/938] [D loss: 0.698250] [G loss: 0.915297]\n",
            "[Epoch 1/200] [Batch 541/938] [D loss: 0.695669] [G loss: 0.915950]\n",
            "[Epoch 1/200] [Batch 542/938] [D loss: 0.699585] [G loss: 0.914974]\n",
            "[Epoch 1/200] [Batch 543/938] [D loss: 0.699935] [G loss: 0.915995]\n",
            "[Epoch 1/200] [Batch 544/938] [D loss: 0.691117] [G loss: 0.916993]\n",
            "[Epoch 1/200] [Batch 545/938] [D loss: 0.701028] [G loss: 0.915431]\n",
            "[Epoch 1/200] [Batch 546/938] [D loss: 0.694041] [G loss: 0.921217]\n",
            "[Epoch 1/200] [Batch 547/938] [D loss: 0.689201] [G loss: 0.916936]\n",
            "[Epoch 1/200] [Batch 548/938] [D loss: 0.701700] [G loss: 0.914479]\n",
            "[Epoch 1/200] [Batch 549/938] [D loss: 0.691237] [G loss: 0.915862]\n",
            "[Epoch 1/200] [Batch 550/938] [D loss: 0.692970] [G loss: 0.912619]\n",
            "[Epoch 1/200] [Batch 551/938] [D loss: 0.701458] [G loss: 0.919615]\n",
            "[Epoch 1/200] [Batch 552/938] [D loss: 0.690687] [G loss: 0.920386]\n",
            "[Epoch 1/200] [Batch 553/938] [D loss: 0.694870] [G loss: 0.910077]\n",
            "[Epoch 1/200] [Batch 554/938] [D loss: 0.689221] [G loss: 0.916966]\n",
            "[Epoch 1/200] [Batch 555/938] [D loss: 0.693171] [G loss: 0.914233]\n",
            "[Epoch 1/200] [Batch 556/938] [D loss: 0.696008] [G loss: 0.912307]\n",
            "[Epoch 1/200] [Batch 557/938] [D loss: 0.693413] [G loss: 0.917501]\n",
            "[Epoch 1/200] [Batch 558/938] [D loss: 0.694629] [G loss: 0.914467]\n",
            "[Epoch 1/200] [Batch 559/938] [D loss: 0.695181] [G loss: 0.913672]\n",
            "[Epoch 1/200] [Batch 560/938] [D loss: 0.698760] [G loss: 0.920826]\n",
            "[Epoch 1/200] [Batch 561/938] [D loss: 0.698601] [G loss: 0.913300]\n",
            "[Epoch 1/200] [Batch 562/938] [D loss: 0.694964] [G loss: 0.911474]\n",
            "[Epoch 1/200] [Batch 563/938] [D loss: 0.692451] [G loss: 0.911937]\n",
            "[Epoch 1/200] [Batch 564/938] [D loss: 0.698291] [G loss: 0.914282]\n",
            "[Epoch 1/200] [Batch 565/938] [D loss: 0.694360] [G loss: 0.918476]\n",
            "[Epoch 1/200] [Batch 566/938] [D loss: 0.695381] [G loss: 0.912497]\n",
            "[Epoch 1/200] [Batch 567/938] [D loss: 0.698224] [G loss: 0.916684]\n",
            "[Epoch 1/200] [Batch 568/938] [D loss: 0.690327] [G loss: 0.912910]\n",
            "[Epoch 1/200] [Batch 569/938] [D loss: 0.699210] [G loss: 0.914254]\n",
            "[Epoch 1/200] [Batch 570/938] [D loss: 0.692758] [G loss: 0.913697]\n",
            "[Epoch 1/200] [Batch 571/938] [D loss: 0.691173] [G loss: 0.911407]\n",
            "[Epoch 1/200] [Batch 572/938] [D loss: 0.691928] [G loss: 0.911326]\n",
            "[Epoch 1/200] [Batch 573/938] [D loss: 0.691448] [G loss: 0.914322]\n",
            "[Epoch 1/200] [Batch 574/938] [D loss: 0.692338] [G loss: 0.913527]\n",
            "[Epoch 1/200] [Batch 575/938] [D loss: 0.698690] [G loss: 0.916669]\n",
            "[Epoch 1/200] [Batch 576/938] [D loss: 0.691957] [G loss: 0.914665]\n",
            "[Epoch 1/200] [Batch 577/938] [D loss: 0.696988] [G loss: 0.916640]\n",
            "[Epoch 1/200] [Batch 578/938] [D loss: 0.696185] [G loss: 0.916581]\n",
            "[Epoch 1/200] [Batch 579/938] [D loss: 0.693933] [G loss: 0.915705]\n",
            "[Epoch 1/200] [Batch 580/938] [D loss: 0.698361] [G loss: 0.914936]\n",
            "[Epoch 1/200] [Batch 581/938] [D loss: 0.698036] [G loss: 0.915222]\n",
            "[Epoch 1/200] [Batch 582/938] [D loss: 0.696742] [G loss: 0.914110]\n",
            "[Epoch 1/200] [Batch 583/938] [D loss: 0.690777] [G loss: 0.912737]\n",
            "[Epoch 1/200] [Batch 584/938] [D loss: 0.694975] [G loss: 0.912482]\n",
            "[Epoch 1/200] [Batch 585/938] [D loss: 0.696208] [G loss: 0.913736]\n",
            "[Epoch 1/200] [Batch 586/938] [D loss: 0.695551] [G loss: 0.910355]\n",
            "[Epoch 1/200] [Batch 587/938] [D loss: 0.694358] [G loss: 0.916740]\n",
            "[Epoch 1/200] [Batch 588/938] [D loss: 0.697279] [G loss: 0.914877]\n",
            "[Epoch 1/200] [Batch 589/938] [D loss: 0.696546] [G loss: 0.914270]\n",
            "[Epoch 1/200] [Batch 590/938] [D loss: 0.699351] [G loss: 0.917980]\n",
            "[Epoch 1/200] [Batch 591/938] [D loss: 0.697765] [G loss: 0.914938]\n",
            "[Epoch 1/200] [Batch 592/938] [D loss: 0.692520] [G loss: 0.912775]\n",
            "[Epoch 1/200] [Batch 593/938] [D loss: 0.693430] [G loss: 0.915175]\n",
            "[Epoch 1/200] [Batch 594/938] [D loss: 0.690943] [G loss: 0.916367]\n",
            "[Epoch 1/200] [Batch 595/938] [D loss: 0.694048] [G loss: 0.911054]\n",
            "[Epoch 1/200] [Batch 596/938] [D loss: 0.694359] [G loss: 0.915513]\n",
            "[Epoch 1/200] [Batch 597/938] [D loss: 0.689646] [G loss: 0.914427]\n",
            "[Epoch 1/200] [Batch 598/938] [D loss: 0.692902] [G loss: 0.918308]\n",
            "[Epoch 1/200] [Batch 599/938] [D loss: 0.695353] [G loss: 0.916940]\n",
            "[Epoch 1/200] [Batch 600/938] [D loss: 0.696803] [G loss: 0.915948]\n",
            "[Epoch 1/200] [Batch 601/938] [D loss: 0.700382] [G loss: 0.912880]\n",
            "[Epoch 1/200] [Batch 602/938] [D loss: 0.689571] [G loss: 0.911885]\n",
            "[Epoch 1/200] [Batch 603/938] [D loss: 0.694225] [G loss: 0.916307]\n",
            "[Epoch 1/200] [Batch 604/938] [D loss: 0.691938] [G loss: 0.914800]\n",
            "[Epoch 1/200] [Batch 605/938] [D loss: 0.698501] [G loss: 0.915336]\n",
            "[Epoch 1/200] [Batch 606/938] [D loss: 0.692638] [G loss: 0.916220]\n",
            "[Epoch 1/200] [Batch 607/938] [D loss: 0.695896] [G loss: 0.917329]\n",
            "[Epoch 1/200] [Batch 608/938] [D loss: 0.696794] [G loss: 0.913983]\n",
            "[Epoch 1/200] [Batch 609/938] [D loss: 0.696607] [G loss: 0.915493]\n",
            "[Epoch 1/200] [Batch 610/938] [D loss: 0.691014] [G loss: 0.918375]\n",
            "[Epoch 1/200] [Batch 611/938] [D loss: 0.701381] [G loss: 0.913283]\n",
            "[Epoch 1/200] [Batch 612/938] [D loss: 0.696800] [G loss: 0.911519]\n",
            "[Epoch 1/200] [Batch 613/938] [D loss: 0.698710] [G loss: 0.915014]\n",
            "[Epoch 1/200] [Batch 614/938] [D loss: 0.695758] [G loss: 0.918256]\n",
            "[Epoch 1/200] [Batch 615/938] [D loss: 0.690998] [G loss: 0.917275]\n",
            "[Epoch 1/200] [Batch 616/938] [D loss: 0.700276] [G loss: 0.911360]\n",
            "[Epoch 1/200] [Batch 617/938] [D loss: 0.698227] [G loss: 0.913034]\n",
            "[Epoch 1/200] [Batch 618/938] [D loss: 0.699185] [G loss: 0.915411]\n",
            "[Epoch 1/200] [Batch 619/938] [D loss: 0.695609] [G loss: 0.917677]\n",
            "[Epoch 1/200] [Batch 620/938] [D loss: 0.700430] [G loss: 0.916190]\n",
            "[Epoch 1/200] [Batch 621/938] [D loss: 0.699554] [G loss: 0.914667]\n",
            "[Epoch 1/200] [Batch 622/938] [D loss: 0.690039] [G loss: 0.911402]\n",
            "[Epoch 1/200] [Batch 623/938] [D loss: 0.692748] [G loss: 0.911931]\n",
            "[Epoch 1/200] [Batch 624/938] [D loss: 0.697810] [G loss: 0.914121]\n",
            "[Epoch 1/200] [Batch 625/938] [D loss: 0.693460] [G loss: 0.914704]\n",
            "[Epoch 1/200] [Batch 626/938] [D loss: 0.696478] [G loss: 0.916861]\n",
            "[Epoch 1/200] [Batch 627/938] [D loss: 0.694683] [G loss: 0.913514]\n",
            "[Epoch 1/200] [Batch 628/938] [D loss: 0.693164] [G loss: 0.916477]\n",
            "[Epoch 1/200] [Batch 629/938] [D loss: 0.697617] [G loss: 0.911146]\n",
            "[Epoch 1/200] [Batch 630/938] [D loss: 0.697582] [G loss: 0.911977]\n",
            "[Epoch 1/200] [Batch 631/938] [D loss: 0.695309] [G loss: 0.918447]\n",
            "[Epoch 1/200] [Batch 632/938] [D loss: 0.695790] [G loss: 0.913529]\n",
            "[Epoch 1/200] [Batch 633/938] [D loss: 0.695777] [G loss: 0.917652]\n",
            "[Epoch 1/200] [Batch 634/938] [D loss: 0.697480] [G loss: 0.915989]\n",
            "[Epoch 1/200] [Batch 635/938] [D loss: 0.696219] [G loss: 0.913805]\n",
            "[Epoch 1/200] [Batch 636/938] [D loss: 0.696447] [G loss: 0.917401]\n",
            "[Epoch 1/200] [Batch 637/938] [D loss: 0.698363] [G loss: 0.914720]\n",
            "[Epoch 1/200] [Batch 638/938] [D loss: 0.698741] [G loss: 0.912623]\n",
            "[Epoch 1/200] [Batch 639/938] [D loss: 0.695817] [G loss: 0.913750]\n",
            "[Epoch 1/200] [Batch 640/938] [D loss: 0.703183] [G loss: 0.917646]\n",
            "[Epoch 1/200] [Batch 641/938] [D loss: 0.693856] [G loss: 0.919942]\n",
            "[Epoch 1/200] [Batch 642/938] [D loss: 0.694241] [G loss: 0.912742]\n",
            "[Epoch 1/200] [Batch 643/938] [D loss: 0.684701] [G loss: 0.913862]\n",
            "[Epoch 1/200] [Batch 644/938] [D loss: 0.698763] [G loss: 0.916962]\n",
            "[Epoch 1/200] [Batch 645/938] [D loss: 0.695010] [G loss: 0.915879]\n",
            "[Epoch 1/200] [Batch 646/938] [D loss: 0.694821] [G loss: 0.916752]\n",
            "[Epoch 1/200] [Batch 647/938] [D loss: 0.694244] [G loss: 0.920319]\n",
            "[Epoch 1/200] [Batch 648/938] [D loss: 0.702543] [G loss: 0.915710]\n",
            "[Epoch 1/200] [Batch 649/938] [D loss: 0.701734] [G loss: 0.914935]\n",
            "[Epoch 1/200] [Batch 650/938] [D loss: 0.697889] [G loss: 0.918824]\n",
            "[Epoch 1/200] [Batch 651/938] [D loss: 0.692891] [G loss: 0.914846]\n",
            "[Epoch 1/200] [Batch 652/938] [D loss: 0.696462] [G loss: 0.918405]\n",
            "[Epoch 1/200] [Batch 653/938] [D loss: 0.695941] [G loss: 0.912645]\n",
            "[Epoch 1/200] [Batch 654/938] [D loss: 0.694995] [G loss: 0.913392]\n",
            "[Epoch 1/200] [Batch 655/938] [D loss: 0.694722] [G loss: 0.916421]\n",
            "[Epoch 1/200] [Batch 656/938] [D loss: 0.694383] [G loss: 0.913639]\n",
            "[Epoch 1/200] [Batch 657/938] [D loss: 0.697078] [G loss: 0.911319]\n",
            "[Epoch 1/200] [Batch 658/938] [D loss: 0.694859] [G loss: 0.916995]\n",
            "[Epoch 1/200] [Batch 659/938] [D loss: 0.692039] [G loss: 0.915737]\n",
            "[Epoch 1/200] [Batch 660/938] [D loss: 0.699779] [G loss: 0.914485]\n",
            "[Epoch 1/200] [Batch 661/938] [D loss: 0.691366] [G loss: 0.917130]\n",
            "[Epoch 1/200] [Batch 662/938] [D loss: 0.698399] [G loss: 0.914139]\n",
            "[Epoch 1/200] [Batch 663/938] [D loss: 0.697542] [G loss: 0.918031]\n",
            "[Epoch 1/200] [Batch 664/938] [D loss: 0.689582] [G loss: 0.915150]\n",
            "[Epoch 1/200] [Batch 665/938] [D loss: 0.691271] [G loss: 0.914047]\n",
            "[Epoch 1/200] [Batch 666/938] [D loss: 0.692725] [G loss: 0.919030]\n",
            "[Epoch 1/200] [Batch 667/938] [D loss: 0.697631] [G loss: 0.920389]\n",
            "[Epoch 1/200] [Batch 668/938] [D loss: 0.690256] [G loss: 0.916156]\n",
            "[Epoch 1/200] [Batch 669/938] [D loss: 0.695513] [G loss: 0.916748]\n",
            "[Epoch 1/200] [Batch 670/938] [D loss: 0.697187] [G loss: 0.917509]\n",
            "[Epoch 1/200] [Batch 671/938] [D loss: 0.698377] [G loss: 0.915262]\n",
            "[Epoch 1/200] [Batch 672/938] [D loss: 0.694019] [G loss: 0.913902]\n",
            "[Epoch 1/200] [Batch 673/938] [D loss: 0.697394] [G loss: 0.912221]\n",
            "[Epoch 1/200] [Batch 674/938] [D loss: 0.694344] [G loss: 0.914518]\n",
            "[Epoch 1/200] [Batch 675/938] [D loss: 0.696450] [G loss: 0.917664]\n",
            "[Epoch 1/200] [Batch 676/938] [D loss: 0.692577] [G loss: 0.913950]\n",
            "[Epoch 1/200] [Batch 677/938] [D loss: 0.693278] [G loss: 0.918938]\n",
            "[Epoch 1/200] [Batch 678/938] [D loss: 0.696435] [G loss: 0.918541]\n",
            "[Epoch 1/200] [Batch 679/938] [D loss: 0.692950] [G loss: 0.918906]\n",
            "[Epoch 1/200] [Batch 680/938] [D loss: 0.696429] [G loss: 0.915208]\n",
            "[Epoch 1/200] [Batch 681/938] [D loss: 0.695639] [G loss: 0.912857]\n",
            "[Epoch 1/200] [Batch 682/938] [D loss: 0.697933] [G loss: 0.911816]\n",
            "[Epoch 1/200] [Batch 683/938] [D loss: 0.692683] [G loss: 0.915029]\n",
            "[Epoch 1/200] [Batch 684/938] [D loss: 0.697176] [G loss: 0.917517]\n",
            "[Epoch 1/200] [Batch 685/938] [D loss: 0.691955] [G loss: 0.914367]\n",
            "[Epoch 1/200] [Batch 686/938] [D loss: 0.694760] [G loss: 0.912623]\n",
            "[Epoch 1/200] [Batch 687/938] [D loss: 0.701288] [G loss: 0.911349]\n",
            "[Epoch 1/200] [Batch 688/938] [D loss: 0.695257] [G loss: 0.917754]\n",
            "[Epoch 1/200] [Batch 689/938] [D loss: 0.699462] [G loss: 0.918317]\n",
            "[Epoch 1/200] [Batch 690/938] [D loss: 0.698405] [G loss: 0.919273]\n",
            "[Epoch 1/200] [Batch 691/938] [D loss: 0.694621] [G loss: 0.915567]\n",
            "[Epoch 1/200] [Batch 692/938] [D loss: 0.697772] [G loss: 0.912716]\n",
            "[Epoch 1/200] [Batch 693/938] [D loss: 0.696095] [G loss: 0.915609]\n",
            "[Epoch 1/200] [Batch 694/938] [D loss: 0.696026] [G loss: 0.910470]\n",
            "[Epoch 1/200] [Batch 695/938] [D loss: 0.699935] [G loss: 0.913270]\n",
            "[Epoch 1/200] [Batch 696/938] [D loss: 0.696460] [G loss: 0.913987]\n",
            "[Epoch 1/200] [Batch 697/938] [D loss: 0.694005] [G loss: 0.918353]\n",
            "[Epoch 1/200] [Batch 698/938] [D loss: 0.696845] [G loss: 0.914949]\n",
            "[Epoch 1/200] [Batch 699/938] [D loss: 0.697076] [G loss: 0.916219]\n",
            "[Epoch 1/200] [Batch 700/938] [D loss: 0.691003] [G loss: 0.911634]\n",
            "[Epoch 1/200] [Batch 701/938] [D loss: 0.699250] [G loss: 0.914171]\n",
            "[Epoch 1/200] [Batch 702/938] [D loss: 0.692530] [G loss: 0.908794]\n",
            "[Epoch 1/200] [Batch 703/938] [D loss: 0.696683] [G loss: 0.916461]\n",
            "[Epoch 1/200] [Batch 704/938] [D loss: 0.697496] [G loss: 0.915597]\n",
            "[Epoch 1/200] [Batch 705/938] [D loss: 0.695942] [G loss: 0.913105]\n",
            "[Epoch 1/200] [Batch 706/938] [D loss: 0.692537] [G loss: 0.913352]\n",
            "[Epoch 1/200] [Batch 707/938] [D loss: 0.701345] [G loss: 0.916076]\n",
            "[Epoch 1/200] [Batch 708/938] [D loss: 0.695890] [G loss: 0.912804]\n",
            "[Epoch 1/200] [Batch 709/938] [D loss: 0.690885] [G loss: 0.919058]\n",
            "[Epoch 1/200] [Batch 710/938] [D loss: 0.694182] [G loss: 0.913420]\n",
            "[Epoch 1/200] [Batch 711/938] [D loss: 0.697014] [G loss: 0.913238]\n",
            "[Epoch 1/200] [Batch 712/938] [D loss: 0.697088] [G loss: 0.915201]\n",
            "[Epoch 1/200] [Batch 713/938] [D loss: 0.698393] [G loss: 0.921388]\n",
            "[Epoch 1/200] [Batch 714/938] [D loss: 0.698119] [G loss: 0.913723]\n",
            "[Epoch 1/200] [Batch 715/938] [D loss: 0.690008] [G loss: 0.913558]\n",
            "[Epoch 1/200] [Batch 716/938] [D loss: 0.698501] [G loss: 0.917705]\n",
            "[Epoch 1/200] [Batch 717/938] [D loss: 0.695121] [G loss: 0.913142]\n",
            "[Epoch 1/200] [Batch 718/938] [D loss: 0.695217] [G loss: 0.915585]\n",
            "[Epoch 1/200] [Batch 719/938] [D loss: 0.703007] [G loss: 0.912793]\n",
            "[Epoch 1/200] [Batch 720/938] [D loss: 0.698767] [G loss: 0.917092]\n",
            "[Epoch 1/200] [Batch 721/938] [D loss: 0.691602] [G loss: 0.914006]\n",
            "[Epoch 1/200] [Batch 722/938] [D loss: 0.700372] [G loss: 0.913721]\n",
            "[Epoch 1/200] [Batch 723/938] [D loss: 0.697267] [G loss: 0.918161]\n",
            "[Epoch 1/200] [Batch 724/938] [D loss: 0.693484] [G loss: 0.916302]\n",
            "[Epoch 1/200] [Batch 725/938] [D loss: 0.702751] [G loss: 0.913296]\n",
            "[Epoch 1/200] [Batch 726/938] [D loss: 0.693161] [G loss: 0.913240]\n",
            "[Epoch 1/200] [Batch 727/938] [D loss: 0.694534] [G loss: 0.912021]\n",
            "[Epoch 1/200] [Batch 728/938] [D loss: 0.694126] [G loss: 0.914421]\n",
            "[Epoch 1/200] [Batch 729/938] [D loss: 0.692009] [G loss: 0.918298]\n",
            "[Epoch 1/200] [Batch 730/938] [D loss: 0.693791] [G loss: 0.920758]\n",
            "[Epoch 1/200] [Batch 731/938] [D loss: 0.694664] [G loss: 0.909848]\n",
            "[Epoch 1/200] [Batch 732/938] [D loss: 0.694185] [G loss: 0.914902]\n",
            "[Epoch 1/200] [Batch 733/938] [D loss: 0.697263] [G loss: 0.916369]\n",
            "[Epoch 1/200] [Batch 734/938] [D loss: 0.691583] [G loss: 0.913660]\n",
            "[Epoch 1/200] [Batch 735/938] [D loss: 0.693426] [G loss: 0.911265]\n",
            "[Epoch 1/200] [Batch 736/938] [D loss: 0.693460] [G loss: 0.920036]\n",
            "[Epoch 1/200] [Batch 737/938] [D loss: 0.696148] [G loss: 0.920656]\n",
            "[Epoch 1/200] [Batch 738/938] [D loss: 0.693672] [G loss: 0.911316]\n",
            "[Epoch 1/200] [Batch 739/938] [D loss: 0.693854] [G loss: 0.913548]\n",
            "[Epoch 1/200] [Batch 740/938] [D loss: 0.695299] [G loss: 0.914062]\n",
            "[Epoch 1/200] [Batch 741/938] [D loss: 0.702253] [G loss: 0.911844]\n",
            "[Epoch 1/200] [Batch 742/938] [D loss: 0.695410] [G loss: 0.914419]\n",
            "[Epoch 1/200] [Batch 743/938] [D loss: 0.702036] [G loss: 0.912445]\n",
            "[Epoch 1/200] [Batch 744/938] [D loss: 0.694273] [G loss: 0.914655]\n",
            "[Epoch 1/200] [Batch 745/938] [D loss: 0.694260] [G loss: 0.915541]\n",
            "[Epoch 1/200] [Batch 746/938] [D loss: 0.698193] [G loss: 0.913363]\n",
            "[Epoch 1/200] [Batch 747/938] [D loss: 0.690636] [G loss: 0.919622]\n",
            "[Epoch 1/200] [Batch 748/938] [D loss: 0.696102] [G loss: 0.914175]\n",
            "[Epoch 1/200] [Batch 749/938] [D loss: 0.694412] [G loss: 0.917886]\n",
            "[Epoch 1/200] [Batch 750/938] [D loss: 0.694240] [G loss: 0.923109]\n",
            "[Epoch 1/200] [Batch 751/938] [D loss: 0.699002] [G loss: 0.915557]\n",
            "[Epoch 1/200] [Batch 752/938] [D loss: 0.698981] [G loss: 0.916355]\n",
            "[Epoch 1/200] [Batch 753/938] [D loss: 0.693961] [G loss: 0.915478]\n",
            "[Epoch 1/200] [Batch 754/938] [D loss: 0.697204] [G loss: 0.910412]\n",
            "[Epoch 1/200] [Batch 755/938] [D loss: 0.698472] [G loss: 0.917081]\n",
            "[Epoch 1/200] [Batch 756/938] [D loss: 0.695784] [G loss: 0.913358]\n",
            "[Epoch 1/200] [Batch 757/938] [D loss: 0.698446] [G loss: 0.916877]\n",
            "[Epoch 1/200] [Batch 758/938] [D loss: 0.692636] [G loss: 0.916926]\n",
            "[Epoch 1/200] [Batch 759/938] [D loss: 0.697020] [G loss: 0.916080]\n",
            "[Epoch 1/200] [Batch 760/938] [D loss: 0.697035] [G loss: 0.916508]\n",
            "[Epoch 1/200] [Batch 761/938] [D loss: 0.696388] [G loss: 0.917484]\n",
            "[Epoch 1/200] [Batch 762/938] [D loss: 0.694047] [G loss: 0.913167]\n",
            "[Epoch 1/200] [Batch 763/938] [D loss: 0.696449] [G loss: 0.914986]\n",
            "[Epoch 1/200] [Batch 764/938] [D loss: 0.697419] [G loss: 0.915724]\n",
            "[Epoch 1/200] [Batch 765/938] [D loss: 0.697567] [G loss: 0.913725]\n",
            "[Epoch 1/200] [Batch 766/938] [D loss: 0.702468] [G loss: 0.913847]\n",
            "[Epoch 1/200] [Batch 767/938] [D loss: 0.701691] [G loss: 0.907883]\n",
            "[Epoch 1/200] [Batch 768/938] [D loss: 0.687403] [G loss: 0.914084]\n",
            "[Epoch 1/200] [Batch 769/938] [D loss: 0.693264] [G loss: 0.910189]\n",
            "[Epoch 1/200] [Batch 770/938] [D loss: 0.692838] [G loss: 0.917075]\n",
            "[Epoch 1/200] [Batch 771/938] [D loss: 0.699762] [G loss: 0.915944]\n",
            "[Epoch 1/200] [Batch 772/938] [D loss: 0.699590] [G loss: 0.915539]\n",
            "[Epoch 1/200] [Batch 773/938] [D loss: 0.697356] [G loss: 0.914728]\n",
            "[Epoch 1/200] [Batch 774/938] [D loss: 0.694991] [G loss: 0.915283]\n",
            "[Epoch 1/200] [Batch 775/938] [D loss: 0.697132] [G loss: 0.914299]\n",
            "[Epoch 1/200] [Batch 776/938] [D loss: 0.702997] [G loss: 0.916970]\n",
            "[Epoch 1/200] [Batch 777/938] [D loss: 0.698733] [G loss: 0.915238]\n",
            "[Epoch 1/200] [Batch 778/938] [D loss: 0.699544] [G loss: 0.911921]\n",
            "[Epoch 1/200] [Batch 779/938] [D loss: 0.698369] [G loss: 0.916527]\n",
            "[Epoch 1/200] [Batch 780/938] [D loss: 0.694820] [G loss: 0.913447]\n",
            "[Epoch 1/200] [Batch 781/938] [D loss: 0.698253] [G loss: 0.917035]\n",
            "[Epoch 1/200] [Batch 782/938] [D loss: 0.692552] [G loss: 0.916229]\n",
            "[Epoch 1/200] [Batch 783/938] [D loss: 0.697797] [G loss: 0.918894]\n",
            "[Epoch 1/200] [Batch 784/938] [D loss: 0.691618] [G loss: 0.915103]\n",
            "[Epoch 1/200] [Batch 785/938] [D loss: 0.692964] [G loss: 0.914779]\n",
            "[Epoch 1/200] [Batch 786/938] [D loss: 0.698234] [G loss: 0.916264]\n",
            "[Epoch 1/200] [Batch 787/938] [D loss: 0.695209] [G loss: 0.916947]\n",
            "[Epoch 1/200] [Batch 788/938] [D loss: 0.700277] [G loss: 0.915053]\n",
            "[Epoch 1/200] [Batch 789/938] [D loss: 0.698066] [G loss: 0.914629]\n",
            "[Epoch 1/200] [Batch 790/938] [D loss: 0.695819] [G loss: 0.911687]\n",
            "[Epoch 1/200] [Batch 791/938] [D loss: 0.689937] [G loss: 0.915220]\n",
            "[Epoch 1/200] [Batch 792/938] [D loss: 0.695893] [G loss: 0.917884]\n",
            "[Epoch 1/200] [Batch 793/938] [D loss: 0.696148] [G loss: 0.920192]\n",
            "[Epoch 1/200] [Batch 794/938] [D loss: 0.695121] [G loss: 0.916417]\n",
            "[Epoch 1/200] [Batch 795/938] [D loss: 0.695598] [G loss: 0.912178]\n",
            "[Epoch 1/200] [Batch 796/938] [D loss: 0.695314] [G loss: 0.918430]\n",
            "[Epoch 1/200] [Batch 797/938] [D loss: 0.696816] [G loss: 0.912718]\n",
            "[Epoch 1/200] [Batch 798/938] [D loss: 0.697529] [G loss: 0.916765]\n",
            "[Epoch 1/200] [Batch 799/938] [D loss: 0.700950] [G loss: 0.916370]\n",
            "[Epoch 1/200] [Batch 800/938] [D loss: 0.698455] [G loss: 0.915820]\n",
            "[Epoch 1/200] [Batch 801/938] [D loss: 0.693336] [G loss: 0.915252]\n",
            "[Epoch 1/200] [Batch 802/938] [D loss: 0.693306] [G loss: 0.913424]\n",
            "[Epoch 1/200] [Batch 803/938] [D loss: 0.697833] [G loss: 0.916463]\n",
            "[Epoch 1/200] [Batch 804/938] [D loss: 0.696585] [G loss: 0.914062]\n",
            "[Epoch 1/200] [Batch 805/938] [D loss: 0.694518] [G loss: 0.919203]\n",
            "[Epoch 1/200] [Batch 806/938] [D loss: 0.693392] [G loss: 0.914154]\n",
            "[Epoch 1/200] [Batch 807/938] [D loss: 0.691127] [G loss: 0.915871]\n",
            "[Epoch 1/200] [Batch 808/938] [D loss: 0.698435] [G loss: 0.909681]\n",
            "[Epoch 1/200] [Batch 809/938] [D loss: 0.696364] [G loss: 0.912791]\n",
            "[Epoch 1/200] [Batch 810/938] [D loss: 0.701715] [G loss: 0.916670]\n",
            "[Epoch 1/200] [Batch 811/938] [D loss: 0.695818] [G loss: 0.912015]\n",
            "[Epoch 1/200] [Batch 812/938] [D loss: 0.694130] [G loss: 0.911024]\n",
            "[Epoch 1/200] [Batch 813/938] [D loss: 0.693687] [G loss: 0.914505]\n",
            "[Epoch 1/200] [Batch 814/938] [D loss: 0.695853] [G loss: 0.917284]\n",
            "[Epoch 1/200] [Batch 815/938] [D loss: 0.694799] [G loss: 0.918221]\n",
            "[Epoch 1/200] [Batch 816/938] [D loss: 0.694606] [G loss: 0.919056]\n",
            "[Epoch 1/200] [Batch 817/938] [D loss: 0.700417] [G loss: 0.917098]\n",
            "[Epoch 1/200] [Batch 818/938] [D loss: 0.697786] [G loss: 0.914302]\n",
            "[Epoch 1/200] [Batch 819/938] [D loss: 0.700450] [G loss: 0.916958]\n",
            "[Epoch 1/200] [Batch 820/938] [D loss: 0.690220] [G loss: 0.918453]\n",
            "[Epoch 1/200] [Batch 821/938] [D loss: 0.693684] [G loss: 0.914657]\n",
            "[Epoch 1/200] [Batch 822/938] [D loss: 0.695288] [G loss: 0.918742]\n",
            "[Epoch 1/200] [Batch 823/938] [D loss: 0.693202] [G loss: 0.914925]\n",
            "[Epoch 1/200] [Batch 824/938] [D loss: 0.693689] [G loss: 0.914716]\n",
            "[Epoch 1/200] [Batch 825/938] [D loss: 0.690267] [G loss: 0.912791]\n",
            "[Epoch 1/200] [Batch 826/938] [D loss: 0.696317] [G loss: 0.915832]\n",
            "[Epoch 1/200] [Batch 827/938] [D loss: 0.697260] [G loss: 0.913705]\n",
            "[Epoch 1/200] [Batch 828/938] [D loss: 0.696468] [G loss: 0.915818]\n",
            "[Epoch 1/200] [Batch 829/938] [D loss: 0.691778] [G loss: 0.914189]\n",
            "[Epoch 1/200] [Batch 830/938] [D loss: 0.697393] [G loss: 0.915285]\n",
            "[Epoch 1/200] [Batch 831/938] [D loss: 0.692245] [G loss: 0.915514]\n",
            "[Epoch 1/200] [Batch 832/938] [D loss: 0.696423] [G loss: 0.913479]\n",
            "[Epoch 1/200] [Batch 833/938] [D loss: 0.698188] [G loss: 0.912461]\n",
            "[Epoch 1/200] [Batch 834/938] [D loss: 0.696265] [G loss: 0.912709]\n",
            "[Epoch 1/200] [Batch 835/938] [D loss: 0.696669] [G loss: 0.913098]\n",
            "[Epoch 1/200] [Batch 836/938] [D loss: 0.692881] [G loss: 0.918141]\n",
            "[Epoch 1/200] [Batch 837/938] [D loss: 0.699623] [G loss: 0.914251]\n",
            "[Epoch 1/200] [Batch 838/938] [D loss: 0.694369] [G loss: 0.913104]\n",
            "[Epoch 1/200] [Batch 839/938] [D loss: 0.693311] [G loss: 0.915950]\n",
            "[Epoch 1/200] [Batch 840/938] [D loss: 0.691645] [G loss: 0.912747]\n",
            "[Epoch 1/200] [Batch 841/938] [D loss: 0.696114] [G loss: 0.914866]\n",
            "[Epoch 1/200] [Batch 842/938] [D loss: 0.692985] [G loss: 0.918318]\n",
            "[Epoch 1/200] [Batch 843/938] [D loss: 0.700440] [G loss: 0.916048]\n",
            "[Epoch 1/200] [Batch 844/938] [D loss: 0.697724] [G loss: 0.914263]\n",
            "[Epoch 1/200] [Batch 845/938] [D loss: 0.696099] [G loss: 0.911585]\n",
            "[Epoch 1/200] [Batch 846/938] [D loss: 0.688105] [G loss: 0.918867]\n",
            "[Epoch 1/200] [Batch 847/938] [D loss: 0.698353] [G loss: 0.912647]\n",
            "[Epoch 1/200] [Batch 848/938] [D loss: 0.694737] [G loss: 0.917451]\n",
            "[Epoch 1/200] [Batch 849/938] [D loss: 0.695811] [G loss: 0.917943]\n",
            "[Epoch 1/200] [Batch 850/938] [D loss: 0.697711] [G loss: 0.915524]\n",
            "[Epoch 1/200] [Batch 851/938] [D loss: 0.696071] [G loss: 0.917887]\n",
            "[Epoch 1/200] [Batch 852/938] [D loss: 0.696200] [G loss: 0.919175]\n",
            "[Epoch 1/200] [Batch 853/938] [D loss: 0.689828] [G loss: 0.916408]\n",
            "[Epoch 1/200] [Batch 854/938] [D loss: 0.698532] [G loss: 0.915311]\n",
            "[Epoch 1/200] [Batch 855/938] [D loss: 0.691843] [G loss: 0.912405]\n",
            "[Epoch 1/200] [Batch 856/938] [D loss: 0.691895] [G loss: 0.916611]\n",
            "[Epoch 1/200] [Batch 857/938] [D loss: 0.695056] [G loss: 0.912484]\n",
            "[Epoch 1/200] [Batch 858/938] [D loss: 0.689602] [G loss: 0.916438]\n",
            "[Epoch 1/200] [Batch 859/938] [D loss: 0.695192] [G loss: 0.912644]\n",
            "[Epoch 1/200] [Batch 860/938] [D loss: 0.700230] [G loss: 0.914088]\n",
            "[Epoch 1/200] [Batch 861/938] [D loss: 0.696374] [G loss: 0.913879]\n",
            "[Epoch 1/200] [Batch 862/938] [D loss: 0.694000] [G loss: 0.913918]\n",
            "[Epoch 1/200] [Batch 863/938] [D loss: 0.689663] [G loss: 0.918769]\n",
            "[Epoch 1/200] [Batch 864/938] [D loss: 0.693010] [G loss: 0.912827]\n",
            "[Epoch 1/200] [Batch 865/938] [D loss: 0.696227] [G loss: 0.914525]\n",
            "[Epoch 1/200] [Batch 866/938] [D loss: 0.692663] [G loss: 0.915175]\n",
            "[Epoch 1/200] [Batch 867/938] [D loss: 0.688353] [G loss: 0.917321]\n",
            "[Epoch 1/200] [Batch 868/938] [D loss: 0.697332] [G loss: 0.918363]\n",
            "[Epoch 1/200] [Batch 869/938] [D loss: 0.690078] [G loss: 0.913472]\n",
            "[Epoch 1/200] [Batch 870/938] [D loss: 0.691058] [G loss: 0.917423]\n",
            "[Epoch 1/200] [Batch 871/938] [D loss: 0.694644] [G loss: 0.918436]\n",
            "[Epoch 1/200] [Batch 872/938] [D loss: 0.698193] [G loss: 0.913001]\n",
            "[Epoch 1/200] [Batch 873/938] [D loss: 0.697369] [G loss: 0.913761]\n",
            "[Epoch 1/200] [Batch 874/938] [D loss: 0.692311] [G loss: 0.908996]\n",
            "[Epoch 1/200] [Batch 875/938] [D loss: 0.701478] [G loss: 0.912975]\n",
            "[Epoch 1/200] [Batch 876/938] [D loss: 0.696921] [G loss: 0.914033]\n",
            "[Epoch 1/200] [Batch 877/938] [D loss: 0.693439] [G loss: 0.915047]\n",
            "[Epoch 1/200] [Batch 878/938] [D loss: 0.693807] [G loss: 0.914115]\n",
            "[Epoch 1/200] [Batch 879/938] [D loss: 0.697469] [G loss: 0.914865]\n",
            "[Epoch 1/200] [Batch 880/938] [D loss: 0.699301] [G loss: 0.916023]\n",
            "[Epoch 1/200] [Batch 881/938] [D loss: 0.703462] [G loss: 0.916186]\n",
            "[Epoch 1/200] [Batch 882/938] [D loss: 0.697633] [G loss: 0.916894]\n",
            "[Epoch 1/200] [Batch 883/938] [D loss: 0.697268] [G loss: 0.913614]\n",
            "[Epoch 1/200] [Batch 884/938] [D loss: 0.691105] [G loss: 0.914713]\n",
            "[Epoch 1/200] [Batch 885/938] [D loss: 0.696449] [G loss: 0.914670]\n",
            "[Epoch 1/200] [Batch 886/938] [D loss: 0.694645] [G loss: 0.918523]\n",
            "[Epoch 1/200] [Batch 887/938] [D loss: 0.692404] [G loss: 0.915499]\n",
            "[Epoch 1/200] [Batch 888/938] [D loss: 0.696016] [G loss: 0.915314]\n",
            "[Epoch 1/200] [Batch 889/938] [D loss: 0.699599] [G loss: 0.913408]\n",
            "[Epoch 1/200] [Batch 890/938] [D loss: 0.694703] [G loss: 0.918258]\n",
            "[Epoch 1/200] [Batch 891/938] [D loss: 0.701725] [G loss: 0.912568]\n",
            "[Epoch 1/200] [Batch 892/938] [D loss: 0.694289] [G loss: 0.913607]\n",
            "[Epoch 1/200] [Batch 893/938] [D loss: 0.698003] [G loss: 0.915061]\n",
            "[Epoch 1/200] [Batch 894/938] [D loss: 0.697785] [G loss: 0.912095]\n",
            "[Epoch 1/200] [Batch 895/938] [D loss: 0.692335] [G loss: 0.913774]\n",
            "[Epoch 1/200] [Batch 896/938] [D loss: 0.695613] [G loss: 0.920824]\n",
            "[Epoch 1/200] [Batch 897/938] [D loss: 0.705898] [G loss: 0.914510]\n",
            "[Epoch 1/200] [Batch 898/938] [D loss: 0.698455] [G loss: 0.917763]\n",
            "[Epoch 1/200] [Batch 899/938] [D loss: 0.699258] [G loss: 0.913799]\n",
            "[Epoch 1/200] [Batch 900/938] [D loss: 0.692707] [G loss: 0.918928]\n",
            "[Epoch 1/200] [Batch 901/938] [D loss: 0.696679] [G loss: 0.911771]\n",
            "[Epoch 1/200] [Batch 902/938] [D loss: 0.697387] [G loss: 0.916363]\n",
            "[Epoch 1/200] [Batch 903/938] [D loss: 0.691598] [G loss: 0.915280]\n",
            "[Epoch 1/200] [Batch 904/938] [D loss: 0.694153] [G loss: 0.913524]\n",
            "[Epoch 1/200] [Batch 905/938] [D loss: 0.694512] [G loss: 0.917968]\n",
            "[Epoch 1/200] [Batch 906/938] [D loss: 0.695201] [G loss: 0.915742]\n",
            "[Epoch 1/200] [Batch 907/938] [D loss: 0.697313] [G loss: 0.913419]\n",
            "[Epoch 1/200] [Batch 908/938] [D loss: 0.696743] [G loss: 0.916845]\n",
            "[Epoch 1/200] [Batch 909/938] [D loss: 0.696941] [G loss: 0.913338]\n",
            "[Epoch 1/200] [Batch 910/938] [D loss: 0.701927] [G loss: 0.914721]\n",
            "[Epoch 1/200] [Batch 911/938] [D loss: 0.688955] [G loss: 0.919585]\n",
            "[Epoch 1/200] [Batch 912/938] [D loss: 0.693588] [G loss: 0.918348]\n",
            "[Epoch 1/200] [Batch 913/938] [D loss: 0.693780] [G loss: 0.913724]\n",
            "[Epoch 1/200] [Batch 914/938] [D loss: 0.687872] [G loss: 0.914825]\n",
            "[Epoch 1/200] [Batch 915/938] [D loss: 0.700360] [G loss: 0.913754]\n",
            "[Epoch 1/200] [Batch 916/938] [D loss: 0.695509] [G loss: 0.911430]\n",
            "[Epoch 1/200] [Batch 917/938] [D loss: 0.694641] [G loss: 0.915416]\n",
            "[Epoch 1/200] [Batch 918/938] [D loss: 0.695537] [G loss: 0.917818]\n",
            "[Epoch 1/200] [Batch 919/938] [D loss: 0.698550] [G loss: 0.917814]\n",
            "[Epoch 1/200] [Batch 920/938] [D loss: 0.695273] [G loss: 0.913899]\n",
            "[Epoch 1/200] [Batch 921/938] [D loss: 0.700882] [G loss: 0.914103]\n",
            "[Epoch 1/200] [Batch 922/938] [D loss: 0.696871] [G loss: 0.916486]\n",
            "[Epoch 1/200] [Batch 923/938] [D loss: 0.694717] [G loss: 0.914235]\n",
            "[Epoch 1/200] [Batch 924/938] [D loss: 0.698578] [G loss: 0.915533]\n",
            "[Epoch 1/200] [Batch 925/938] [D loss: 0.700326] [G loss: 0.915902]\n",
            "[Epoch 1/200] [Batch 926/938] [D loss: 0.702225] [G loss: 0.912357]\n",
            "[Epoch 1/200] [Batch 927/938] [D loss: 0.691742] [G loss: 0.914377]\n",
            "[Epoch 1/200] [Batch 928/938] [D loss: 0.692827] [G loss: 0.912363]\n",
            "[Epoch 1/200] [Batch 929/938] [D loss: 0.687400] [G loss: 0.917289]\n",
            "[Epoch 1/200] [Batch 930/938] [D loss: 0.693998] [G loss: 0.915888]\n",
            "[Epoch 1/200] [Batch 931/938] [D loss: 0.692419] [G loss: 0.921104]\n",
            "[Epoch 1/200] [Batch 932/938] [D loss: 0.694702] [G loss: 0.914889]\n",
            "[Epoch 1/200] [Batch 933/938] [D loss: 0.695845] [G loss: 0.918181]\n",
            "[Epoch 1/200] [Batch 934/938] [D loss: 0.696575] [G loss: 0.915372]\n",
            "[Epoch 1/200] [Batch 935/938] [D loss: 0.691914] [G loss: 0.919041]\n",
            "[Epoch 1/200] [Batch 936/938] [D loss: 0.695772] [G loss: 0.915093]\n",
            "[Epoch 1/200] [Batch 937/938] [D loss: 0.697406] [G loss: 0.911314]\n",
            "[Epoch 2/200] [Batch 0/938] [D loss: 0.698710] [G loss: 0.913485]\n",
            "[Epoch 2/200] [Batch 1/938] [D loss: 0.690913] [G loss: 0.912045]\n",
            "[Epoch 2/200] [Batch 2/938] [D loss: 0.696080] [G loss: 0.913434]\n",
            "[Epoch 2/200] [Batch 3/938] [D loss: 0.696546] [G loss: 0.914855]\n",
            "[Epoch 2/200] [Batch 4/938] [D loss: 0.689603] [G loss: 0.913488]\n",
            "[Epoch 2/200] [Batch 5/938] [D loss: 0.699962] [G loss: 0.917254]\n",
            "[Epoch 2/200] [Batch 6/938] [D loss: 0.692863] [G loss: 0.914853]\n",
            "[Epoch 2/200] [Batch 7/938] [D loss: 0.690687] [G loss: 0.916277]\n",
            "[Epoch 2/200] [Batch 8/938] [D loss: 0.698537] [G loss: 0.918363]\n",
            "[Epoch 2/200] [Batch 9/938] [D loss: 0.695733] [G loss: 0.918794]\n",
            "[Epoch 2/200] [Batch 10/938] [D loss: 0.697272] [G loss: 0.915626]\n",
            "[Epoch 2/200] [Batch 11/938] [D loss: 0.699918] [G loss: 0.912096]\n",
            "[Epoch 2/200] [Batch 12/938] [D loss: 0.701205] [G loss: 0.917799]\n",
            "[Epoch 2/200] [Batch 13/938] [D loss: 0.688549] [G loss: 0.914544]\n",
            "[Epoch 2/200] [Batch 14/938] [D loss: 0.699368] [G loss: 0.913376]\n",
            "[Epoch 2/200] [Batch 15/938] [D loss: 0.701372] [G loss: 0.912278]\n",
            "[Epoch 2/200] [Batch 16/938] [D loss: 0.692223] [G loss: 0.914357]\n",
            "[Epoch 2/200] [Batch 17/938] [D loss: 0.701361] [G loss: 0.916570]\n",
            "[Epoch 2/200] [Batch 18/938] [D loss: 0.696297] [G loss: 0.914409]\n",
            "[Epoch 2/200] [Batch 19/938] [D loss: 0.693820] [G loss: 0.914446]\n",
            "[Epoch 2/200] [Batch 20/938] [D loss: 0.695955] [G loss: 0.910498]\n",
            "[Epoch 2/200] [Batch 21/938] [D loss: 0.695485] [G loss: 0.917619]\n",
            "[Epoch 2/200] [Batch 22/938] [D loss: 0.695073] [G loss: 0.913059]\n",
            "[Epoch 2/200] [Batch 23/938] [D loss: 0.691286] [G loss: 0.917479]\n",
            "[Epoch 2/200] [Batch 24/938] [D loss: 0.702998] [G loss: 0.918734]\n",
            "[Epoch 2/200] [Batch 25/938] [D loss: 0.694899] [G loss: 0.918367]\n",
            "[Epoch 2/200] [Batch 26/938] [D loss: 0.693154] [G loss: 0.916654]\n",
            "[Epoch 2/200] [Batch 27/938] [D loss: 0.698285] [G loss: 0.913941]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1iC9n0v6WA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}